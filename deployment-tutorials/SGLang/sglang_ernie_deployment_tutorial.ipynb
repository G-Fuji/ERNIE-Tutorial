{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "773ec6a8-593a-4ecc-aa3d-74e50fc174ae",
   "metadata": {},
   "source": [
    "# Tutorial on Deploying the ERNIE-4.5-0.3B Model with SGLang\n",
    "\n",
    "## Introduction to SGLang\n",
    "\n",
    "SGLang (Structured Generation Language) is a high-performance large language model serving framework jointly developed by UC Berkeley and Stanford. By collaboratively designing the backend runtime and frontend programming language, this framework achieves faster inference speed and more flexible control than traditional frameworks. SGLang has gained widespread recognition in both academia and industry, and is adopted by many well-known companies for production use.\n",
    "\n",
    "| Feature Category | Specific Functions | Technical Advantages |\n",
    "|---------|---------|----------|\n",
    "| **Backend Runtime Optimization** | RadixAttention Prefix Cache | Reduces duplicate computations by sharing prefixes, improving batch processing efficiency |\n",
    "| | Zero-Overhead CPU Scheduler | Eliminates scheduling delays and improves GPU utilization |\n",
    "| | Prefill-Decode Separation | Separates compute-intensive and memory-intensive operations to optimize resource utilization |\n",
    "| | Speculative Decoding | Generates multiple candidate tokens in parallel, accelerating the generation process |\n",
    "| | Continuous Batching | Dynamic batch management to improve throughput |\n",
    "| **Front-End Programming API** | Structured Generation | Supports structured output formats such as JSON and regular expressions |\n",
    "| | Chained Calls | Simplifies programming for complex conversations and multi-turn interactions |\n",
    "| | Parallel Execution | Native support for concurrent request processing |\n",
    "| **Model Support** | Generative Models | Mainstream models such as ERNIE, Qwen, and DeepSeek |\n",
    "| | Quantization Support | Quantization methods such as FP4/FP8/INT4/AWQ/GPTQ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7ae517-cb1e-4ff4-9254-86accb5c3abe",
   "metadata": {},
   "source": [
    "## ERNIE-4.5 Model Support\n",
    "\n",
    "SGLang natively supports the ERNIE-4.5 series of models, including:\n",
    "- **ERNIE-4.5-0.3B** - Lightweight, dense model\n",
    "- **ERNIE-4.5-21B-A3B** - MoE model\n",
    "- **ERNIE-4.5-300B-A47B** - Large MoE model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80766536-730e-4dd9-82b0-65edc6be4a69",
   "metadata": {},
   "source": [
    "## Environment Preparation\n",
    "\n",
    "### Installing SGLang\n",
    "```bash\n",
    "git clone -b v0.5.0rc2 https://github.com/sgl-project/sglang.git\n",
    "cd sglang\n",
    "\n",
    "pip install --upgrade pip\n",
    "pip install -e \"python[all]\"\n",
    "```bash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956bf0ee-be9b-40a5-9b2c-ebfec9cc3274",
   "metadata": {},
   "source": [
    "## Deployment Method Comparison\n",
    "\n",
    "| Deployment Method | Applicable Scenarios | Advantages | Disadvantages |\n",
    "|---------|---------|------|------|\n",
    "| **Command Line Server** | Production deployment, API service | High performance, good stability, concurrency support | Requires server management |\n",
    "| **Python Script** | Batch processing, automated tasks | High flexibility, easy integration | Requires programming knowledge |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40255f58-0485-4cc9-b27f-0d5601c5ea79",
   "metadata": {},
   "source": [
    "## Deploying the ERNIE-4.5-0.3B Model\n",
    "\n",
    "### 1. Environment Preparation and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaef307-30dc-4a3d-9c6c-1743986c74ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGLang Version: 0.5.0rc2\n",
      "PyTorch Version: 2.8.0+cu128\n",
      "CUDA Available: True\n",
      "GPU Device: NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "source": [
    "# Check Installation\n",
    "import sglang as sgl\n",
    "import torch\n",
    "print(f\"SGLang Version: {sgl.__version__}\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Device: {torch.cuda.get_device_name()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f70283-beaf-49b6-a2e2-2d7543cf63af",
   "metadata": {},
   "source": [
    "### 2. Launching the Local SGLang Server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea564b1-da3d-48f9-97ce-418c406bc5c0",
   "metadata": {},
   "source": [
    "We use `baidu/ERNIE-4.5-0.3B-PT` as an example to deploy the model on a local server.\n",
    "\n",
    "```bash\n",
    "python -m sglang.launch_server \\\n",
    "    --model-path baidu/ERNIE-4.5-0.3B-PT \\\n",
    "    --host 0.0.0.0 \\\n",
    "    --port 30000 \\\n",
    "    --trust-remote-code\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fba5224-c22a-4ff9-8d65-57d344ab318d",
   "metadata": {},
   "source": [
    "**Note**: \n",
    "- Use `--host 0.0.0.0` to allow access from Windows hosts\n",
    "- The first run will automatically download the model from HuggingFace, and configuring a mirror can significantly speed up the download process\n",
    "- After startup, you will see \"Launched server at http://0.0.0.0:30000\" in the console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a952e867-1bb8-4a28-9f1c-482404ecc949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“‹ Model Information:\n",
      "Model Path: baidu/ERNIE-4.5-0.3B-PT\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "model_info = requests.get(\"http://127.0.0.1:30000/get_model_info\")\n",
    "if model_info.status_code == 200:\n",
    "    info = model_info.json()\n",
    "    print(f\"\\nðŸ“‹ Model Information:\")\n",
    "    print(f\"Model Path: {info.get('model_path', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a31fde2-da58-49de-9fbd-344f9b03329a",
   "metadata": {},
   "source": [
    "### 3. Using OpenAI-Compatible API Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f2ae29cb-519a-47a7-b9b9-0e8e674addbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model response: Hello! I'm an AI assistant, and I'm happy to help you. Is there anything I can do for you? Like answering questions, solving problems, or just chatting about everyday things? ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# Configuring the Client\n",
    "client = openai.OpenAI(\n",
    "    base_url=\"http://localhost:30000/v1\",\n",
    "    api_key=\"EMPTY\"  # SGLang does not require an API key\n",
    ")\n",
    "\n",
    "# Sending a Chat Request\n",
    "response = client.chat.completions.create(\n",
    "    model=\"baidu/ERNIE-4.5-0.3B-PT\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Hello, please introduce yourself.\"}\n",
    "    ],\n",
    "    max_tokens=100,\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "print(f\"Model response: {response.choices[0].message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f65b7fb-451b-4cd6-96a2-37249789f140",
   "metadata": {},
   "source": [
    "### 4. ä½¿ç”¨SGLangåŽŸç”ŸAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "719f0dd7-b4a8-4699-8690-f3541292377a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model response: Welcome to Beijing! As China's capital, Beijing has many unique and bustling places. (Gestures) Here, you can visit famous attractions such as the Palace Museum, the Temple of Heaven, and Beihai Park. You can see historical sites while experiencing the ancient and modern charm of Beijing.\n"
     ]
    }
   ],
   "source": [
    "import sglang as sgl\n",
    "\n",
    "# Configuring the Backend\n",
    "sgl.set_default_backend(sgl.RuntimeEndpoint(\"http://localhost:30000\"))\n",
    "\n",
    "# Defining the Generation Function\n",
    "@sgl.function\n",
    "def chat_with_ernie(s, user_message):\n",
    "    s += sgl.user(user_message)\n",
    "    s += sgl.assistant(sgl.gen(\"response\", max_tokens=100))\n",
    "\n",
    "# Calling the Model\n",
    "state = chat_with_ernie.run(user_message=\"Please introduce Beijing to us!\")\n",
    "print(f\"Model response: {state['response']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c00718f-30cc-4387-845f-ad3e2a8c6017",
   "metadata": {},
   "source": [
    "## Summarize\n",
    "\n",
    "This tutorial demonstrates how to deploy and use the ERNIE series of models (using a 0.3B model as an example). As a next-generation LLM service framework, SGLang offers significant advantages in performance and ease of use. This tutorial will help you quickly get started with SGLang and leverage the power of ERNIE models in your own projects.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "| Learning Directions | Recommended Resources | Application Scenarios |\n",
    "|---------|---------|----------|\n",
    "| **Advanced Features** | [SGLang Official Documentation](https://docs.sglang.ai/) | Production Deployment and Performance Optimization |\n",
    "| **Model Fine-tuning** | ERNIE-Tutorial Training Tutorial | Customized Model Development |\n",
    "| **Structured Output** | SGLang Structured Document Generation | JSON Generation and Code Generation |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84770f77-e1d4-4f75-a2aa-7cbc9944e159",
   "metadata": {},
   "source": [
    "### Contact Us\n",
    "\n",
    "If you encounter any issues or have any suggestions, please contact us through the following channels:\n",
    "\n",
    "- **GitHub Issues**: Submit issues in the project repository\n",
    "- **WeChat**: G_Fuji\n",
    "- **Community Forum**: Participate in technical discussions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SGLang Environment",
   "language": "python",
   "name": "sglang"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
