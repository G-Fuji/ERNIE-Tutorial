{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "773ec6a8-593a-4ecc-aa3d-74e50fc174ae",
   "metadata": {},
   "source": [
    "# SGLang部署ERNIE-4.5-0.3B模型教程\n",
    "\n",
    "## SGLang简介\n",
    "\n",
    "SGLang（Structured Generation Language）是由UC Berkeley和Stanford联合开发的高性能大语言模型服务框架。该框架通过协同设计后端运行时和前端编程语言，实现了比传统框架更快的推理速度和更灵活的控制能力。SGLang在学术界和工业界都获得了广泛认可，被多家知名公司采用用于生产环境。\n",
    "\n",
    "| 特性类别 | 具体功能 | 技术优势 |\n",
    "|---------|---------|----------|\n",
    "| **后端运行时优化** | RadixAttention前缀缓存 | 通过共享前缀减少重复计算，提升批处理效率 |\n",
    "| | 零开销CPU调度器 | 消除调度延迟，提高GPU利用率 |\n",
    "| | 预填充-解码分离 | 分离计算密集和内存密集操作，优化资源利用 |\n",
    "| | 推测解码 | 并行生成多个候选token，加速生成过程 |\n",
    "| | 连续批处理 | 动态批处理管理，提高吞吐量 |\n",
    "| **前端编程接口** | 结构化生成 | 支持JSON、正则表达式等结构化输出 |\n",
    "| | 链式调用 | 简化复杂对话和多轮交互的编程 |\n",
    "| | 并行执行 | 原生支持并发请求处理 |\n",
    "| **模型支持** | 生成模型 | ERNIE、Qwen、DeepSeek等主流模型 |\n",
    "| | 量化支持 | FP4/FP8/INT4/AWQ/GPTQ等量化方法 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7ae517-cb1e-4ff4-9254-86accb5c3abe",
   "metadata": {},
   "source": [
    "## ERNIE-4.5模型支持\n",
    "\n",
    "SGLang原生支持ERNIE-4.5系列模型，包括：\n",
    "- **ERNIE-4.5-0.3B** - 轻量级密集模型\n",
    "- **ERNIE-4.5-21B-A3B** - MoE模型\n",
    "- **ERNIE-4.5-300B-A47B** - 大型MoE模型\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80766536-730e-4dd9-82b0-65edc6be4a69",
   "metadata": {},
   "source": [
    "## 环境准备\n",
    "\n",
    "### 安装SGLang\n",
    "\n",
    "```bash\n",
    "git clone -b v0.5.0rc2 https://github.com/sgl-project/sglang.git\n",
    "cd sglang\n",
    "\n",
    "pip install --upgrade pip\n",
    "pip install -e \"python[all]\"\n",
    "```bash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956bf0ee-be9b-40a5-9b2c-ebfec9cc3274",
   "metadata": {},
   "source": [
    "## 部署方式对比\n",
    "\n",
    "| 部署方式 | 适用场景 | 优势 | 劣势 |\n",
    "|---------|---------|------|------|\n",
    "| **命令行服务** | 生产部署、API服务 | 高性能、稳定性好、支持并发 | 需要服务器管理 |\n",
    "| **Python脚本** | 批量处理、自动化任务 | 灵活性高、易于集成 | 需要编程基础 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40255f58-0485-4cc9-b27f-0d5601c5ea79",
   "metadata": {},
   "source": [
    "## 部署ERNIE-4.5-0.3B模型\n",
    "\n",
    "### 1. 环境准备和安装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8eaef307-30dc-4a3d-9c6c-1743986c74ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGLang版本: 0.5.0rc2\n",
      "PyTorch版本: 2.8.0+cu128\n",
      "CUDA可用: True\n",
      "GPU设备: NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "source": [
    "# 验证安装\n",
    "import sglang as sgl\n",
    "import torch\n",
    "print(f\"SGLang版本: {sgl.__version__}\")\n",
    "print(f\"PyTorch版本: {torch.__version__}\")\n",
    "print(f\"CUDA可用: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU设备: {torch.cuda.get_device_name()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f70283-beaf-49b6-a2e2-2d7543cf63af",
   "metadata": {},
   "source": [
    "### 2. 启动本地SGLang服务"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea564b1-da3d-48f9-97ce-418c406bc5c0",
   "metadata": {},
   "source": [
    "我们以`baidu/ERNIE-4.5-0.3B-PT`为例，在终端启动进行部署\n",
    "\n",
    "```bash\n",
    "python -m sglang.launch_server \\\n",
    "    --model-path baidu/ERNIE-4.5-0.3B-PT \\\n",
    "    --host 0.0.0.0 \\\n",
    "    --port 30000 \\\n",
    "    --trust-remote-code\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fba5224-c22a-4ff9-8d65-57d344ab318d",
   "metadata": {},
   "source": [
    "**注意事项**：\n",
    "- 使用 `--host 0.0.0.0` 允许从Windows主机访问WSL中的服务\n",
    "- 首次运行会自动从HuggingFace下载模型，配置镜像后下载速度会显著提升\n",
    "- 服务启动后会显示类似 \"Launched server at http://0.0.0.0:30000\" 的信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a952e867-1bb8-4a28-9f1c-482404ecc949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 模型信息:\n",
      "模型路径: baidu/ERNIE-4.5-0.3B-PT\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "model_info = requests.get(\"http://127.0.0.1:30000/get_model_info\")\n",
    "if model_info.status_code == 200:\n",
    "    info = model_info.json()\n",
    "    print(f\"\\n📋 模型信息:\")\n",
    "    print(f\"模型路径: {info.get('model_path', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a31fde2-da58-49de-9fbd-344f9b03329a",
   "metadata": {},
   "source": [
    "### 3. 使用OpenAI兼容API调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f2ae29cb-519a-47a7-b9b9-0e8e674addbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型回复: 你好呀！我是AI助手，很高兴能为你提供帮助。有什么我可以帮你的吗？比如回答问题、解答问题，或者只是聊聊日常话题？😊\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# 配置客户端\n",
    "client = openai.OpenAI(\n",
    "    base_url=\"http://localhost:30000/v1\",\n",
    "    api_key=\"EMPTY\"  # SGLang不需要API密钥\n",
    ")\n",
    "\n",
    "# 发送聊天请求\n",
    "response = client.chat.completions.create(\n",
    "    model=\"baidu/ERNIE-4.5-0.3B-PT\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"你好，请介绍一下你自己\"}\n",
    "    ],\n",
    "    max_tokens=100,\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "print(f\"模型回复: {response.choices[0].message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f65b7fb-451b-4cd6-96a2-37249789f140",
   "metadata": {},
   "source": [
    "### 4. 使用SGLang原生API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "719f0dd7-b4a8-4699-8690-f3541292377a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERNIE回复:  欢迎来到北京！北京作为中国的首都，有许多独特而热闹的地方呢。（手势示意）在这里，您可以参观著名景点，如故宫博物院、天坛公园、北海公园等，既能看到历史遗迹，又能感受北京的古韵今风。\n"
     ]
    }
   ],
   "source": [
    "import sglang as sgl\n",
    "\n",
    "# 设置后端\n",
    "sgl.set_default_backend(sgl.RuntimeEndpoint(\"http://localhost:30000\"))\n",
    "\n",
    "# 定义生成函数\n",
    "@sgl.function\n",
    "def chat_with_ernie(s, user_message):\n",
    "    s += sgl.user(user_message)\n",
    "    s += sgl.assistant(sgl.gen(\"response\", max_tokens=100))\n",
    "\n",
    "# 调用模型\n",
    "state = chat_with_ernie.run(user_message=\"介绍下北京！\")\n",
    "print(f\"ERNIE回复: {state['response']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c00718f-30cc-4387-845f-ad3e2a8c6017",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "本教程展示了如何部署和使用ERNIE系列模型（以0.3B为例）。SGLang作为新一代LLM服务框架，在性能和易用性方面都有显著优势。通过本教程，您可以快速上手SGLang，并在自己的项目中应用ERNIE模型的强大能力。\n",
    "\n",
    "### 下一步建议\n",
    "\n",
    "| 学习方向 | 推荐资源 | 应用场景 |\n",
    "|---------|---------|----------|\n",
    "| **高级功能** | [SGLang官方文档](https://docs.sglang.ai/) | 生产环境部署、性能优化 |\n",
    "| **模型微调** | ERNIE-Tutorial训练教程 | 定制化模型开发 |\n",
    "| **结构化输出** | SGLang结构化生成文档 | JSON生成、代码生成 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84770f77-e1d4-4f75-a2aa-7cbc9944e159",
   "metadata": {},
   "source": [
    "### 联系我们\n",
    "\n",
    "如果您在使用过程中遇到问题或有任何建议，欢迎通过以下方式联系：\n",
    "\n",
    "- **GitHub Issues**：在项目仓库中提交问题\n",
    "- **微信**：G_Fuji\n",
    "- **社区论坛**：参与相关技术讨论"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SGLang Environment",
   "language": "python",
   "name": "sglang"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
