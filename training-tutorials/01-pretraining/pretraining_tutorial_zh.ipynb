{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于 ERNIE 4.5-0.3B 的大语言模型预训练教程\n",
    "\n",
    "## 1. 引言\n",
    "\n",
    "欢迎来到这篇关于使用 `ERNIEKit` 对 `ERNIE 4.5-0.3B` 模型进行预训练的教程！在当前的AI浪潮中，大语言模型 (Large Language Models, LLMs) 无疑是最耀眼的明星之一。百度文心（ERNIE）系列模型作为国内领先的大模型，以其卓越的性能和持续的技术创新而备受瞩目。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 什么是大语言模型预训练 (PT)？\n",
    "\n",
    "想象一下我们是如何学习语言的。在正式学习语法规则和词汇含义之前，我们会先大量接触和模仿周围人的说话方式。大语言模型的预训练 (Pre-training, PT) 与此类似。\n",
    "\n",
    "简单来说，**预训练是指在大规模无标签文本数据上训练模型，让模型学习语言的内在规律、语法结构、语义信息以及世界知识的过程。** 这个阶段的模型并不针对某一个特定任务（如下游的问答、翻译），而是致力于构建一个通用的语言理解和生成能力的基础。这就像是为模型打下一个坚实的语言基础，使其后续能更好地适应各种具体的NLP任务。\n",
    "\n",
    "预训练的核心任务通常是\"预测下一个词\" (Next Token Prediction)。给定一段文本，模型需要预测接下来最可能出现的词是什么。通过在海量文本上不断进行这样的预测练习，模型逐渐学会了词语之间的搭配关系、句法结构，甚至一些常识和逻辑。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 为什么选择 ERNIE 4.5-0.3B 和 ERNIEKit？\n",
    "\n",
    "在深入实践之前，让我们先花些时间，将 `ERNIE 4.5` 模型和 `ERNIEKit` 工具套件放置在当前主流的开源生态中进行一个横向对比。这能帮助我们更好地理解它们各自的特点和优势。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 ERNIE 4.5 模型家族概览\n",
    "\n",
    "`ERNIE 4.5` 并不仅仅指一个模型，而是百度推出的一个覆盖从轻量级到千亿级参数的、包含多种规格的庞大模型家族。为了更好地理解我们即将使用的 `0.3B` 模型的定位，让我们先看一下 `ERNIE 4.5` 家族的全貌：\n",
    "\n",
    "| 模型类别 | 模型名称 (部分) | 参数规模 (总参数/激活参数) | 主要特点 | 适用场景 |\n",
    "| :--- | :--- | :--- | :--- | :--- |\n",
    "| MoE 大语言模型 | `ERNIE-4.5-300B-A47B` | ~300B / 47B | 旗舰级纯语言模型，性能顶尖 | 要求极致性能的复杂任务 |\n",
    "| MoE 大语言模型 | `ERNIE-4.5-21B-A3B` | ~21B / 3B | 高性能、高性价比的 MoE 模型 | 需要强大能力但资源受限的场景 |\n",
    "| 多模态大模型 | `ERNIE-4.5-VL-424B-A47B`| ~424B / 47B | 支持文本、图像、视频输入 | 复杂的图文视频理解与生成 |\n",
    "| **稠密语言模型** | **`ERNIE-4.5-0.3B`** | **3亿 (0.3B)** | **轻量级、资源友好、架构标准** | **学习、实验、快速验证、低资源部署** |\n",
    "\n",
    "*注：MoE (Mixture-of-Experts) 是一种先进的模型架构，它拥有巨大的总参数量，但在处理每个输入时只激活一部分参数，从而实现高效推理。稠密模型 (Dense Model) 则会在每次计算时动用所有参数。*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 为什么以 ERNIE 4.5-0.3B 为例？\n",
    "\n",
    "通过上表，我们可以清晰地看到 `ERNIE 4.5-0.3B` 在家族中的独特定位。在本教程中，我们选择它作为主角，主要基于以下几点考量：\n",
    "\n",
    "1.  **为学习和实验而生**：与动辄需要大型集群才能训练的 MoE 巨型模型不同，`0.3B`（3亿）的参数量是专为开发者学习、研究和快速实验设计的。它的资源消耗“亲民”，让我们能在个人电脑或单台服务器上完成从预训练到微调的全过程。\n",
    "2.  **极佳的资源友好性**：我们可以在单张消费级显卡（如 RTX 3090/4090, 24GB 显存）上运行本教程的完整流程。这极大地降低了学习大模型技术的硬件门槛。\n",
    "3.  **标准架构的代表性**：作为一个标准的稠密（Dense）Transformer 模型，`ERNIE 4.5-0.3B` 的内部结构更易于理解，没有 MoE 等复杂组件。吃透了它的训练过程，就掌握了绝大多数标准大模型的核心原理，为将来理解更复杂的模型打下坚实基础。\n",
    "4.  **官方工具链的完整支持**：`ERNIEKit` 为包括 `0.3B` 在内的全系列模型提供了一致的、工业级的工具链支持。用它来学习 `0.3B` 模型，就相当于在“专业级的驾校”里“开教练车”，能平滑地将所学技能迁移到未来操作更大、更复杂的模型上。\n",
    "\n",
    "因此，`ERNIE 4.5-0.3B` 是我们进入文心大模型世界的理想“第一站”。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.3 主流开发工具套件对比\n",
    "\n",
    "有了好的模型，还需要称手的工具。大模型的开发工具套件负责处理数据、驱动训练、执行推理等一系列复杂流程。\n",
    "\n",
    "| 特性 | **ERNIEKit** | **Hugging Face (transformers+trl)** | **LLaMA-Factory** |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **开发者/社区** | 百度 (Baidu) | Hugging Face Community | hiyouga (Community) |\n",
    "| **核心框架** | PaddlePaddle | PyTorch, TensorFlow, JAX | PyTorch |\n",
    "| **主要功能** | 全生命周期：预训练、SFT、DPO、LoRA、量化(QAT)、部署 | 核心组件库，支持几乎所有模型和训练方法，需编写较多代码 | 一站式微调框架，配置驱动，支持多种高效微调算法 |\n",
    "| **易用性** | 工业级，命令行+配置文件，提供WebUI，学习曲线中等 | 非常灵活，但需要较强的编码能力，学习曲线较陡 | 对新手极其友好，提供WebUI，配置简单，学习曲线平缓 |\n",
    "| **模型支持** | 专注于 ERNIE 系列模型，提供深度优化 | 支持最广泛的开源模型（Model Hub） | 支持主流的 LLaMA, Qwen, ChatGLM 等多种模型 |\n",
    "| **适用场景** | ERNIE 模型深度开发、工业级应用、PaddlePaddle 技术栈 | 通用模型研究、算法实验、需要高度定制化的任务 | 快速上手、个人开发者、教学、高效微调实验 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.4 为什么选择 ERNIEKit？\n",
    "\n",
    "正如其名，`ERNIEKit` 是为 ERNIE 模型家族量身打造的官方工具套件。选择它，意味着：\n",
    "\n",
    "*   **最佳适配与性能**：ERNIEKit 对 ERNIE 系列模型的支持是原生和最深入的。它提供了针对性的优化，能够最大化地发挥模型在飞桨（PaddlePaddle）框架上的训练和推理性能。\n",
    "*   **工业级完整流程**：它不仅仅是一个微调工具，而是覆盖了从数据处理、预训练、监督微调（SFT）、偏好对齐（DPO）、参数高效调整（LoRA）到量化感知训练（QAT）和部署的全链路能力。学习 ERNIEKit 有助于理解大模型工业化落地的完整图景。\n",
    "*   **官方维护与支持**：作为官方工具，其迭代更新会与 ERNIE 模型的最新进展保持同步，能获得最及时、最权威的技术支持。\n",
    "\n",
    "通过本教程，我们将以 `ERNIE 4.5-0.3B` 为例，使用 `ERNIEKit` 中提供的底层预训练脚本，探索预训练的奥秘。这套组合拳（**官方模型 + 官方工具**）是深入学习百度文心大模型技术体系的最佳路径。即使我们使用的是一个相对较小的模型和数据集，其核心原理和流程对于理解更大模型的预训练也是相通的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 本教程的目标读者和学习成果\n",
    "\n",
    "本教程主要面向：\n",
    "\n",
    "*   对大语言模型预训练感兴趣的初学者。\n",
    "*   希望了解如何在 ERNIEKit (PaddlePaddle) 框架下进行模型预训练的开发者。\n",
    "*   有一定 Python 和深度学习基础，并希望动手实践 LLM 的学习者。\n",
    "\n",
    "通过本教程，您将能够：\n",
    "\n",
    "*   理解大语言模型预训练的基本概念和意义。\n",
    "*   掌握使用 ERNIEKit 进行 ERNIE 4.5 模型预训练的完整流程。\n",
    "*   了解预训练数据的准备方法。\n",
    "*   学会如何配置 `yaml` 文件并启动预训练任务。\n",
    "*   对预训练结果有一个初步的分析。\n",
    "*   为后续进行模型微调 (Fine-tuning) 和特定任务应用打下基础。\n",
    "\n",
    "让我们开始这段激动人心的学习之旅吧！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 环境准备\n",
    "\n",
    "在开始我们的预训练之旅之前，我们需要确保拥有正确的开发环境。这主要包括安装核心的深度学习框架 PaddlePaddle 和 ERNIEKit 工具库。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 安装 PaddlePaddle 和 ERNIEKit\n",
    "\n",
    "ERNIEKit 对环境有一定要求，**强烈建议使用官方推荐的 Docker 镜像**，以避免环境不一致带来的问题。如果无法使用 Docker，请确保您的本地环境满足[官方文档的先决条件](https://github.com/PaddlePaddle/ERNIE/blob/develop/docs/erniekit.md#21-prerequisites) (如 CUDA >= 12.3, Python 3.10+ 等)。\n",
    "\n",
    "**1. 克隆 ERNIE-develop 仓库**\n",
    "\n",
    "ERNIEKit 的代码和所有脚本都包含在 `ERNIE-develop` 仓库中。首先，我们需要将其克隆到本地。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:20:06.135474Z",
     "iopub.status.busy": "2025-07-17T10:20:06.135162Z",
     "iopub.status.idle": "2025-07-17T10:20:06.139232Z",
     "shell.execute_reply": "2025-07-17T10:20:06.138750Z",
     "shell.execute_reply.started": "2025-07-17T10:20:06.135453Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/ERNIE-develop\r\n"
     ]
    }
   ],
   "source": [
    "# git clone https://github.com/PaddlePaddle/ERNIE.git\n",
    "%cd ERNIE-develop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. 安装依赖**\n",
    "\n",
    "ERNIEKit 所需的依赖项都列在 `requirements/gpu/requirements.txt` 文件中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python -m pip install -r requirements/gpu/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**验证安装**：\n",
    "\n",
    "安装完成后，您可以运行以下代码来验证 PaddlePaddle 是否成功安装并能正确识别您的 GPU。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T02:30:28.775301Z",
     "iopub.status.busy": "2025-07-17T02:30:28.774920Z",
     "iopub.status.idle": "2025-07-17T02:30:30.527612Z",
     "shell.execute_reply": "2025-07-17T02:30:30.526670Z",
     "shell.execute_reply.started": "2025-07-17T02:30:28.775277Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/utils/cpp_extension/extension_utils.py:715: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\r\n",
      "  warnings.warn(warning_message)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running verify PaddlePaddle program ... \r\n",
      "PaddlePaddle works well on 1 GPU.\r\n",
      "PaddlePaddle is installed successfully! Let's start deep learning with PaddlePaddle now.\r\n",
      "PaddlePaddle GPU is available!\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0717 10:30:30.392132   294 pir_interpreter.cc:1524] New Executor is Running ...\r\n",
      "W0717 10:30:30.393514   294 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.8, Runtime API Version: 12.6\r\n",
      "I0717 10:30:30.394114   294 pir_interpreter.cc:1547] pir interpreter is running by multi-thread mode ...\r\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "\n",
    "# 检查GPU是否可用\n",
    "try:\n",
    "    paddle.utils.run_check()\n",
    "    print(\"PaddlePaddle GPU is available!\")\n",
    "except Exception as e:\n",
    "    print(f\"PaddlePaddle GPU check failed: {e}\")\n",
    "    print(\"If you intended to use GPU, please check your CUDA setup and PaddlePaddle installation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "至此，我们的环境准备工作就完成了！接下来，我们将一起准备用于预训练的数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 数据准备\n",
    "\n",
    "大语言模型之所以\"大\"，不仅仅在于其参数量，更在于其训练所依赖的海量数据。预训练阶段的数据是模型学习语言知识的源泉。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 预训练数据格式 (.bin / .idx)\n",
    "\n",
    "为了高效地加载和处理大规模文本数据，`ERNIEKit` 和 `PaddleNLP` 采用了标准的二进制 `mmap` (memory-mapped file) 格式。\n",
    "\n",
    "*   **.bin 文件**：这是一个二进制文件，它存储了所有文本数据经过 Tokenizer（分词器）处理后转换得到的 Token ID 序列。简单来说，就是把所有的文字都变成了数字。\n",
    "*   **.idx 文件**：这是一个索引文件，它记录了 `.bin` 文件中每条训练样本（通常是一篇文章或一个文档）的起始位置和长度。这样，在训练时可以快速定位到任意一条数据。\n",
    "\n",
    "这种格式的数据组织方式有以下优点：\n",
    "\n",
    "*   **高效读取**：可以直接在内存中映射文件内容，避免了大量的磁盘I/O操作。\n",
    "*   **节省内存**：不需要一次性将所有数据都加载到内存中，可以按需读取。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 获取预训练数据\n",
    "\n",
    "为了方便用户快速开始，PaddleNLP 官方提供了一个处理好的 OpenWebTextCorpus 数据集子集，包含约10万篇文章。我们将使用这个数据集作为本教程的示例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T02:31:26.758876Z",
     "iopub.status.busy": "2025-07-17T02:31:26.758503Z",
     "iopub.status.idle": "2025-07-17T02:31:26.974419Z",
     "shell.execute_reply": "2025-07-17T02:31:26.973689Z",
     "shell.execute_reply.started": "2025-07-17T02:31:26.758856Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 在 ERNIE-develop 目录下创建 data 文件夹\n",
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T02:32:02.156163Z",
     "iopub.status.busy": "2025-07-17T02:32:02.155771Z",
     "iopub.status.idle": "2025-07-17T02:32:04.602744Z",
     "shell.execute_reply": "2025-07-17T02:32:04.602043Z",
     "shell.execute_reply.started": "2025-07-17T02:32:02.156140Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-07-17 10:32:02--  https://bj.bcebos.com/paddlenlp/models/transformers/llama/data/llama_openwebtext_100k.bin\r\n",
      "Resolving bj.bcebos.com (bj.bcebos.com)... 100.67.184.196, 100.64.80.160, 100.67.184.48\r\n",
      "Connecting to bj.bcebos.com (bj.bcebos.com)|100.67.184.196|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 246736546 (235M) [application/octet-stream]\r\n",
      "Saving to: './data/llama_openwebtext_100k.bin'\r\n",
      "\r\n",
      "llama_openwebtext_1 100%[===================>] 235.31M   123MB/s    in 1.9s    \r\n",
      "\r\n",
      "2025-07-17 10:32:04 (123 MB/s) - './data/llama_openwebtext_100k.bin' saved [246736546/246736546]\r\n",
      "\r\n",
      "--2025-07-17 10:32:04--  https://bj.bcebos.com/paddlenlp/models/transformers/llama/data/llama_openwebtext_100k.idx\r\n",
      "Resolving bj.bcebos.com (bj.bcebos.com)... 100.67.184.48, 100.64.80.160, 100.67.184.196\r\n",
      "Connecting to bj.bcebos.com (bj.bcebos.com)|100.67.184.48|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 2000042 (1.9M) [application/octet-stream]\r\n",
      "Saving to: './data/llama_openwebtext_100k.idx'\r\n",
      "\r\n",
      "llama_openwebtext_1 100%[===================>]   1.91M  --.-KB/s    in 0.02s   \r\n",
      "\r\n",
      "2025-07-17 10:32:04 (126 MB/s) - './data/llama_openwebtext_100k.idx' saved [2000042/2000042]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# 下载数据文件\n",
    "!wget https://bj.bcebos.com/paddlenlp/models/transformers/llama/data/llama_openwebtext_100k.bin -P ./data/\n",
    "!wget https://bj.bcebos.com/paddlenlp/models/transformers/llama/data/llama_openwebtext_100k.idx -P ./data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下载完成后，您的 `./data/` 目录下应该会有两个文件：\n",
    "*   `llama_openwebtext_100k.bin`\n",
    "*   `llama_openwebtext_100k.idx`\n",
    "\n",
    "**重要提示：** 这些数据文件虽然最初是为 LLaMA 模型准备的，但其 `mmap` 格式是通用的，同样适用于 ERNIE 等模型的预训练。在实际训练时，我们会使用 ERNIE 4.5 的 Tokenizer 来处理这些文本数据转换成的 token ID。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 (可选) 使用自定义数据\n",
    "\n",
    "如果您想使用自己的文本数据，需要将其转换为 `.bin` 和 `.idx` 格式。`PaddleNLP` 仓库（注意不是 ERNIE-develop 仓库）中提供了数据预处理脚本 `llm/tools/preprocess_data.py`。\n",
    "\n",
    "大致流程如下：\n",
    "1.  **收集** 您的原始文本数据（如 `.txt` 或 `.jsonl` 文件）。\n",
    "2.  **运行脚本**：使用 `preprocess_data.py` 脚本，指定模型对应的 `tokenizer_name_or_path`（例如，应使用 `PaddlePaddle/ERNIE-4.5-0.3B-Paddle` 的 tokenizer），将您的文本文件转换为 `.bin` 和 `.idx` 文件。\n",
    "    ```bash\n",
    "    # 示例命令 (需在 PaddleNLP 仓库下运行，并安装其依赖)\n",
    "    # python llm/tools/preprocess_data.py \\\n",
    "    #     --model_name_or_path PaddlePaddle/ERNIE-4.5-0.3B-Paddle \\\n",
    "    #     --input_path /path/to/your/text_files.list \\\n",
    "    #     --output_prefix /path/to/your/output/my_data\n",
    "    ```\n",
    "详细用法请参考 PaddleNLP 仓库中的相关文档。对于本教程，我们直接使用已下载好的数据。\n",
    "\n",
    "现在数据已经准备好了，下一步我们将简要介绍一下大模型预训练的基本原理。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 模型预训练原理简介\n",
    "\n",
    "在我们动手运行代码之前，花一些时间了解预训练背后的基本原理是非常有益的。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 核心思想：Next Token Prediction (下一个词元预测)\n",
    "\n",
    "大语言模型预训练最核心、最经典的任务就是 **Next Token Prediction**，也叫做 Causal Language Modeling (CLM，因果语言建模)。\n",
    "\n",
    "**简单来说，就是给定一段文本序列，模型的目标是预测这个序列中的下一个词元 (Token) 是什么。**\n",
    "\n",
    "**举个例子：**\n",
    "\n",
    "假设我们有这样一句话：\"今天天气真不错，我们一起去公园\"\n",
    "\n",
    "1.  当模型看到：`[\"今天\"]` -> 它需要预测：`\"天气\"`\n",
    "2.  当模型看到：`[\"今天\", \"天气\"]` -> 它需要预测：`\"真\"`\n",
    "3.  当模型看到：`[\"今天\", \"天气\", \"真\"]` -> 它需要预测：`\"不错\"`\n",
    "\n",
    "模型会接触海量的文本数据，在这些数据上不断地进行这种\"猜词游戏\"。通过比较自己的预测和真实文本中的下一个词，模型会计算出一个\"错误程度\"（即损失 Loss），然后根据这个错误来调整内部的参数（权重），力求下次猜得更准。\n",
    "\n",
    "这个过程虽然简单，但当数据量足够大、模型参数足够多时，模型为了降低预测错误，就必须学会：\n",
    "\n",
    "*   **词汇知识**：哪些词经常一起出现。\n",
    "*   **语法结构**：主谓宾、时态等。\n",
    "*   **语义连贯性**：上下文应该如何衔接。\n",
    "*   **常识知识**：例如，\"天空是蓝色的\"。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 模型架构：Transformer\n",
    "\n",
    "目前几乎所有主流的大语言模型，包括 ERNIE 4.5，都基于 **Transformer** 架构。对于 Next Token Prediction 任务，通常使用的是 Transformer 的 **Decoder-Only** (仅解码器) 架构。\n",
    "\n",
    "其核心组件包括：\n",
    "1.  **Embedding Layer (嵌入层)** ：将输入的 Token ID 转换为能捕捉语义的向量。\n",
    "2.  **Positional Encoding (位置编码)** ：为模型注入 Token 在序列中的位置信息。\n",
    "3.  **Multi-Head Self-Attention (多头自注意力机制)** ：Transformer 的核心，允许模型在处理一个 Token 时，动态地关注序列中所有其他 Token 的信息。\n",
    "4.  **Feed-Forward Network (前馈神经网络)** ：进行进一步的非线性变换，增强模型的表达能力。\n",
    "5.  **Layer Normalization 和 Residual Connections** ：稳定训练过程，使训练更深的网络成为可能。\n",
    "\n",
    "通过堆叠多个这样的 Transformer Block (例如 ERNIE 4.5-0.3B 有32层)，模型就能够学习到非常复杂的语言模式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 损失函数：Cross-Entropy (交叉熵)\n",
    "\n",
    "在模型预测出下一个词元的概率分布后，我们使用**交叉熵损失 (Cross-Entropy Loss)** 来衡量预测的好坏。它会比较**模型预测的概率分布**和**真实的下一个词元**之间的\"差异\"。训练的目标就是通过不断调整模型的参数，使得在整个训练数据集上的总交叉熵损失最小化。\n",
    "\n",
    "了解了这些基本原理后，我们就可以更有信心地开始实际操作了！\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 开始预训练\n",
    "\n",
    "理论知识武装完毕，数据也准备就绪，现在是时候动手实践，启动我们的第一个 ERNIE 4.5 预训练任务了！\n",
    "\n",
    "**重要前提：**\n",
    "1.  请确保您已按照 **\"2. 环境准备\"** 部分的说明，安装了所有依赖。\n",
    "2.  请确保您已按照 **\"3. 数据准备\"** 部分的说明，下载了数据文件并放置在 `./data/` 目录下。\n",
    "3.  **工作目录**：后续的所有命令，都假设您当前的终端工作目录是 `ERNIE-develop`。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 预训练脚本和配置文件\n",
    "\n",
    "我们知道 `ERNIEKit` 中执行预训练的核心脚本是 `./examples/pre-training/ernie/pretrain`。我们需要通过一个 `yaml` 配置文件来告诉这个脚本使用哪个模型、用什么数据、以及如何进行训练。\n",
    "\n",
    "原始仓库中的 `pretrain_96_gpus.yaml` 是为千亿级 MoE 模型在大型集群上设计的，无法直接使用。我们需要创建一个简化版的配置文件，专门用于在单张 GPU 上训练 `ERNIE 4.5-0.3B` 模型。\n",
    "\n",
    "**创建配置文件 `pretrain_ernie_0.3b_demo.yaml`**\n",
    "\n",
    "请在 `ERNIE-develop` 目录下创建一个新的 `yaml` 文件，命名为 `pretrain_ernie_0.3b_demo.yaml`，并将以下内容复制进去："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "# 适用于 ERNIE 4.5-0.3B 单卡预训练的示例配置文件\n",
    "\n",
    "# ---------------------------model args-------------------------------------------------#\n",
    "model_args:\n",
    "    model_name_or_path: \"../../../data/models/30654/ERNIE-4.5-0.3B-Base-Paddle\" # 指定模型名称，ERNIEKit会尝试从AI Studio或HuggingFace下载\n",
    "    tokenizer_name: \"../../../data/models/30654/ERNIE-4.5-0.3B-Base-Paddle\" # 指定分词器\n",
    "    output_dir: ./output_pretrain/ # 训练过程中模型权重、日志等的输出目录\n",
    "    max_seq_length: 1024 # 模型处理的最大序列长度，可根据显存调整\n",
    "\n",
    "# ---------------------------trainer args-------------------------------------------------#\n",
    "trainer_args:\n",
    "    input_dir: \"1.0 ../../data/llama_openwebtext_100k 1.0 ../../data/llama_openwebtext_100k\" # 训练和验证数据集的权重及路径\n",
    "    split: \"998,1,1\" # 训练、验证、测试集划分比例\n",
    "\n",
    "    do_train: True\n",
    "    dataloader_num_workers: 0 # Windows下建议设为0，Linux可适当调大\n",
    "    disable_tqdm: True\n",
    "    logging_steps: 10 # 每隔10步打印一次日志\n",
    "    eval_steps: 100 # 每隔100步进行一次评估\n",
    "    save_steps: 200 # 每隔200步保存一次模型权重 (checkpoint)\n",
    "    max_steps: 400 # 最大训练步数，用于快速演示\n",
    "    \n",
    "    # --- 学习率与优化器 ---\n",
    "    adam_beta1: 0.9\n",
    "    adam_beta2: 0.95\n",
    "    adam_epsilon: 1e-8\n",
    "    learning_rate: 1e-4\n",
    "    min_lr: 1e-5\n",
    "    lr_scheduler: \"wsd_cosine\" # 使用带预热的余弦退火学习率策略\n",
    "    max_grad_norm: 1.0\n",
    "    weight_decay: 0.1\n",
    "    warmup_steps: 50 # 学习率预热步数\n",
    "    \n",
    "    # --- 批大小与显存 ---\n",
    "    gradient_accumulation_steps: 8 # 梯度累积步数\n",
    "    per_device_train_batch_size: 1 # 每张卡的批大小，实际 batch_size = per_device_train_batch_size * gradient_accumulation_steps\n",
    "    per_device_eval_batch_size: 2\n",
    "    head_dim: 128 # 注意力头的维度大小，需要与预训练模型保持一致\n",
    "    \n",
    "    # --- 性能与精度 ---\n",
    "    bf16: False # 是否启用 BF16，如果GPU不支持（如30/40系），请设为False\n",
    "    fp16: True  # 是否启用 FP16 (混合精度) 训练，对30/40系GPU友好\n",
    "    fp16_opt_level: \"O1\" # FP16 优化级别，O1 较稳定\n",
    "    \n",
    "    # --- 分布式参数 (单卡训练设为1或默认) ---\n",
    "    moe_group: \"dummy\" # 对于非MoE模型，设置为dummy以禁用MoE相关逻辑\n",
    "    pipeline_parallel_degree: 1\n",
    "    tensor_parallel_degree: 1\n",
    "    sharding: \"\" # 单卡训练不使用sharding\n",
    "    \n",
    "    # --- 其他 ---\n",
    "    seed: 42\n",
    "    save_total_limit: 2 # 最多保存多少个checkpoint\n",
    "    overwrite_output_dir: true # 覆盖输出目录\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**关键参数解释**：\n",
    "*   `model_name_or_path`: 指定了我们要训练的模型。ERNIEKit 会自动处理下载。\n",
    "*   `output_dir`: 所有训练产物（模型权重、日志）的保存位置。\n",
    "*   `input_dir`: 指向我们下载的 `.bin` 和 `.idx` 数据文件。**注意**：这里不需要文件后缀，只需要路径。\n",
    "*   `max_seq_length`: 模型能处理的文本最大长度。此值越大，显存占用越高。1024 对大部分24GB显存的显卡来说是安全的。\n",
    "*   `max_steps`, `save_steps`, `logging_steps`: 控制训练的总步数、保存频率和日志打印频率。我们设置为较小的值以便快速看到结果。\n",
    "*   `per_device_train_batch_size` & `gradient_accumulation_steps`: 这是控制**有效批大小 (Effective Batch Size)** 和**显存占用**的关键。`per_device_train_batch_size` 是单次前向传播的样本数，直接影响显存。通过累积 `gradient_accumulation_steps` 次梯度再更新一次模型，我们可以在不增加显存的情况下，达到 `1 * 8 = 8` 的有效批大小。\n",
    "*   `fp16: True`: 启用混合精度训练，可以显著减少显存占用并加速训练，对于消费级显卡至关重要。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 下载模型\n",
    "\n",
    "在开始训练之前，我们需要先将 `ERNIE-4.5-0.3B-Paddle` 模型文件下载到本地。您可以使用 `aistudio-sdk` (推荐) 或 `huggingface-cli`。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**首先安装 aistudio-sdk:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade aistudio-sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**然后下载模型:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!aistudio download --model PaddlePaddle/ERNIE-4.5-0.3B-Paddle --local_dir baidu/ERNIE-4.5-0.3B-Paddle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下载完成后，我们的配置文件中指定的 `\"baidu/ERNIE-4.5-0.3B-Paddle\"` 路径就能被正确找到了。如果下载出现`time out`的同学，可以尝试重新下载，或者使用[本项目](https://aistudio.baidu.com/project/edit/9382861)挂载的模型：/home/aistudio/data/models/30654/ERNIE-4.5-0.3B-Base-Paddle。\n",
    "\n",
    "\n",
    "本项目将采用挂在的模型进行演示！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 启动单卡预训练\n",
    "\n",
    "一切准备就绪后，我们可以在 `ERNIE-develop` 目录下执行以下命令来启动单卡预训练。\n",
    "\n",
    "- /home/aistudio/ERNIE-develop/examples/pre-training/models/moe/token_dispatcher/fp8_utils.py，注释Fp8的导入\n",
    "- /home/aistudio/ERNIE-develop/examples/pre-training/models/fp8_linear.py ， 注释Fp8的导入\n",
    "- /home/aistudio/ERNIE-develop/examples/pre-training/models/ernie/modeling.py ,注释Fp8的导入\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "修复 MoE 参数错误 (如果遇到)\n",
    "\n",
    "如果您在运行脚本时遇到 `KeyError: 'moe_group'` 等其他错误，这是因为脚本假设配置文件中一定有 `moe_group` 参数（这是为 MoE 模型设计的），但我们的简化配置中没有它（因为 `ERNIE-4.5-0.3B` 是稠密模型）。\n",
    "\n",
    "**快速修复步骤**：\n",
    "1. 打开文件 `ERNIE-develop/examples/pre-training/ernie/pretrain.py` (使用文本编辑器)。\n",
    "2. 找到这一行 (大约第 394 行)：`if trainer_args[\"moe_group\"].lower() in {\"mp\", \"tp\", \"model\", \"dummy\"}:`\n",
    "3. 将其修改为：`moe_group = trainer_args.get(\"moe_group\", None)  # 添加检查，避免 KeyError\\nif moe_group and moe_group.lower() in {\"mp\", \"tp\", \"model\", \"dummy\"}:`\n",
    "4. 在`/home/aistudio/ERNIE-develop/examples/pre-training/models/ernie/configuration.py`的ErnieMoEConfig类中（大约247行）加入`self.head_dim = None`\n",
    "5. 在`/home/aistudio/ERNIE-develop/examples/pre-training/models/ernie/modeling_moe.py`的大约1502行加入（原因：官方代码在计算 RoPE 的 sin 和 cos 缓存时，使用了 float64 类型，而示例模型期望的是 float32）：\n",
    "```\n",
    "            cos_cached = np.cos(emb)[:, :].astype(\"float32\")\n",
    "            sin_cached = np.sin(emb)[:, :].astype(\"float32\")\n",
    "```\n",
    "6. 在`/home/aistudio/ERNIE-develop/examples/pre-training/ernie/src/trainers/pretraining_trainer.py`大约1096行，删除：  (添加一个分布式环境的判断)\n",
    "```python\n",
    "# dist.all_reduce(tr_loss, dist.ReduceOp.SUM)\n",
    "# tr_loss_scalar = tr_loss.item() / dist.get_world_size()\n",
    "\n",
    "```\n",
    "加入：\n",
    "```python\n",
    "            if self.args.world_size > 1:\n",
    "                dist.all_reduce(tr_loss, dist.ReduceOp.SUM)\n",
    "                tr_loss_scalar = tr_loss.item() / dist.get_world_size()\n",
    "            else:\n",
    "                tr_loss_scalar = tr_loss_single_dp_scalar\n",
    "\n",
    "```\n",
    "\n",
    "删除（大约1150行）\n",
    "```python\n",
    "dist.all_reduce(numel_tensor)\n",
    "```\n",
    "加入：\n",
    "\n",
    "```python\n",
    "                if self.args.world_size > 1:\n",
    "                    dist.all_reduce(numel_tensor)\n",
    "```\n",
    "\n",
    "删除（大约1212行）：\n",
    "```python\n",
    "\n",
    "paddle.distributed.barrier()\n",
    "```\n",
    "\n",
    "加入:\n",
    "```python\n",
    "if self.args.world_size > 1:\n",
    "                paddle.distributed.barrier()\n",
    "```\n",
    "6. 保存文件并重新运行启动命令。\n",
    "\n",
    "这个修改是安全的，不会影响我们的训练，因为我们不使用 MoE 功能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:20:31.400242Z",
     "iopub.status.busy": "2025-07-17T10:20:31.399933Z",
     "iopub.status.idle": "2025-07-17T10:24:04.158096Z",
     "shell.execute_reply": "2025-07-17T10:24:04.157357Z",
     "shell.execute_reply.started": "2025-07-17T10:20:31.400223Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/ERNIE-develop/examples/pre-training\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/utils/cpp_extension/extension_utils.py:715: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\r\n",
      "  warnings.warn(warning_message)\r\n",
      "/home/aistudio/external-libraries/lib/python3.10/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\r\n",
      "  warnings.warn(\r\n",
      "[WARNING] 2025-07-17 18:20:33,983 [ modeling.py:   75]:    Use flash attention in scaled-dot-product. Attention mask is deprecated\r\n",
      "W0717 18:20:34.138628  2289 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.8, Runtime API Version: 12.6\r\n",
      "[WARNING] 2025-07-17 18:20:34,147 [    utils.py:   28]:    moe_permutation is not installed.\r\n",
      "[INFO] 2025-07-17 18:20:34,169 [trainer_utils.py:   71]:    The Training Main Process Started Successfully. time: 2025-07-17 18:20:34, pid: 2289\r\n",
      "[INFO] 2025-07-17 18:20:34,633 [process_utils.py:  180]:    Check affinity before setting: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127}\r\n",
      "[INFO] 2025-07-17 18:20:34,633 [process_utils.py:  183]:    check affinity after setting: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95}\r\n",
      "[INFO] 2025-07-17 18:20:34,633 [ pretrain.py:  163]:    set affinity successed.\r\n",
      "model_args:\r\n",
      "    max_seq_length: 1024\r\n",
      "    model_name_or_path: ../../../data/models/30654/ERNIE-4.5-0.3B-Base-Paddle\r\n",
      "    output_dir: ./output_pretrain/\r\n",
      "    tokenizer_name: ../../../data/models/30654/ERNIE-4.5-0.3B-Base-Paddle\r\n",
      "trainer_args:\r\n",
      "    adam_beta1: 0.9\r\n",
      "    adam_beta2: 0.95\r\n",
      "    adam_epsilon: 1.0e-08\r\n",
      "    bf16: false\r\n",
      "    dataloader_num_workers: 0\r\n",
      "    disable_tqdm: true\r\n",
      "    do_train: true\r\n",
      "    eval_steps: 100\r\n",
      "    fp16: true\r\n",
      "    fp16_opt_level: O1\r\n",
      "    gradient_accumulation_steps: 8\r\n",
      "    head_dim: 128\r\n",
      "    input_dir: 1.0 ../../data/llama_openwebtext_100k 1.0 ../../data/llama_openwebtext_100k\r\n",
      "    learning_rate: 0.0001\r\n",
      "    logging_steps: 10\r\n",
      "    lr_scheduler: wsd_cosine\r\n",
      "    max_grad_norm: 1.0\r\n",
      "    max_steps: 400\r\n",
      "    min_lr: 1.0e-05\r\n",
      "    moe_group: dummy\r\n",
      "    overwrite_output_dir: true\r\n",
      "    per_device_eval_batch_size: 2\r\n",
      "    per_device_train_batch_size: 1\r\n",
      "    pipeline_parallel_degree: 1\r\n",
      "    save_steps: 200\r\n",
      "    save_total_limit: 2\r\n",
      "    seed: 42\r\n",
      "    sharding: ''\r\n",
      "    split: 998,1,1\r\n",
      "    tensor_parallel_degree: 1\r\n",
      "    warmup_steps: 50\r\n",
      "    weight_decay: 0.1\r\n",
      "\r\n",
      "[INFO] 2025-07-17 18:20:34,657 [argparser.py:  426]:    user has defined resume_from_checkpoint: None\r\n",
      "[INFO] 2025-07-17 18:20:34,658 [training_args.py: 1837]:    The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\r\n",
      "[WARNING] 2025-07-17 18:20:34,658 [pretraining_trainer.py:  320]:    eval_batch_size set to 1\r\n",
      "[INFO] 2025-07-17 18:20:34,659 [ pretrain.py:  235]:    model_config_from_yaml: {}\r\n",
      "[INFO] 2025-07-17 18:20:34,663 [seed_utils.py:   76][rank--1]:    The global seed is set to 1067 and local seed is set to 1068. mp_init_seed=43\r\n",
      "[INFO] 2025-07-17 18:20:34,663 [ pretrain.py:  398][rank--1]:    disable moe flag when using moe-group=dummy\r\n",
      "[INFO] 2025-07-17 18:20:34,667 [configuration_utils.py:  887][rank--1]:    Loading configuration file ../../../data/models/30654/ERNIE-4.5-0.3B-Base-Paddle/config.json\r\n",
      "[WARNING] 2025-07-17 18:20:34,672 [configuration_utils.py:  918][rank--1]:    You are using a model of type ernie4_5 to instantiate a model of type ernie. This is not supported for all configurations of models and can yield errors.\r\n",
      "[INFO] 2025-07-17 18:20:36,029 [ pretrain.py:  426][rank--1]:    using tokenizer=<class 'src.tokenizers.tokenization_eb_v2.ErnieBotTokenizer'>, bos:1 eos:2 pad:0 \r\n",
      "[INFO] 2025-07-17 18:20:36,030 [modeling_moe.py: 1955][rank--1]:    change initializer-range from 0.02 to 0.018041293779826325\r\n",
      "[INFO] 2025-07-17 18:20:36,030 [modeling_moe.py:  220][rank--1]:    using moe-group: dummy\r\n",
      "[INFO] 2025-07-17 18:20:36,040 [ modeling.py:  846][rank--1]:    using recompute attn=False\r\n",
      "[INFO] 2025-07-17 18:20:36,040 [ modeling.py:  868][rank--1]:    use GQA - num_heads: 16- num_key_value_heads: 2\r\n",
      "[INFO] 2025-07-17 18:20:36,207 [ modeling.py:  846][rank--1]:    using recompute attn=False\r\n",
      "[INFO] 2025-07-17 18:20:36,207 [ modeling.py:  868][rank--1]:    use GQA - num_heads: 16- num_key_value_heads: 2\r\n",
      "[INFO] 2025-07-17 18:20:36,210 [ modeling.py:  846][rank--1]:    using recompute attn=False\r\n",
      "[INFO] 2025-07-17 18:20:36,211 [ modeling.py:  868][rank--1]:    use GQA - num_heads: 16- num_key_value_heads: 2\r\n",
      "[INFO] 2025-07-17 18:20:36,214 [ modeling.py:  846][rank--1]:    using recompute attn=False\r\n",
      "[INFO] 2025-07-17 18:20:36,214 [ modeling.py:  868][rank--1]:    use GQA - num_heads: 16- num_key_value_heads: 2\r\n",
      "[INFO] 2025-07-17 18:20:36,217 [ modeling.py:  846][rank--1]:    using recompute attn=False\r\n",
      "[INFO] 2025-07-17 18:20:36,217 [ modeling.py:  868][rank--1]:    use GQA - num_heads: 16- num_key_value_heads: 2\r\n",
      "[INFO] 2025-07-17 18:20:36,220 [ modeling.py:  846][rank--1]:    using recompute attn=False\r\n",
      "[INFO] 2025-07-17 18:20:36,220 [ modeling.py:  868][rank--1]:    use GQA - num_heads: 16- num_key_value_heads: 2\r\n",
      "[INFO] 2025-07-17 18:20:36,223 [ modeling.py:  846][rank--1]:    using recompute attn=False\r\n",
      "[INFO] 2025-07-17 18:20:36,223 [ modeling.py:  868][rank--1]:    use GQA - num_heads: 16- num_key_value_heads: 2\r\n",
      "[INFO] 2025-07-17 18:20:36,226 [ modeling.py:  846][rank--1]:    using recompute attn=False\r\n",
      "[INFO] 2025-07-17 18:20:36,227 [ modeling.py:  868][rank--1]:    use GQA - num_heads: 16- num_key_value_heads: 2\r\n",
      "[INFO] 2025-07-17 18:20:36,230 [ modeling.py:  846][rank--1]:    using recompute attn=False\r\n",
      "[INFO] 2025-07-17 18:20:36,230 [ modeling.py:  868][rank--1]:    use GQA - num_heads: 16- num_key_value_heads: 2\r\n",
      "[INFO] 2025-07-17 18:20:36,233 [ modeling.py:  846][rank--1]:    using recompute attn=False\r\n",
      "[INFO] 2025-07-17 18:20:36,233 [ modeling.py:  868][rank--1]:    use GQA - num_heads: 16- num_key_value_heads: 2\r\n",
      "[INFO] 2025-07-17 18:20:36,236 [ modeling.py:  846][rank--1]:    using recompute attn=False\r\n",
      "[INFO] 2025-07-17 18:20:36,236 [ modeling.py:  868][rank--1]:    use GQA - num_heads: 16- num_key_value_heads: 2\r\n",
      "[INFO] 2025-07-17 18:20:36,239 [ modeling.py:  846][rank--1]:    using recompute attn=False\r\n",
      "[INFO] 2025-07-17 18:20:36,239 [ modeling.py:  868][rank--1]:    use GQA - num_heads: 16- num_key_value_heads: 2\r\n",
      "[INFO] 2025-07-17 18:20:36,242 [ modeling.py:  846][rank--1]:    using recompute attn=False\r\n",
      "[INFO] 2025-07-17 18:20:36,243 [ modeling.py:  868][rank--1]:    use GQA - num_heads: 16- num_key_value_heads: 2\r\n",
      "[INFO] 2025-07-17 18:20:36,246 [ modeling.py:  846][rank--1]:    using recompute attn=False\r\n",
      "[INFO] 2025-07-17 18:20:36,246 [ modeling.py:  868][rank--1]:    use GQA - num_heads: 16- num_key_value_heads: 2\r\n",
      "[INFO] 2025-07-17 18:20:36,249 [ modeling.py:  846][rank--1]:    using recompute attn=False\r\n",
      "[INFO] 2025-07-17 18:20:36,249 [ modeling.py:  868][rank--1]:    use GQA - num_heads: 16- num_key_value_heads: 2\r\n",
      "[INFO] 2025-07-17 18:20:36,252 [ modeling.py:  846][rank--1]:    using recompute attn=False\r\n",
      "[INFO] 2025-07-17 18:20:36,253 [ modeling.py:  868][rank--1]:    use GQA - num_heads: 16- num_key_value_heads: 2\r\n",
      "[INFO] 2025-07-17 18:20:36,256 [ modeling.py:  846][rank--1]:    using recompute attn=False\r\n",
      "[INFO] 2025-07-17 18:20:36,256 [ modeling.py:  868][rank--1]:    use GQA - num_heads: 16- num_key_value_heads: 2\r\n",
      "[INFO] 2025-07-17 18:20:36,259 [ modeling.py:  846][rank--1]:    using recompute attn=False\r\n",
      "[INFO] 2025-07-17 18:20:36,259 [ modeling.py:  868][rank--1]:    use GQA - num_heads: 16- num_key_value_heads: 2\r\n",
      "[INFO] 2025-07-17 18:20:36,276 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[103424, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Embedding'>, norm=185.66087341308594,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:36,276 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.482173919677734,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:36,277 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.556285381317139,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:36,277 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.524847030639648,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:36,277 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.455974578857422,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:36,559 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=32.006832122802734,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:36,560 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.995466232299805,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:36,560 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[3072, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=32.01797866821289,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:36,560 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.46722412109375,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:36,561 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.5408453941345215,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:36,561 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.534718036651611,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:36,561 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.4708194732666,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:36,834 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.978988647460938,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:36,834 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=32.02152633666992,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:36,835 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[3072, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=32.012290954589844,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:36,835 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.469261169433594,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:36,835 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.533514022827148,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:36,836 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.536715507507324,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:36,836 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.475147247314453,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,109 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.995868682861328,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,109 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.97521209716797,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,109 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[3072, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.993942260742188,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,110 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.494447708129883,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,110 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.545706272125244,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,110 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.566837310791016,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,111 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.485050201416016,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,384 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.99711036682129,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,384 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.996898651123047,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,385 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[3072, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.9808349609375,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,385 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.475849151611328,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,385 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.524013519287109,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,386 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.518404006958008,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,386 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.47666358947754,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,658 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.994958877563477,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,659 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.992769241333008,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,659 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[3072, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=32.00996017456055,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,659 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.457767486572266,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,660 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.525047779083252,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,660 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.54331636428833,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,660 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.465002059936523,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,930 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=32.003177642822266,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,930 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.997249603271484,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,931 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[3072, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.99708366394043,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,931 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.490497589111328,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,931 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.547593116760254,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,932 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.55280876159668,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,932 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.457677841186523,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:38,201 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=32.02156066894531,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:38,202 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.982208251953125,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:38,202 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[3072, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.995250701904297,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:38,202 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.471481323242188,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:38,203 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.564767360687256,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:38,203 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.530235290527344,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:38,203 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.4751033782959,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:38,475 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=32.009246826171875,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:38,475 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.999523162841797,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:38,476 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[3072, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.986326217651367,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:38,476 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.483654022216797,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:38,477 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.5150604248046875,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:38,477 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.523664951324463,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:38,477 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.470033645629883,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:38,747 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=32.01503372192383,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:38,747 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=32.024803161621094,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:38,748 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[3072, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.997573852539062,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:38,748 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.493417739868164,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:38,749 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.554461479187012,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:38,749 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.5301432609558105,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:38,749 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.481325149536133,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,024 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=32.00417709350586,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,024 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=32.0085563659668,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,024 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[3072, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=32.01596450805664,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,025 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.4786376953125,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,025 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.508820533752441,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,026 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.547279357910156,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,026 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.492019653320312,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,297 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=32.011329650878906,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,298 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.999645233154297,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,298 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[3072, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.99070167541504,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,299 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.46446418762207,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,299 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.516327857971191,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,299 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.528645038604736,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,300 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.501235961914062,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,571 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.991666793823242,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,572 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.997385025024414,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,572 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[3072, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.981103897094727,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,573 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.49822235107422,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,573 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.540865421295166,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,573 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.524744510650635,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,574 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.467687606811523,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,843 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.995445251464844,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,844 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.995624542236328,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,844 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[3072, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.981586456298828,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,844 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.491823196411133,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,845 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.511590957641602,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,845 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.541938304901123,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,845 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.48663902282715,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,114 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.991615295410156,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,115 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=32.00380325317383,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,115 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[3072, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.987363815307617,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,115 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.49142074584961,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,116 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.532582759857178,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,116 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.53924560546875,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,116 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.488527297973633,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,391 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=32.00778579711914,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,391 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.986154556274414,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,392 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[3072, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.999208450317383,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,392 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.481130599975586,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,392 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.542202949523926,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,393 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.503232955932617,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,393 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.46438217163086,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,665 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.99226951599121,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,665 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.995437622070312,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,666 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[3072, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.98405647277832,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,666 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.476409912109375,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,667 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.525158405303955,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,667 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.534249782562256,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,667 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.45987319946289,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,938 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=32.00616455078125,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,938 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=32.00851821899414,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,939 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[3072, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.992990493774414,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,939 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.472869873046875,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,939 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.546419620513916,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,940 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.542144775390625,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,940 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.469633102416992,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:41,208 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=32.01312255859375,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:41,209 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=32.00554656982422,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:41,209 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[3072, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=32.01273727416992,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:41,210 [ modeling.py: 2134][rank--1]:    output-weight:[103424, 1024] config.tie_word_embeddings=True\r\n",
      "[INFO] 2025-07-17 18:20:41,211 [modeling_moe.py: 1967][rank--1]:    Use normal RMSNorm\r\n",
      "[INFO] 2025-07-17 18:20:41,213 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[103424, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'models.ernie.modeling.ErnieLMHead'>, norm=185.63902282714844,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:41,213 [modeling_moe.py: 1972][rank--1]:    using post init div: factor:0.16666666666666666\r\n",
      "[INFO] 2025-07-17 18:20:41,215 [ pretrain.py:  457][rank--1]:    using model type:<class 'models.ernie.modeling_moe.ErnieMoEForCausalLM'>\r\n",
      "[INFO] 2025-07-17 18:20:41,217 [ pretrain.py:  460][rank--1]:    using model=<class 'models.ernie.modeling_moe.ErnieMoEForCausalLM'>, cfg=ErnieMoEConfig {\r\n",
      "  \"architectures\": [\r\n",
      "    \"Ernie4_5_ForCausalLM\"\r\n",
      "  ],\r\n",
      "  \"attention_probs_dropout_prob\": 0.0,\r\n",
      "  \"aux_loss_type\": \"\",\r\n",
      "  \"bos_token_id\": 1,\r\n",
      "  \"compression_ratio\": 1.0,\r\n",
      "  \"decoderlayer_act_offload_settings\": {\r\n",
      "    \"type\": \"\",\r\n",
      "    \"value\": \"\"\r\n",
      "  },\r\n",
      "  \"enable_delay_scale_loss\": true,\r\n",
      "  \"enable_mtp_magic_send\": false,\r\n",
      "  \"eos_token_id\": 2,\r\n",
      "  \"expert_mlp_use_bias\": null,\r\n",
      "  \"fp16_opt_level\": \"O1\",\r\n",
      "  \"fp8_configs\": {\r\n",
      "    \"layers\": {\r\n",
      "      \"attn_fc1_linear\": true,\r\n",
      "      \"attn_fc2_linear\": true,\r\n",
      "      \"attn_tp_fc1_linear\": true,\r\n",
      "      \"attn_tp_fc2_linear\": true,\r\n",
      "      \"mlp_fc1_linear\": true,\r\n",
      "      \"mlp_fc2_linear\": true,\r\n",
      "      \"mlp_tp_fc1_linear\": true,\r\n",
      "      \"mlp_tp_fc2_linear\": true\r\n",
      "    },\r\n",
      "    \"quant_scheme\": \"DelayedScaling\",\r\n",
      "    \"recipe\": {\r\n",
      "      \"amax_compute_algo\": \"max\",\r\n",
      "      \"amax_history_len\": 1024,\r\n",
      "      \"calibrating\": true,\r\n",
      "      \"format\": \"hybrid\",\r\n",
      "      \"fuse_wgrad_accumulation\": false,\r\n",
      "      \"quant_weight_at_first_microbatch\": false\r\n",
      "    },\r\n",
      "    \"smooth_swiglu\": false\r\n",
      "  },\r\n",
      "  \"fp8_fused_ops_configs\": {\r\n",
      "    \"split_group_gemm\": true,\r\n",
      "    \"stack_quant\": false,\r\n",
      "    \"swiglu_probs_bwd\": false\r\n",
      "  },\r\n",
      "  \"fp8_mem_configs\": {\r\n",
      "    \"clear_origin_weight_when_offline_quant\": false,\r\n",
      "    \"dequant_input\": false,\r\n",
      "    \"offline_quant_expert_weight\": false,\r\n",
      "    \"recompute_fwd_gate_up\": false,\r\n",
      "    \"shared_expert\": false\r\n",
      "  },\r\n",
      "  \"freq_allocation\": 0,\r\n",
      "  \"fuse_attn_ffn\": false,\r\n",
      "  \"fuse_gate_detach_matmul\": false,\r\n",
      "  \"fuse_linear\": false,\r\n",
      "  \"fuse_ln\": false,\r\n",
      "  \"fuse_rms_norm\": false,\r\n",
      "  \"fuse_rope\": false,\r\n",
      "  \"fuse_swiglu\": false,\r\n",
      "  \"global_aux_loss\": false,\r\n",
      "  \"head_dim\": null,\r\n",
      "  \"hidden_act\": \"silu\",\r\n",
      "  \"hidden_dropout_prob\": 0.0,\r\n",
      "  \"hidden_size\": 1024,\r\n",
      "  \"ignored_index\": -100,\r\n",
      "  \"initializer_range\": 0.018041293779826325,\r\n",
      "  \"insert_empty_layer\": [],\r\n",
      "  \"intermediate_size\": 3072,\r\n",
      "  \"loss_subbatch_seqlen\": 32768,\r\n",
      "  \"max_position_embeddings\": 131072,\r\n",
      "  \"micro_batch_size\": 1,\r\n",
      "  \"model_type\": \"ernie\",\r\n",
      "  \"moe_all_to_all_dropout\": 0.0,\r\n",
      "  \"moe_aux_loss_lambda\": 0.01,\r\n",
      "  \"moe_capacity\": [],\r\n",
      "  \"moe_dense_experts_token_type_id\": 3,\r\n",
      "  \"moe_dropout_prob\": 0.0,\r\n",
      "  \"moe_fuse_experts\": false,\r\n",
      "  \"moe_gate_act\": \"softmax\",\r\n",
      "  \"moe_group_experts\": false,\r\n",
      "  \"moe_intermediate_size\": 0,\r\n",
      "  \"moe_k\": 2,\r\n",
      "  \"moe_layer_end_index\": 17,\r\n",
      "  \"moe_layer_feed_fake_token\": false,\r\n",
      "  \"moe_layer_interval\": 2,\r\n",
      "  \"moe_layer_start_index\": 0,\r\n",
      "  \"moe_norm_gate_logits\": true,\r\n",
      "  \"moe_num_dense_experts\": 0,\r\n",
      "  \"moe_num_experts\": 0,\r\n",
      "  \"moe_num_shared_experts\": 0,\r\n",
      "  \"moe_rank\": 0,\r\n",
      "  \"moe_reverse_token_drop\": false,\r\n",
      "  \"moe_use_aux_free\": false,\r\n",
      "  \"moe_world_size\": 1,\r\n",
      "  \"multi_token_pred_depth\": 0,\r\n",
      "  \"multi_token_pred_lambda\": 0.3,\r\n",
      "  \"n_group\": 0,\r\n",
      "  \"num_acc_steps\": null,\r\n",
      "  \"num_attention_heads\": 16,\r\n",
      "  \"num_experts_per_tok\": 8,\r\n",
      "  \"num_hidden_layers\": 18,\r\n",
      "  \"num_key_value_heads\": 2,\r\n",
      "  \"offload_pp_data_chunk_size\": 0,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"paddleformers_version\": \"0.1\",\r\n",
      "  \"pp_no_recompute_layer\": null,\r\n",
      "  \"remove_tail_layer\": false,\r\n",
      "  \"resampler_fuse_rms_norm\": false,\r\n",
      "  \"rms_norm_eps\": 1e-05,\r\n",
      "  \"rope_3d\": false,\r\n",
      "  \"rope_reorder\": true,\r\n",
      "  \"rope_theta\": 500000,\r\n",
      "  \"scaling_factor\": null,\r\n",
      "  \"selective_no_recompute_num\": 0,\r\n",
      "  \"seqlen\": 1024,\r\n",
      "  \"skip_recompute_ops\": {},\r\n",
      "  \"tie_word_embeddings\": true,\r\n",
      "  \"token_balance_loss\": false,\r\n",
      "  \"token_balance_seqlen\": 1024,\r\n",
      "  \"topk_group\": 0,\r\n",
      "  \"use_bias\": false,\r\n",
      "  \"use_combine_before_a2a\": false,\r\n",
      "  \"use_ep_comm_overlap\": false,\r\n",
      "  \"use_fast_ln\": false,\r\n",
      "  \"use_flash_attn\": true,\r\n",
      "  \"use_flash_attn_with_mask\": false,\r\n",
      "  \"use_fp8\": false,\r\n",
      "  \"use_fp8_fuse_node\": false,\r\n",
      "  \"use_fp8_mlp\": false,\r\n",
      "  \"use_fused_head_loss_fn\": false,\r\n",
      "  \"use_linear_residual_norm_recompute\": false,\r\n",
      "  \"use_mem_eff_attn\": false,\r\n",
      "  \"use_mp_gathered_weight\": false,\r\n",
      "  \"use_qk_norm\": false,\r\n",
      "  \"use_quant_before_a2a\": false,\r\n",
      "  \"use_recompute\": false,\r\n",
      "  \"use_recompute_attn\": false,\r\n",
      "  \"use_recompute_dnd\": false,\r\n",
      "  \"use_recompute_lm_head\": false,\r\n",
      "  \"use_recompute_loss_fn\": false,\r\n",
      "  \"use_recompute_moe\": false,\r\n",
      "  \"use_recompute_mtp\": false,\r\n",
      "  \"use_recompute_resampler\": false,\r\n",
      "  \"use_rms_qkv_recompute\": false,\r\n",
      "  \"use_rmsnorm\": true,\r\n",
      "  \"use_sparse_head_and_loss_fn\": false,\r\n",
      "  \"use_tpsp_comm_overlap\": false,\r\n",
      "  \"using_dynamic_sequence_length\": false,\r\n",
      "  \"vocab_size\": 103424,\r\n",
      "  \"weight_share_add_bias\": true\r\n",
      "}\r\n",
      "\r\n",
      " > building dataset index ...\r\n",
      "    reading sizes...\r\n",
      "    reading pointers...\r\n",
      "    reading document index...\r\n",
      "    creating numpy buffer of mmap...\r\n",
      "    creating memory view of numpy buffer...\r\n",
      " > finished creating indexed dataset in 0.000759 seconds\r\n",
      "    number of documents: 100000\r\n",
      " > dataset split:\r\n",
      "    train:\r\n",
      "     document indices in [0, 99800) total of 99800 documents\r\n",
      "    validation:\r\n",
      "     document indices in [99800, 99900) total of 100 documents\r\n",
      "    test:\r\n",
      "     document indices in [99900, 100000) total of 100 documents\r\n",
      "searching for causal dataset, build_indices=False, share_folder False, check_rank_flag False\r\n",
      "build success\r\n",
      " > loading doc-idx mapping from ../../data/index-cache/0e61683deaa39422e24fb3e0b520cfc5_doc_idx.npy\r\n",
      " > loading sample-idx mapping from ../../data/index-cache/0e61683deaa39422e24fb3e0b520cfc5_sample_idx.npy\r\n",
      " > loading shuffle-idx mapping from ../../data/index-cache/0e61683deaa39422e24fb3e0b520cfc5_shuffle_idx.npy\r\n",
      "    loaded indexed file in 0.001 seconds\r\n",
      "    total number of samples: 120288\r\n",
      "    total number of epochs: 1\r\n",
      "searching for causal dataset, build_indices=False, share_folder False, check_rank_flag False\r\n",
      "build success\r\n",
      " > loading doc-idx mapping from ../../data/index-cache/e6dc69eb0f94509922f5234cc25c5440_doc_idx.npy\r\n",
      " > loading sample-idx mapping from ../../data/index-cache/e6dc69eb0f94509922f5234cc25c5440_sample_idx.npy\r\n",
      " > loading shuffle-idx mapping from ../../data/index-cache/e6dc69eb0f94509922f5234cc25c5440_shuffle_idx.npy\r\n",
      "    loaded indexed file in 0.001 seconds\r\n",
      "    total number of samples: 103\r\n",
      "    total number of epochs: 1\r\n",
      "searching for causal dataset, build_indices=False, share_folder False, check_rank_flag False\r\n",
      "build success\r\n",
      " > loading doc-idx mapping from ../../data/index-cache/64bf0bdeaf57319af37ad010202fa307_doc_idx.npy\r\n",
      " > loading sample-idx mapping from ../../data/index-cache/64bf0bdeaf57319af37ad010202fa307_sample_idx.npy\r\n",
      " > loading shuffle-idx mapping from ../../data/index-cache/64bf0bdeaf57319af37ad010202fa307_shuffle_idx.npy\r\n",
      "    loaded indexed file in 0.001 seconds\r\n",
      "    total number of samples: 87\r\n",
      "    total number of epochs: 1\r\n",
      " > building dataset index ...\r\n",
      "    reading sizes...\r\n",
      "    reading pointers...\r\n",
      "    reading document index...\r\n",
      "    creating numpy buffer of mmap...\r\n",
      "    creating memory view of numpy buffer...\r\n",
      " > finished creating indexed dataset in 0.000288 seconds\r\n",
      "    number of documents: 100000\r\n",
      " > dataset split:\r\n",
      "    train:\r\n",
      "     document indices in [0, 99800) total of 99800 documents\r\n",
      "    validation:\r\n",
      "     document indices in [99800, 99900) total of 100 documents\r\n",
      "    test:\r\n",
      "     document indices in [99900, 100000) total of 100 documents\r\n",
      "searching for causal dataset, build_indices=False, share_folder False, check_rank_flag False\r\n",
      "build success\r\n",
      " > loading doc-idx mapping from ../../data/index-cache/0e61683deaa39422e24fb3e0b520cfc5_doc_idx.npy\r\n",
      " > loading sample-idx mapping from ../../data/index-cache/0e61683deaa39422e24fb3e0b520cfc5_sample_idx.npy\r\n",
      " > loading shuffle-idx mapping from ../../data/index-cache/0e61683deaa39422e24fb3e0b520cfc5_shuffle_idx.npy\r\n",
      "    loaded indexed file in 0.001 seconds\r\n",
      "    total number of samples: 120288\r\n",
      "    total number of epochs: 1\r\n",
      "searching for causal dataset, build_indices=False, share_folder False, check_rank_flag False\r\n",
      "build success\r\n",
      " > loading doc-idx mapping from ../../data/index-cache/e6dc69eb0f94509922f5234cc25c5440_doc_idx.npy\r\n",
      " > loading sample-idx mapping from ../../data/index-cache/e6dc69eb0f94509922f5234cc25c5440_sample_idx.npy\r\n",
      " > loading shuffle-idx mapping from ../../data/index-cache/e6dc69eb0f94509922f5234cc25c5440_shuffle_idx.npy\r\n",
      "    loaded indexed file in 0.001 seconds\r\n",
      "    total number of samples: 103\r\n",
      "    total number of epochs: 1\r\n",
      "searching for causal dataset, build_indices=False, share_folder False, check_rank_flag False\r\n",
      "build success\r\n",
      " > loading doc-idx mapping from ../../data/index-cache/64bf0bdeaf57319af37ad010202fa307_doc_idx.npy\r\n",
      " > loading sample-idx mapping from ../../data/index-cache/64bf0bdeaf57319af37ad010202fa307_sample_idx.npy\r\n",
      " > loading shuffle-idx mapping from ../../data/index-cache/64bf0bdeaf57319af37ad010202fa307_shuffle_idx.npy\r\n",
      "    loaded indexed file in 0.001 seconds\r\n",
      "    total number of samples: 87\r\n",
      "    total number of epochs: 1\r\n",
      "building indices for the blendable dataset, Since --data_cache is not specified, the index file will not be stored.\r\n",
      "> building indices for blendable datasets ...\r\n",
      " > sample ratios:\r\n",
      "   dataset 0, input: 0.5, achieved: 0.5\r\n",
      "   dataset 1, input: 0.5, achieved: 0.5\r\n",
      "> elapsed time for building blendable dataset indices: 0.00 (sec)\r\n",
      "> size of blendable dataset: 3200 samples\r\n",
      "building indices for the blendable dataset, Since --data_cache is not specified, the index file will not be stored.\r\n",
      "> building indices for blendable datasets ...\r\n",
      " > sample ratios:\r\n",
      "   dataset 0, input: 0.5, achieved: 0.5\r\n",
      "   dataset 1, input: 0.5, achieved: 0.5\r\n",
      "> elapsed time for building blendable dataset indices: 0.00 (sec)\r\n",
      "> size of blendable dataset: 50 samples\r\n",
      "building indices for the blendable dataset, Since --data_cache is not specified, the index file will not be stored.\r\n",
      "> building indices for blendable datasets ...\r\n",
      " > sample ratios:\r\n",
      "   dataset 0, input: 0.5, achieved: 0.5\r\n",
      "   dataset 1, input: 0.5, achieved: 0.5\r\n",
      "> elapsed time for building blendable dataset indices: 0.00 (sec)\r\n",
      "> size of blendable dataset: 100 samples\r\n",
      "[INFO] 2025-07-17 18:20:41,248 [trainer_utils.py:  173][rank--1]:    The global seed is set to 42, local seed is set to 43 and random seed is set to 42.\r\n",
      "[INFO] 2025-07-17 18:20:41,286 [  trainer.py:  459][rank--1]:    max_steps is given, it will override any value given in num_train_epochs\r\n",
      "[INFO] 2025-07-17 18:20:41,286 [  trainer.py:  514][rank--1]:    Using half precision\r\n",
      "[DEBUG] 2025-07-17 18:20:41,286 [  trainer.py: 3788][rank--1]:    ============================================================\r\n",
      "[DEBUG] 2025-07-17 18:20:41,286 [  trainer.py: 3794][rank--1]:        Training Configuration Arguments    \r\n",
      "[DEBUG] 2025-07-17 18:20:41,286 [  trainer.py: 3795][rank--1]:    paddle commit id              : cdcd76a93d1dfe767dde768198e1d7c7488b93f6\r\n",
      "[DEBUG] 2025-07-17 18:20:41,286 [  trainer.py: 3796][rank--1]:    paddleformers commit id       : 053a5a5e2a72cd2d3b997cbcff81b14af9fe4d47\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    _no_sync_in_gradient_accumulation: True\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    _use_moe                      : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    adam_beta1                    : 0.9\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    adam_beta2                    : 0.95\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    adam_epsilon                  : 1e-08\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    amp_custom_black_list         : None\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    amp_custom_white_list         : None\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    amp_master_grad               : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    audio_config                  : {}\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    auto_parallel_resume_form_hybrid_parallel: False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    base_seq_length               : 4096\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    bf16                          : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    bf16_full_eval                : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    ckpt_quant_stage              : O0\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    combine_batch                 : 0\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    context_parallel_degree       : -1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    count_trained_tokens          : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    current_device                : gpu:0\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    data_parallel_config          : \r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    data_parallel_degree          : 1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    data_parallel_rank            : 0\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    dataloader_drop_last          : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    dataloader_num_workers        : 0\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    dataloader_shuffle            : True\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    dataset                       : None\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    dataset_rank                  : 0\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    dataset_world_size            : 1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    ddp_find_unused_parameters    : None\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    decay_function                : half_life\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    device                        : gpu\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    disable_tqdm                  : True\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    distributed_dataloader        : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    do_eval                       : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    do_export                     : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    do_predict                    : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    do_train                      : True\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    enable_auto_parallel          : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    enable_delay_scale_loss       : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    enable_global_training_logs   : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    enable_mtp_magic_send         : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    enable_optimizer_timer        : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    enable_zero_cost_checkpoint   : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    eval_accumulation_steps       : None\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    eval_batch_size               : 1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    eval_iters                    : 10\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    eval_steps                    : 100\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    evaluation_strategy           : IntervalStrategy.NO\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    expert_max_capacity           : 4294967296\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    expert_min_capacity           : 1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    expert_parallel_degree        : -1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    expert_tensor_parallel_degree : -1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    flash_device_save_steps       : 0\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    flatten_param_grads           : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    force_reshard_pp              : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    fp16                          : True\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    fp16_full_eval                : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    fp16_opt_level                : O1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    from_scratch                  : 1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    fuse_sequence_parallel_allreduce: False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    gc_interval                   : 0\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    global_batch_size             : -1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    global_logging_interval       : 1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    global_shuffle_num_examples   : 0\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    gradient_accumulation_steps   : 8\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    greater_is_better             : None\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    hybrid_parallel_topo_order    : pp_first\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    ignore_data_skip              : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    ignore_load_lr_and_optim      : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    ignore_save_lr_and_optim      : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    input_dir                     : 1.0 ../../data/llama_openwebtext_100k 1.0 ../../data/llama_openwebtext_100k\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    label_names                   : None\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    lazy_data_processing          : True\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    learning_rate                 : 0.0001\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    load_best_model_at_end        : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    load_sharded_model            : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    local_process_index           : 0\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    local_rank                    : -1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    log_global_grad_norm          : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    log_level                     : -1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    log_level_replica             : -1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    log_on_each_node              : True\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    logging_dir                   : ./output_pretrain/runs/Jul17_18-20-34_jupyter-2553954-9382861\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    logging_first_step            : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    logging_steps                 : 10\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    logging_strategy              : IntervalStrategy.STEPS\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    logical_process_index         : 0\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    lr_end                        : 1e-07\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    lr_scheduler                  : wsd_cosine\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    lr_scheduler_type             : SchedulerType.LINEAR\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    max_evaluate_steps            : -1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    max_grad_norm                 : 1.0\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    max_gradient_accumulation_steps: 8\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    max_seq_length                : 1024\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    max_steps                     : 400\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    metric_for_best_model         : None\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    metrics_output_path           : None\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    min_lr                        : 1e-05\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    minimum_eval_times            : None\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    model_name_or_path            : ../../../data/models/30654/ERNIE-4.5-0.3B-Base-Paddle\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    moe_gate_lr_ratio             : None\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    moe_group                     : dummy\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    moe_use_aux_free_update_coef  : 0.001\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    moe_with_send_router_loss     : True\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    multi_token_pred_depth        : 0\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    need_data                     : True\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    no_cuda                       : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    num_consecutive               : 1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    num_cycles                    : 0.5\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    num_train_epochs              : 1.0\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    offload_optim                 : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    optim                         : OptimizerNames.ADAMW\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    optim_shard_num               : 1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    optimizer_name_suffix         : None\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    ordered_save_group_size       : 0\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    output_dir                    : ./output_pretrain/\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    output_signal_dir             : ./output_pretrain/\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    overwrite_output_dir          : True\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    pad_token_id                  : 0\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    past_index                    : -1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    pdc_download_ckpt             : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    pdc_download_timeout          : 300\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    per_device_eval_batch_size    : 1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    per_device_train_batch_size   : 1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    pipeline_parallel_config      : \r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    pipeline_parallel_degree      : -1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    pipeline_parallel_rank        : 0\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    power                         : 1.0\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    pre_alloc_memory              : 0.0\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    prediction_loss_only          : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    prefetch_factor               : 2\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    process_index                 : 0\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    recompute                     : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    reeao_dataset_rank            : 0\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    reeao_dataset_world_size      : 1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    refined_recompute             : {}\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    release_grads                 : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    remove_unused_columns         : True\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    report_to                     : ['visualdl']\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    resume_from_checkpoint        : None\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    run_name                      : ./output_pretrain/\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    same_data                     : None\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    save_on_each_node             : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    save_rng_states               : True\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    save_sharded_model            : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    save_sharding_stage1_model_include_freeze_params: False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    save_steps                    : 200\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    save_strategy                 : IntervalStrategy.STEPS\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    save_tokenizer                : True\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    save_total_limit              : 2\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    scale_loss                    : 32768\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    seed                          : 42\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    sep_parallel_degree           : -1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    sequence_parallel             : 0\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    sequence_parallel_config      : \r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    sharding                      : []\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    sharding_comm_buffer_size_MB  : -1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    sharding_degree               : -1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    sharding_parallel_config      : \r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    sharding_parallel_degree      : -1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    sharding_parallel_mesh_dimension: dp\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    sharding_parallel_rank        : 0\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    should_load_dataset           : True\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    should_load_sharding_stage1_model: False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    should_log                    : True\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    should_save                   : True\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    should_save_model_state       : True\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    should_save_model_with_tensor_fusion: False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    should_save_sharding_stage1_model: False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    shuffle_consecutive           : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    skip_data_intervals           : None\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    skip_memory_metrics           : True\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    skip_profile_timer            : True\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    split                         : 998,1,1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    split_inputs_sequence_dim     : True\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    split_norm_comm               : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    tensor_parallel_config        : \r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    tensor_parallel_degree        : -1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    tensor_parallel_rank          : 0\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    tensorwise_offload_optimizer  : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    test_iters                    : 100\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    to_static                     : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    tokenizer_name                : ../../../data/models/30654/ERNIE-4.5-0.3B-Base-Paddle\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    train_batch_size              : 1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    train_moe_only                : None\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    unified_checkpoint            : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    unified_checkpoint_config     : \r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    use_async_save                : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    use_expert_parallel           : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    use_fp8                       : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    use_hybrid_parallel           : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    use_lowprecision_moment       : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    use_moe                       : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    use_sp_callback               : True\r\n",
      "[DEBUG] 2025-07-17 18:20:41,293 [  trainer.py: 3802][rank--1]:    virtual_pp_degree             : 1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,293 [  trainer.py: 3802][rank--1]:    vocab_path                    : None\r\n",
      "[DEBUG] 2025-07-17 18:20:41,293 [  trainer.py: 3802][rank--1]:    wandb_api_key                 : None\r\n",
      "[DEBUG] 2025-07-17 18:20:41,293 [  trainer.py: 3802][rank--1]:    wandb_http_proxy              : None\r\n",
      "[DEBUG] 2025-07-17 18:20:41,293 [  trainer.py: 3802][rank--1]:    warmup_ratio                  : 0.0\r\n",
      "[DEBUG] 2025-07-17 18:20:41,293 [  trainer.py: 3802][rank--1]:    warmup_steps                  : 50\r\n",
      "[DEBUG] 2025-07-17 18:20:41,293 [  trainer.py: 3802][rank--1]:    weight_decay                  : 0.1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,293 [  trainer.py: 3802][rank--1]:    weight_name_suffix            : None\r\n",
      "[DEBUG] 2025-07-17 18:20:41,293 [  trainer.py: 3802][rank--1]:    world_size                    : 1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,293 [  trainer.py: 3802][rank--1]:    zcc_ema_interval              : 1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,293 [  trainer.py: 3802][rank--1]:    zcc_pipeline_hooks_capacity_usage: 0.6\r\n",
      "[DEBUG] 2025-07-17 18:20:41,293 [  trainer.py: 3802][rank--1]:    zcc_save_ema_coef             : None\r\n",
      "[DEBUG] 2025-07-17 18:20:41,293 [  trainer.py: 3802][rank--1]:    zcc_workers_num               : 3\r\n",
      "[DEBUG] 2025-07-17 18:20:41,293 [  trainer.py: 3804][rank--1]:    \r\n",
      "[INFO] 2025-07-17 18:20:41,293 [     misc.py:   97][rank--1]:    global_training_logs: use skip zero\r\n",
      "[INFO] 2025-07-17 18:20:41,293 [  trainer.py:  837][rank--1]:    Starting training from resume_from_checkpoint : None\r\n",
      "[INFO] 2025-07-17 18:20:41,293 [pretraining_trainer.py: 1276][rank--1]:    using wsd lr scheduler, num_steady_steps=None\r\n",
      "[INFO] 2025-07-17 18:20:41,296 [  trainer.py:  955][rank--1]:    [timelog] checkpoint loading time: 0.00s (2025-07-17 18:20:41) \r\n",
      "[INFO] 2025-07-17 18:20:41,296 [  trainer.py:  956][rank--1]:    ***** Running training *****\r\n",
      "[INFO] 2025-07-17 18:20:41,296 [  trainer.py:  957][rank--1]:      Num examples = 3,200\r\n",
      "[INFO] 2025-07-17 18:20:41,296 [  trainer.py:  958][rank--1]:      Num Epochs = 1\r\n",
      "[INFO] 2025-07-17 18:20:41,296 [  trainer.py:  959][rank--1]:      Instantaneous batch size per device = 1\r\n",
      "[INFO] 2025-07-17 18:20:41,296 [  trainer.py:  960][rank--1]:      Total train batch size (w. parallel, distributed & accumulation) = 8\r\n",
      "[INFO] 2025-07-17 18:20:41,296 [  trainer.py:  961][rank--1]:      Gradient Accumulation steps = 8\r\n",
      "[INFO] 2025-07-17 18:20:41,296 [  trainer.py:  962][rank--1]:      Total optimization steps = 400\r\n",
      "[INFO] 2025-07-17 18:20:41,296 [  trainer.py:  963][rank--1]:      Total num train samples = 3,200\r\n",
      "[DEBUG] 2025-07-17 18:20:41,297 [  trainer.py:  973][rank--1]:      Number of trainable parameters = 318,280,704 (per device)\r\n",
      "[INFO] 2025-07-17 18:20:47,126 [logging_callback.py:   43][rank--1]:    loss: 11.311073303222656, loss_cur_dp: 11.311073303222656, learning_rate: 2.000000e-05, global_step: 10, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 5.822300, global_samples_per_second: 13.740300, global_steps_per_second: 1.717500, tokens_trained_current_step: 8192, timestamp: 1752747647125, TFLOPS_per_sec_per_card: 17.928000, tokens_per_sec_per_card: 14069.800000, tokens_per_sec_per_card_average: 14069.800000, lm_loss_cur_dp: 11.311073303222656, progress_or_epoch: 0.025000\r\n",
      "[INFO] 2025-07-17 18:20:51,509 [logging_callback.py:   43][rank--1]:    loss: 10.29632568359375, loss_cur_dp: 10.29632568359375, learning_rate: 4.000000e-05, global_step: 20, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.383600, global_samples_per_second: 18.249700, global_steps_per_second: 2.281200, tokens_trained_current_step: 8192, timestamp: 1752747651508, TFLOPS_per_sec_per_card: 23.813000, tokens_per_sec_per_card: 18687.600000, tokens_per_sec_per_card_average: 18687.600000, lm_loss_cur_dp: 10.29632568359375, progress_or_epoch: 0.050000\r\n",
      "[INFO] 2025-07-17 18:20:55,870 [logging_callback.py:   43][rank--1]:    loss: 9.719583129882812, loss_cur_dp: 9.719583129882812, learning_rate: 6.000000e-05, global_step: 30, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.360600, global_samples_per_second: 18.346200, global_steps_per_second: 2.293300, tokens_trained_current_step: 8192, timestamp: 1752747655869, TFLOPS_per_sec_per_card: 23.939000, tokens_per_sec_per_card: 18786.700000, tokens_per_sec_per_card_average: 18737.200000, lm_loss_cur_dp: 9.719583511352539, progress_or_epoch: 0.075000\r\n",
      "[INFO] 2025-07-17 18:21:00,263 [logging_callback.py:   43][rank--1]:    loss: 9.083602905273438, loss_cur_dp: 9.083602905273438, learning_rate: 8.000000e-05, global_step: 40, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.392200, global_samples_per_second: 18.214100, global_steps_per_second: 2.276800, tokens_trained_current_step: 8192, timestamp: 1752747660261, TFLOPS_per_sec_per_card: 23.767000, tokens_per_sec_per_card: 18651.500000, tokens_per_sec_per_card_average: 18708.600000, lm_loss_cur_dp: 9.083602905273438, progress_or_epoch: 0.100000\r\n",
      "[INFO] 2025-07-17 18:21:04,657 [logging_callback.py:   43][rank--1]:    loss: 8.313115692138672, loss_cur_dp: 8.313115692138672, learning_rate: 1.000000e-04, global_step: 50, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.394100, global_samples_per_second: 18.206000, global_steps_per_second: 2.275800, tokens_trained_current_step: 8192, timestamp: 1752747664656, TFLOPS_per_sec_per_card: 23.756000, tokens_per_sec_per_card: 18643.400000, tokens_per_sec_per_card_average: 18692.300000, lm_loss_cur_dp: 8.313116073608398, progress_or_epoch: 0.125000\r\n",
      "[INFO] 2025-07-17 18:21:09,061 [logging_callback.py:   43][rank--1]:    loss: 7.887854766845703, loss_cur_dp: 7.887854766845703, learning_rate: 1.000000e-04, global_step: 60, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.404500, global_samples_per_second: 18.163100, global_steps_per_second: 2.270400, tokens_trained_current_step: 8192, timestamp: 1752747669060, TFLOPS_per_sec_per_card: 23.700000, tokens_per_sec_per_card: 18599.100000, tokens_per_sec_per_card_average: 18673.700000, lm_loss_cur_dp: 7.887855052947998, progress_or_epoch: 0.150000\r\n",
      "[INFO] 2025-07-17 18:21:13,451 [logging_callback.py:   43][rank--1]:    loss: 7.324617004394531, loss_cur_dp: 7.324617004394531, learning_rate: 1.000000e-04, global_step: 70, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.389400, global_samples_per_second: 18.225900, global_steps_per_second: 2.278200, tokens_trained_current_step: 8192, timestamp: 1752747673450, TFLOPS_per_sec_per_card: 23.781000, tokens_per_sec_per_card: 18663.000000, tokens_per_sec_per_card_average: 18671.900000, lm_loss_cur_dp: 7.3246169090271, progress_or_epoch: 0.175000\r\n",
      "[INFO] 2025-07-17 18:21:17,830 [logging_callback.py:   43][rank--1]:    loss: 7.417249298095703, loss_cur_dp: 7.417249298095703, learning_rate: 1.000000e-04, global_step: 80, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.379200, global_samples_per_second: 18.268200, global_steps_per_second: 2.283500, tokens_trained_current_step: 8192, timestamp: 1752747677829, TFLOPS_per_sec_per_card: 23.837000, tokens_per_sec_per_card: 18706.400000, tokens_per_sec_per_card_average: 18676.800000, lm_loss_cur_dp: 7.4172492027282715, progress_or_epoch: 0.200000\r\n",
      "[INFO] 2025-07-17 18:21:22,200 [logging_callback.py:   43][rank--1]:    loss: 7.066650390625, loss_cur_dp: 7.066650390625, learning_rate: 1.000000e-04, global_step: 90, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.369600, global_samples_per_second: 18.308300, global_steps_per_second: 2.288500, tokens_trained_current_step: 8192, timestamp: 1752747682199, TFLOPS_per_sec_per_card: 23.889000, tokens_per_sec_per_card: 18747.400000, tokens_per_sec_per_card_average: 18685.600000, lm_loss_cur_dp: 7.066650390625, progress_or_epoch: 0.225000\r\n",
      "[INFO] 2025-07-17 18:21:26,586 [logging_callback.py:   43][rank--1]:    loss: 7.089629364013672, loss_cur_dp: 7.089629364013672, learning_rate: 1.000000e-04, global_step: 100, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.385900, global_samples_per_second: 18.240200, global_steps_per_second: 2.280000, tokens_trained_current_step: 8192, timestamp: 1752747686585, TFLOPS_per_sec_per_card: 23.800000, tokens_per_sec_per_card: 18677.800000, tokens_per_sec_per_card_average: 18684.800000, lm_loss_cur_dp: 7.089629650115967, progress_or_epoch: 0.250000\r\n",
      "[INFO] 2025-07-17 18:21:30,976 [logging_callback.py:   43][rank--1]:    loss: 6.943177795410156, loss_cur_dp: 6.943177795410156, learning_rate: 1.000000e-04, global_step: 110, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.390300, global_samples_per_second: 18.222200, global_steps_per_second: 2.277800, tokens_trained_current_step: 8192, timestamp: 1752747690975, TFLOPS_per_sec_per_card: 23.777000, tokens_per_sec_per_card: 18659.700000, tokens_per_sec_per_card_average: 18682.300000, lm_loss_cur_dp: 6.943177700042725, progress_or_epoch: 0.275000\r\n",
      "[INFO] 2025-07-17 18:21:35,368 [logging_callback.py:   43][rank--1]:    loss: 6.9135894775390625, loss_cur_dp: 6.9135894775390625, learning_rate: 1.000000e-04, global_step: 120, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.391500, global_samples_per_second: 18.216800, global_steps_per_second: 2.277100, tokens_trained_current_step: 8192, timestamp: 1752747695367, TFLOPS_per_sec_per_card: 23.770000, tokens_per_sec_per_card: 18654.000000, tokens_per_sec_per_card_average: 18679.700000, lm_loss_cur_dp: 6.9135894775390625, progress_or_epoch: 0.300000\r\n",
      "[INFO] 2025-07-17 18:21:39,747 [logging_callback.py:   43][rank--1]:    loss: 6.667790222167969, loss_cur_dp: 6.667790222167969, learning_rate: 1.000000e-04, global_step: 130, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.379200, global_samples_per_second: 18.268200, global_steps_per_second: 2.283500, tokens_trained_current_step: 8192, timestamp: 1752747699746, TFLOPS_per_sec_per_card: 23.837000, tokens_per_sec_per_card: 18706.400000, tokens_per_sec_per_card_average: 18681.900000, lm_loss_cur_dp: 6.667790412902832, progress_or_epoch: 0.325000\r\n",
      "[INFO] 2025-07-17 18:21:44,139 [logging_callback.py:   43][rank--1]:    loss: 7.002772521972656, loss_cur_dp: 7.002772521972656, learning_rate: 1.000000e-04, global_step: 140, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.391800, global_samples_per_second: 18.215800, global_steps_per_second: 2.277000, tokens_trained_current_step: 8192, timestamp: 1752747704138, TFLOPS_per_sec_per_card: 23.769000, tokens_per_sec_per_card: 18653.200000, tokens_per_sec_per_card_average: 18679.700000, lm_loss_cur_dp: 7.002772808074951, progress_or_epoch: 0.350000\r\n",
      "[INFO] 2025-07-17 18:21:48,564 [logging_callback.py:   43][rank--1]:    loss: 6.7738395690917965, loss_cur_dp: 6.7738395690917965, learning_rate: 1.000000e-04, global_step: 150, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.424900, global_samples_per_second: 18.079400, global_steps_per_second: 2.259900, tokens_trained_current_step: 8192, timestamp: 1752747708563, TFLOPS_per_sec_per_card: 23.590000, tokens_per_sec_per_card: 18513.100000, tokens_per_sec_per_card_average: 18667.800000, lm_loss_cur_dp: 6.773839473724365, progress_or_epoch: 0.375000\r\n",
      "[INFO] 2025-07-17 18:21:52,982 [logging_callback.py:   43][rank--1]:    loss: 6.789023590087891, loss_cur_dp: 6.789023590087891, learning_rate: 1.000000e-04, global_step: 160, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.417700, global_samples_per_second: 18.108900, global_steps_per_second: 2.263600, tokens_trained_current_step: 8192, timestamp: 1752747712981, TFLOPS_per_sec_per_card: 23.629000, tokens_per_sec_per_card: 18543.400000, tokens_per_sec_per_card_average: 18659.500000, lm_loss_cur_dp: 6.7890238761901855, progress_or_epoch: 0.400000\r\n",
      "[INFO] 2025-07-17 18:21:57,398 [logging_callback.py:   43][rank--1]:    loss: 6.626300811767578, loss_cur_dp: 6.626300811767578, learning_rate: 1.000000e-04, global_step: 170, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.416400, global_samples_per_second: 18.114400, global_steps_per_second: 2.264300, tokens_trained_current_step: 8192, timestamp: 1752747717397, TFLOPS_per_sec_per_card: 23.636000, tokens_per_sec_per_card: 18549.100000, tokens_per_sec_per_card_average: 18652.600000, lm_loss_cur_dp: 6.626300811767578, progress_or_epoch: 0.425000\r\n",
      "[INFO] 2025-07-17 18:22:01,761 [logging_callback.py:   43][rank--1]:    loss: 6.652262878417969, loss_cur_dp: 6.652262878417969, learning_rate: 1.000000e-04, global_step: 180, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.362500, global_samples_per_second: 18.338200, global_steps_per_second: 2.292300, tokens_trained_current_step: 8192, timestamp: 1752747721760, TFLOPS_per_sec_per_card: 23.928000, tokens_per_sec_per_card: 18778.500000, tokens_per_sec_per_card_average: 18660.000000, lm_loss_cur_dp: 6.652263164520264, progress_or_epoch: 0.450000\r\n",
      "[INFO] 2025-07-17 18:22:06,313 [logging_callback.py:   43][rank--1]:    loss: 6.602664184570313, loss_cur_dp: 6.602664184570313, learning_rate: 1.000000e-04, global_step: 190, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.551800, global_samples_per_second: 17.575500, global_steps_per_second: 2.196900, tokens_trained_current_step: 8192, timestamp: 1752747726312, TFLOPS_per_sec_per_card: 22.933000, tokens_per_sec_per_card: 17997.000000, tokens_per_sec_per_card_average: 18623.200000, lm_loss_cur_dp: 6.602664470672607, progress_or_epoch: 0.475000\r\n",
      "[INFO] 2025-07-17 18:22:10,728 [logging_callback.py:   43][rank--1]:    loss: 6.532521057128906, loss_cur_dp: 6.532521057128906, learning_rate: 1.000000e-04, global_step: 200, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.415100, global_samples_per_second: 18.119500, global_steps_per_second: 2.264900, tokens_trained_current_step: 8192, timestamp: 1752747730727, TFLOPS_per_sec_per_card: 23.642000, tokens_per_sec_per_card: 18554.100000, tokens_per_sec_per_card_average: 18619.500000, lm_loss_cur_dp: 6.5325212478637695, progress_or_epoch: 0.500000\r\n",
      "[INFO] 2025-07-17 18:22:10,730 [  trainer.py: 2931][rank--1]:    Saving model checkpoint to ./output_pretrain/checkpoint-200\r\n",
      "[INFO] 2025-07-17 18:22:10,734 [tokenizer_utils_base.py: 1894][rank--1]:    tokenizer config file saved in ./output_pretrain/checkpoint-200/tokenizer_config.json\r\n",
      "[INFO] 2025-07-17 18:22:10,735 [tokenizer_utils_base.py: 1900][rank--1]:    Special tokens file saved in ./output_pretrain/checkpoint-200/special_tokens_map.json\r\n",
      "[INFO] 2025-07-17 18:22:10,735 [tokenizer_utils_base.py: 1929][rank--1]:    added tokens file saved in ./output_pretrain/checkpoint-200/added_tokens.json\r\n",
      "[INFO] 2025-07-17 18:22:11,105 [configuration_utils.py:  741][rank--1]:    Configuration saved in ./output_pretrain/checkpoint-200/config.json\r\n",
      "[INFO] 2025-07-17 18:22:11,107 [configuration_utils.py:  334][rank--1]:    Configuration saved in ./output_pretrain/checkpoint-200/generation_config.json\r\n",
      "[INFO] 2025-07-17 18:22:15,762 [model_utils.py: 2895][rank--1]:    Model weights saved in ./output_pretrain/checkpoint-200/model_state.pdparams\r\n",
      "[INFO] 2025-07-17 18:22:15,766 [  trainer.py: 2790][rank--1]:    Saving optimizer files.\r\n",
      "[INFO] 2025-07-17 18:22:22,073 [logging_callback.py:   43][rank--1]:    is_persistent_ckpt: 1, save_ckpt_time_sec: 11.342713, global_save_step: 200, train_time_sec_without_save: 83.604954, average_tokens_per_sec_per_card_without_save: 19596.900000, average_tokens_per_sec_per_card_with_save: 17255.820000, one_day_billion_tokens_without_save: 1.690000, one_day_billion_tokens_with_save: 1.490000, progress_or_epoch: 0.500000\r\n",
      "[INFO] 2025-07-17 18:22:26,615 [logging_callback.py:   43][rank--1]:    loss: 6.419066619873047, loss_cur_dp: 6.419066619873047, learning_rate: 1.000000e-04, global_step: 210, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.539700, global_samples_per_second: 17.622400, global_steps_per_second: 2.202800, tokens_trained_current_step: 8192, timestamp: 1752747746614, TFLOPS_per_sec_per_card: 22.994000, tokens_per_sec_per_card: 18045.300000, tokens_per_sec_per_card_average: 18045.300000, lm_loss_cur_dp: 6.419066905975342, progress_or_epoch: 0.525000\r\n",
      "[INFO] 2025-07-17 18:22:31,106 [logging_callback.py:   43][rank--1]:    loss: 6.728121948242188, loss_cur_dp: 6.728121948242188, learning_rate: 1.000000e-04, global_step: 220, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.491000, global_samples_per_second: 17.813400, global_steps_per_second: 2.226700, tokens_trained_current_step: 8192, timestamp: 1752747751105, TFLOPS_per_sec_per_card: 23.244000, tokens_per_sec_per_card: 18241.100000, tokens_per_sec_per_card_average: 18143.200000, lm_loss_cur_dp: 6.728122234344482, progress_or_epoch: 0.550000\r\n",
      "[INFO] 2025-07-17 18:22:35,609 [logging_callback.py:   43][rank--1]:    loss: 6.455517578125, loss_cur_dp: 6.455517578125, learning_rate: 1.000000e-04, global_step: 230, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.502800, global_samples_per_second: 17.766600, global_steps_per_second: 2.220800, tokens_trained_current_step: 8192, timestamp: 1752747755608, TFLOPS_per_sec_per_card: 23.182000, tokens_per_sec_per_card: 18192.800000, tokens_per_sec_per_card_average: 18159.700000, lm_loss_cur_dp: 6.455517768859863, progress_or_epoch: 0.575000\r\n",
      "[INFO] 2025-07-17 18:22:40,178 [logging_callback.py:   43][rank--1]:    loss: 6.425564575195312, loss_cur_dp: 6.425564575195312, learning_rate: 1.000000e-04, global_step: 240, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.569100, global_samples_per_second: 17.509100, global_steps_per_second: 2.188600, tokens_trained_current_step: 8192, timestamp: 1752747760177, TFLOPS_per_sec_per_card: 22.846000, tokens_per_sec_per_card: 17929.000000, tokens_per_sec_per_card_average: 18102.000000, lm_loss_cur_dp: 6.425564765930176, progress_or_epoch: 0.600000\r\n",
      "[INFO] 2025-07-17 18:22:44,584 [logging_callback.py:   43][rank--1]:    loss: 6.2918346405029295, loss_cur_dp: 6.2918346405029295, learning_rate: 1.000000e-04, global_step: 250, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.406300, global_samples_per_second: 18.155700, global_steps_per_second: 2.269500, tokens_trained_current_step: 8192, timestamp: 1752747764583, TFLOPS_per_sec_per_card: 23.690000, tokens_per_sec_per_card: 18591.700000, tokens_per_sec_per_card_average: 18200.000000, lm_loss_cur_dp: 6.291834831237793, progress_or_epoch: 0.625000\r\n",
      "[INFO] 2025-07-17 18:22:48,989 [logging_callback.py:   43][rank--1]:    loss: 6.37108154296875, loss_cur_dp: 6.37108154296875, learning_rate: 1.000000e-04, global_step: 260, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.404200, global_samples_per_second: 18.164300, global_steps_per_second: 2.270500, tokens_trained_current_step: 8192, timestamp: 1752747768988, TFLOPS_per_sec_per_card: 23.701000, tokens_per_sec_per_card: 18599.900000, tokens_per_sec_per_card_average: 18266.600000, lm_loss_cur_dp: 6.371081829071045, progress_or_epoch: 0.650000\r\n",
      "[INFO] 2025-07-17 18:22:53,446 [logging_callback.py:   43][rank--1]:    loss: 6.3871711730957035, loss_cur_dp: 6.3871711730957035, learning_rate: 1.000000e-04, global_step: 270, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.457400, global_samples_per_second: 17.947600, global_steps_per_second: 2.243400, tokens_trained_current_step: 8192, timestamp: 1752747773445, TFLOPS_per_sec_per_card: 23.418000, tokens_per_sec_per_card: 18377.900000, tokens_per_sec_per_card_average: 18282.500000, lm_loss_cur_dp: 6.387171268463135, progress_or_epoch: 0.675000\r\n",
      "[INFO] 2025-07-17 18:22:57,964 [logging_callback.py:   43][rank--1]:    loss: 6.175587844848633, loss_cur_dp: 6.175587844848633, learning_rate: 1.000000e-04, global_step: 280, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.517500, global_samples_per_second: 17.708900, global_steps_per_second: 2.213600, tokens_trained_current_step: 8192, timestamp: 1752747777963, TFLOPS_per_sec_per_card: 23.107000, tokens_per_sec_per_card: 18133.800000, tokens_per_sec_per_card_average: 18263.900000, lm_loss_cur_dp: 6.175588130950928, progress_or_epoch: 0.700000\r\n",
      "[INFO] 2025-07-17 18:23:02,408 [logging_callback.py:   43][rank--1]:    loss: 6.2560478210449215, loss_cur_dp: 6.2560478210449215, learning_rate: 1.000000e-04, global_step: 290, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.443700, global_samples_per_second: 18.003000, global_steps_per_second: 2.250400, tokens_trained_current_step: 8192, timestamp: 1752747782407, TFLOPS_per_sec_per_card: 23.491000, tokens_per_sec_per_card: 18435.300000, tokens_per_sec_per_card_average: 18283.000000, lm_loss_cur_dp: 6.25604772567749, progress_or_epoch: 0.725000\r\n",
      "[INFO] 2025-07-17 18:23:06,833 [logging_callback.py:   43][rank--1]:    loss: 6.1966102600097654, loss_cur_dp: 6.1966102600097654, learning_rate: 1.000000e-04, global_step: 300, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.425300, global_samples_per_second: 18.077900, global_steps_per_second: 2.259700, tokens_trained_current_step: 8192, timestamp: 1752747786832, TFLOPS_per_sec_per_card: 23.588000, tokens_per_sec_per_card: 18511.500000, tokens_per_sec_per_card_average: 18305.800000, lm_loss_cur_dp: 6.196610450744629, progress_or_epoch: 0.750000\r\n",
      "[INFO] 2025-07-17 18:23:11,246 [logging_callback.py:   43][rank--1]:    loss: 6.184060668945312, loss_cur_dp: 6.184060668945312, learning_rate: 1.000000e-04, global_step: 310, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.413100, global_samples_per_second: 18.127800, global_steps_per_second: 2.266000, tokens_trained_current_step: 8192, timestamp: 1752747791245, TFLOPS_per_sec_per_card: 23.654000, tokens_per_sec_per_card: 18563.100000, tokens_per_sec_per_card_average: 18329.200000, lm_loss_cur_dp: 6.184060573577881, progress_or_epoch: 0.775000\r\n",
      "[INFO] 2025-07-17 18:23:15,734 [logging_callback.py:   43][rank--1]:    loss: 6.228264617919922, loss_cur_dp: 6.228264617919922, learning_rate: 1.000000e-04, global_step: 320, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.488000, global_samples_per_second: 17.825300, global_steps_per_second: 2.228200, tokens_trained_current_step: 8192, timestamp: 1752747795733, TFLOPS_per_sec_per_card: 23.259000, tokens_per_sec_per_card: 18253.400000, tokens_per_sec_per_card_average: 18322.900000, lm_loss_cur_dp: 6.228264808654785, progress_or_epoch: 0.800000\r\n",
      "[INFO] 2025-07-17 18:23:20,118 [logging_callback.py:   43][rank--1]:    loss: 6.387460327148437, loss_cur_dp: 6.387460327148437, learning_rate: 1.000000e-04, global_step: 330, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.383800, global_samples_per_second: 18.249000, global_steps_per_second: 2.281100, tokens_trained_current_step: 8192, timestamp: 1752747800117, TFLOPS_per_sec_per_card: 23.812000, tokens_per_sec_per_card: 18686.800000, tokens_per_sec_per_card_average: 18350.900000, lm_loss_cur_dp: 6.387460231781006, progress_or_epoch: 0.825000\r\n",
      "[INFO] 2025-07-17 18:23:24,465 [logging_callback.py:   43][rank--1]:    loss: 6.1727344512939455, loss_cur_dp: 6.1727344512939455, learning_rate: 1.000000e-04, global_step: 340, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.346700, global_samples_per_second: 18.404900, global_steps_per_second: 2.300600, tokens_trained_current_step: 8192, timestamp: 1752747804464, TFLOPS_per_sec_per_card: 24.015000, tokens_per_sec_per_card: 18846.500000, tokens_per_sec_per_card_average: 18386.300000, lm_loss_cur_dp: 6.17273473739624, progress_or_epoch: 0.850000\r\n",
      "[INFO] 2025-07-17 18:23:28,896 [logging_callback.py:   43][rank--1]:    loss: 6.076834869384766, loss_cur_dp: 6.076834869384766, learning_rate: 1.000000e-04, global_step: 350, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.431100, global_samples_per_second: 18.054400, global_steps_per_second: 2.256800, tokens_trained_current_step: 8192, timestamp: 1752747808895, TFLOPS_per_sec_per_card: 23.558000, tokens_per_sec_per_card: 18487.700000, tokens_per_sec_per_card_average: 18393.100000, lm_loss_cur_dp: 6.0768351554870605, progress_or_epoch: 0.875000\r\n",
      "[INFO] 2025-07-17 18:23:33,239 [logging_callback.py:   43][rank--1]:    loss: 6.216682052612304, loss_cur_dp: 6.216682052612304, learning_rate: 1.000000e-04, global_step: 360, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.343300, global_samples_per_second: 18.419200, global_steps_per_second: 2.302400, tokens_trained_current_step: 8192, timestamp: 1752747813239, TFLOPS_per_sec_per_card: 24.034000, tokens_per_sec_per_card: 18861.300000, tokens_per_sec_per_card_average: 18422.300000, lm_loss_cur_dp: 6.216681957244873, progress_or_epoch: 0.900000\r\n",
      "[INFO] 2025-07-17 18:23:37,655 [logging_callback.py:   43][rank--1]:    loss: 6.279055786132813, loss_cur_dp: 6.279055786132813, learning_rate: 5.006144e-05, global_step: 370, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.415400, global_samples_per_second: 18.118400, global_steps_per_second: 2.264800, tokens_trained_current_step: 8192, timestamp: 1752747817654, TFLOPS_per_sec_per_card: 23.641000, tokens_per_sec_per_card: 18553.200000, tokens_per_sec_per_card_average: 18430.000000, lm_loss_cur_dp: 6.279056072235107, progress_or_epoch: 0.925000\r\n",
      "[INFO] 2025-07-17 18:23:42,112 [logging_callback.py:   43][rank--1]:    loss: 5.976035308837891, loss_cur_dp: 5.976035308837891, learning_rate: 2.644696e-05, global_step: 380, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.456200, global_samples_per_second: 17.952400, global_steps_per_second: 2.244100, tokens_trained_current_step: 8192, timestamp: 1752747822110, TFLOPS_per_sec_per_card: 23.425000, tokens_per_sec_per_card: 18383.700000, tokens_per_sec_per_card_average: 18427.400000, lm_loss_cur_dp: 5.9760355949401855, progress_or_epoch: 0.950000\r\n",
      "[INFO] 2025-07-17 18:23:46,605 [logging_callback.py:   43][rank--1]:    loss: 5.983847045898438, loss_cur_dp: 5.983847045898438, learning_rate: 1.528036e-05, global_step: 390, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.493300, global_samples_per_second: 17.804200, global_steps_per_second: 2.225500, tokens_trained_current_step: 8192, timestamp: 1752747826604, TFLOPS_per_sec_per_card: 23.231000, tokens_per_sec_per_card: 18231.300000, tokens_per_sec_per_card_average: 18417.100000, lm_loss_cur_dp: 5.983847141265869, progress_or_epoch: 0.975000\r\n",
      "[INFO] 2025-07-17 18:23:51,101 [logging_callback.py:   43][rank--1]:    loss: 6.152989196777344, loss_cur_dp: 6.152989196777344, learning_rate: 1.000000e-05, global_step: 400, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.496400, global_samples_per_second: 17.792100, global_steps_per_second: 2.224000, tokens_trained_current_step: 8192, timestamp: 1752747831100, TFLOPS_per_sec_per_card: 23.216000, tokens_per_sec_per_card: 18219.000000, tokens_per_sec_per_card_average: 18407.200000, lm_loss_cur_dp: 6.152989387512207, progress_or_epoch: 1.000000\r\n",
      "[INFO] 2025-07-17 18:23:51,103 [  trainer.py: 2931][rank--1]:    Saving model checkpoint to ./output_pretrain/checkpoint-400\r\n",
      "[INFO] 2025-07-17 18:23:51,107 [tokenizer_utils_base.py: 1894][rank--1]:    tokenizer config file saved in ./output_pretrain/checkpoint-400/tokenizer_config.json\r\n",
      "[INFO] 2025-07-17 18:23:51,107 [tokenizer_utils_base.py: 1900][rank--1]:    Special tokens file saved in ./output_pretrain/checkpoint-400/special_tokens_map.json\r\n",
      "[INFO] 2025-07-17 18:23:51,108 [tokenizer_utils_base.py: 1929][rank--1]:    added tokens file saved in ./output_pretrain/checkpoint-400/added_tokens.json\r\n",
      "[INFO] 2025-07-17 18:23:51,115 [configuration_utils.py:  741][rank--1]:    Configuration saved in ./output_pretrain/checkpoint-400/config.json\r\n",
      "[INFO] 2025-07-17 18:23:51,117 [configuration_utils.py:  334][rank--1]:    Configuration saved in ./output_pretrain/checkpoint-400/generation_config.json\r\n",
      "[INFO] 2025-07-17 18:23:54,829 [model_utils.py: 2895][rank--1]:    Model weights saved in ./output_pretrain/checkpoint-400/model_state.pdparams\r\n",
      "[INFO] 2025-07-17 18:23:54,831 [  trainer.py: 2790][rank--1]:    Saving optimizer files.\r\n",
      "[INFO] 2025-07-17 18:24:00,414 [logging_callback.py:   43][rank--1]:    is_persistent_ckpt: 1, save_ckpt_time_sec: 9.310926, global_save_step: 400, train_time_sec_without_save: 89.028941, average_tokens_per_sec_per_card_without_save: 18403.000000, average_tokens_per_sec_per_card_with_save: 16660.590000, one_day_billion_tokens_without_save: 1.590000, one_day_billion_tokens_with_save: 1.440000, progress_or_epoch: 1.000000\r\n",
      "[INFO] 2025-07-17 18:24:00,415 [  trainer.py: 1415][rank--1]:    \r\n",
      "Training completed. \r\n",
      "\r\n",
      "[INFO] 2025-07-17 18:24:00,416 [logging_callback.py:   43][rank--1]:    train_runtime: 199.118400, train_samples_per_second: 16.070800, train_steps_per_second: 2.008900, train_loss: 6.959455, progress_or_epoch: 1.000000\r\n",
      "[INFO] 2025-07-17 18:24:00,417 [  trainer.py: 2931][rank--1]:    Saving model checkpoint to ./output_pretrain/\r\n",
      "[INFO] 2025-07-17 18:24:00,420 [tokenizer_utils_base.py: 1894][rank--1]:    tokenizer config file saved in ./output_pretrain/tokenizer_config.json\r\n",
      "[INFO] 2025-07-17 18:24:00,421 [tokenizer_utils_base.py: 1900][rank--1]:    Special tokens file saved in ./output_pretrain/special_tokens_map.json\r\n",
      "[INFO] 2025-07-17 18:24:00,421 [tokenizer_utils_base.py: 1929][rank--1]:    added tokens file saved in ./output_pretrain/added_tokens.json\r\n",
      "[INFO] 2025-07-17 18:24:00,428 [configuration_utils.py:  741][rank--1]:    Configuration saved in ./output_pretrain/config.json\r\n",
      "[INFO] 2025-07-17 18:24:00,429 [configuration_utils.py:  334][rank--1]:    Configuration saved in ./output_pretrain/generation_config.json\r\n",
      "[INFO] 2025-07-17 18:24:02,927 [model_utils.py: 2895][rank--1]:    Model weights saved in ./output_pretrain/model_state.pdparams\r\n",
      "[INFO] 2025-07-17 18:24:02,928 [trainer_utils.py:  679][rank--1]:    ***** train metrics *****\r\n",
      "[INFO] 2025-07-17 18:24:02,928 [trainer_utils.py:  684][rank--1]:      progress_or_epoch        =        1.0\r\n",
      "[INFO] 2025-07-17 18:24:02,928 [trainer_utils.py:  684][rank--1]:      train_loss               =     6.9595\r\n",
      "[INFO] 2025-07-17 18:24:02,928 [trainer_utils.py:  684][rank--1]:      train_runtime            = 0:03:19.11\r\n",
      "[INFO] 2025-07-17 18:24:02,928 [trainer_utils.py:  684][rank--1]:      train_samples_per_second =    16.0708\r\n",
      "[INFO] 2025-07-17 18:24:02,928 [trainer_utils.py:  684][rank--1]:      train_steps_per_second   =     2.0089\r\n"
     ]
    }
   ],
   "source": [
    "# 1. 首先，切换工作目录到 pre-training 文件夹\n",
    "%cd ./examples/pre-training/\n",
    "\n",
    "# 2. 然后，从此目录启动训练脚本\n",
    "#    注意：配置文件的路径因为工作目录变化，需要使用 ../../ 来返回到项目根目录\n",
    "!python -u ernie/pretrain.py --config ../../pretrain_ernie_0.3b_demo.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 观察训练过程\n",
    "\n",
    "当训练开始后，您会在终端看到类似下面的日志信息（具体数值可能不同）：\n",
    "\n",
    "**关键日志解读：**\n",
    "*   `global_step`: 当前的总训练步数。\n",
    "*   `loss`: 当前这一步计算出的损失值。**这是非常重要的指标！** 我们期望看到 `loss` 随着训练的进行而逐渐下降。\n",
    "*   `learning_rate`: 当前的学习率。您可以看到它在 `warmup_steps` 内逐渐增加。\n",
    "*   `speed`: 训练速度，表示每秒处理多少步。\n",
    "*   `vram`: 训练过程中占用的显存（MB）。\n",
    "\n",
    "**预期现象：**\n",
    "*   **Loss 下降**：这是最重要的，表明模型正在从数据中学习。\n",
    "*   **显存占用**：对于 `ERNIE-4.5-0.3B` 模型，在 上述配置下，显存占用预计在 10GB 左右范围。如果出现 `CUDA out of memory` 错误，说明显存不足，需要调整配置（见后续\"进阶与常见问题\"部分）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 结果分析与解读\n",
    "\n",
    "当训练达到您在配置文件中设定的 `max_steps` 后，预训练过程就告一段落了。所有的训练输出，都会保存在配置文件 `output_dir` 指定的目录下，即 `./output_pretrain/`。\n",
    "\n",
    "训练完成后，您可以查看这个目录的内容："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:25:03.515270Z",
     "iopub.status.busy": "2025-07-17T10:25:03.514988Z",
     "iopub.status.idle": "2025-07-17T10:25:03.750814Z",
     "shell.execute_reply": "2025-07-17T10:25:03.750222Z",
     "shell.execute_reply.started": "2025-07-17T10:25:03.515248Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1.6G\r\n",
      "-rw-r--r-- 1 aistudio aistudio  23K Jul 17 18:24 added_tokens.json\r\n",
      "-rw-r--r-- 1 aistudio aistudio  179 Jul 17 18:24 all_results.json\r\n",
      "drwxr-xr-x 1 aistudio aistudio 4.0K Jul 17 17:25 \u001b[0m\u001b[01;34mcheckpoint-200\u001b[0m/\r\n",
      "drwxr-xr-x 2 aistudio aistudio 4.0K Jul 17 18:24 \u001b[01;34mcheckpoint-400\u001b[0m/\r\n",
      "-rw-r--r-- 1 aistudio aistudio 4.1K Jul 17 18:24 config.json\r\n",
      "-rw-r--r-- 1 aistudio aistudio  167 Jul 17 18:24 generation_config.json\r\n",
      "drwxr-xr-x 1 aistudio aistudio 4.0K Jul 17 15:47 \u001b[01;34mlog\u001b[0m/\r\n",
      "-rw-r--r-- 1 aistudio aistudio 1.6G Jul 17 18:24 model_state.pdparams\r\n",
      "drwxr-xr-x 1 aistudio aistudio 4.0K Jul 17 18:20 \u001b[01;34mruns\u001b[0m/\r\n",
      "-rw-r--r-- 1 aistudio aistudio  16K Jul 17 18:24 special_tokens_map.json\r\n",
      "-rw-r--r-- 1 aistudio aistudio 9.8K Jul 17 18:24 static_name_to_dyg_name.json\r\n",
      "-rw-r--r-- 1 aistudio aistudio 1.6M Jul 17 18:24 tokenizer.model\r\n",
      "-rw-r--r-- 1 aistudio aistudio 132K Jul 17 18:24 tokenizer_config.json\r\n",
      "-rw-r--r-- 1 aistudio aistudio  179 Jul 17 18:24 train_results.json\r\n",
      "-rw-r--r-- 1 aistudio aistudio  322 Jul 17 18:24 trainer_state.json\r\n",
      "-rw-r--r-- 1 aistudio aistudio 4.4K Jul 17 18:24 training_args.bin\r\n"
     ]
    }
   ],
   "source": [
    "ls -lh ./output_pretrain/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**关键文件和目录解释：**\n",
    "*   **根目录文件**：保存的是训练完成时（达到 `max_steps`）的最终模型和配置。\n",
    "*   **`checkpoint-<step_number>/`**: 这些是根据 `save_steps` 参数定期保存的检查点目录。每个检查点都包含当时的完整模型状态，可以用于从该点恢复训练，或者加载该阶段的模型进行评估。\n",
    "*   **`visualdl/`**: VisualDL 的日志文件，可以使用 `visualdl --logdir ./output_pretrain/visualdl` 来启动一个Web服务，可视化地查看 loss 曲线等指标。\n",
    "\n",
    "**初步评估预训练效果：**\n",
    "对于我们这个简短的教程，主要关注 **`loss` 是否有明显的下降趋势**。例如，从初始的 9-10 下降到 6-7 的区间，就可以认为基本的预训练流程是成功的，模型学到了一些语言的统计规律。要获得一个真正强大的模型，需要在更大规模的数据集上进行更长时间的训练。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 进阶与常见问题\n",
    "\n",
    "### 7.1 显存不足 (CUDA out of memory)\n",
    "\n",
    "这是最常见的问题。解决方案：\n",
    "1.  **增大梯度累积步数**：在配置文件中进一步增大 `gradient_accumulation_steps` (例如 16, 32)。这是最有效且推荐的方法。\n",
    "2.  **减小批大小**：将 `per_device_train_batch_size` 设为更小的值（但通常已经是1了）。\n",
    "3.  **减小序列长度**：减小 `max_seq_length` (例如 512)，但这会影响模型学习长距离依赖的能力。\n",
    "4.  **使用更激进的优化**：`ERNIEKit` 支持梯度重计算（Recompute）等更高级的显存优化技术，可以在配置文件中开启 `recompute: True`（可能在 `model_args`下），但这会增加计算时间。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 总结与展望\n",
    "\n",
    "恭喜您！通过本教程，您已经：\n",
    "\n",
    "*   了解了使用 `ERNIEKit` 对 `ERNIE 4.5` 模型进行预训练的完整流程。\n",
    "*   掌握了如何准备数据、配置 `yaml` 文件以及启动和监控训练。\n",
    "*   对预训练的核心概念、关键参数和结果分析有了深入的理解。\n",
    "\n",
    "本次教程的核心是，我们通过分析 `ERNIEKit` 的底层脚本，成功地将一个为大型集群设计的复杂预训练流程，简化为了一个可以在单张消费级显卡上运行的、适合学习和实验的迷你流程。\n",
    "\n",
    "**展望未来：**\n",
    "预训练得到的模型是一个通用的\"语言底座\"。接下来，您可以探索：\n",
    "\n",
    "*   **更大规模的预训练**：在更多的数据上，训练更长的时间，以获得性能更强的基础模型。\n",
    "*   **模型微调 (Fine-tuning)** ：这通常是预训练之后的下一步。使用有监督的数据（如问答对）对预训练好的模型进行微调（SFT），可以使其更好地遵循指令，完成特定任务。`ERNIEKit` 提供了强大的 `erniekit train` 命令来支持 SFT 和 DPO 等微调方法。\n",
    "\n",
    "希望本教程能为您打开探索文心（ERNIE）大模型世界的大门。感谢您的阅读！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 问题反馈/与我联系： Wechat：G_Fuji"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
