{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial on pre-training large language models based on ERNIE 4.5-0.3B\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "Welcome to this tutorial on pre-training the `ERNIE 4.5-0.3B` model using `ERNIEKit`! In the current AI wave, large language models (LLMs) are undoubtedly one of the brightest stars. As a leading large model in China, the Baidu ERNIE series of models has attracted widespread attention for its outstanding performance and continuous technological innovation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 What is large language model pre-training (PT)?\n",
    "\n",
    "Imagine how we learn language. Before formally learning grammar rules and vocabulary meanings, we first extensively expose ourselves to and imitate the way people around us speak. Large language model pre-training (Pre-training, PT) is similar to this.\n",
    "\n",
    "In simple terms, **pre-training refers to the process of training a model on large-scale unlabeled text data to enable it to learn the intrinsic patterns, grammatical structures, semantic information, and world knowledge of language.** At this stage, the model is not tailored for a specific task (such as downstream question-answering or translation) but focuses on building a foundational capability for general language understanding and generation. This is akin to laying a solid linguistic foundation for the model, enabling it to better adapt to various specific NLP tasks in the future.\n",
    "\n",
    "The core task of pre-training is typically “next token prediction.” Given a text segment, the model must predict the most likely next word. Through repeated prediction exercises on massive text datasets, the model gradually learns word collocation patterns, syntactic structures, and even common sense and logical reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Why choose ERNIE 4.5-0.3B and ERNIEKit?\n",
    "\n",
    "Before diving into practical applications, let's take some time to compare the `ERNIE 4.5` model and the `ERNIEKit` toolkit with other mainstream open-source solutions currently available. This will help us better understand their respective features and advantages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 Overview of the ERNIE 4.5 Model Family\n",
    "\n",
    "ERNIE 4.5 is not just a single model, but a large family of models launched by Baidu, covering a wide range of specifications from lightweight to trillion-parameter models. To better understand the positioning of the 0.3B model we are about to use, let's first take a look at the ERNIE 4.5 family as a whole:\n",
    "\n",
    "| Model Category | Model Name (Partial) | Parameter Scale (Total Parameters/Activated Parameters) | Key Features | Application Scenarios |\n",
    "| :--- | :--- | :--- | :--- | :--- |\n",
    "| MoE Large Language Model | `ERNIE-4.5-300B-A47B` | ~300B / 47B | Flagship pure language model with top-tier performance | Complex tasks requiring extreme performance |\n",
    "| MoE Large Language Model | `ERNIE-4.5-21B-A3B` | ~21B / 3B | High-performance, cost-effective MoE model | Scenarios requiring strong capabilities but with limited resources |\n",
    "| Multimodal large model | `ERNIE-4.5-VL-424B-A47B`| ~424B / 47B | Supports text, image, and video input | Complex text-image-video understanding and generation |\n",
    "| **Dense Language Model** | **`ERNIE-4.5-0.3B`** | **300 million (0.3B)** | **Lightweight, resource-friendly, standard architecture** | **Learning, experimentation, rapid validation, low-resource deployment** |\n",
    "\n",
    "*Note: MoE (Mixture-of-Experts) is an advanced model architecture with a large total number of parameters, but only a portion of the parameters are activated when processing each input, enabling efficient inference. Dense models, on the other hand, utilize all parameters during each computation.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 Why use ERNIE 4.5-0.3B as an example?\n",
    "\n",
    "From the table above, we can clearly see the unique positioning of `ERNIE 4.5-0.3B` within the family. In this tutorial, we have chosen it as the main focus based on the following considerations:\n",
    "\n",
    "1.  **Designed for learning and experimentation**: Unlike MoE giant models that often require large clusters for training, the `0.3B` (300 million) parameter count is specifically designed for developers to learn, research, and conduct rapid experiments. Its resource consumption is “user-friendly,” allowing us to complete the entire process from pre-training to fine-tuning on a personal computer or a single server.\n",
    "2. **Excellent resource efficiency**: We can run the entire process of this tutorial on a single consumer-grade GPU (such as RTX 3090/4090 with 24GB VRAM). This significantly lowers the hardware barrier for learning large-scale model technology.\n",
    "3.  **Representative of standard architecture**: As a standard dense Transformer model, the internal structure of `ERNIE 4.5-0.3B` is easier to understand, without complex components like MoE. Mastering its training process means grasping the core principles of most standard large models, laying a solid foundation for understanding more complex models in the future.\n",
    "4.  **Full Support from Official Toolchains**: `ERNIEKit` provides consistent, industrial-grade toolchain support for the entire series of models, including `0.3B`. Using it to learn the `0.3B` model is akin to driving a “training vehicle” in a “professional driving school,” enabling smooth transfer of learned skills to future operations of larger, more complex models.\n",
    "\n",
    "Therefore, `ERNIE 4.5-0.3B` is the ideal “first stop” for entering the world of large language models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.3 Comparison of mainstream development toolkits\n",
    "\n",
    "With a good model, you also need the right tools. Large model development toolkits are responsible for handling data, driving training, executing inference, and a series of other complex processes.\n",
    "\n",
    "| Features | **ERNIEKit** | **Hugging Face (transformers+trl)** | **LLaMA-Factory** |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **Developer/Community** | Baidu | Hugging Face Community | hiyouga (Community) |\n",
    "| **Core Framework** | PaddlePaddle | PyTorch, TensorFlow, JAX | PyTorch |\n",
    "| **Main Features** | Full lifecycle: pre-training, SFT, DPO, LoRA, quantization (QAT), deployment | Core component library, supports almost all models and training methods, requires writing a lot of code | One-stop fine-tuning framework, configuration-driven, supports multiple efficient fine-tuning algorithms |\n",
    "| **Usability** | Industrial-grade, command line + configuration files, provides WebUI, moderate learning curve | Highly flexible but requires strong coding skills, steep learning curve | Extremely user-friendly for beginners, provides WebUI, simple configuration, gentle learning curve |\n",
    "| **Model Support** | Focuses on ERNIE series models, provides deep optimization | Supports the widest range of open-source models (Model Hub) | Supports mainstream models such as LLaMA, Qwen, ChatGLM, etc. |\n",
    "| **Application Scenarios** | ERNIE model deep development, industrial-grade applications, PaddlePaddle technology stack | General model research, algorithm experiments, tasks requiring high customization | Quick setup, individual developers, education, efficient fine-tuning experiments |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.4 Why choose ERNIEKit?\n",
    "\n",
    "As its name suggests, `ERNIEKit` is the official toolkit tailored for the ERNIE model family. Choosing it means:\n",
    "\n",
    "*   **Optimal compatibility and performance**: ERNIEKit offers native and in-depth support for the ERNIE model series. It provides targeted optimizations to maximize the training and inference performance of the models within the PaddlePaddle framework.\n",
    "*   **Industrial-grade end-to-end workflow**: It is not just a fine-tuning tool but covers the entire workflow from data processing, pre-training, supervised fine-tuning (SFT), preference alignment (DPO), parameter-efficient adjustment (LoRA), to quantization-aware training (QAT) and deployment. Learning ERNIEKit helps understand the complete picture of large-scale model industrialization.\n",
    "* **Official maintenance and support**: As an official tool, its iterative updates are synchronized with the latest developments in ERNIE models, providing the most timely and authoritative technical support.\n",
    "\n",
    "In this tutorial, we will use `ERNIE 4.5-0.3B` as an example and explore the mysteries of pre-training using the underlying pre-training scripts provided in `ERNIEKit`. This combination (**official model + official tool**) is the optimal path for deeply understanding Baidu Wenxin's large-scale model technology system. Even when using a relatively small model and dataset, the core principles and processes are applicable to understanding the pre-training of larger models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Target Audience and Learning Outcomes of This Tutorial\n",
    "\n",
    "This tutorial is primarily intended for:\n",
    "\n",
    "* Beginners interested in pre-training large language models.\n",
    "* Developers who wish to learn how to pre-train models using the ERNIEKit (PaddlePaddle) framework.\n",
    "* Learners with a basic understanding of Python and deep learning who wish to gain hands-on experience with LLM.\n",
    "\n",
    "By the end of this tutorial, you will be able to:\n",
    "\n",
    "* Understand the basic concepts and significance of large language model pre-training.\n",
    "* Master the complete process of pre-training the ERNIE 4.5 model using ERNIEKit.\n",
    "* Understand methods for preparing pre-training data.\n",
    "* Learn how to configure the `yaml` file and launch the pre-training task.\n",
    "* Conduct an initial analysis of pre-training results.\n",
    "* Lay the groundwork for subsequent model fine-tuning and specific task applications.\n",
    "\n",
    "Let’s embark on this exciting learning journey together!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Environment Preparation\n",
    "\n",
    "Before embarking on our pre-training journey, we need to ensure that we have the correct development environment. This mainly involves installing the core deep learning frameworks PaddlePaddle and ERNIEKit toolkit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Installing PaddlePaddle and ERNIEKit\n",
    "\n",
    "ERNIEKit has certain environment requirements. **We strongly recommend using the officially recommended Docker image** to avoid issues caused by inconsistent environments. If Docker is unavailable, ensure your local environment meets the prerequisites outlined in the official documentation (https://github.com/PaddlePaddle/ERNIE/blob/develop/docs/erniekit.md#21-prerequisites), such as CUDA >= 12.3, Python 3.10+, etc.\n",
    "\n",
    "**1. Clone the ERNIE-develop repository**\n",
    "\n",
    "The ERNIEKit code and all scripts are contained in the `ERNIE-develop` repository. First, we need to clone it to our local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:20:06.135474Z",
     "iopub.status.busy": "2025-07-17T10:20:06.135162Z",
     "iopub.status.idle": "2025-07-17T10:20:06.139232Z",
     "shell.execute_reply": "2025-07-17T10:20:06.138750Z",
     "shell.execute_reply.started": "2025-07-17T10:20:06.135453Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/ERNIE-develop\r\n"
     ]
    }
   ],
   "source": [
    "# git clone https://github.com/PaddlePaddle/ERNIE.git\n",
    "%cd ERNIE-develop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Install dependencies**\n",
    "\n",
    "All dependencies required by ERNIEKit are listed in the `requirements/gpu/requirements.txt` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python -m pip install -r requirements/gpu/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verify installation**:\n",
    "\n",
    "After installation, you can run the following code to verify that PaddlePaddle has been successfully installed and can correctly identify your GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T02:30:28.775301Z",
     "iopub.status.busy": "2025-07-17T02:30:28.774920Z",
     "iopub.status.idle": "2025-07-17T02:30:30.527612Z",
     "shell.execute_reply": "2025-07-17T02:30:30.526670Z",
     "shell.execute_reply.started": "2025-07-17T02:30:28.775277Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/utils/cpp_extension/extension_utils.py:715: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\r\n",
      "  warnings.warn(warning_message)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running verify PaddlePaddle program ... \r\n",
      "PaddlePaddle works well on 1 GPU.\r\n",
      "PaddlePaddle is installed successfully! Let's start deep learning with PaddlePaddle now.\r\n",
      "PaddlePaddle GPU is available!\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0717 10:30:30.392132   294 pir_interpreter.cc:1524] New Executor is Running ...\r\n",
      "W0717 10:30:30.393514   294 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.8, Runtime API Version: 12.6\r\n",
      "I0717 10:30:30.394114   294 pir_interpreter.cc:1547] pir interpreter is running by multi-thread mode ...\r\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "\n",
    "# Check if GPU is available\n",
    "try:\n",
    "    paddle.utils.run_check()\n",
    "    print(\"PaddlePaddle GPU is available!\")\n",
    "except Exception as e:\n",
    "    print(f\"PaddlePaddle GPU check failed: {e}\")\n",
    "    print(\"If you intended to use GPU, please check your CUDA setup and PaddlePaddle installation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, our environment setup is complete! Next, we will prepare the data for pre-training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preparation\n",
    "\n",
    "Large language models are “large” not only in terms of the number of parameters, but also in terms of the massive amount of data on which their training relies. The data used in the pre-training stage is the source from which the model learns language knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Pre-training Data Format (.bin / .idx)\n",
    "\n",
    "To efficiently load and process large-scale text data, `ERNIEKit` and `PaddleNLP` use the standard binary `mmap` (memory-mapped file) format.\n",
    "\n",
    "*   **.bin file**: This is a binary file that stores the sequence of token IDs obtained after all text data has been processed by the tokenizer. In simple terms, all text has been converted into numbers.\n",
    "*   **.idx file**: This is an index file that records the starting position and length of each training sample (usually an article or document) in the `.bin` file. This allows for quick access to any data during training.\n",
    "\n",
    "This data organization format has the following advantages:\n",
    "\n",
    "* **Efficient reading**: The file content can be directly mapped in memory, avoiding a large number of disk I/O operations.\n",
    "* **Memory saving**: It is not necessary to load all data into memory at once; data can be read on demand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Obtaining pre-trained data\n",
    "\n",
    "To help users get started quickly, PaddleNLP officially provides a processed subset of the OpenWebTextCorpus dataset, containing approximately 100,000 articles. We will use this dataset as an example in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T02:31:26.758876Z",
     "iopub.status.busy": "2025-07-17T02:31:26.758503Z",
     "iopub.status.idle": "2025-07-17T02:31:26.974419Z",
     "shell.execute_reply": "2025-07-17T02:31:26.973689Z",
     "shell.execute_reply.started": "2025-07-17T02:31:26.758856Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a data folder in the ERNIE-develop directory\n",
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T02:32:02.156163Z",
     "iopub.status.busy": "2025-07-17T02:32:02.155771Z",
     "iopub.status.idle": "2025-07-17T02:32:04.602744Z",
     "shell.execute_reply": "2025-07-17T02:32:04.602043Z",
     "shell.execute_reply.started": "2025-07-17T02:32:02.156140Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-07-17 10:32:02--  https://bj.bcebos.com/paddlenlp/models/transformers/llama/data/llama_openwebtext_100k.bin\r\n",
      "Resolving bj.bcebos.com (bj.bcebos.com)... 100.67.184.196, 100.64.80.160, 100.67.184.48\r\n",
      "Connecting to bj.bcebos.com (bj.bcebos.com)|100.67.184.196|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 246736546 (235M) [application/octet-stream]\r\n",
      "Saving to: './data/llama_openwebtext_100k.bin'\r\n",
      "\r\n",
      "llama_openwebtext_1 100%[===================>] 235.31M   123MB/s    in 1.9s    \r\n",
      "\r\n",
      "2025-07-17 10:32:04 (123 MB/s) - './data/llama_openwebtext_100k.bin' saved [246736546/246736546]\r\n",
      "\r\n",
      "--2025-07-17 10:32:04--  https://bj.bcebos.com/paddlenlp/models/transformers/llama/data/llama_openwebtext_100k.idx\r\n",
      "Resolving bj.bcebos.com (bj.bcebos.com)... 100.67.184.48, 100.64.80.160, 100.67.184.196\r\n",
      "Connecting to bj.bcebos.com (bj.bcebos.com)|100.67.184.48|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 2000042 (1.9M) [application/octet-stream]\r\n",
      "Saving to: './data/llama_openwebtext_100k.idx'\r\n",
      "\r\n",
      "llama_openwebtext_1 100%[===================>]   1.91M  --.-KB/s    in 0.02s   \r\n",
      "\r\n",
      "2025-07-17 10:32:04 (126 MB/s) - './data/llama_openwebtext_100k.idx' saved [2000042/2000042]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# Download data file\n",
    "!wget https://bj.bcebos.com/paddlenlp/models/transformers/llama/data/llama_openwebtext_100k.bin -P ./data/\n",
    "!wget https://bj.bcebos.com/paddlenlp/models/transformers/llama/data/llama_openwebtext_100k.idx -P ./data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the download is complete, there should be two files in your `./data/` directory:\n",
    "*   `llama_openwebtext_100k.bin`\n",
    "*   `llama_openwebtext_100k.idx`\n",
    "\n",
    "**Important Note:** Although these data files were originally prepared for the LLaMA model, their `mmap` format is universal and can also be used for pre-training models such as ERNIE. During actual training, we will use the ERNIE 4.5 Tokenizer to process the token IDs converted from these text data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 (Optional) Using Custom Data\n",
    "\n",
    "If you want to use your own text data, you need to convert it to `.bin` and `.idx` formats. The `PaddleNLP` repository (note that this is not the ERNIE-develop repository) provides a data preprocessing script `llm/tools/preprocess_data.py`.\n",
    "\n",
    "The general process is as follows:\n",
    "1.  **Collect** your raw text data (e.g., `.txt` or `.jsonl` files).\n",
    "2.  **Run the script**: Use the `preprocess_data.py` script, specifying the `tokenizer_name_or_path` corresponding to the model (e.g., use the tokenizer from `PaddlePaddle/ERNIE-4.5-0.3B-Paddle`), to convert your text files into `.bin` and `.idx` files.\n",
    "    ```bash\n",
    "    # Example command (must be run in the PaddleNLP repository and its dependencies must be installed)\n",
    "    # python llm/tools/preprocess_data.py \\\n",
    "    #     --model_name_or_path PaddlePaddle/ERNIE-4.5-0.3B-Paddle \\\n",
    "    #     --input_path /path/to/your/text_files.list \\\n",
    "    #     --output_prefix /path/to/your/output/my_data\n",
    "    ```\n",
    "For detailed usage, please refer to the relevant documentation in the PaddleNLP repository. For this tutorial, we will directly use the pre-downloaded data.\n",
    "\n",
    "Now that the data is ready, we will briefly introduce the basic principles of large model pre-training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Introduction to the Principles of Model Pre-training\n",
    "\n",
    "Before we start running the code, it is helpful to take some time to understand the basic principles behind pre-training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Core Idea: Next Token Prediction\n",
    "\n",
    "The most core and classic task in large language model pre-training is **Next Token Prediction**, also known as Causal Language Modeling (CLM).\n",
    "\n",
    "**In simple terms, given a text sequence, the model's objective is to predict the next token in the sequence.**  \n",
    "\n",
    "**For example:**  \n",
    "\n",
    "Suppose we have the following sentence: \"The weather is really nice today, let's go to the park together.\"\n",
    "\n",
    "1. When the model sees: `[\"The\"]` -> It needs to predict: `\"weather\"`\n",
    "2. When the model sees: `[\"The\", \"weather\"]` -> It needs to predict: `\"is\"`\n",
    "3. When the model sees: `[\"The\", \"weather\", \"is\"]` -> It needs to predict: `\"really\"`\n",
    "4. When the model sees: `[\"The\", \"weather\", \"is\", \"really\"]` -> It needs to predict: `\"nice\"`\n",
    "\n",
    "The model is exposed to a massive amount of text data and continuously plays this “word prediction game” on this data. By comparing its predictions with the next word in the actual text, the model calculates an “error rate” (i.e., loss) and then adjusts its internal parameters (weights) based on this error to improve the accuracy of its predictions.\n",
    "\n",
    "Although this process is simple, when the amount of data is large enough and the model parameters are numerous enough, the model must learn to reduce prediction errors by:\n",
    "\n",
    "*   **Vocabulary knowledge**: which words frequently appear together.\n",
    "*   **Grammatical structure**: subject-verb-object, tense, etc.\n",
    "*   **Semantic coherence**: how the context should flow.\n",
    "*   **Common sense knowledge**: for example, “the sky is blue.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Model Architecture: Transformer\n",
    "\n",
    "Currently, almost all mainstream large language models, including ERNIE 4.5, are based on the **Transformer** architecture. For the Next Token Prediction task, the **Decoder-Only** architecture of the Transformer is typically used.\n",
    "\n",
    "Its core components include:\n",
    "1.  **Embedding Layer**: Converts input token IDs into vectors that capture semantic meaning.\n",
    "2.  **Positional Encoding**: Injects positional information about tokens within the sequence into the model.\n",
    "3.  **Multi-Head Self-Attention**: The core of the Transformer, allowing the model to dynamically focus on information from all other tokens in the sequence while processing a single token.\n",
    "4.  **Feed-Forward Network**: Performs further nonlinear transformations to enhance the model's expressive capabilities.\n",
    "5.  **Layer Normalization and Residual Connections**: Stabilize the training process, enabling the training of deeper networks.\n",
    "\n",
    "By stacking multiple such Transformer Blocks (e.g., ERNIE 4.5-0.3B has 32 layers), the model can learn highly complex language patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Loss Function: Cross-Entropy\n",
    "\n",
    "After the model predicts the probability distribution of the next word, we use **cross-entropy loss** to measure the accuracy of the prediction. It compares the **probability distribution predicted by the model** with the **actual next word** to determine the “difference” between them. The goal of training is to continuously adjust the model's parameters to minimize the total cross-entropy loss across the entire training dataset.  \n",
    "\n",
    "With an understanding of these basic principles, we can now proceed with greater confidence into practical implementation!  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Start pre-training\n",
    "\n",
    "With the theoretical knowledge in place and the data ready, it's time to put theory into practice and launch our first ERNIE 4.5 pre-training task!\n",
    "\n",
    "**Important prerequisites:**\n",
    "1.  Please ensure that you have installed all dependencies according to the instructions in the **“2. Environment Preparation”** section.\n",
    "2. Please ensure that you have downloaded the data files and placed them in the `./data/` directory according to the instructions in the **“3. Data Preparation”** section.\n",
    "3. **Working Directory**: All subsequent commands assume that your current terminal working directory is `ERNIE-develop`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Pre-training Script and Configuration File\n",
    "\n",
    "We know that the core script for pre-training in `ERNIEKit` is `./examples/pre-training/ernie/pretrain`. We need to use a `yaml` configuration file to tell this script which model to use, what data to use, and how to train.\n",
    "\n",
    "The `pretrain_96_gpus.yaml` file in the original repository is designed for trillion-scale MoE models on large clusters and cannot be used directly. We need to create a simplified configuration file specifically for training the `ERNIE 4.5-0.3B` model on a single GPU.\n",
    "\n",
    "**Create the configuration file `pretrain_ernie_0.3b_demo.yaml`**\n",
    "\n",
    "Create a new `yaml` file named `pretrain_ernie_0.3b_demo.yaml` in the `ERNIE-develop` directory and copy the following content into it:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "# Example configuration file for ERNIE 4.5-0.3B single-card pre-training\n",
    "\n",
    "# ---------------------------model args------------------------------------- ------------#\n",
    "model_args:\n",
    "    model_name_or_path: “../../../data/models/30654/ERNIE-4.5-0.3B-Base-Paddle” # Specify the model name; ERNIEKit will attempt to download it from AI Studio or HuggingFace\n",
    "    tokenizer_name: “../../../data/models/30654/ERNIE-4.5-0.3B-Base-Paddle” # Specify the tokenizer\n",
    "    output_dir: ./output_pretrain/ # Output directory for model weights, logs, etc. during training\n",
    "    max_seq_length: 1024 # Maximum sequence length processed by the model, adjustable based on GPU memory\n",
    "\n",
    "# ---------------------------trainer args-------------------------------------- -----------#\n",
    "trainer_args:\n",
    "    input_dir: “1.0 ../../data/llama_openwebtext_100k 1.0 ../../data/llama_openwebtext_100k” # Weights and paths of training and validation datasets\n",
    "    split: “998,1,1” # Split ratio for training, validation, and test sets\n",
    "\n",
    "    do_train: True\n",
    "    dataloader_num_workers: 0 # Recommended to set to 0 on Windows; can be increased appropriately on Linux\n",
    "    disable_tqdm: True\n",
    "    logging_steps: 10 # Print logs every 10 steps\n",
    "    eval_steps: 100 # Evaluate every 100 steps\n",
    "    save_steps: 200 # Save model weights (checkpoint) every 200 steps\n",
    "    max_steps: 400 # Maximum number of training steps, for quick demonstration\n",
    "    \n",
    "    # --- Learning rate and optimizer ---\n",
    "    adam_beta1: 0.9\n",
    "adam_beta2: 0.95\n",
    "adam_epsilon: 1e-8\n",
    "learning_rate: 1e-4\n",
    "min_lr: 1e-5\n",
    "lr_scheduler: “wsd_cosine” # Use a cosine annealing learning rate strategy with warmup\n",
    "max_grad_norm: 1.0\n",
    "    weight_decay: 0.1\n",
    "    warmup_steps: 50 # Learning rate warmup steps\n",
    "    \n",
    "    # --- Batch size and memory ---\n",
    "    gradient_accumulation_steps: 8 # Gradient accumulation steps\n",
    "    per_device_train_batch_size: 1 # Batch size per card, actual batch_size = per_device_train_batch_size * gradient_accumulation_steps\n",
    "    per_device_eval_batch_size: 2\n",
    "    head_dim: 128 # Attention head dimension size, must be consistent with the pre-trained model\n",
    "    \n",
    "    # --- Performance and accuracy ---\n",
    "    bf16: False # Whether to enable BF16. If the GPU does not support it (such as the 30/40 series), set it to False\n",
    "    fp16: True  # Whether to enable FP16 (mixed precision) training, which is friendly to the 30/40 series GPUs\n",
    "    fp16_opt_level: “O1” # FP16 optimization level, O1 is more stable\n",
    "    \n",
    "    # --- Distributed parameters (set to 1 or default for single-card training) ---\n",
    "    moe_group: “dummy” # For non-MoE models, set to dummy to disable MoE-related logic\n",
    "    pipeline_parallel_degree: 1\n",
    "    tensor_parallel_degree: 1\n",
    "    sharding: “” # Do not use sharding for single-card training\n",
    "    \n",
    "    # --- Other ---\n",
    "    seed: 42\n",
    "    save_total_limit: 2 # Maximum number of checkpoints to save\n",
    "    overwrite_output_dir: true # Overwrite the output directory\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Parameter Explanation**:\n",
    "*   `model_name_or_path`: Specifies the model we want to train. ERNIEKit will automatically handle the download.\n",
    "*   `output_dir`: The location where all training products (model weights, logs) are saved.\n",
    "*   `input_dir`: Points to the downloaded `.bin` and `.idx` data files. **Note**: No file extensions are needed here; only the path is required.\n",
    "* `max_seq_length`: The maximum text length the model can process. The larger this value, the higher the GPU memory usage. 1024 is safe for most GPUs with 24GB of memory.\n",
    "* `max_steps`, `save_steps`, `logging_steps`: Control the total number of training steps, save frequency, and logging frequency. We set these to smaller values to see results quickly.\n",
    "* `per_device_train_batch_size` & `gradient_accumulation_steps`: These are key parameters for controlling the **effective batch size** and **GPU memory usage**. `per_device_train_batch_size` specifies the number of samples per forward pass, directly affecting GPU memory usage. By accumulating gradients over `gradient_accumulation_steps` steps before updating the model, we can achieve an effective batch size of `1 * 8 = 8` without increasing memory usage.\n",
    "*   `fp16: True`: Enables mixed-precision training, significantly reducing memory usage and accelerating training, which is critical for consumer-grade GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Downloading the model\n",
    "\n",
    "Before starting training, we need to download the `ERNIE-4.5-0.3B-Paddle` model file to our local machine. You can use `aistudio-sdk` (recommended) or `huggingface-cli`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First, install aistudio-sdk:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade aistudio-sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Then download the model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!aistudio download --model PaddlePaddle/ERNIE-4.5-0.3B-Paddle --local_dir baidu/ERNIE-4.5-0.3B-Paddle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the download is complete, the path `“baidu/ERNIE-4.5-0.3B-Paddle”` specified in our configuration file will be found correctly. If you encounter a `time out` during download, you can try downloading again or use the model mounted in [this project](https://aistudio.baidu.com/project/edit/9382861): /home/aistudio/data/models/30654/ERNIE-4.5-0.3B-Base-Paddle.\n",
    "\n",
    "\n",
    "This project will use the mounted model for demonstration purposes!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Starting Single-Card Pre-training\n",
    "\n",
    "Once everything is ready, we can execute the following commands in the `ERNIE-develop` directory to start single-card pre-training.\n",
    "\n",
    "- /home/aistudio/ERNIE-develop/examples/pre-training/models/moe/token_dispatcher/fp8_utils.py, comment out the import of Fp8\n",
    "- /home/aistudio/ERNIE-develop/examples/pre-training/models/fp8_linear.py, comment out the import of Fp8\n",
    "- /home/aistudio/ERNIE-develop/examples/pre-training/models/ernie/modeling.py, comment out the import of Fp8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix MoE parameter error (if encountered)\n",
    "\n",
    "If you encounter errors such as `KeyError: ‘moe_group’` while running the script, it is because the script assumes that the configuration file must contain the `moe_group` parameter (which is designed for MoE models), but our simplified configuration does not include it (because `ERNIE-4.5-0.3B` is a dense model).\n",
    "\n",
    "**Quick fix steps**:\n",
    "1. Open the file `ERNIE-develop/examples/pre-training/ernie/pretrain.py` (using a text editor).\n",
    "2. Find this line (approximately line 394): `if trainer_args[“moe_group”].lower() in {“mp”, “tp”, ‘model’, “dummy”}:`\n",
    "3. Modify it to: `moe_group = trainer_args.get(“moe_group”, None)  # Add a check to avoid KeyError\\nif moe_group and moe_group.lower() in {“mp”, “tp”, ‘model’, “dummy”}:`\n",
    "4. Add `self.head_dim = None` to the ErnieMoEConfig class in `/home/aistudio/ERNIE-develop/examples/pre-training/models/ernie/configuration.py` (approximately line 247).\n",
    "5. Add the following to approximately line 1502 in `/home/aistudio/ERNIE-develop/examples/pre-training/models/ernie/modeling_moe.py` (reason: the official code uses the float64 type when calculating the sin and cos caches for RoPE, while the example model expects float32):\n",
    "```\n",
    "            cos_cached = np.cos(emb)[:, :].astype(“float32”)\n",
    "            sin_cached = np.sin(emb)[:, :].astype(“float32”)\n",
    "```\n",
    "6. In `/home/aistudio/ERNIE-develop/examples/pre-training/ernie/src/trainers/pretraining_trainer.py` around line 1096, remove:  (Add a check for a distributed environment)\n",
    "```python\n",
    "# dist.all_reduce(tr_loss, dist.ReduceOp.SUM)\n",
    "# tr_loss_scalar = tr_loss.item() / dist.get_world_size()\n",
    "\n",
    "```\n",
    "Add:\n",
    "```python\n",
    "            if self.args.world_size > 1:\n",
    "                dist.all_reduce(tr_loss, dist.ReduceOp.SUM)\n",
    "                tr_loss_scalar = tr_loss.item() / dist.get_world_size()\n",
    "            else:\n",
    "                tr_loss_scalar = tr_loss_single_dp_scalar\n",
    "\n",
    "```\n",
    "\n",
    "Remove (approximately line 1150):\n",
    "```python\n",
    "dist.all_reduce(numel_tensor)\n",
    "```\n",
    "Add:\n",
    "\n",
    "```python\n",
    "                if self.args.world_size > 1:\n",
    "                    dist.all_reduce(numel_tensor)\n",
    "```\n",
    "\n",
    "Remove (approximately line 1212):\n",
    "```python\n",
    "\n",
    "paddle.distributed.barrier()\n",
    "```\n",
    "\n",
    "Add:\n",
    "```python\n",
    "if self.args.world_size > 1:\n",
    "                paddle.distributed.barrier()\n",
    "```\n",
    "6. Save the file and rerun the startup command.\n",
    "\n",
    "This modification is safe and will not affect our training because we do not use the MoE feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:20:31.400242Z",
     "iopub.status.busy": "2025-07-17T10:20:31.399933Z",
     "iopub.status.idle": "2025-07-17T10:24:04.158096Z",
     "shell.execute_reply": "2025-07-17T10:24:04.157357Z",
     "shell.execute_reply.started": "2025-07-17T10:20:31.400223Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/ERNIE-develop/examples/pre-training\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/utils/cpp_extension/extension_utils.py:715: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\r\n",
      "  warnings.warn(warning_message)\r\n",
      "/home/aistudio/external-libraries/lib/python3.10/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\r\n",
      "  warnings.warn(\r\n",
      "[WARNING] 2025-07-17 18:20:33,983 [ modeling.py:   75]:    Use flash attention in scaled-dot-product. Attention mask is deprecated\r\n",
      "W0717 18:20:34.138628  2289 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.8, Runtime API Version: 12.6\r\n",
      "[WARNING] 2025-07-17 18:20:34,147 [    utils.py:   28]:    moe_permutation is not installed.\r\n",
      "[INFO] 2025-07-17 18:20:34,169 [trainer_utils.py:   71]:    The Training Main Process Started Successfully. time: 2025-07-17 18:20:34, pid: 2289\r\n",
      "[INFO] 2025-07-17 18:20:34,633 [process_utils.py:  180]:    Check affinity before setting: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127}\r\n",
      "[INFO] 2025-07-17 18:20:34,633 [process_utils.py:  183]:    check affinity after setting: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95}\r\n",
      "[INFO] 2025-07-17 18:20:34,633 [ pretrain.py:  163]:    set affinity successed.\r\n",
      "model_args:\r\n",
      "    max_seq_length: 1024\r\n",
      "    model_name_or_path: ../../../data/models/30654/ERNIE-4.5-0.3B-Base-Paddle\r\n",
      "    output_dir: ./output_pretrain/\r\n",
      "    tokenizer_name: ../../../data/models/30654/ERNIE-4.5-0.3B-Base-Paddle\r\n",
      "trainer_args:\r\n",
      "    adam_beta1: 0.9\r\n",
      "    adam_beta2: 0.95\r\n",
      "    adam_epsilon: 1.0e-08\r\n",
      "    bf16: false\r\n",
      "    dataloader_num_workers: 0\r\n",
      "    disable_tqdm: true\r\n",
      "    do_train: true\r\n",
      "    eval_steps: 100\r\n",
      "    fp16: true\r\n",
      "    fp16_opt_level: O1\r\n",
      "    gradient_accumulation_steps: 8\r\n",
      "    head_dim: 128\r\n",
      "    input_dir: 1.0 ../../data/llama_openwebtext_100k 1.0 ../../data/llama_openwebtext_100k\r\n",
      "    learning_rate: 0.0001\r\n",
      "    logging_steps: 10\r\n",
      "    lr_scheduler: wsd_cosine\r\n",
      "    max_grad_norm: 1.0\r\n",
      "    max_steps: 400\r\n",
      "    min_lr: 1.0e-05\r\n",
      "    moe_group: dummy\r\n",
      "    overwrite_output_dir: true\r\n",
      "    per_device_eval_batch_size: 2\r\n",
      "    per_device_train_batch_size: 1\r\n",
      "    pipeline_parallel_degree: 1\r\n",
      "    save_steps: 200\r\n",
      "    save_total_limit: 2\r\n",
      "    seed: 42\r\n",
      "    sharding: ''\r\n",
      "    split: 998,1,1\r\n",
      "    tensor_parallel_degree: 1\r\n",
      "    warmup_steps: 50\r\n",
      "    weight_decay: 0.1\r\n",
      "\r\n",
      "[INFO] 2025-07-17 18:20:34,657 [argparser.py:  426]:    user has defined resume_from_checkpoint: None\r\n",
      "[INFO] 2025-07-17 18:20:34,658 [training_args.py: 1837]:    The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\r\n",
      "[WARNING] 2025-07-17 18:20:34,658 [pretraining_trainer.py:  320]:    eval_batch_size set to 1\r\n",
      "[INFO] 2025-07-17 18:20:34,659 [ pretrain.py:  235]:    model_config_from_yaml: {}\r\n",
      "[INFO] 2025-07-17 18:20:34,663 [seed_utils.py:   76][rank--1]:    The global seed is set to 1067 and local seed is set to 1068. mp_init_seed=43\r\n",
      "[INFO] 2025-07-17 18:20:34,663 [ pretrain.py:  398][rank--1]:    disable moe flag when using moe-group=dummy\r\n",
      "[INFO] 2025-07-17 18:20:34,667 [configuration_utils.py:  887][rank--1]:    Loading configuration file ../../../data/models/30654/ERNIE-4.5-0.3B-Base-Paddle/config.json\r\n",
      "[WARNING] 2025-07-17 18:20:34,672 [configuration_utils.py:  918][rank--1]:    You are using a model of type ernie4_5 to instantiate a model of type ernie. This is not supported for all configurations of models and can yield errors.\r\n",
      "[INFO] 2025-07-17 18:20:36,029 [ pretrain.py:  426][rank--1]:    using tokenizer=<class 'src.tokenizers.tokenization_eb_v2.ErnieBotTokenizer'>, bos:1 eos:2 pad:0 \r\n",
      "[INFO] 2025-07-17 18:20:36,030 [modeling_moe.py: 1955][rank--1]:    change initializer-range from 0.02 to 0.018041293779826325\r\n",
      "[INFO] 2025-07-17 18:20:36,030 [modeling_moe.py:  220][rank--1]:    using moe-group: dummy\r\n",
      "[INFO] 2025-07-17 18:20:36,040 [ modeling.py:  846][rank--1]:    using recompute attn=False\r\n",
      "[INFO] 2025-07-17 18:20:36,040 [ modeling.py:  868][rank--1]:    use GQA - num_heads: 16- num_key_value_heads: 2\r\n",
      "[INFO] 2025-07-17 18:20:36,207 [ modeling.py:  846][rank--1]:    using recompute attn=False\r\n",
      "[INFO] 2025-07-17 18:20:36,207 [ modeling.py:  868][rank--1]:    use GQA - num_heads: 16- num_key_value_heads: 2\r\n",
      "[INFO] 2025-07-17 18:20:36,210 [ modeling.py:  846][rank--1]:    using recompute attn=False\r\n",
      "[INFO] 2025-07-17 18:20:36,211 [ modeling.py:  868][rank--1]:    use GQA - num_heads: 16- num_key_value_heads: 2\r\n",
      "[INFO] 2025-07-17 18:20:36,214 [ modeling.py:  846][rank--1]:    using recompute attn=False\r\n",
      "[INFO] 2025-07-17 18:20:36,214 [ modeling.py:  868][rank--1]:    use GQA - num_heads: 16- num_key_value_heads: 2\r\n",
      "[INFO] 2025-07-17 18:20:36,217 [ modeling.py:  846][rank--1]:    using recompute attn=False\r\n",
      "[INFO] 2025-07-17 18:20:36,217 [ modeling.py:  868][rank--1]:    use GQA - num_heads: 16- num_key_value_heads: 2\r\n",
      "[INFO] 2025-07-17 18:20:36,220 [ modeling.py:  846][rank--1]:    using recompute attn=False\r\n",
      "[INFO] 2025-07-17 18:20:36,220 [ modeling.py:  868][rank--1]:    use GQA - num_heads: 16- num_key_value_heads: 2\r\n",
      "[INFO] 2025-07-17 18:20:36,223 [ modeling.py:  846][rank--1]:    using recompute attn=False\r\n",
      "[INFO] 2025-07-17 18:20:36,223 [ modeling.py:  868][rank--1]:    use GQA - num_heads: 16- num_key_value_heads: 2\r\n",
      "[INFO] 2025-07-17 18:20:36,226 [ modeling.py:  846][rank--1]:    using recompute attn=False\r\n",
      "[INFO] 2025-07-17 18:20:36,227 [ modeling.py:  868][rank--1]:    use GQA - num_heads: 16- num_key_value_heads: 2\r\n",
      "[INFO] 2025-07-17 18:20:36,230 [ modeling.py:  846][rank--1]:    using recompute attn=False\r\n",
      "[INFO] 2025-07-17 18:20:36,230 [ modeling.py:  868][rank--1]:    use GQA - num_heads: 16- num_key_value_heads: 2\r\n",
      "[INFO] 2025-07-17 18:20:36,233 [ modeling.py:  846][rank--1]:    using recompute attn=False\r\n",
      "[INFO] 2025-07-17 18:20:36,233 [ modeling.py:  868][rank--1]:    use GQA - num_heads: 16- num_key_value_heads: 2\r\n",
      "[INFO] 2025-07-17 18:20:36,236 [ modeling.py:  846][rank--1]:    using recompute attn=False\r\n",
      "[INFO] 2025-07-17 18:20:36,236 [ modeling.py:  868][rank--1]:    use GQA - num_heads: 16- num_key_value_heads: 2\r\n",
      "[INFO] 2025-07-17 18:20:36,239 [ modeling.py:  846][rank--1]:    using recompute attn=False\r\n",
      "[INFO] 2025-07-17 18:20:36,239 [ modeling.py:  868][rank--1]:    use GQA - num_heads: 16- num_key_value_heads: 2\r\n",
      "[INFO] 2025-07-17 18:20:36,242 [ modeling.py:  846][rank--1]:    using recompute attn=False\r\n",
      "[INFO] 2025-07-17 18:20:36,243 [ modeling.py:  868][rank--1]:    use GQA - num_heads: 16- num_key_value_heads: 2\r\n",
      "[INFO] 2025-07-17 18:20:36,246 [ modeling.py:  846][rank--1]:    using recompute attn=False\r\n",
      "[INFO] 2025-07-17 18:20:36,246 [ modeling.py:  868][rank--1]:    use GQA - num_heads: 16- num_key_value_heads: 2\r\n",
      "[INFO] 2025-07-17 18:20:36,249 [ modeling.py:  846][rank--1]:    using recompute attn=False\r\n",
      "[INFO] 2025-07-17 18:20:36,249 [ modeling.py:  868][rank--1]:    use GQA - num_heads: 16- num_key_value_heads: 2\r\n",
      "[INFO] 2025-07-17 18:20:36,252 [ modeling.py:  846][rank--1]:    using recompute attn=False\r\n",
      "[INFO] 2025-07-17 18:20:36,253 [ modeling.py:  868][rank--1]:    use GQA - num_heads: 16- num_key_value_heads: 2\r\n",
      "[INFO] 2025-07-17 18:20:36,256 [ modeling.py:  846][rank--1]:    using recompute attn=False\r\n",
      "[INFO] 2025-07-17 18:20:36,256 [ modeling.py:  868][rank--1]:    use GQA - num_heads: 16- num_key_value_heads: 2\r\n",
      "[INFO] 2025-07-17 18:20:36,259 [ modeling.py:  846][rank--1]:    using recompute attn=False\r\n",
      "[INFO] 2025-07-17 18:20:36,259 [ modeling.py:  868][rank--1]:    use GQA - num_heads: 16- num_key_value_heads: 2\r\n",
      "[INFO] 2025-07-17 18:20:36,276 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[103424, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Embedding'>, norm=185.66087341308594,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:36,276 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.482173919677734,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:36,277 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.556285381317139,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:36,277 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.524847030639648,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:36,277 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.455974578857422,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:36,559 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=32.006832122802734,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:36,560 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.995466232299805,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:36,560 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[3072, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=32.01797866821289,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:36,560 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.46722412109375,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:36,561 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.5408453941345215,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:36,561 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.534718036651611,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:36,561 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.4708194732666,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:36,834 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.978988647460938,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:36,834 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=32.02152633666992,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:36,835 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[3072, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=32.012290954589844,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:36,835 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.469261169433594,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:36,835 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.533514022827148,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:36,836 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.536715507507324,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:36,836 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.475147247314453,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,109 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.995868682861328,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,109 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.97521209716797,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,109 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[3072, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.993942260742188,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,110 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.494447708129883,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,110 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.545706272125244,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,110 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.566837310791016,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,111 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.485050201416016,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,384 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.99711036682129,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,384 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.996898651123047,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,385 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[3072, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.9808349609375,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,385 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.475849151611328,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,385 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.524013519287109,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,386 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.518404006958008,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,386 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.47666358947754,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,658 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.994958877563477,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,659 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.992769241333008,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,659 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[3072, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=32.00996017456055,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,659 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.457767486572266,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,660 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.525047779083252,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,660 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.54331636428833,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,660 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.465002059936523,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,930 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=32.003177642822266,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,930 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.997249603271484,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,931 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[3072, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.99708366394043,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,931 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.490497589111328,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,931 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.547593116760254,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,932 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.55280876159668,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:37,932 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.457677841186523,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:38,201 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=32.02156066894531,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:38,202 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.982208251953125,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:38,202 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[3072, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.995250701904297,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:38,202 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.471481323242188,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:38,203 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.564767360687256,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:38,203 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.530235290527344,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:38,203 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.4751033782959,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:38,475 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=32.009246826171875,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:38,475 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.999523162841797,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:38,476 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[3072, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.986326217651367,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:38,476 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.483654022216797,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:38,477 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.5150604248046875,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:38,477 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.523664951324463,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:38,477 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.470033645629883,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:38,747 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=32.01503372192383,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:38,747 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=32.024803161621094,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:38,748 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[3072, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.997573852539062,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:38,748 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.493417739868164,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:38,749 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.554461479187012,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:38,749 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.5301432609558105,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:38,749 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.481325149536133,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,024 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=32.00417709350586,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,024 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=32.0085563659668,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,024 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[3072, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=32.01596450805664,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,025 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.4786376953125,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,025 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.508820533752441,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,026 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.547279357910156,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,026 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.492019653320312,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,297 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=32.011329650878906,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,298 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.999645233154297,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,298 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[3072, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.99070167541504,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,299 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.46446418762207,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,299 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.516327857971191,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,299 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.528645038604736,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,300 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.501235961914062,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,571 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.991666793823242,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,572 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.997385025024414,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,572 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[3072, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.981103897094727,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,573 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.49822235107422,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,573 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.540865421295166,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,573 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.524744510650635,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,574 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.467687606811523,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,843 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.995445251464844,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,844 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.995624542236328,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,844 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[3072, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.981586456298828,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,844 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.491823196411133,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,845 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.511590957641602,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,845 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.541938304901123,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:39,845 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.48663902282715,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,114 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.991615295410156,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,115 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=32.00380325317383,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,115 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[3072, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.987363815307617,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,115 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.49142074584961,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,116 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.532582759857178,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,116 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.53924560546875,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,116 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.488527297973633,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,391 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=32.00778579711914,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,391 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.986154556274414,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,392 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[3072, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.999208450317383,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,392 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.481130599975586,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,392 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.542202949523926,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,393 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.503232955932617,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,393 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.46438217163086,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,665 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.99226951599121,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,665 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.995437622070312,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,666 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[3072, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.98405647277832,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,666 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.476409912109375,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,667 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.525158405303955,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,667 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.534249782562256,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,667 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.45987319946289,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,938 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=32.00616455078125,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,938 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=32.00851821899414,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,939 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[3072, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=31.992990493774414,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,939 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.472869873046875,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,939 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.546419620513916,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,940 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 128], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=6.542144775390625,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:40,940 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=18.469633102416992,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:41,208 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=32.01312255859375,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:41,209 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[1024, 3072], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=32.00554656982422,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:41,209 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[3072, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'paddle.nn.layer.common.Linear'>, norm=32.01273727416992,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:41,210 [ modeling.py: 2134][rank--1]:    output-weight:[103424, 1024] config.tie_word_embeddings=True\r\n",
      "[INFO] 2025-07-17 18:20:41,211 [modeling_moe.py: 1967][rank--1]:    Use normal RMSNorm\r\n",
      "[INFO] 2025-07-17 18:20:41,213 [modeling_moe.py: 1462][rank--1]:    dist-init-fc: shape=[103424, 1024], dtype=paddle.float32 range=0.018041293779826325,type=<class 'models.ernie.modeling.ErnieLMHead'>, norm=185.63902282714844,is_moe=False\r\n",
      "[INFO] 2025-07-17 18:20:41,213 [modeling_moe.py: 1972][rank--1]:    using post init div: factor:0.16666666666666666\r\n",
      "[INFO] 2025-07-17 18:20:41,215 [ pretrain.py:  457][rank--1]:    using model type:<class 'models.ernie.modeling_moe.ErnieMoEForCausalLM'>\r\n",
      "[INFO] 2025-07-17 18:20:41,217 [ pretrain.py:  460][rank--1]:    using model=<class 'models.ernie.modeling_moe.ErnieMoEForCausalLM'>, cfg=ErnieMoEConfig {\r\n",
      "  \"architectures\": [\r\n",
      "    \"Ernie4_5_ForCausalLM\"\r\n",
      "  ],\r\n",
      "  \"attention_probs_dropout_prob\": 0.0,\r\n",
      "  \"aux_loss_type\": \"\",\r\n",
      "  \"bos_token_id\": 1,\r\n",
      "  \"compression_ratio\": 1.0,\r\n",
      "  \"decoderlayer_act_offload_settings\": {\r\n",
      "    \"type\": \"\",\r\n",
      "    \"value\": \"\"\r\n",
      "  },\r\n",
      "  \"enable_delay_scale_loss\": true,\r\n",
      "  \"enable_mtp_magic_send\": false,\r\n",
      "  \"eos_token_id\": 2,\r\n",
      "  \"expert_mlp_use_bias\": null,\r\n",
      "  \"fp16_opt_level\": \"O1\",\r\n",
      "  \"fp8_configs\": {\r\n",
      "    \"layers\": {\r\n",
      "      \"attn_fc1_linear\": true,\r\n",
      "      \"attn_fc2_linear\": true,\r\n",
      "      \"attn_tp_fc1_linear\": true,\r\n",
      "      \"attn_tp_fc2_linear\": true,\r\n",
      "      \"mlp_fc1_linear\": true,\r\n",
      "      \"mlp_fc2_linear\": true,\r\n",
      "      \"mlp_tp_fc1_linear\": true,\r\n",
      "      \"mlp_tp_fc2_linear\": true\r\n",
      "    },\r\n",
      "    \"quant_scheme\": \"DelayedScaling\",\r\n",
      "    \"recipe\": {\r\n",
      "      \"amax_compute_algo\": \"max\",\r\n",
      "      \"amax_history_len\": 1024,\r\n",
      "      \"calibrating\": true,\r\n",
      "      \"format\": \"hybrid\",\r\n",
      "      \"fuse_wgrad_accumulation\": false,\r\n",
      "      \"quant_weight_at_first_microbatch\": false\r\n",
      "    },\r\n",
      "    \"smooth_swiglu\": false\r\n",
      "  },\r\n",
      "  \"fp8_fused_ops_configs\": {\r\n",
      "    \"split_group_gemm\": true,\r\n",
      "    \"stack_quant\": false,\r\n",
      "    \"swiglu_probs_bwd\": false\r\n",
      "  },\r\n",
      "  \"fp8_mem_configs\": {\r\n",
      "    \"clear_origin_weight_when_offline_quant\": false,\r\n",
      "    \"dequant_input\": false,\r\n",
      "    \"offline_quant_expert_weight\": false,\r\n",
      "    \"recompute_fwd_gate_up\": false,\r\n",
      "    \"shared_expert\": false\r\n",
      "  },\r\n",
      "  \"freq_allocation\": 0,\r\n",
      "  \"fuse_attn_ffn\": false,\r\n",
      "  \"fuse_gate_detach_matmul\": false,\r\n",
      "  \"fuse_linear\": false,\r\n",
      "  \"fuse_ln\": false,\r\n",
      "  \"fuse_rms_norm\": false,\r\n",
      "  \"fuse_rope\": false,\r\n",
      "  \"fuse_swiglu\": false,\r\n",
      "  \"global_aux_loss\": false,\r\n",
      "  \"head_dim\": null,\r\n",
      "  \"hidden_act\": \"silu\",\r\n",
      "  \"hidden_dropout_prob\": 0.0,\r\n",
      "  \"hidden_size\": 1024,\r\n",
      "  \"ignored_index\": -100,\r\n",
      "  \"initializer_range\": 0.018041293779826325,\r\n",
      "  \"insert_empty_layer\": [],\r\n",
      "  \"intermediate_size\": 3072,\r\n",
      "  \"loss_subbatch_seqlen\": 32768,\r\n",
      "  \"max_position_embeddings\": 131072,\r\n",
      "  \"micro_batch_size\": 1,\r\n",
      "  \"model_type\": \"ernie\",\r\n",
      "  \"moe_all_to_all_dropout\": 0.0,\r\n",
      "  \"moe_aux_loss_lambda\": 0.01,\r\n",
      "  \"moe_capacity\": [],\r\n",
      "  \"moe_dense_experts_token_type_id\": 3,\r\n",
      "  \"moe_dropout_prob\": 0.0,\r\n",
      "  \"moe_fuse_experts\": false,\r\n",
      "  \"moe_gate_act\": \"softmax\",\r\n",
      "  \"moe_group_experts\": false,\r\n",
      "  \"moe_intermediate_size\": 0,\r\n",
      "  \"moe_k\": 2,\r\n",
      "  \"moe_layer_end_index\": 17,\r\n",
      "  \"moe_layer_feed_fake_token\": false,\r\n",
      "  \"moe_layer_interval\": 2,\r\n",
      "  \"moe_layer_start_index\": 0,\r\n",
      "  \"moe_norm_gate_logits\": true,\r\n",
      "  \"moe_num_dense_experts\": 0,\r\n",
      "  \"moe_num_experts\": 0,\r\n",
      "  \"moe_num_shared_experts\": 0,\r\n",
      "  \"moe_rank\": 0,\r\n",
      "  \"moe_reverse_token_drop\": false,\r\n",
      "  \"moe_use_aux_free\": false,\r\n",
      "  \"moe_world_size\": 1,\r\n",
      "  \"multi_token_pred_depth\": 0,\r\n",
      "  \"multi_token_pred_lambda\": 0.3,\r\n",
      "  \"n_group\": 0,\r\n",
      "  \"num_acc_steps\": null,\r\n",
      "  \"num_attention_heads\": 16,\r\n",
      "  \"num_experts_per_tok\": 8,\r\n",
      "  \"num_hidden_layers\": 18,\r\n",
      "  \"num_key_value_heads\": 2,\r\n",
      "  \"offload_pp_data_chunk_size\": 0,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"paddleformers_version\": \"0.1\",\r\n",
      "  \"pp_no_recompute_layer\": null,\r\n",
      "  \"remove_tail_layer\": false,\r\n",
      "  \"resampler_fuse_rms_norm\": false,\r\n",
      "  \"rms_norm_eps\": 1e-05,\r\n",
      "  \"rope_3d\": false,\r\n",
      "  \"rope_reorder\": true,\r\n",
      "  \"rope_theta\": 500000,\r\n",
      "  \"scaling_factor\": null,\r\n",
      "  \"selective_no_recompute_num\": 0,\r\n",
      "  \"seqlen\": 1024,\r\n",
      "  \"skip_recompute_ops\": {},\r\n",
      "  \"tie_word_embeddings\": true,\r\n",
      "  \"token_balance_loss\": false,\r\n",
      "  \"token_balance_seqlen\": 1024,\r\n",
      "  \"topk_group\": 0,\r\n",
      "  \"use_bias\": false,\r\n",
      "  \"use_combine_before_a2a\": false,\r\n",
      "  \"use_ep_comm_overlap\": false,\r\n",
      "  \"use_fast_ln\": false,\r\n",
      "  \"use_flash_attn\": true,\r\n",
      "  \"use_flash_attn_with_mask\": false,\r\n",
      "  \"use_fp8\": false,\r\n",
      "  \"use_fp8_fuse_node\": false,\r\n",
      "  \"use_fp8_mlp\": false,\r\n",
      "  \"use_fused_head_loss_fn\": false,\r\n",
      "  \"use_linear_residual_norm_recompute\": false,\r\n",
      "  \"use_mem_eff_attn\": false,\r\n",
      "  \"use_mp_gathered_weight\": false,\r\n",
      "  \"use_qk_norm\": false,\r\n",
      "  \"use_quant_before_a2a\": false,\r\n",
      "  \"use_recompute\": false,\r\n",
      "  \"use_recompute_attn\": false,\r\n",
      "  \"use_recompute_dnd\": false,\r\n",
      "  \"use_recompute_lm_head\": false,\r\n",
      "  \"use_recompute_loss_fn\": false,\r\n",
      "  \"use_recompute_moe\": false,\r\n",
      "  \"use_recompute_mtp\": false,\r\n",
      "  \"use_recompute_resampler\": false,\r\n",
      "  \"use_rms_qkv_recompute\": false,\r\n",
      "  \"use_rmsnorm\": true,\r\n",
      "  \"use_sparse_head_and_loss_fn\": false,\r\n",
      "  \"use_tpsp_comm_overlap\": false,\r\n",
      "  \"using_dynamic_sequence_length\": false,\r\n",
      "  \"vocab_size\": 103424,\r\n",
      "  \"weight_share_add_bias\": true\r\n",
      "}\r\n",
      "\r\n",
      " > building dataset index ...\r\n",
      "    reading sizes...\r\n",
      "    reading pointers...\r\n",
      "    reading document index...\r\n",
      "    creating numpy buffer of mmap...\r\n",
      "    creating memory view of numpy buffer...\r\n",
      " > finished creating indexed dataset in 0.000759 seconds\r\n",
      "    number of documents: 100000\r\n",
      " > dataset split:\r\n",
      "    train:\r\n",
      "     document indices in [0, 99800) total of 99800 documents\r\n",
      "    validation:\r\n",
      "     document indices in [99800, 99900) total of 100 documents\r\n",
      "    test:\r\n",
      "     document indices in [99900, 100000) total of 100 documents\r\n",
      "searching for causal dataset, build_indices=False, share_folder False, check_rank_flag False\r\n",
      "build success\r\n",
      " > loading doc-idx mapping from ../../data/index-cache/0e61683deaa39422e24fb3e0b520cfc5_doc_idx.npy\r\n",
      " > loading sample-idx mapping from ../../data/index-cache/0e61683deaa39422e24fb3e0b520cfc5_sample_idx.npy\r\n",
      " > loading shuffle-idx mapping from ../../data/index-cache/0e61683deaa39422e24fb3e0b520cfc5_shuffle_idx.npy\r\n",
      "    loaded indexed file in 0.001 seconds\r\n",
      "    total number of samples: 120288\r\n",
      "    total number of epochs: 1\r\n",
      "searching for causal dataset, build_indices=False, share_folder False, check_rank_flag False\r\n",
      "build success\r\n",
      " > loading doc-idx mapping from ../../data/index-cache/e6dc69eb0f94509922f5234cc25c5440_doc_idx.npy\r\n",
      " > loading sample-idx mapping from ../../data/index-cache/e6dc69eb0f94509922f5234cc25c5440_sample_idx.npy\r\n",
      " > loading shuffle-idx mapping from ../../data/index-cache/e6dc69eb0f94509922f5234cc25c5440_shuffle_idx.npy\r\n",
      "    loaded indexed file in 0.001 seconds\r\n",
      "    total number of samples: 103\r\n",
      "    total number of epochs: 1\r\n",
      "searching for causal dataset, build_indices=False, share_folder False, check_rank_flag False\r\n",
      "build success\r\n",
      " > loading doc-idx mapping from ../../data/index-cache/64bf0bdeaf57319af37ad010202fa307_doc_idx.npy\r\n",
      " > loading sample-idx mapping from ../../data/index-cache/64bf0bdeaf57319af37ad010202fa307_sample_idx.npy\r\n",
      " > loading shuffle-idx mapping from ../../data/index-cache/64bf0bdeaf57319af37ad010202fa307_shuffle_idx.npy\r\n",
      "    loaded indexed file in 0.001 seconds\r\n",
      "    total number of samples: 87\r\n",
      "    total number of epochs: 1\r\n",
      " > building dataset index ...\r\n",
      "    reading sizes...\r\n",
      "    reading pointers...\r\n",
      "    reading document index...\r\n",
      "    creating numpy buffer of mmap...\r\n",
      "    creating memory view of numpy buffer...\r\n",
      " > finished creating indexed dataset in 0.000288 seconds\r\n",
      "    number of documents: 100000\r\n",
      " > dataset split:\r\n",
      "    train:\r\n",
      "     document indices in [0, 99800) total of 99800 documents\r\n",
      "    validation:\r\n",
      "     document indices in [99800, 99900) total of 100 documents\r\n",
      "    test:\r\n",
      "     document indices in [99900, 100000) total of 100 documents\r\n",
      "searching for causal dataset, build_indices=False, share_folder False, check_rank_flag False\r\n",
      "build success\r\n",
      " > loading doc-idx mapping from ../../data/index-cache/0e61683deaa39422e24fb3e0b520cfc5_doc_idx.npy\r\n",
      " > loading sample-idx mapping from ../../data/index-cache/0e61683deaa39422e24fb3e0b520cfc5_sample_idx.npy\r\n",
      " > loading shuffle-idx mapping from ../../data/index-cache/0e61683deaa39422e24fb3e0b520cfc5_shuffle_idx.npy\r\n",
      "    loaded indexed file in 0.001 seconds\r\n",
      "    total number of samples: 120288\r\n",
      "    total number of epochs: 1\r\n",
      "searching for causal dataset, build_indices=False, share_folder False, check_rank_flag False\r\n",
      "build success\r\n",
      " > loading doc-idx mapping from ../../data/index-cache/e6dc69eb0f94509922f5234cc25c5440_doc_idx.npy\r\n",
      " > loading sample-idx mapping from ../../data/index-cache/e6dc69eb0f94509922f5234cc25c5440_sample_idx.npy\r\n",
      " > loading shuffle-idx mapping from ../../data/index-cache/e6dc69eb0f94509922f5234cc25c5440_shuffle_idx.npy\r\n",
      "    loaded indexed file in 0.001 seconds\r\n",
      "    total number of samples: 103\r\n",
      "    total number of epochs: 1\r\n",
      "searching for causal dataset, build_indices=False, share_folder False, check_rank_flag False\r\n",
      "build success\r\n",
      " > loading doc-idx mapping from ../../data/index-cache/64bf0bdeaf57319af37ad010202fa307_doc_idx.npy\r\n",
      " > loading sample-idx mapping from ../../data/index-cache/64bf0bdeaf57319af37ad010202fa307_sample_idx.npy\r\n",
      " > loading shuffle-idx mapping from ../../data/index-cache/64bf0bdeaf57319af37ad010202fa307_shuffle_idx.npy\r\n",
      "    loaded indexed file in 0.001 seconds\r\n",
      "    total number of samples: 87\r\n",
      "    total number of epochs: 1\r\n",
      "building indices for the blendable dataset, Since --data_cache is not specified, the index file will not be stored.\r\n",
      "> building indices for blendable datasets ...\r\n",
      " > sample ratios:\r\n",
      "   dataset 0, input: 0.5, achieved: 0.5\r\n",
      "   dataset 1, input: 0.5, achieved: 0.5\r\n",
      "> elapsed time for building blendable dataset indices: 0.00 (sec)\r\n",
      "> size of blendable dataset: 3200 samples\r\n",
      "building indices for the blendable dataset, Since --data_cache is not specified, the index file will not be stored.\r\n",
      "> building indices for blendable datasets ...\r\n",
      " > sample ratios:\r\n",
      "   dataset 0, input: 0.5, achieved: 0.5\r\n",
      "   dataset 1, input: 0.5, achieved: 0.5\r\n",
      "> elapsed time for building blendable dataset indices: 0.00 (sec)\r\n",
      "> size of blendable dataset: 50 samples\r\n",
      "building indices for the blendable dataset, Since --data_cache is not specified, the index file will not be stored.\r\n",
      "> building indices for blendable datasets ...\r\n",
      " > sample ratios:\r\n",
      "   dataset 0, input: 0.5, achieved: 0.5\r\n",
      "   dataset 1, input: 0.5, achieved: 0.5\r\n",
      "> elapsed time for building blendable dataset indices: 0.00 (sec)\r\n",
      "> size of blendable dataset: 100 samples\r\n",
      "[INFO] 2025-07-17 18:20:41,248 [trainer_utils.py:  173][rank--1]:    The global seed is set to 42, local seed is set to 43 and random seed is set to 42.\r\n",
      "[INFO] 2025-07-17 18:20:41,286 [  trainer.py:  459][rank--1]:    max_steps is given, it will override any value given in num_train_epochs\r\n",
      "[INFO] 2025-07-17 18:20:41,286 [  trainer.py:  514][rank--1]:    Using half precision\r\n",
      "[DEBUG] 2025-07-17 18:20:41,286 [  trainer.py: 3788][rank--1]:    ============================================================\r\n",
      "[DEBUG] 2025-07-17 18:20:41,286 [  trainer.py: 3794][rank--1]:        Training Configuration Arguments    \r\n",
      "[DEBUG] 2025-07-17 18:20:41,286 [  trainer.py: 3795][rank--1]:    paddle commit id              : cdcd76a93d1dfe767dde768198e1d7c7488b93f6\r\n",
      "[DEBUG] 2025-07-17 18:20:41,286 [  trainer.py: 3796][rank--1]:    paddleformers commit id       : 053a5a5e2a72cd2d3b997cbcff81b14af9fe4d47\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    _no_sync_in_gradient_accumulation: True\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    _use_moe                      : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    adam_beta1                    : 0.9\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    adam_beta2                    : 0.95\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    adam_epsilon                  : 1e-08\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    amp_custom_black_list         : None\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    amp_custom_white_list         : None\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    amp_master_grad               : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    audio_config                  : {}\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    auto_parallel_resume_form_hybrid_parallel: False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    base_seq_length               : 4096\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    bf16                          : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    bf16_full_eval                : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    ckpt_quant_stage              : O0\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    combine_batch                 : 0\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    context_parallel_degree       : -1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    count_trained_tokens          : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    current_device                : gpu:0\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    data_parallel_config          : \r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    data_parallel_degree          : 1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    data_parallel_rank            : 0\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    dataloader_drop_last          : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    dataloader_num_workers        : 0\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    dataloader_shuffle            : True\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    dataset                       : None\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    dataset_rank                  : 0\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    dataset_world_size            : 1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    ddp_find_unused_parameters    : None\r\n",
      "[DEBUG] 2025-07-17 18:20:41,287 [  trainer.py: 3802][rank--1]:    decay_function                : half_life\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    device                        : gpu\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    disable_tqdm                  : True\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    distributed_dataloader        : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    do_eval                       : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    do_export                     : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    do_predict                    : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    do_train                      : True\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    enable_auto_parallel          : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    enable_delay_scale_loss       : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    enable_global_training_logs   : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    enable_mtp_magic_send         : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    enable_optimizer_timer        : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    enable_zero_cost_checkpoint   : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    eval_accumulation_steps       : None\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    eval_batch_size               : 1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    eval_iters                    : 10\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    eval_steps                    : 100\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    evaluation_strategy           : IntervalStrategy.NO\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    expert_max_capacity           : 4294967296\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    expert_min_capacity           : 1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    expert_parallel_degree        : -1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    expert_tensor_parallel_degree : -1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    flash_device_save_steps       : 0\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    flatten_param_grads           : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    force_reshard_pp              : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    fp16                          : True\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    fp16_full_eval                : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    fp16_opt_level                : O1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    from_scratch                  : 1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    fuse_sequence_parallel_allreduce: False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    gc_interval                   : 0\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    global_batch_size             : -1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,288 [  trainer.py: 3802][rank--1]:    global_logging_interval       : 1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    global_shuffle_num_examples   : 0\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    gradient_accumulation_steps   : 8\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    greater_is_better             : None\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    hybrid_parallel_topo_order    : pp_first\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    ignore_data_skip              : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    ignore_load_lr_and_optim      : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    ignore_save_lr_and_optim      : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    input_dir                     : 1.0 ../../data/llama_openwebtext_100k 1.0 ../../data/llama_openwebtext_100k\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    label_names                   : None\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    lazy_data_processing          : True\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    learning_rate                 : 0.0001\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    load_best_model_at_end        : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    load_sharded_model            : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    local_process_index           : 0\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    local_rank                    : -1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    log_global_grad_norm          : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    log_level                     : -1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    log_level_replica             : -1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    log_on_each_node              : True\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    logging_dir                   : ./output_pretrain/runs/Jul17_18-20-34_jupyter-2553954-9382861\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    logging_first_step            : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    logging_steps                 : 10\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    logging_strategy              : IntervalStrategy.STEPS\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    logical_process_index         : 0\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    lr_end                        : 1e-07\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    lr_scheduler                  : wsd_cosine\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    lr_scheduler_type             : SchedulerType.LINEAR\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    max_evaluate_steps            : -1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    max_grad_norm                 : 1.0\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    max_gradient_accumulation_steps: 8\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    max_seq_length                : 1024\r\n",
      "[DEBUG] 2025-07-17 18:20:41,289 [  trainer.py: 3802][rank--1]:    max_steps                     : 400\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    metric_for_best_model         : None\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    metrics_output_path           : None\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    min_lr                        : 1e-05\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    minimum_eval_times            : None\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    model_name_or_path            : ../../../data/models/30654/ERNIE-4.5-0.3B-Base-Paddle\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    moe_gate_lr_ratio             : None\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    moe_group                     : dummy\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    moe_use_aux_free_update_coef  : 0.001\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    moe_with_send_router_loss     : True\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    multi_token_pred_depth        : 0\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    need_data                     : True\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    no_cuda                       : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    num_consecutive               : 1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    num_cycles                    : 0.5\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    num_train_epochs              : 1.0\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    offload_optim                 : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    optim                         : OptimizerNames.ADAMW\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    optim_shard_num               : 1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    optimizer_name_suffix         : None\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    ordered_save_group_size       : 0\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    output_dir                    : ./output_pretrain/\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    output_signal_dir             : ./output_pretrain/\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    overwrite_output_dir          : True\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    pad_token_id                  : 0\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    past_index                    : -1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    pdc_download_ckpt             : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    pdc_download_timeout          : 300\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    per_device_eval_batch_size    : 1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    per_device_train_batch_size   : 1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    pipeline_parallel_config      : \r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    pipeline_parallel_degree      : -1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    pipeline_parallel_rank        : 0\r\n",
      "[DEBUG] 2025-07-17 18:20:41,290 [  trainer.py: 3802][rank--1]:    power                         : 1.0\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    pre_alloc_memory              : 0.0\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    prediction_loss_only          : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    prefetch_factor               : 2\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    process_index                 : 0\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    recompute                     : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    reeao_dataset_rank            : 0\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    reeao_dataset_world_size      : 1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    refined_recompute             : {}\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    release_grads                 : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    remove_unused_columns         : True\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    report_to                     : ['visualdl']\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    resume_from_checkpoint        : None\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    run_name                      : ./output_pretrain/\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    same_data                     : None\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    save_on_each_node             : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    save_rng_states               : True\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    save_sharded_model            : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    save_sharding_stage1_model_include_freeze_params: False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    save_steps                    : 200\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    save_strategy                 : IntervalStrategy.STEPS\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    save_tokenizer                : True\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    save_total_limit              : 2\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    scale_loss                    : 32768\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    seed                          : 42\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    sep_parallel_degree           : -1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    sequence_parallel             : 0\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    sequence_parallel_config      : \r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    sharding                      : []\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    sharding_comm_buffer_size_MB  : -1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    sharding_degree               : -1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    sharding_parallel_config      : \r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    sharding_parallel_degree      : -1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,291 [  trainer.py: 3802][rank--1]:    sharding_parallel_mesh_dimension: dp\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    sharding_parallel_rank        : 0\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    should_load_dataset           : True\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    should_load_sharding_stage1_model: False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    should_log                    : True\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    should_save                   : True\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    should_save_model_state       : True\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    should_save_model_with_tensor_fusion: False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    should_save_sharding_stage1_model: False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    shuffle_consecutive           : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    skip_data_intervals           : None\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    skip_memory_metrics           : True\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    skip_profile_timer            : True\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    split                         : 998,1,1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    split_inputs_sequence_dim     : True\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    split_norm_comm               : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    tensor_parallel_config        : \r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    tensor_parallel_degree        : -1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    tensor_parallel_rank          : 0\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    tensorwise_offload_optimizer  : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    test_iters                    : 100\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    to_static                     : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    tokenizer_name                : ../../../data/models/30654/ERNIE-4.5-0.3B-Base-Paddle\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    train_batch_size              : 1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    train_moe_only                : None\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    unified_checkpoint            : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    unified_checkpoint_config     : \r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    use_async_save                : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    use_expert_parallel           : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    use_fp8                       : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    use_hybrid_parallel           : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    use_lowprecision_moment       : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    use_moe                       : False\r\n",
      "[DEBUG] 2025-07-17 18:20:41,292 [  trainer.py: 3802][rank--1]:    use_sp_callback               : True\r\n",
      "[DEBUG] 2025-07-17 18:20:41,293 [  trainer.py: 3802][rank--1]:    virtual_pp_degree             : 1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,293 [  trainer.py: 3802][rank--1]:    vocab_path                    : None\r\n",
      "[DEBUG] 2025-07-17 18:20:41,293 [  trainer.py: 3802][rank--1]:    wandb_api_key                 : None\r\n",
      "[DEBUG] 2025-07-17 18:20:41,293 [  trainer.py: 3802][rank--1]:    wandb_http_proxy              : None\r\n",
      "[DEBUG] 2025-07-17 18:20:41,293 [  trainer.py: 3802][rank--1]:    warmup_ratio                  : 0.0\r\n",
      "[DEBUG] 2025-07-17 18:20:41,293 [  trainer.py: 3802][rank--1]:    warmup_steps                  : 50\r\n",
      "[DEBUG] 2025-07-17 18:20:41,293 [  trainer.py: 3802][rank--1]:    weight_decay                  : 0.1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,293 [  trainer.py: 3802][rank--1]:    weight_name_suffix            : None\r\n",
      "[DEBUG] 2025-07-17 18:20:41,293 [  trainer.py: 3802][rank--1]:    world_size                    : 1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,293 [  trainer.py: 3802][rank--1]:    zcc_ema_interval              : 1\r\n",
      "[DEBUG] 2025-07-17 18:20:41,293 [  trainer.py: 3802][rank--1]:    zcc_pipeline_hooks_capacity_usage: 0.6\r\n",
      "[DEBUG] 2025-07-17 18:20:41,293 [  trainer.py: 3802][rank--1]:    zcc_save_ema_coef             : None\r\n",
      "[DEBUG] 2025-07-17 18:20:41,293 [  trainer.py: 3802][rank--1]:    zcc_workers_num               : 3\r\n",
      "[DEBUG] 2025-07-17 18:20:41,293 [  trainer.py: 3804][rank--1]:    \r\n",
      "[INFO] 2025-07-17 18:20:41,293 [     misc.py:   97][rank--1]:    global_training_logs: use skip zero\r\n",
      "[INFO] 2025-07-17 18:20:41,293 [  trainer.py:  837][rank--1]:    Starting training from resume_from_checkpoint : None\r\n",
      "[INFO] 2025-07-17 18:20:41,293 [pretraining_trainer.py: 1276][rank--1]:    using wsd lr scheduler, num_steady_steps=None\r\n",
      "[INFO] 2025-07-17 18:20:41,296 [  trainer.py:  955][rank--1]:    [timelog] checkpoint loading time: 0.00s (2025-07-17 18:20:41) \r\n",
      "[INFO] 2025-07-17 18:20:41,296 [  trainer.py:  956][rank--1]:    ***** Running training *****\r\n",
      "[INFO] 2025-07-17 18:20:41,296 [  trainer.py:  957][rank--1]:      Num examples = 3,200\r\n",
      "[INFO] 2025-07-17 18:20:41,296 [  trainer.py:  958][rank--1]:      Num Epochs = 1\r\n",
      "[INFO] 2025-07-17 18:20:41,296 [  trainer.py:  959][rank--1]:      Instantaneous batch size per device = 1\r\n",
      "[INFO] 2025-07-17 18:20:41,296 [  trainer.py:  960][rank--1]:      Total train batch size (w. parallel, distributed & accumulation) = 8\r\n",
      "[INFO] 2025-07-17 18:20:41,296 [  trainer.py:  961][rank--1]:      Gradient Accumulation steps = 8\r\n",
      "[INFO] 2025-07-17 18:20:41,296 [  trainer.py:  962][rank--1]:      Total optimization steps = 400\r\n",
      "[INFO] 2025-07-17 18:20:41,296 [  trainer.py:  963][rank--1]:      Total num train samples = 3,200\r\n",
      "[DEBUG] 2025-07-17 18:20:41,297 [  trainer.py:  973][rank--1]:      Number of trainable parameters = 318,280,704 (per device)\r\n",
      "[INFO] 2025-07-17 18:20:47,126 [logging_callback.py:   43][rank--1]:    loss: 11.311073303222656, loss_cur_dp: 11.311073303222656, learning_rate: 2.000000e-05, global_step: 10, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 5.822300, global_samples_per_second: 13.740300, global_steps_per_second: 1.717500, tokens_trained_current_step: 8192, timestamp: 1752747647125, TFLOPS_per_sec_per_card: 17.928000, tokens_per_sec_per_card: 14069.800000, tokens_per_sec_per_card_average: 14069.800000, lm_loss_cur_dp: 11.311073303222656, progress_or_epoch: 0.025000\r\n",
      "[INFO] 2025-07-17 18:20:51,509 [logging_callback.py:   43][rank--1]:    loss: 10.29632568359375, loss_cur_dp: 10.29632568359375, learning_rate: 4.000000e-05, global_step: 20, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.383600, global_samples_per_second: 18.249700, global_steps_per_second: 2.281200, tokens_trained_current_step: 8192, timestamp: 1752747651508, TFLOPS_per_sec_per_card: 23.813000, tokens_per_sec_per_card: 18687.600000, tokens_per_sec_per_card_average: 18687.600000, lm_loss_cur_dp: 10.29632568359375, progress_or_epoch: 0.050000\r\n",
      "[INFO] 2025-07-17 18:20:55,870 [logging_callback.py:   43][rank--1]:    loss: 9.719583129882812, loss_cur_dp: 9.719583129882812, learning_rate: 6.000000e-05, global_step: 30, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.360600, global_samples_per_second: 18.346200, global_steps_per_second: 2.293300, tokens_trained_current_step: 8192, timestamp: 1752747655869, TFLOPS_per_sec_per_card: 23.939000, tokens_per_sec_per_card: 18786.700000, tokens_per_sec_per_card_average: 18737.200000, lm_loss_cur_dp: 9.719583511352539, progress_or_epoch: 0.075000\r\n",
      "[INFO] 2025-07-17 18:21:00,263 [logging_callback.py:   43][rank--1]:    loss: 9.083602905273438, loss_cur_dp: 9.083602905273438, learning_rate: 8.000000e-05, global_step: 40, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.392200, global_samples_per_second: 18.214100, global_steps_per_second: 2.276800, tokens_trained_current_step: 8192, timestamp: 1752747660261, TFLOPS_per_sec_per_card: 23.767000, tokens_per_sec_per_card: 18651.500000, tokens_per_sec_per_card_average: 18708.600000, lm_loss_cur_dp: 9.083602905273438, progress_or_epoch: 0.100000\r\n",
      "[INFO] 2025-07-17 18:21:04,657 [logging_callback.py:   43][rank--1]:    loss: 8.313115692138672, loss_cur_dp: 8.313115692138672, learning_rate: 1.000000e-04, global_step: 50, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.394100, global_samples_per_second: 18.206000, global_steps_per_second: 2.275800, tokens_trained_current_step: 8192, timestamp: 1752747664656, TFLOPS_per_sec_per_card: 23.756000, tokens_per_sec_per_card: 18643.400000, tokens_per_sec_per_card_average: 18692.300000, lm_loss_cur_dp: 8.313116073608398, progress_or_epoch: 0.125000\r\n",
      "[INFO] 2025-07-17 18:21:09,061 [logging_callback.py:   43][rank--1]:    loss: 7.887854766845703, loss_cur_dp: 7.887854766845703, learning_rate: 1.000000e-04, global_step: 60, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.404500, global_samples_per_second: 18.163100, global_steps_per_second: 2.270400, tokens_trained_current_step: 8192, timestamp: 1752747669060, TFLOPS_per_sec_per_card: 23.700000, tokens_per_sec_per_card: 18599.100000, tokens_per_sec_per_card_average: 18673.700000, lm_loss_cur_dp: 7.887855052947998, progress_or_epoch: 0.150000\r\n",
      "[INFO] 2025-07-17 18:21:13,451 [logging_callback.py:   43][rank--1]:    loss: 7.324617004394531, loss_cur_dp: 7.324617004394531, learning_rate: 1.000000e-04, global_step: 70, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.389400, global_samples_per_second: 18.225900, global_steps_per_second: 2.278200, tokens_trained_current_step: 8192, timestamp: 1752747673450, TFLOPS_per_sec_per_card: 23.781000, tokens_per_sec_per_card: 18663.000000, tokens_per_sec_per_card_average: 18671.900000, lm_loss_cur_dp: 7.3246169090271, progress_or_epoch: 0.175000\r\n",
      "[INFO] 2025-07-17 18:21:17,830 [logging_callback.py:   43][rank--1]:    loss: 7.417249298095703, loss_cur_dp: 7.417249298095703, learning_rate: 1.000000e-04, global_step: 80, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.379200, global_samples_per_second: 18.268200, global_steps_per_second: 2.283500, tokens_trained_current_step: 8192, timestamp: 1752747677829, TFLOPS_per_sec_per_card: 23.837000, tokens_per_sec_per_card: 18706.400000, tokens_per_sec_per_card_average: 18676.800000, lm_loss_cur_dp: 7.4172492027282715, progress_or_epoch: 0.200000\r\n",
      "[INFO] 2025-07-17 18:21:22,200 [logging_callback.py:   43][rank--1]:    loss: 7.066650390625, loss_cur_dp: 7.066650390625, learning_rate: 1.000000e-04, global_step: 90, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.369600, global_samples_per_second: 18.308300, global_steps_per_second: 2.288500, tokens_trained_current_step: 8192, timestamp: 1752747682199, TFLOPS_per_sec_per_card: 23.889000, tokens_per_sec_per_card: 18747.400000, tokens_per_sec_per_card_average: 18685.600000, lm_loss_cur_dp: 7.066650390625, progress_or_epoch: 0.225000\r\n",
      "[INFO] 2025-07-17 18:21:26,586 [logging_callback.py:   43][rank--1]:    loss: 7.089629364013672, loss_cur_dp: 7.089629364013672, learning_rate: 1.000000e-04, global_step: 100, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.385900, global_samples_per_second: 18.240200, global_steps_per_second: 2.280000, tokens_trained_current_step: 8192, timestamp: 1752747686585, TFLOPS_per_sec_per_card: 23.800000, tokens_per_sec_per_card: 18677.800000, tokens_per_sec_per_card_average: 18684.800000, lm_loss_cur_dp: 7.089629650115967, progress_or_epoch: 0.250000\r\n",
      "[INFO] 2025-07-17 18:21:30,976 [logging_callback.py:   43][rank--1]:    loss: 6.943177795410156, loss_cur_dp: 6.943177795410156, learning_rate: 1.000000e-04, global_step: 110, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.390300, global_samples_per_second: 18.222200, global_steps_per_second: 2.277800, tokens_trained_current_step: 8192, timestamp: 1752747690975, TFLOPS_per_sec_per_card: 23.777000, tokens_per_sec_per_card: 18659.700000, tokens_per_sec_per_card_average: 18682.300000, lm_loss_cur_dp: 6.943177700042725, progress_or_epoch: 0.275000\r\n",
      "[INFO] 2025-07-17 18:21:35,368 [logging_callback.py:   43][rank--1]:    loss: 6.9135894775390625, loss_cur_dp: 6.9135894775390625, learning_rate: 1.000000e-04, global_step: 120, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.391500, global_samples_per_second: 18.216800, global_steps_per_second: 2.277100, tokens_trained_current_step: 8192, timestamp: 1752747695367, TFLOPS_per_sec_per_card: 23.770000, tokens_per_sec_per_card: 18654.000000, tokens_per_sec_per_card_average: 18679.700000, lm_loss_cur_dp: 6.9135894775390625, progress_or_epoch: 0.300000\r\n",
      "[INFO] 2025-07-17 18:21:39,747 [logging_callback.py:   43][rank--1]:    loss: 6.667790222167969, loss_cur_dp: 6.667790222167969, learning_rate: 1.000000e-04, global_step: 130, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.379200, global_samples_per_second: 18.268200, global_steps_per_second: 2.283500, tokens_trained_current_step: 8192, timestamp: 1752747699746, TFLOPS_per_sec_per_card: 23.837000, tokens_per_sec_per_card: 18706.400000, tokens_per_sec_per_card_average: 18681.900000, lm_loss_cur_dp: 6.667790412902832, progress_or_epoch: 0.325000\r\n",
      "[INFO] 2025-07-17 18:21:44,139 [logging_callback.py:   43][rank--1]:    loss: 7.002772521972656, loss_cur_dp: 7.002772521972656, learning_rate: 1.000000e-04, global_step: 140, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.391800, global_samples_per_second: 18.215800, global_steps_per_second: 2.277000, tokens_trained_current_step: 8192, timestamp: 1752747704138, TFLOPS_per_sec_per_card: 23.769000, tokens_per_sec_per_card: 18653.200000, tokens_per_sec_per_card_average: 18679.700000, lm_loss_cur_dp: 7.002772808074951, progress_or_epoch: 0.350000\r\n",
      "[INFO] 2025-07-17 18:21:48,564 [logging_callback.py:   43][rank--1]:    loss: 6.7738395690917965, loss_cur_dp: 6.7738395690917965, learning_rate: 1.000000e-04, global_step: 150, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.424900, global_samples_per_second: 18.079400, global_steps_per_second: 2.259900, tokens_trained_current_step: 8192, timestamp: 1752747708563, TFLOPS_per_sec_per_card: 23.590000, tokens_per_sec_per_card: 18513.100000, tokens_per_sec_per_card_average: 18667.800000, lm_loss_cur_dp: 6.773839473724365, progress_or_epoch: 0.375000\r\n",
      "[INFO] 2025-07-17 18:21:52,982 [logging_callback.py:   43][rank--1]:    loss: 6.789023590087891, loss_cur_dp: 6.789023590087891, learning_rate: 1.000000e-04, global_step: 160, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.417700, global_samples_per_second: 18.108900, global_steps_per_second: 2.263600, tokens_trained_current_step: 8192, timestamp: 1752747712981, TFLOPS_per_sec_per_card: 23.629000, tokens_per_sec_per_card: 18543.400000, tokens_per_sec_per_card_average: 18659.500000, lm_loss_cur_dp: 6.7890238761901855, progress_or_epoch: 0.400000\r\n",
      "[INFO] 2025-07-17 18:21:57,398 [logging_callback.py:   43][rank--1]:    loss: 6.626300811767578, loss_cur_dp: 6.626300811767578, learning_rate: 1.000000e-04, global_step: 170, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.416400, global_samples_per_second: 18.114400, global_steps_per_second: 2.264300, tokens_trained_current_step: 8192, timestamp: 1752747717397, TFLOPS_per_sec_per_card: 23.636000, tokens_per_sec_per_card: 18549.100000, tokens_per_sec_per_card_average: 18652.600000, lm_loss_cur_dp: 6.626300811767578, progress_or_epoch: 0.425000\r\n",
      "[INFO] 2025-07-17 18:22:01,761 [logging_callback.py:   43][rank--1]:    loss: 6.652262878417969, loss_cur_dp: 6.652262878417969, learning_rate: 1.000000e-04, global_step: 180, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.362500, global_samples_per_second: 18.338200, global_steps_per_second: 2.292300, tokens_trained_current_step: 8192, timestamp: 1752747721760, TFLOPS_per_sec_per_card: 23.928000, tokens_per_sec_per_card: 18778.500000, tokens_per_sec_per_card_average: 18660.000000, lm_loss_cur_dp: 6.652263164520264, progress_or_epoch: 0.450000\r\n",
      "[INFO] 2025-07-17 18:22:06,313 [logging_callback.py:   43][rank--1]:    loss: 6.602664184570313, loss_cur_dp: 6.602664184570313, learning_rate: 1.000000e-04, global_step: 190, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.551800, global_samples_per_second: 17.575500, global_steps_per_second: 2.196900, tokens_trained_current_step: 8192, timestamp: 1752747726312, TFLOPS_per_sec_per_card: 22.933000, tokens_per_sec_per_card: 17997.000000, tokens_per_sec_per_card_average: 18623.200000, lm_loss_cur_dp: 6.602664470672607, progress_or_epoch: 0.475000\r\n",
      "[INFO] 2025-07-17 18:22:10,728 [logging_callback.py:   43][rank--1]:    loss: 6.532521057128906, loss_cur_dp: 6.532521057128906, learning_rate: 1.000000e-04, global_step: 200, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.415100, global_samples_per_second: 18.119500, global_steps_per_second: 2.264900, tokens_trained_current_step: 8192, timestamp: 1752747730727, TFLOPS_per_sec_per_card: 23.642000, tokens_per_sec_per_card: 18554.100000, tokens_per_sec_per_card_average: 18619.500000, lm_loss_cur_dp: 6.5325212478637695, progress_or_epoch: 0.500000\r\n",
      "[INFO] 2025-07-17 18:22:10,730 [  trainer.py: 2931][rank--1]:    Saving model checkpoint to ./output_pretrain/checkpoint-200\r\n",
      "[INFO] 2025-07-17 18:22:10,734 [tokenizer_utils_base.py: 1894][rank--1]:    tokenizer config file saved in ./output_pretrain/checkpoint-200/tokenizer_config.json\r\n",
      "[INFO] 2025-07-17 18:22:10,735 [tokenizer_utils_base.py: 1900][rank--1]:    Special tokens file saved in ./output_pretrain/checkpoint-200/special_tokens_map.json\r\n",
      "[INFO] 2025-07-17 18:22:10,735 [tokenizer_utils_base.py: 1929][rank--1]:    added tokens file saved in ./output_pretrain/checkpoint-200/added_tokens.json\r\n",
      "[INFO] 2025-07-17 18:22:11,105 [configuration_utils.py:  741][rank--1]:    Configuration saved in ./output_pretrain/checkpoint-200/config.json\r\n",
      "[INFO] 2025-07-17 18:22:11,107 [configuration_utils.py:  334][rank--1]:    Configuration saved in ./output_pretrain/checkpoint-200/generation_config.json\r\n",
      "[INFO] 2025-07-17 18:22:15,762 [model_utils.py: 2895][rank--1]:    Model weights saved in ./output_pretrain/checkpoint-200/model_state.pdparams\r\n",
      "[INFO] 2025-07-17 18:22:15,766 [  trainer.py: 2790][rank--1]:    Saving optimizer files.\r\n",
      "[INFO] 2025-07-17 18:22:22,073 [logging_callback.py:   43][rank--1]:    is_persistent_ckpt: 1, save_ckpt_time_sec: 11.342713, global_save_step: 200, train_time_sec_without_save: 83.604954, average_tokens_per_sec_per_card_without_save: 19596.900000, average_tokens_per_sec_per_card_with_save: 17255.820000, one_day_billion_tokens_without_save: 1.690000, one_day_billion_tokens_with_save: 1.490000, progress_or_epoch: 0.500000\r\n",
      "[INFO] 2025-07-17 18:22:26,615 [logging_callback.py:   43][rank--1]:    loss: 6.419066619873047, loss_cur_dp: 6.419066619873047, learning_rate: 1.000000e-04, global_step: 210, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.539700, global_samples_per_second: 17.622400, global_steps_per_second: 2.202800, tokens_trained_current_step: 8192, timestamp: 1752747746614, TFLOPS_per_sec_per_card: 22.994000, tokens_per_sec_per_card: 18045.300000, tokens_per_sec_per_card_average: 18045.300000, lm_loss_cur_dp: 6.419066905975342, progress_or_epoch: 0.525000\r\n",
      "[INFO] 2025-07-17 18:22:31,106 [logging_callback.py:   43][rank--1]:    loss: 6.728121948242188, loss_cur_dp: 6.728121948242188, learning_rate: 1.000000e-04, global_step: 220, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.491000, global_samples_per_second: 17.813400, global_steps_per_second: 2.226700, tokens_trained_current_step: 8192, timestamp: 1752747751105, TFLOPS_per_sec_per_card: 23.244000, tokens_per_sec_per_card: 18241.100000, tokens_per_sec_per_card_average: 18143.200000, lm_loss_cur_dp: 6.728122234344482, progress_or_epoch: 0.550000\r\n",
      "[INFO] 2025-07-17 18:22:35,609 [logging_callback.py:   43][rank--1]:    loss: 6.455517578125, loss_cur_dp: 6.455517578125, learning_rate: 1.000000e-04, global_step: 230, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.502800, global_samples_per_second: 17.766600, global_steps_per_second: 2.220800, tokens_trained_current_step: 8192, timestamp: 1752747755608, TFLOPS_per_sec_per_card: 23.182000, tokens_per_sec_per_card: 18192.800000, tokens_per_sec_per_card_average: 18159.700000, lm_loss_cur_dp: 6.455517768859863, progress_or_epoch: 0.575000\r\n",
      "[INFO] 2025-07-17 18:22:40,178 [logging_callback.py:   43][rank--1]:    loss: 6.425564575195312, loss_cur_dp: 6.425564575195312, learning_rate: 1.000000e-04, global_step: 240, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.569100, global_samples_per_second: 17.509100, global_steps_per_second: 2.188600, tokens_trained_current_step: 8192, timestamp: 1752747760177, TFLOPS_per_sec_per_card: 22.846000, tokens_per_sec_per_card: 17929.000000, tokens_per_sec_per_card_average: 18102.000000, lm_loss_cur_dp: 6.425564765930176, progress_or_epoch: 0.600000\r\n",
      "[INFO] 2025-07-17 18:22:44,584 [logging_callback.py:   43][rank--1]:    loss: 6.2918346405029295, loss_cur_dp: 6.2918346405029295, learning_rate: 1.000000e-04, global_step: 250, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.406300, global_samples_per_second: 18.155700, global_steps_per_second: 2.269500, tokens_trained_current_step: 8192, timestamp: 1752747764583, TFLOPS_per_sec_per_card: 23.690000, tokens_per_sec_per_card: 18591.700000, tokens_per_sec_per_card_average: 18200.000000, lm_loss_cur_dp: 6.291834831237793, progress_or_epoch: 0.625000\r\n",
      "[INFO] 2025-07-17 18:22:48,989 [logging_callback.py:   43][rank--1]:    loss: 6.37108154296875, loss_cur_dp: 6.37108154296875, learning_rate: 1.000000e-04, global_step: 260, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.404200, global_samples_per_second: 18.164300, global_steps_per_second: 2.270500, tokens_trained_current_step: 8192, timestamp: 1752747768988, TFLOPS_per_sec_per_card: 23.701000, tokens_per_sec_per_card: 18599.900000, tokens_per_sec_per_card_average: 18266.600000, lm_loss_cur_dp: 6.371081829071045, progress_or_epoch: 0.650000\r\n",
      "[INFO] 2025-07-17 18:22:53,446 [logging_callback.py:   43][rank--1]:    loss: 6.3871711730957035, loss_cur_dp: 6.3871711730957035, learning_rate: 1.000000e-04, global_step: 270, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.457400, global_samples_per_second: 17.947600, global_steps_per_second: 2.243400, tokens_trained_current_step: 8192, timestamp: 1752747773445, TFLOPS_per_sec_per_card: 23.418000, tokens_per_sec_per_card: 18377.900000, tokens_per_sec_per_card_average: 18282.500000, lm_loss_cur_dp: 6.387171268463135, progress_or_epoch: 0.675000\r\n",
      "[INFO] 2025-07-17 18:22:57,964 [logging_callback.py:   43][rank--1]:    loss: 6.175587844848633, loss_cur_dp: 6.175587844848633, learning_rate: 1.000000e-04, global_step: 280, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.517500, global_samples_per_second: 17.708900, global_steps_per_second: 2.213600, tokens_trained_current_step: 8192, timestamp: 1752747777963, TFLOPS_per_sec_per_card: 23.107000, tokens_per_sec_per_card: 18133.800000, tokens_per_sec_per_card_average: 18263.900000, lm_loss_cur_dp: 6.175588130950928, progress_or_epoch: 0.700000\r\n",
      "[INFO] 2025-07-17 18:23:02,408 [logging_callback.py:   43][rank--1]:    loss: 6.2560478210449215, loss_cur_dp: 6.2560478210449215, learning_rate: 1.000000e-04, global_step: 290, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.443700, global_samples_per_second: 18.003000, global_steps_per_second: 2.250400, tokens_trained_current_step: 8192, timestamp: 1752747782407, TFLOPS_per_sec_per_card: 23.491000, tokens_per_sec_per_card: 18435.300000, tokens_per_sec_per_card_average: 18283.000000, lm_loss_cur_dp: 6.25604772567749, progress_or_epoch: 0.725000\r\n",
      "[INFO] 2025-07-17 18:23:06,833 [logging_callback.py:   43][rank--1]:    loss: 6.1966102600097654, loss_cur_dp: 6.1966102600097654, learning_rate: 1.000000e-04, global_step: 300, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.425300, global_samples_per_second: 18.077900, global_steps_per_second: 2.259700, tokens_trained_current_step: 8192, timestamp: 1752747786832, TFLOPS_per_sec_per_card: 23.588000, tokens_per_sec_per_card: 18511.500000, tokens_per_sec_per_card_average: 18305.800000, lm_loss_cur_dp: 6.196610450744629, progress_or_epoch: 0.750000\r\n",
      "[INFO] 2025-07-17 18:23:11,246 [logging_callback.py:   43][rank--1]:    loss: 6.184060668945312, loss_cur_dp: 6.184060668945312, learning_rate: 1.000000e-04, global_step: 310, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.413100, global_samples_per_second: 18.127800, global_steps_per_second: 2.266000, tokens_trained_current_step: 8192, timestamp: 1752747791245, TFLOPS_per_sec_per_card: 23.654000, tokens_per_sec_per_card: 18563.100000, tokens_per_sec_per_card_average: 18329.200000, lm_loss_cur_dp: 6.184060573577881, progress_or_epoch: 0.775000\r\n",
      "[INFO] 2025-07-17 18:23:15,734 [logging_callback.py:   43][rank--1]:    loss: 6.228264617919922, loss_cur_dp: 6.228264617919922, learning_rate: 1.000000e-04, global_step: 320, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.488000, global_samples_per_second: 17.825300, global_steps_per_second: 2.228200, tokens_trained_current_step: 8192, timestamp: 1752747795733, TFLOPS_per_sec_per_card: 23.259000, tokens_per_sec_per_card: 18253.400000, tokens_per_sec_per_card_average: 18322.900000, lm_loss_cur_dp: 6.228264808654785, progress_or_epoch: 0.800000\r\n",
      "[INFO] 2025-07-17 18:23:20,118 [logging_callback.py:   43][rank--1]:    loss: 6.387460327148437, loss_cur_dp: 6.387460327148437, learning_rate: 1.000000e-04, global_step: 330, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.383800, global_samples_per_second: 18.249000, global_steps_per_second: 2.281100, tokens_trained_current_step: 8192, timestamp: 1752747800117, TFLOPS_per_sec_per_card: 23.812000, tokens_per_sec_per_card: 18686.800000, tokens_per_sec_per_card_average: 18350.900000, lm_loss_cur_dp: 6.387460231781006, progress_or_epoch: 0.825000\r\n",
      "[INFO] 2025-07-17 18:23:24,465 [logging_callback.py:   43][rank--1]:    loss: 6.1727344512939455, loss_cur_dp: 6.1727344512939455, learning_rate: 1.000000e-04, global_step: 340, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.346700, global_samples_per_second: 18.404900, global_steps_per_second: 2.300600, tokens_trained_current_step: 8192, timestamp: 1752747804464, TFLOPS_per_sec_per_card: 24.015000, tokens_per_sec_per_card: 18846.500000, tokens_per_sec_per_card_average: 18386.300000, lm_loss_cur_dp: 6.17273473739624, progress_or_epoch: 0.850000\r\n",
      "[INFO] 2025-07-17 18:23:28,896 [logging_callback.py:   43][rank--1]:    loss: 6.076834869384766, loss_cur_dp: 6.076834869384766, learning_rate: 1.000000e-04, global_step: 350, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.431100, global_samples_per_second: 18.054400, global_steps_per_second: 2.256800, tokens_trained_current_step: 8192, timestamp: 1752747808895, TFLOPS_per_sec_per_card: 23.558000, tokens_per_sec_per_card: 18487.700000, tokens_per_sec_per_card_average: 18393.100000, lm_loss_cur_dp: 6.0768351554870605, progress_or_epoch: 0.875000\r\n",
      "[INFO] 2025-07-17 18:23:33,239 [logging_callback.py:   43][rank--1]:    loss: 6.216682052612304, loss_cur_dp: 6.216682052612304, learning_rate: 1.000000e-04, global_step: 360, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.343300, global_samples_per_second: 18.419200, global_steps_per_second: 2.302400, tokens_trained_current_step: 8192, timestamp: 1752747813239, TFLOPS_per_sec_per_card: 24.034000, tokens_per_sec_per_card: 18861.300000, tokens_per_sec_per_card_average: 18422.300000, lm_loss_cur_dp: 6.216681957244873, progress_or_epoch: 0.900000\r\n",
      "[INFO] 2025-07-17 18:23:37,655 [logging_callback.py:   43][rank--1]:    loss: 6.279055786132813, loss_cur_dp: 6.279055786132813, learning_rate: 5.006144e-05, global_step: 370, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.415400, global_samples_per_second: 18.118400, global_steps_per_second: 2.264800, tokens_trained_current_step: 8192, timestamp: 1752747817654, TFLOPS_per_sec_per_card: 23.641000, tokens_per_sec_per_card: 18553.200000, tokens_per_sec_per_card_average: 18430.000000, lm_loss_cur_dp: 6.279056072235107, progress_or_epoch: 0.925000\r\n",
      "[INFO] 2025-07-17 18:23:42,112 [logging_callback.py:   43][rank--1]:    loss: 5.976035308837891, loss_cur_dp: 5.976035308837891, learning_rate: 2.644696e-05, global_step: 380, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.456200, global_samples_per_second: 17.952400, global_steps_per_second: 2.244100, tokens_trained_current_step: 8192, timestamp: 1752747822110, TFLOPS_per_sec_per_card: 23.425000, tokens_per_sec_per_card: 18383.700000, tokens_per_sec_per_card_average: 18427.400000, lm_loss_cur_dp: 5.9760355949401855, progress_or_epoch: 0.950000\r\n",
      "[INFO] 2025-07-17 18:23:46,605 [logging_callback.py:   43][rank--1]:    loss: 5.983847045898438, loss_cur_dp: 5.983847045898438, learning_rate: 1.528036e-05, global_step: 390, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.493300, global_samples_per_second: 17.804200, global_steps_per_second: 2.225500, tokens_trained_current_step: 8192, timestamp: 1752747826604, TFLOPS_per_sec_per_card: 23.231000, tokens_per_sec_per_card: 18231.300000, tokens_per_sec_per_card_average: 18417.100000, lm_loss_cur_dp: 5.983847141265869, progress_or_epoch: 0.975000\r\n",
      "[INFO] 2025-07-17 18:23:51,101 [logging_callback.py:   43][rank--1]:    loss: 6.152989196777344, loss_cur_dp: 6.152989196777344, learning_rate: 1.000000e-05, global_step: 400, mem_allocated_gb: 5.867755, max_mem_allocated_gb: 8.419803, mem_reserved_gb: 8.815919, max_mem_reserved_gb: 8.815919, loss_scale: 32770.000000, global_runtime: 4.496400, global_samples_per_second: 17.792100, global_steps_per_second: 2.224000, tokens_trained_current_step: 8192, timestamp: 1752747831100, TFLOPS_per_sec_per_card: 23.216000, tokens_per_sec_per_card: 18219.000000, tokens_per_sec_per_card_average: 18407.200000, lm_loss_cur_dp: 6.152989387512207, progress_or_epoch: 1.000000\r\n",
      "[INFO] 2025-07-17 18:23:51,103 [  trainer.py: 2931][rank--1]:    Saving model checkpoint to ./output_pretrain/checkpoint-400\r\n",
      "[INFO] 2025-07-17 18:23:51,107 [tokenizer_utils_base.py: 1894][rank--1]:    tokenizer config file saved in ./output_pretrain/checkpoint-400/tokenizer_config.json\r\n",
      "[INFO] 2025-07-17 18:23:51,107 [tokenizer_utils_base.py: 1900][rank--1]:    Special tokens file saved in ./output_pretrain/checkpoint-400/special_tokens_map.json\r\n",
      "[INFO] 2025-07-17 18:23:51,108 [tokenizer_utils_base.py: 1929][rank--1]:    added tokens file saved in ./output_pretrain/checkpoint-400/added_tokens.json\r\n",
      "[INFO] 2025-07-17 18:23:51,115 [configuration_utils.py:  741][rank--1]:    Configuration saved in ./output_pretrain/checkpoint-400/config.json\r\n",
      "[INFO] 2025-07-17 18:23:51,117 [configuration_utils.py:  334][rank--1]:    Configuration saved in ./output_pretrain/checkpoint-400/generation_config.json\r\n",
      "[INFO] 2025-07-17 18:23:54,829 [model_utils.py: 2895][rank--1]:    Model weights saved in ./output_pretrain/checkpoint-400/model_state.pdparams\r\n",
      "[INFO] 2025-07-17 18:23:54,831 [  trainer.py: 2790][rank--1]:    Saving optimizer files.\r\n",
      "[INFO] 2025-07-17 18:24:00,414 [logging_callback.py:   43][rank--1]:    is_persistent_ckpt: 1, save_ckpt_time_sec: 9.310926, global_save_step: 400, train_time_sec_without_save: 89.028941, average_tokens_per_sec_per_card_without_save: 18403.000000, average_tokens_per_sec_per_card_with_save: 16660.590000, one_day_billion_tokens_without_save: 1.590000, one_day_billion_tokens_with_save: 1.440000, progress_or_epoch: 1.000000\r\n",
      "[INFO] 2025-07-17 18:24:00,415 [  trainer.py: 1415][rank--1]:    \r\n",
      "Training completed. \r\n",
      "\r\n",
      "[INFO] 2025-07-17 18:24:00,416 [logging_callback.py:   43][rank--1]:    train_runtime: 199.118400, train_samples_per_second: 16.070800, train_steps_per_second: 2.008900, train_loss: 6.959455, progress_or_epoch: 1.000000\r\n",
      "[INFO] 2025-07-17 18:24:00,417 [  trainer.py: 2931][rank--1]:    Saving model checkpoint to ./output_pretrain/\r\n",
      "[INFO] 2025-07-17 18:24:00,420 [tokenizer_utils_base.py: 1894][rank--1]:    tokenizer config file saved in ./output_pretrain/tokenizer_config.json\r\n",
      "[INFO] 2025-07-17 18:24:00,421 [tokenizer_utils_base.py: 1900][rank--1]:    Special tokens file saved in ./output_pretrain/special_tokens_map.json\r\n",
      "[INFO] 2025-07-17 18:24:00,421 [tokenizer_utils_base.py: 1929][rank--1]:    added tokens file saved in ./output_pretrain/added_tokens.json\r\n",
      "[INFO] 2025-07-17 18:24:00,428 [configuration_utils.py:  741][rank--1]:    Configuration saved in ./output_pretrain/config.json\r\n",
      "[INFO] 2025-07-17 18:24:00,429 [configuration_utils.py:  334][rank--1]:    Configuration saved in ./output_pretrain/generation_config.json\r\n",
      "[INFO] 2025-07-17 18:24:02,927 [model_utils.py: 2895][rank--1]:    Model weights saved in ./output_pretrain/model_state.pdparams\r\n",
      "[INFO] 2025-07-17 18:24:02,928 [trainer_utils.py:  679][rank--1]:    ***** train metrics *****\r\n",
      "[INFO] 2025-07-17 18:24:02,928 [trainer_utils.py:  684][rank--1]:      progress_or_epoch        =        1.0\r\n",
      "[INFO] 2025-07-17 18:24:02,928 [trainer_utils.py:  684][rank--1]:      train_loss               =     6.9595\r\n",
      "[INFO] 2025-07-17 18:24:02,928 [trainer_utils.py:  684][rank--1]:      train_runtime            = 0:03:19.11\r\n",
      "[INFO] 2025-07-17 18:24:02,928 [trainer_utils.py:  684][rank--1]:      train_samples_per_second =    16.0708\r\n",
      "[INFO] 2025-07-17 18:24:02,928 [trainer_utils.py:  684][rank--1]:      train_steps_per_second   =     2.0089\r\n"
     ]
    }
   ],
   "source": [
    "# 1. 首先，切换工作目录到 pre-training 文件夹\n",
    "%cd ./examples/pre-training/\n",
    "\n",
    "# 2. 然后，从此目录启动训练脚本\n",
    "#    注意：配置文件的路径因为工作目录变化，需要使用 ../../ 来返回到项目根目录\n",
    "!python -u ernie/pretrain.py --config ../../pretrain_ernie_0.3b_demo.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Observing the Training Process\n",
    "\n",
    "Once training begins, you will see log information similar to the following in the terminal (specific values may vary):\n",
    "\n",
    "**Key Log Interpretation:**\n",
    "*   `global_step`: The current total number of training steps.\n",
    "*   `loss`: The loss value calculated for the current step. **This is a very important metric!** We expect to see `loss` gradually decrease as training progresses.\n",
    "*   `learning_rate`: The current learning rate. You can observe it gradually increasing within the `warmup_steps`.\n",
    "*   `speed`: Training speed, indicating the number of steps processed per second.\n",
    "*   `vram`: VRAM usage during training (MB).\n",
    "\n",
    "**Expected Phenomena:**\n",
    "*   **Loss Decrease**: This is the most critical indicator, signifying that the model is learning from the data.\n",
    "* **VRAM usage**: For the `ERNIE-4.5-0.3B` model, under the above configuration, VRAM usage is expected to be around 10GB. If a `CUDA out of memory` error occurs, it indicates insufficient VRAM, and the configuration needs to be adjusted (see the “Advanced and Common Issues” section below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Result Analysis and Interpretation\n",
    "\n",
    "When training reaches the `max_steps` you set in the configuration file, the pre-training process is complete. All training outputs are saved in the directory specified in the configuration file `output_dir`, i.e., `./output_pretrain/`.\n",
    "\n",
    "After training is complete, you can view the contents of this directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:25:03.515270Z",
     "iopub.status.busy": "2025-07-17T10:25:03.514988Z",
     "iopub.status.idle": "2025-07-17T10:25:03.750814Z",
     "shell.execute_reply": "2025-07-17T10:25:03.750222Z",
     "shell.execute_reply.started": "2025-07-17T10:25:03.515248Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1.6G\r\n",
      "-rw-r--r-- 1 aistudio aistudio  23K Jul 17 18:24 added_tokens.json\r\n",
      "-rw-r--r-- 1 aistudio aistudio  179 Jul 17 18:24 all_results.json\r\n",
      "drwxr-xr-x 1 aistudio aistudio 4.0K Jul 17 17:25 \u001b[0m\u001b[01;34mcheckpoint-200\u001b[0m/\r\n",
      "drwxr-xr-x 2 aistudio aistudio 4.0K Jul 17 18:24 \u001b[01;34mcheckpoint-400\u001b[0m/\r\n",
      "-rw-r--r-- 1 aistudio aistudio 4.1K Jul 17 18:24 config.json\r\n",
      "-rw-r--r-- 1 aistudio aistudio  167 Jul 17 18:24 generation_config.json\r\n",
      "drwxr-xr-x 1 aistudio aistudio 4.0K Jul 17 15:47 \u001b[01;34mlog\u001b[0m/\r\n",
      "-rw-r--r-- 1 aistudio aistudio 1.6G Jul 17 18:24 model_state.pdparams\r\n",
      "drwxr-xr-x 1 aistudio aistudio 4.0K Jul 17 18:20 \u001b[01;34mruns\u001b[0m/\r\n",
      "-rw-r--r-- 1 aistudio aistudio  16K Jul 17 18:24 special_tokens_map.json\r\n",
      "-rw-r--r-- 1 aistudio aistudio 9.8K Jul 17 18:24 static_name_to_dyg_name.json\r\n",
      "-rw-r--r-- 1 aistudio aistudio 1.6M Jul 17 18:24 tokenizer.model\r\n",
      "-rw-r--r-- 1 aistudio aistudio 132K Jul 17 18:24 tokenizer_config.json\r\n",
      "-rw-r--r-- 1 aistudio aistudio  179 Jul 17 18:24 train_results.json\r\n",
      "-rw-r--r-- 1 aistudio aistudio  322 Jul 17 18:24 trainer_state.json\r\n",
      "-rw-r--r-- 1 aistudio aistudio 4.4K Jul 17 18:24 training_args.bin\r\n"
     ]
    }
   ],
   "source": [
    "ls -lh ./output_pretrain/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key files and directories explained:**\n",
    "*   **Root directory files**: These contain the final model and configuration at the end of training (when `max_steps` is reached).\n",
    "*   **`checkpoint-<step_number>/`**: These are checkpoint directories saved periodically according to the `save_steps` parameter. Each checkpoint contains the complete model state at that point in time, which can be used to resume training from that point or load the model at that stage for evaluation.\n",
    "*   **`visualdl/`**: VisualDL log files. You can start a web service using `visualdl --logdir ./output_pretrain/visualdl` to visually view metrics such as the loss curve.\n",
    "\n",
    "**Preliminary evaluation of pre-training effectiveness:**\n",
    "For this brief tutorial, the primary focus is on whether the **`loss` shows a clear downward trend**. For example, a decrease from an initial range of 9-10 to 6-7 can be considered a successful basic pre-training process, indicating that the model has learned some statistical patterns of the language. To achieve a truly powerful model, longer training on a larger dataset is required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Advanced Topics and Common Issues\n",
    "\n",
    "### 7.1 Insufficient Memory (CUDA Out of Memory)\n",
    "\n",
    "This is the most common issue. Solutions:\n",
    "1.  **Increase the gradient accumulation steps**: Further increase `gradient_accumulation_steps` in the configuration file (e.g., 16, 32). This is the most effective and recommended method.\n",
    "2.  **Reduce the batch size**: Set `per_device_train_batch_size` to a smaller value (but it is usually already set to 1).\n",
    "3.  **Reduce the sequence length**: Reduce `max_seq_length` (e.g., 512), but this will affect the model's ability to learn long-range dependencies.\n",
    "4.  **Use more aggressive optimization**: `ERNIEKit` supports advanced memory optimization techniques such as gradient recomputation (Recompute), which can be enabled in the configuration file by setting `recompute: True` (possibly under `model_args`), but this will increase computation time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary and Outlook\n",
    "\n",
    "Congratulations! By completing this tutorial, you have:\n",
    "\n",
    "*  Gained a comprehensive understanding of the process of pre-training the `ERNIE 4.5` model using `ERNIEKit`.\n",
    "*  Mastered how to prepare data, configure `yaml` files, and start and monitor training.\n",
    "*  Gained an in-depth understanding of the core concepts, key parameters, and results analysis of pre-training.\n",
    "\n",
    "The core of this tutorial is that by analyzing the underlying scripts of `ERNIEKit`, we have successfully simplified a complex pre-training process designed for large clusters into a mini-process that can run on a single consumer-grade GPU, making it suitable for learning and experimentation.\n",
    "\n",
    "**Looking ahead:**\n",
    "The pre-trained model serves as a general-purpose “language foundation.” Moving forward, you can explore:\n",
    "\n",
    "*   **Larger-scale pre-training**: Train on more data for longer periods to obtain more powerful foundational models.\n",
    "*   **Model fine-tuning (Fine-tuning)**: This is typically the next step after pre-training. Fine-tuning a pre-trained model using supervised data (such as question-answer pairs) can make it better at following instructions and completing specific tasks. `ERNIEKit` provides a powerful `erniekit train` command to support fine-tuning methods such as SFT and DPO.\n",
    "\n",
    "We hope this tutorial opens the door to exploring the world of the ERNIE large model. Thank you for reading!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedback/Contact me: WeChat: G_Fuji"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
