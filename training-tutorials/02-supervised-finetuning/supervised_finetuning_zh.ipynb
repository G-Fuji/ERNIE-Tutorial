{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于 ERNIE-4.5-0.3B 的大语言模型监督微调 (SFT) 教程\n",
    "\n",
    "## 1. 引言\n",
    "\n",
    "欢迎来到这篇关于使用 ERNIEkit 对 ERNIE-4.5-0.3B 模型进行监督微调 (Supervised Fine-Tuning, SFT) 的教程！在上一篇预训练教程中，我们已经探索了如何从零开始构建一个语言模型，赋予它理解和生成文本的基础能力。然而，一个经过预训练的通用大模型，就像一个知识渊博但未经专门训练的通才，它拥有海量的知识，却不一定能精准地遵循我们的具体指令来完成特定任务。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 什么是大语言模型监督微调 (SFT)？\n",
    "\n",
    "**监督微调 (SFT)** 是将通用大模型转化为专业助手的关键步骤。它在预训练好的模型基础上，利用一个包含“指令 (Instruction/Prompt)”和“期望输出 (Response/Output)”的标注数据集，对模型进行进一步的训练。这个过程好比是为一位博学的通才提供“岗前培训”，教会它如何理解并遵循人类的指令，如何针对特定问题生成高质量的回答，或者如何模仿某种特定的对话风格和格式。\n",
    "\n",
    "**SFT 与预训练 (PT) 的核心区别：**\n",
    "\n",
    "| 特性 | 预训练 (PT) | 监督微调 (SFT) |\n",
    "|---|---|---|\n",
    "| **目标** | 学习通用的语言规律、语法结构和世界知识 | 学习遵循指令、解决特定任务、对齐人类意图和价值观 |\n",
    "| **数据** | 大规模、**无标签**的纯文本数据（如网页、书籍、代码） | 相对较小规模、**有高质量标签**的“指令-输出”对数据 |\n",
    "| **学习方式** | 无监督或自监督学习（如预测下一个词） | 有监督学习（学习从输入指令到期望输出的映射） |\n",
    "| **计算资源** | 通常需求巨大，需要海量数据和超长训练时间 | 相对较小，可在预训练模型基础上进行高效、快速的迭代 |\n",
    "| **模型角色** | 训练一个“基础模型” (Base Model)，奠定能力基础 | 在“基础模型”上进行“指令调优” (Instruction Tuning)，特化模型行为 |\n",
    "\n",
    "简而言之，预训练让模型“学会说话”，而监督微调则教模型“好好说话”、“听话办事”，使其行为与人类的期望对齐。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 SFT 的应用场景和意义\n",
    "\n",
    "SFT 是释放大语言模型潜力的核心技术，其意义和应用场景极为广泛。我们可以通过下表来直观感受：\n",
    "\n",
    "|  | 应用场景 | 核心意义 | \n",
    "| :---: | :--- | :--- | \n",
    "| 🎯 | **提升特定任务性能** | 通过在特定领域的指令数据上进行SFT，可以显著提升模型在客服问答、代码生成、法律文书摘要、医疗咨询等任务上的专业性、准确性和可靠性。 | \n",
    "| 🙏 | **模型对齐 (Alignment)** | SFT 是实现模型与人类意图和价值观对齐的关键一步。通过精心设计的指令和期望的回答（通常强调有用性、真实性和无害性），引导模型生成负责任、有帮助的内容。 | \n",
    "| 💬 | **构建强大的对话式AI** | 所有顶尖的聊天机器人，无一不经过了大量的SFT训练。这使得它们能够进行流畅、自然、且富有逻辑的多轮对话，真正成为用户的得力助手。 | \n",
    "| 🎭 | **遵循特定风格或格式** | 我们可以通过SFT训练模型以固定的格式（如JSON、Markdown）输出，或者扮演特定的角色（如莎士比亚、技术专家），甚至生成具有特定情感基调的文本。 | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 为什么选择 ERNIE-4.5-0.3B 进行 SFT？\n",
    "\n",
    "选择 `ERNIE-4.5-0.3B` 作为我们SFT实践的主角，是基于以下几点关键优势：\n",
    "\n",
    "|  | 优势 | 详细说明 |\n",
    "| :---: | :--- | :--- |\n",
    "| 🏆 | **卓越的预训练基础** | `ERNIE-4.5-0.3B` 作为文心大模型的最新成员，其本身经过了海量、高质量数据的充分预训练，具备了世界领先的中文处理能力和通用语言理解能力。这是一个极其强大的SFT起点。 |\n",
    "| 💰 | **参数规模适中，性价比高** | 0.3B（3亿）的参数量，使得在消费级或主流的计算资源上进行全参数SFT成为可能。这极大地降低了开发者和研究者进行实验和快速迭代的门槛，是探索SFT的最佳选择之一。 |\n",
    "| 🛠️ | **ERNIEkit 的全面支持** | ERNIEkit 是飞桨为文心大模型量身打造的开发套件，提供了从预训练、SFT、到推理部署的全流程工具。其SFT脚本经过精心优化，支持全参数微调、LoRA等多种参数高效微调（PEFT）方法，并且配置灵活，使用便捷。 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 本教程的目标读者和学习成果\n",
    "\n",
    "本教程旨在帮助不同背景的您，深入SFT的世界。看看您属于哪一类读者，以及您将收获什么：\n",
    "\n",
    "|  | 目标读者 | 您将获得的学习成果 (You Will Be Able To) |\n",
    "| :---: | :--- | :--- |\n",
    "| 🧑‍🎓 | **进阶学习者** | 深刻理解SFT的核心原理、应用价值及其与预训练的本质区别。 |\n",
    "| 👨‍💻 | **开发者/工程师** | 掌握使用 ERNIEkit 对 ERNIE-4.5-0.3B 模型进行SFT的完整流程和最佳实践。 |\n",
    "| 🔬 | **研究者** | 了解SFT数据的标准格式和构建方法，并对参数高效微调 (PEFT) 如LoRA有一个初步的认识。 |\n",
    "| 🚀 | **所有读者** | 学会如何解读和配置 ERNIEkit 的SFT `yaml` 文件，启动训练任务，并分析训练过程，最终对微调后的模型进行推理测试，直观感受SFT带来的能力提升。 |\n",
    "\n",
    "现在，让我们一起踏上征程，通过SFT技术，将强大的 ERNIE-4.5-0.3B 模型“调教”成更懂你、更能干的专属AI助手！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 环境准备\n",
    "\n",
    "进行监督微调 (SFT) 的第一步是搭建一个稳定、高效的开发环境。这包括安装核心的深度学习框架 PaddlePaddle、模型开发套件 ERNIEkit，并准备好我们本次实践的主角——ERNIE-4.5-0.3B 模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 安装 PaddlePaddle 和 aistudio-sdk\n",
    "\n",
    "确保您安装了最新或推荐版本的 PaddlePaddle。推荐使用GPU版本的 PaddlePaddle 以获得极致的训练速度。同时，我们需要安装 `aistudio-sdk`，它是一个非常方便的工具，可以帮助我们轻松下载AI-Studio上的模型资源。\n",
    "\n",
    "*在AI studio上运行本项目的同学不需要运行下方的环境安装代码块*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 确保 pip 是最新版本\r\n",
    "!python -m pip install --upgrade pip\r\n",
    "\r\n",
    "# 安装 PaddlePaddle (GPU 版本, 推荐使用最新的稳定版)\r\n",
    "# 如果您的环境（如CUDA版本）不同，请访问官网获取对应指令: https://www.paddlepaddle.org.cn/install/quick\r\n",
    "!python -m pip install paddlepaddle-gpu -i https://mirror.baidu.com/pypi/simple\r\n",
    "\r\n",
    "# 安装 aistudio-sdk\r\n",
    "!pip install --upgrade aistudio-sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**验证安装**："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:57:48.734168Z",
     "iopub.status.busy": "2025-07-17T10:57:48.733664Z",
     "iopub.status.idle": "2025-07-17T10:57:50.521500Z",
     "shell.execute_reply": "2025-07-17T10:57:50.520994Z",
     "shell.execute_reply.started": "2025-07-17T10:57:48.734146Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/utils/cpp_extension/extension_utils.py:715: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\r\n",
      "  warnings.warn(warning_message)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PaddlePaddle Version: 3.1.0\r\n",
      "Running verify PaddlePaddle program ... \r\n",
      "PaddlePaddle works well on 1 GPU.\r\n",
      "PaddlePaddle is installed successfully! Let's start deep learning with PaddlePaddle now.\r\n",
      "PaddlePaddle GPU is available! Found 1 GPU(s).\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0717 18:57:50.384768   265 pir_interpreter.cc:1524] New Executor is Running ...\r\n",
      "W0717 18:57:50.386147   265 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.8, Runtime API Version: 12.6\r\n",
      "I0717 18:57:50.386685   265 pir_interpreter.cc:1547] pir interpreter is running by multi-thread mode ...\r\n"
     ]
    }
   ],
   "source": [
    "import paddle\r\n",
    "\r\n",
    "print(f\"PaddlePaddle Version: {paddle.__version__}\")\r\n",
    "\r\n",
    "# 检查GPU是否可用\r\n",
    "try:\r\n",
    "    paddle.utils.run_check()\r\n",
    "    if paddle.device.cuda.device_count() > 0:\r\n",
    "        print(f\"PaddlePaddle GPU is available! Found {paddle.device.cuda.device_count()} GPU(s).\")\r\n",
    "    else:\r\n",
    "        print(\"PaddlePaddle GPU check passed, but no GPU found. Will use CPU.\")\r\n",
    "except Exception as e:\r\n",
    "    print(f\"PaddlePaddle GPU check failed: {e}\")\r\n",
    "    print(\"If you intended to use GPU, please check your CUDA setup and PaddlePaddle installation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 下载 ERNIEkit 仓库代码和 ERNIE-4.5-0.3B 模型\n",
    "\n",
    "ERNIEkit 的SFT脚本 (`train.py`) 和相关的模型、训练配置文件都位于其官方仓库中。同时，我们需要使用 `aistudio` 命令行工具下载 ERNIE-4.5-0.3B 模型权重。\n",
    "\n",
    "*在AI studio运行的同学不需要运行下方代码块*\n",
    "\n",
    "- ERNIE：/home/aistudio/ERNIE-develop.zip\n",
    "- model：/home/aistudio/data/models/30654/ERNIE-4.5-0.3B-Base-Paddle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1. 克隆 ERNIEkit 仓库\r\n",
    "# 我们将克隆最新的 ERNIE-develop 分支，以获取最新的功能和优化\r\n",
    "!git clone https://github.com/PaddlePaddle/ERNIE.git -b develop ERNIE-develop\r\n",
    "\r\n",
    "# 2. 下载 ERNIE-4.5-0.3B 模型权重\r\n",
    "# 使用 aistudio-sdk 提供的命令行工具下载\r\n",
    "# 模型将被下载到 baidu/ERNIE-4.5-0.3B-Paddle 目录下\r\n",
    "!aistudio download --model PaddlePaddle/ERNIE-4.5-0.3B-Paddle --local_dir baidu/ERNIE-4.5-0.3B-Paddle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**重要目录结构说明**：\n",
    "\n",
    "执行完上述命令后，您的工作目录下应该有类似这样的结构：\n",
    "\n",
    "```\n",
    ".\n",
    "├── ERNIE-develop/\n",
    "│   ├── examples/\n",
    "│   │   ├── configs/\n",
    "│   │   │   └── ERNIE-4.5-0.3B/\n",
    "│   │   │       └── sft/\n",
    "│   │   │           └── run_sft_8k.yaml  <-- 这是我们的SFT配置文件\n",
    "│   │   └── data/\n",
    "│   │       └── sft-train.jsonl        <-- 这是示例的SFT数据\n",
    "│   ├── train.py                     <-- 这是ERNIEkit的训练脚本\n",
    "│   └── ... (其他ERNIEkit代码)\n",
    "└── baidu/\n",
    "    └── ERNIE-4.5-0.3B-Paddle/       <-- 这里存放着模型权重和配置文件\n",
    "        ├── model_state.pdparams\n",
    "        ├── tokenizer_config.json\n",
    "        └── ... (其他模型文件)\n",
    "```\n",
    "\n",
    "Ai studio的同学模型目录则在data文件夹内！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在后续的教程中，我们将主要在 `ERNIE-develop` 目录下进行操作，并使用 `train.py` 脚本，结合 `examples/configs/ERNIE-4.5-0.3B/sft/run_sft_8k.yaml` 配置文件，来加载 `baidu/ERNIE-4.5-0.3B-Paddle` 目录下的模型进行微调。\n",
    "\n",
    "请确保您的目录结构与此一致，以便顺利进行后续步骤。\n",
    "\n",
    "环境和资源都已准备就绪，接下来，让我们深入了解SFT的核心——数据。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SFT 数据准备\n",
    "\n",
    "“Garbage in, garbage out.” 这句名言在SFT中体现得淋漓尽致。SFT的效果在很大程度上取决于所用指令数据的质量。高质量的数据能够引导模型学习到正确的行为模式，而低质量的数据则可能导致模型产生有偏见、不准确甚至有害的输出。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 SFT 数据的特点与格式\n",
    "\n",
    "SFT数据由成对的“指令 (Instruction/Prompt)”和“理想输出 (Response/Output)”组成。ERNIEkit 使用 JSON Lines (jsonl) 格式，其中每一行都是一个独立的JSON对象，代表一个训练样本。这种格式清晰、可扩展，非常适合大规模数据集的处理。\n",
    "\n",
    "**ERNIEkit SFT 数据格式详解：**\n",
    "\n",
    "一个标准的 ERNIEkit SFT 样本结构如下：\n",
    "\n",
    "```json\n",
    "{\"src\": \"你好\", \"tgt\": \"你好！很高兴为您服务。\"}\n",
    "{\"src\": \"请写一首关于月亮的诗。\", \"tgt\": \"床前明月光，疑是地上霜。举头望明月，低头思故乡。\"}\n",
    "```\n",
    "\n",
    "*   `src` (Source): 代表输入给模型的指令或问题。这部分内容会经过模板化处理，作为模型的输入提示 (Prompt)。\n",
    "*   `tgt` (Target): 代表期望模型生成的回答。这是模型需要学习和模仿的目标输出。\n",
    "\n",
    "**对话模板的重要性：**\n",
    "\n",
    "像 ERNIE-4.5 这样的对话模型，在训练时通常会遵循一个特定的对话模板。这个模板定义了用户 (user) 和助手 (assistant) 的角色，并使用特殊的 token 来分隔不同的轮次。ERNIEkit 的训练脚本会自动将 `src` 和 `tgt` 包装成模型预训练时所使用的模板格式。例如，一个简化的模板可能如下所示：\n",
    "\n",
    "```\n",
    "<|im_start|>user\n",
    "{src}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "{tgt}<|im_end|>\n",
    "```\n",
    "\n",
    "模型在训练时，其任务就是根据 `user` 的内容，续写出 `assistant` 的部分。通过这种方式，模型学会了在对话中扮演助手的角色。\n",
    "\n",
    "**高质量SFT数据的关键要素：**\n",
    "\n",
    "*   **多样性**: 指令应覆盖尽可能多的主题和技能，如问答、创作、摘要、翻译、代码生成等。\n",
    "*   **复杂性**: 指令应包含不同难度级别，从简单的事实问答到需要深度推理和创造力的复杂任务。\n",
    "*   **准确性**: `tgt` 的内容必须是准确、高质量且无害的。\n",
    "*   **一致性**: 输出的风格、格式和详细程度应保持一致，除非您有意训练模型掌握多种风格。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 使用 ERNIEkit 提供的示例 SFT 数据集\n",
    "\n",
    "ERNIEkit 在 `ERNIE-develop/examples/data/` 目录下提供了一个名为 `sft-train.jsonl` 的示例数据集。这是一个小型的、经过清洗的数据集，非常适合用于快速跑通SFT流程和功能验证。\n",
    "\n",
    "让我们来查看一下这个示例数据的内容："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T11:00:53.764115Z",
     "iopub.status.busy": "2025-07-17T11:00:53.763790Z",
     "iopub.status.idle": "2025-07-17T11:00:53.768344Z",
     "shell.execute_reply": "2025-07-17T11:00:53.767908Z",
     "shell.execute_reply.started": "2025-07-17T11:00:53.764095Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "查看示例数据: ./ERNIE-develop/examples/data/sft-train.jsonl\r\n",
      "---\r\n",
      "【样本 1】\r\n",
      "  SRC: ['我们如何在日常生活中减少用水？']\r\n",
      "  TGT: ['1. 使用节水装置，如节水淋浴喷头和水龙头。 \\n2. 使用水箱或水桶收集家庭废水，例如洗碗和洗浴。 \\n3. 在社区中提高节水意识。 \\n4. 检查水管和灌溉系统的漏水情况，并及时修复它们。 \\n5. 洗澡时间缩短，使用低流量淋浴头节约用水。 \\n6. 收集雨水，用于园艺或其他非饮用目的。 \\n7. 刷牙或擦手时关掉水龙头。 \\n8. 减少浇水草坪的时间。 \\n9. 尽可能多地重复使用灰水（来自洗衣机、浴室水槽和淋浴的水）。 \\n10. 只购买能源效率高的洗碗机和洗衣机。']\r\n",
      "\r\n",
      "【样本 2】\r\n",
      "  SRC: ['政府可以采取哪些策略来减少空气污染？']\r\n",
      "  TGT: ['1. 实施强制的车辆排放标准和基于激励的计划，以降低车辆的碳足迹。\\n2. 增加公共交通工具，减少公众对车辆的依赖。\\n3. 增加对空气污染的影响的认识，鼓励市民减少污染物的生成。\\n4. 投资于可再生能源的研究和开发，如太阳能和风能。\\n5. 在工厂和发电厂安装空气污染控制装置，例如洗涤器。\\n6. 对车辆和工厂使用清洁燃料。\\n7. 实施更好的城市规划和控制拓展。\\n8. 改善农业效率，减少化肥和杀虫剂的使用。\\n9. 种植更多的树木以减少空气污染。\\n10. 减少木材、煤炭和生物质的燃烧。']\r\n",
      "\r\n",
      "【样本 3】\r\n",
      "  SRC: ['可再生能源的存在对环境有什么影响？']\r\n",
      "  TGT: ['可再生能源的存在可以帮助减少空气污染和温室气体排放，因为它们几乎不会排放二氧化碳、二氧化硫等空气污染物。此外，使用可再生能源可以促进能源效率的进一步提高和能源利用的改善。可再生能源也可以帮助减少对化石燃料的依赖，这不仅可以减少排放，而且还可以帮助减少全球气候变化的风险。最后，可再生能源可以帮助保护自然资源，减少为了能源生产而开发更多土地和资源的需要。']\r\n",
      "\r\n",
      "【样本 4】\r\n",
      "  SRC: ['解释神经网络如何学习。']\r\n",
      "  TGT: ['神经网络是一种机器学习算法，它使用连接的节点集合来近似可以将输入变量映射到输出的函数。为了学习神经网络的参数，计算机需要调整节点之间连接的权重，以便网络为给定输入产生正确的输出。这个调整过程称为学习，通过比较网络产生的输出和期望的结果，然后使用优化算法来调整权重，使得网络输出逼近期望的结果。这个过程在多个输入和期望的输出上重复进行多次迭代。最终，连接节点之间的权重将被调整，以便神经网络的输出与期望的结果相匹配，学习过程将完成。']\r\n",
      "\r\n",
      "【样本 5】\r\n",
      "  SRC: ['给出一个机器学习算法的例子，并解释它是如何工作的。']\r\n",
      "  TGT: ['一个流行的机器学习算法的例子是支持向量机（SVM）。它是一个用于分类和回归任务的监督学习算法。它通过在n维空间中绘制数据点，由空间中的决策边界或超平面进行分离。该算法使用最大边距，这些边距尽可能远离两类数据点。这些边距有助于创建最优的决策超平面。然后，算法通过考虑分类任务中发生的错误来调整决策超平面，并相应地修改超平面。\\n\\n最终，支持向量机可以使用最优的决策超平面执行分类任务，预测数据点的类别。']\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "import json\r\n",
    "\r\n",
    "# 定义示例数据路径\r\n",
    "sample_data_path = \"./ERNIE-develop/examples/data/sft-train.jsonl\"\r\n",
    "\r\n",
    "# 读取并打印前5条样本\r\n",
    "print(f\"查看示例数据: {sample_data_path}\\n---\")\r\n",
    "with open(sample_data_path, 'r', encoding='utf-8') as f:\r\n",
    "    for i, line in enumerate(f):\r\n",
    "        if i >= 5:\r\n",
    "            break\r\n",
    "        data_sample = json.loads(line.strip())\r\n",
    "        print(f\"【样本 {i+1}】\")\r\n",
    "        print(f\"  SRC: {data_sample['src']}\")\r\n",
    "        print(f\"  TGT: {data_sample['tgt']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 如何准备自己的 SFT 数据集\n",
    "\n",
    "在实际应用中，您通常需要根据自己的特定需求构建数据集。以下是构建自定义SFT数据集的一般步骤：\n",
    "\n",
    "1.  **确定目标任务**: 明确您希望模型具备哪些能力。是用于垂直领域的智能客服，还是用于生成特定风格的营销文案？\n",
    "2.  **收集或生成原始数据**: \n",
    "    *   **收集**: 从现有的文档、工单、FAQ、或用户日志中提取“问题-答案”对。\n",
    "    *   **人工标注**: 聘请领域专家或标注人员，根据任务需求编写高质量的指令和回答。\n",
    "    *   **模型生成**: 使用更强大的模型（如GPT-4）生成初步的指令和回答，然后由人工进行筛选和精炼。这是目前构建大规模SFT数据集的主流方法之一。\n",
    "3.  **清洗和格式化**: \n",
    "    *   去除低质量、重复或不相关的数据。\n",
    "    *   进行数据增强，例如，对同一个指令，可以有多种不同的问法。\n",
    "    *   将数据整理成 ERNIEkit 所需的 `jsonl` 格式，即每行一个包含 `src` 和 `tgt` 键的JSON对象。\n",
    "4.  **划分数据集**: 将数据集划分为训练集 (train) 和评估集 (eval/dev)。评估集用于在训练过程中监控模型性能，避免过拟合。通常比例为 95%:5% 或 98%:2%。\n",
    "\n",
    "准备好高质量的数据是SFT成功的基石。现在我们已经了解了数据的准备工作，下一步将深入剖析 ERNIEkit 的SFT配置文件，了解如何通过它来掌控整个微调过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. SFT 配置解析 (`run_sft_8k.yaml`)\n",
    "\n",
    "ERNIEkit 的强大之处在于其灵活性和可配置性。所有的训练参数都集中在 `yaml` 配置文件中，通过修改这个文件，我们可以精确地控制SFT的每一个环节。让我们以 `ERNIE-develop/examples/configs/ERNIE-4.5-0.3B/sft/run_sft_8k.yaml` 为例，逐一解析其中的关键配置项。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 数据配置 (Data)\n",
    "\n",
    "这部分定义了训练和评估所使用的数据集。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "### data\n",
    "train_dataset_type: \"erniekit\"\n",
    "eval_dataset_type: \"erniekit\"\n",
    "train_dataset_path: \"./examples/data/sft-train.jsonl\"\n",
    "train_dataset_prob: \"1.0\"\n",
    "eval_dataset_path: \"./examples/data/sft-eval.jsonl\"\n",
    "eval_dataset_prob: \"1.0\"\n",
    "max_seq_len: 8192\n",
    "num_samples_each_epoch: 6000000\n",
    "```\n",
    "\n",
    "*   `train_dataset_type`, `eval_dataset_type`: 数据集格式类型，这里是 `erniekit`，表示使用我们之前讨论的 `{\"src\": ..., \"tgt\": ...}` 格式。\n",
    "*   `train_dataset_path`, `eval_dataset_path`: 训练和评估数据集的路径。**这里您需要修改为您自己的数据路径。**\n",
    "*   `train_dataset_prob`, `eval_dataset_prob`: 数据集采样概率。当有多个数据集时，可以设置不同概率进行混合训练。\n",
    "*   `max_seq_len`: 模型处理的最大序列长度。`8192` (8K) 是 ERNIE-4.5 的一个常用设置，可以处理非常长的上下文。如果您的GPU显存有限，可以适当减小此值，但这可能会影响模型处理长文本的能力。\n",
    "*   `num_samples_each_epoch`: 每个epoch中包含的样本数。这个值通常设置得比较大，以确保模型在每个epoch中都能看到足够多的数据。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 模型配置 (Model)\n",
    "\n",
    "这部分定义了要微调的基础模型及其相关设置。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "### model\n",
    "model_name_or_path: baidu/ERNIE-4.5-0.3B-Paddle\n",
    "fine_tuning: Full\n",
    "fuse_rope: True\n",
    "use_sparse_head_and_loss_fn: True\n",
    "```\n",
    "\n",
    "*   `model_name_or_path`: **核心参数**。指定基础模型的路径。这里我们使用之前下载的 `baidu/ERNIE-4.5-0.3B-Paddle`。\n",
    "*   `fine_tuning`: 微调方式。`Full` 表示全参数微调，即更新模型的所有权重。这是最彻底但资源消耗也最大的方式。其他选项如 `lora` 将在后续介绍。\n",
    "*   `fuse_rope`: 是否使用优化的 Rotary Position Embedding。`True` 可以提升计算效率。\n",
    "*   `use_sparse_head_and_loss_fn`: 是否使用稀疏的头部和损失函数。这是针对特定模型结构的优化，保持默认即可。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 微调核心配置 (Finetuning)\n",
    "\n",
    "这是控制整个训练流程的核心部分。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "### finetuning\n",
    "# base\n",
    "stage: SFT\n",
    "seed: 23\n",
    "do_train: True\n",
    "do_eval: True\n",
    "distributed_dataloader: False\n",
    "dataloader_num_workers: 1\n",
    "batch_size: 1\n",
    "num_train_epochs: 1\n",
    "max_steps: 100\n",
    "max_evaluate_steps: 10000\n",
    "eval_steps: 10000\n",
    "evaluation_strategy: steps\n",
    "save_steps: 10000000\n",
    "save_total_limit: 5\n",
    "save_strategy: steps\n",
    "logging_steps: 1\n",
    "release_grads: True\n",
    "gradient_accumulation_steps: 8\n",
    "logging_dir: ./vdl_log\n",
    "output_dir: ./output\n",
    "disable_tqdm: True\n",
    "```\n",
    "\n",
    "*   `stage`: 训练阶段，这里是 `SFT`。\n",
    "*   `seed`: 随机种子，用于保证实验的可复现性。\n",
    "*   `do_train`, `do_eval`: 是否执行训练和评估。\n",
    "*   `batch_size`: **重要**。每个设备上的批处理大小。由于大模型非常消耗显存，`1` 是一个常见的起始值。\n",
    "*   `gradient_accumulation_steps`: **重要**。梯度累积步数。这是一种“虚拟”扩大batch size的技巧。实际的 `batch_size` 是 `batch_size` * `gradient_accumulation_steps` * `num_gpus`。在这里，等效的batch size是 `1 * 8 = 8`。增加此值可以模拟更大的batch size，有助于稳定训练，但会减慢训练速度。\n",
    "*   `num_train_epochs`: 训练的总轮数。对于SFT，通常 `1` 到 `3` 个epoch就足够了。\n",
    "*   `max_steps`: 最大训练步数。如果设置了此值，将覆盖 `num_train_epochs`。对于快速实验，可以设置为一个较小的值（如 `100`）。\n",
    "*   `evaluation_strategy`, `eval_steps`: 评估策略。`steps` 表示每隔 `eval_steps` 步进行一次评估。\n",
    "*   `save_strategy`, `save_steps`: 保存策略。`steps` 表示每隔 `save_steps` 步保存一个checkpoint。\n",
    "*   `logging_steps`: 每隔多少步打印一次日志。\n",
    "*   `output_dir`: 训练产物（如模型checkpoint）的输出目录。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 训练与优化器配置 (Train & Optimizer)\n",
    "\n",
    "这部分控制学习率、优化器等超参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "# train\n",
    "warmup_steps: 20\n",
    "learning_rate: 1.0e-5\n",
    "lr_scheduler_type: cosine\n",
    "min_lr: 1.0e-6\n",
    "\n",
    "# optimizer\n",
    "weight_decay: 0.1\n",
    "adam_epsilon: 1.0e-8\n",
    "adam_beta1: 0.9\n",
    "adam_beta2: 0.95\n",
    "offload_optim: True\n",
    "```\n",
    "\n",
    "*   `learning_rate`: **核心超参数**。学习率的大小直接影响模型的收敛速度和最终效果。`1.0e-5` 是一个适用于全参数微调的常用值。对于LoRA等PEFT方法，可能需要更大的学习率。\n",
    "*   `lr_scheduler_type`: 学习率调度策略。`cosine` 表示使用余弦退火策略，是一种非常有效且常用的策略。\n",
    "*   `warmup_steps`: 预热步数。在训练初期，学习率会从一个很小的值线性增长到设定的 `learning_rate`，这有助于训练的稳定。\n",
    "*   `weight_decay`: 权重衰减，一种防止过拟合的正则化技术。\n",
    "*   `offload_optim`: 是否将优化器状态卸载到CPU内存。这是一个节省显存的技巧，但会略微降低训练速度。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 性能与并行配置 (Performance)\n",
    "\n",
    "这部分用于配置分布式训练和混合精度训练，以提升效率和节省资源。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "# performance\n",
    "tensor_parallel_degree: 1\n",
    "pipeline_parallel_degree: 1\n",
    "sharding_parallel_degree: 1\n",
    "sharding: stage1\n",
    "sequence_parallel: True\n",
    "recompute: False\n",
    "compute_type: bf16\n",
    "fp16_opt_level: O2\n",
    "```\n",
    "\n",
    "*   `tensor_parallel_degree`, `pipeline_parallel_degree`, `sharding_parallel_degree`: 分布式训练的并行度。对于单卡训练，这些都应保持为 `1`。\n",
    "*   `sharding`: ZeRO优化策略。`stage1` 可以在多卡训练时显著节省显存。\n",
    "*   `sequence_parallel`: 序列并行，一种针对长序列的显存优化技术。\n",
    "*   `recompute` (Gradient Checkpointing): **重要**。一种用计算换显存的技术。设置为 `True` 会在反向传播时重新计算前向传播的中间结果，而不是存储它们。这能大幅降低显存消耗，但会增加约20-30%的训练时间。**当显存不足时，开启此选项是首选**。\n",
    "*   `compute_type`: 计算精度。`bf16` (BFloat16) 是一种专为深度学习设计的半精度浮点格式，它能大幅降低显存占用并加速计算，同时保持较好的数值稳定性。推荐在支持的硬件上（如NVIDIA A100/H100, RTX 30/40系列）使用。\n",
    "*   `fp16_opt_level`: 混合精度训练等级。`O2` 是一个常用的设置，可以与 `bf16` 配合使用。\n",
    "\n",
    "理解了这些配置项，您就拥有了自由定制SFT过程的能力。在下一节中，我们将把所有知识整合起来，正式启动SFT训练任务。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 启动 SFT 训练\n",
    "\n",
    "理论和配置都已准备就绪，现在是时候亲手启动SFT训练，见证模型能力蜕变的过程了。ERNIEkit 通过一个简单的命令即可启动整个训练流程。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 启动训练命令\n",
    "\n",
    "我们将在 `ERNIE-develop` 目录下，使用 `train.py` 脚本，并指定我们的配置文件 `run_sft_8k.yaml`。\n",
    "\n",
    "**在终端或命令行中执行：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T11:04:20.529339Z",
     "iopub.status.busy": "2025-07-17T11:04:20.528900Z",
     "iopub.status.idle": "2025-07-17T11:04:20.533491Z",
     "shell.execute_reply": "2025-07-17T11:04:20.533022Z",
     "shell.execute_reply.started": "2025-07-17T11:04:20.529305Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/ERNIE-develop\r\n"
     ]
    }
   ],
   "source": [
    "# 首先，请确保您位于 ERNIE-develop 目录下\r\n",
    "%cd ./ERNIE-develop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T11:05:42.879359Z",
     "iopub.status.busy": "2025-07-17T11:05:42.879042Z",
     "iopub.status.idle": "2025-07-17T11:08:37.765662Z",
     "shell.execute_reply": "2025-07-17T11:08:37.764834Z",
     "shell.execute_reply.started": "2025-07-17T11:05:42.879339Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/utils/cpp_extension/extension_utils.py:715: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\r\n",
      "  warnings.warn(warning_message)\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/utils/cpp_extension/extension_utils.py:715: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\r\n",
      "  warnings.warn(warning_message)\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,655 -----------  Configuration  ----------------------\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 auto_cluster_config: 0\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 auto_parallel_config: None\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 auto_tuner_json: None\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 devices: 0\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 elastic_level: -1\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 elastic_timeout: 30\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 enable_gpu_log: True\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 gloo_port: 6767\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 host: None\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 ips: None\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 job_id: default\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 legacy: False\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 log_dir: erniekit_dist_log\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 log_level: INFO\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 log_overwrite: False\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 master: 127.0.0.1:8080\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 max_restart: 3\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 nnodes: 1\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 nproc_per_node: None\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 rank: -1\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 run_mode: collective\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 server_num: None\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 servers: \r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 sort_ip: False\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 start_port: 6070\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 trainer_num: None\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 trainers: \r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 training_script: /home/aistudio/ERNIE-develop/erniekit/launcher.py\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 training_script_args: ['train', 'examples/configs/ERNIE-4.5-0.3B/sft/run_sft_8k.yaml']\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 with_gloo: 1\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 --------------------------------------------------\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 Job: default, mode collective, replicas 1[1:1], elastic False\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,658 Run Pod: lpwbts, replicas 1, status ready\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,671 Watching Pod: lpwbts, replicas 1, status running\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/utils/cpp_extension/extension_utils.py:715: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\r\n",
      "  warnings.warn(warning_message)\r\n",
      "\u001b[32m[2025-07-17 19:05:50,756] [    INFO]\u001b[0m - user has defined resume_from_checkpoint: None\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:50,756] [    INFO]\u001b[0m - The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:50,789] [    INFO]\u001b[0m - Tensor_parallel_degree = 1. Set sequence_parallel to False.\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,789] [   DEBUG]\u001b[0m - ============================================================\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,789] [   DEBUG]\u001b[0m -      Model Configuration Arguments      \u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,789] [   DEBUG]\u001b[0m - paddle commit id              : cdcd76a93d1dfe767dde768198e1d7c7488b93f6\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,789] [   DEBUG]\u001b[0m - paddleformers commit id       : 053a5a5e2a72cd2d3b997cbcff81b14af9fe4d47\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,789] [   DEBUG]\u001b[0m - add_tail_layers               : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,789] [   DEBUG]\u001b[0m - continue_training             : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,789] [   DEBUG]\u001b[0m - fine_tuning                   : Full\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,789] [   DEBUG]\u001b[0m - fuse_gate_detach_matmul       : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,789] [   DEBUG]\u001b[0m - fuse_linear                   : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,789] [   DEBUG]\u001b[0m - fuse_rms_norm                 : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,789] [   DEBUG]\u001b[0m - fuse_rope                     : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,789] [   DEBUG]\u001b[0m - fuse_softmax_mask             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - fuse_swiglu                   : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - lora                          : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - lora_alpha                    : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - lora_path                     : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - lora_plus_scale               : 1.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - lora_rank                     : 8\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - model_name_or_path            : ../data/models/30654/ERNIE-4.5-0.3B-Base-Paddle\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - moe_aux_loss_lambda           : 1e-05\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - moe_group                     : dummy\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - moe_group_experts             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - moe_multimodal_dispatch_use_allgather: v2-alltoall-unpad\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - moe_orthogonal_loss_lambda    : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - moe_use_aux_free              : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - moe_use_hard_gate             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - moe_z_loss_lambda             : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - no_recompute_layers           : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - offload_recompute_inputs      : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - pp_seg_method                 : layer:Ernie4_5_DecoderLayer|EmptyLayer\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - recompute_granularity         : full\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - recompute_use_reentrant       : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - rslora                        : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - rslora_plus                   : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - stage                         : SFT\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - tensor_parallel_output        : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - use_attn_mask_start_row_indices: True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - use_flash_attention           : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - use_fused_head_and_loss_fn    : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - use_recompute_moe             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - use_sparse_flash_attn         : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - use_sparse_head_and_loss_fn   : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - virtual_pp_degree             : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - \u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - ============================================================\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m -       Data Configuration Arguments      \u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - paddle commit id              : cdcd76a93d1dfe767dde768198e1d7c7488b93f6\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - paddleformers commit id       : 053a5a5e2a72cd2d3b997cbcff81b14af9fe4d47\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - buffer_size                   : 500\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - dataset_type                  : iterable\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - eval_dataset_path             : ./examples/data/sft-eval.jsonl\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - eval_dataset_prob             : 1.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - eval_dataset_type             : erniekit\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - greedy_intokens               : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - in_tokens_batching            : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - mask_out_eos_token            : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - max_prompt_len                : 2048\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - max_seq_len                   : 8192\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,792] [   DEBUG]\u001b[0m - num_comparisons               : 6\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,792] [   DEBUG]\u001b[0m - num_samples_each_epoch        : 6000000\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,792] [   DEBUG]\u001b[0m - offline_dataset_path          : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,792] [   DEBUG]\u001b[0m - random_shuffle                : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,792] [   DEBUG]\u001b[0m - train_dataset_path            : ./examples/data/sft-train.jsonl\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,792] [   DEBUG]\u001b[0m - train_dataset_prob            : 1.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,792] [   DEBUG]\u001b[0m - train_dataset_type            : erniekit\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,792] [   DEBUG]\u001b[0m - use_cls                       : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,792] [   DEBUG]\u001b[0m - \u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:50,792] [    INFO]\u001b[0m - The global seed is set to 23, local seed is set to 24 and random seed is set to 23.\u001b[0m\r\n",
      "\u001b[33m[2025-07-17 19:05:50,792] [ WARNING]\u001b[0m - Process rank: -1, device: gpu, world_size: 1, distributed training: False, 16-bits training: True\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:50,792] [    INFO]\u001b[0m - Start to load model ...\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:50,961] [    INFO]\u001b[0m - Loading configuration file ../data/models/30654/ERNIE-4.5-0.3B-Base-Paddle/config.json\u001b[0m\r\n",
      "\u001b[33m[2025-07-17 19:05:50,964] [ WARNING]\u001b[0m - You are using a model of type ernie4_5 to instantiate a model of type ernie4_5_moe. This is not supported for all configurations of models and can yield errors.\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:50,966] [    INFO]\u001b[0m - Loading weights file ../data/models/30654/ERNIE-4.5-0.3B-Base-Paddle/model.safetensors\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:52,982] [    INFO]\u001b[0m - Loaded weights file from disk, setting weights to model.\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:52,983] [    INFO]\u001b[0m - change initializer-range from 0.02 to 0.018041293779826325\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:52,983] [    INFO]\u001b[0m - using moe-group: dummy\u001b[0m\r\n",
      "W0717 19:05:52.987658 17491 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.8, Runtime API Version: 12.6\r\n",
      "\u001b[32m[2025-07-17 19:05:53,265] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,271] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,273] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,279] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,281] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,284] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,286] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,288] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,290] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,293] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,295] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,297] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,300] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,302] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,304] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,361] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,364] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,366] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,370] [    INFO]\u001b[0m - output-weight:[103424, 1024] config.tie_word_embeddings=True\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,371] [    INFO]\u001b[0m - Use fusedRMSNorm\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,451] [    INFO]\u001b[0m - All model checkpoint weights were used when initializing Ernie4_5_MoeForCausalLM.\r\n",
      "\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,452] [    INFO]\u001b[0m - All the weights of Ernie4_5_MoeForCausalLM were initialized from the model checkpoint at ../data/models/30654/ERNIE-4.5-0.3B-Base-Paddle.\r\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use Ernie4_5_MoeForCausalLM for predictions without further training.\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,453] [    INFO]\u001b[0m - Loading configuration file ../data/models/30654/ERNIE-4.5-0.3B-Base-Paddle/generation_config.json\u001b[0m\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddleformers/generation/configuration_utils.py:250: UserWarning: using greedy search strategy. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `decode_strategy=\"greedy_search\" ` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\r\n",
      "  warnings.warn(\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddleformers/generation/configuration_utils.py:255: UserWarning: using greedy search strategy. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `decode_strategy=\"greedy_search\" ` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\r\n",
      "  warnings.warn(\r\n",
      "\u001b[32m[2025-07-17 19:05:53,467] [    INFO]\u001b[0m - Loading model successfully !\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:53,468] [   DEBUG]\u001b[0m - Model config: Ernie4_5_MoeConfig {\r\n",
      "  \"add_tail_layers\": false,\r\n",
      "  \"architectures\": [\r\n",
      "    \"Ernie4_5_ForCausalLM\"\r\n",
      "  ],\r\n",
      "  \"attention_probs_dropout_prob\": 0.0,\r\n",
      "  \"bos_token_id\": 1,\r\n",
      "  \"cachekv_quant\": false,\r\n",
      "  \"compression_ratio\": 1.0,\r\n",
      "  \"dpo_config\": null,\r\n",
      "  \"dtype\": \"bfloat16\",\r\n",
      "  \"enable_delay_scale_loss\": true,\r\n",
      "  \"enable_mtp_magic_send\": false,\r\n",
      "  \"eos_token_id\": 2,\r\n",
      "  \"fuse_gate_detach_matmul\": true,\r\n",
      "  \"fuse_linear\": false,\r\n",
      "  \"fuse_ln\": false,\r\n",
      "  \"fuse_rms_norm\": true,\r\n",
      "  \"fuse_rope\": true,\r\n",
      "  \"fuse_softmax_mask\": false,\r\n",
      "  \"fuse_swiglu\": true,\r\n",
      "  \"global_aux_loss\": false,\r\n",
      "  \"head_dim\": 128,\r\n",
      "  \"hidden_act\": \"silu\",\r\n",
      "  \"hidden_dropout_prob\": 0.0,\r\n",
      "  \"hidden_size\": 1024,\r\n",
      "  \"ignored_index\": -100,\r\n",
      "  \"initializer_range\": 0.018041293779826325,\r\n",
      "  \"intermediate_size\": 3072,\r\n",
      "  \"max_position_embeddings\": 131072,\r\n",
      "  \"max_sequence_length\": 8192,\r\n",
      "  \"micro_batch_size\": -1,\r\n",
      "  \"model_type\": \"ernie4_5_moe\",\r\n",
      "  \"moe_all_to_all_dropout\": 0.0,\r\n",
      "  \"moe_aux_loss_lambda\": 1e-05,\r\n",
      "  \"moe_capacity\": [],\r\n",
      "  \"moe_dense_experts_token_type_id\": 3,\r\n",
      "  \"moe_dropout_prob\": 0.0,\r\n",
      "  \"moe_gate\": \"topk\",\r\n",
      "  \"moe_gate_act\": \"softmax\",\r\n",
      "  \"moe_group_experts\": false,\r\n",
      "  \"moe_group_origin\": \"dummy\",\r\n",
      "  \"moe_group_orthogonal_loss\": true,\r\n",
      "  \"moe_intermediate_size\": 0,\r\n",
      "  \"moe_k\": 2,\r\n",
      "  \"moe_layer_end_index\": 17,\r\n",
      "  \"moe_layer_interval\": 2,\r\n",
      "  \"moe_layer_start_index\": 0,\r\n",
      "  \"moe_multimodal_dispatch_use_allgather\": \"v2-alltoall-unpad\",\r\n",
      "  \"moe_norm_gate_logits\": true,\r\n",
      "  \"moe_num_experts\": null,\r\n",
      "  \"moe_num_shared_experts\": 0,\r\n",
      "  \"moe_orthogonal_loss_lambda\": 0.0,\r\n",
      "  \"moe_rank\": 0,\r\n",
      "  \"moe_reverse_token_drop\": false,\r\n",
      "  \"moe_use_aux_free\": false,\r\n",
      "  \"moe_use_hard_gate\": false,\r\n",
      "  \"moe_world_size\": 1,\r\n",
      "  \"moe_z_loss_lambda\": 0.0,\r\n",
      "  \"multi_token_pred_lambda\": 0.3,\r\n",
      "  \"num_acc_steps\": 8,\r\n",
      "  \"num_attention_heads\": 16,\r\n",
      "  \"num_hidden_layers\": 18,\r\n",
      "  \"num_key_value_heads\": 2,\r\n",
      "  \"num_nextn_predict_layers\": 0,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"paddleformers_version\": \"0.1\",\r\n",
      "  \"pp_seg_method\": \"layer:Ernie4_5_DecoderLayer|EmptyLayer\",\r\n",
      "  \"recompute_granularity\": \"full\",\r\n",
      "  \"recompute_use_reentrant\": true,\r\n",
      "  \"refined_recompute\": {},\r\n",
      "  \"rms_norm_eps\": 1e-05,\r\n",
      "  \"rope_theta\": 500000,\r\n",
      "  \"sinkhorn_2gate\": true,\r\n",
      "  \"sinkhorn_temp\": 0.03,\r\n",
      "  \"skip_recompute_ops\": {},\r\n",
      "  \"tensor_parallel_degree\": -1,\r\n",
      "  \"tie_word_embeddings\": true,\r\n",
      "  \"token_balance_loss\": false,\r\n",
      "  \"token_balance_seqlen\": false,\r\n",
      "  \"use_bias\": false,\r\n",
      "  \"use_flash_attention\": true,\r\n",
      "  \"use_fused_head_and_loss_fn\": false,\r\n",
      "  \"use_recompute_lm_head\": false,\r\n",
      "  \"use_recompute_loss_fn\": false,\r\n",
      "  \"use_recompute_moe\": false,\r\n",
      "  \"use_recompute_mtp\": false,\r\n",
      "  \"use_rmsnorm\": true,\r\n",
      "  \"use_sparse_flash_attn\": true,\r\n",
      "  \"use_sparse_head_and_loss_fn\": true,\r\n",
      "  \"use_var_len_flash_attn\": false,\r\n",
      "  \"vocab_size\": 103424,\r\n",
      "  \"weight_share_add_bias\": true\r\n",
      "}\r\n",
      "\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,468] [    INFO]\u001b[0m - [timelog] basemodel loading time: 2.51s (2025-07-17 19:05:53) \u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:54,506] [    INFO]\u001b[0m - Start to create dataset ...\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:54,515] [    INFO]\u001b[0m - ./examples/data/sft-train.jsonl: task prob: 1.0, ori number of examples: 200, target_num_each_epoch: 6000000\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:54,515] [    INFO]\u001b[0m - Creating dataset successfully ...\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:54,516] [    INFO]\u001b[0m - The global seed is set to 23, local seed is set to 24 and random seed is set to 23.\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:54,555] [    INFO]\u001b[0m - max_steps is given, it will override any value given in num_train_epochs\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:54,555] [    INFO]\u001b[0m - Using half precision\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,568] [   DEBUG]\u001b[0m - ============================================================\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,568] [   DEBUG]\u001b[0m -     Training Configuration Arguments    \u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,568] [   DEBUG]\u001b[0m - paddle commit id              : cdcd76a93d1dfe767dde768198e1d7c7488b93f6\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - paddleformers commit id       : 053a5a5e2a72cd2d3b997cbcff81b14af9fe4d47\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - _no_sync_in_gradient_accumulation: True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - actscale_moving_rate          : 0.01\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - adam_beta1                    : 0.9\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - adam_beta2                    : 0.95\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - adam_epsilon                  : 1e-08\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - amp_custom_black_list         : ['reduce_sum', 'softmax_with_cross_entropy', 'c_softmax_with_cross_entropy', 'elementwise_div', 'sin', 'cos']\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - amp_custom_white_list         : ['lookup_table', 'lookup_table_v2', 'flash_attn', 'matmul', 'matmul_v2', 'fused_gemm_epilogue']\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - amp_master_grad               : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - apply_hadamard                : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - apply_online_actscale_step    : 200\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - attention_probs_dropout_prob  : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - auto_parallel_resume_form_hybrid_parallel: False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - batch_size                    : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - beta                          : 0.1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - bf16                          : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - bf16_full_eval                : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - ckpt_quant_stage              : O0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - compute_type                  : bf16\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - context_parallel_degree       : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - count_trained_tokens          : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - current_device                : gpu:0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - data_parallel_config          : \u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - data_parallel_degree          : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - data_parallel_rank            : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - dataloader_drop_last          : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - dataloader_num_workers        : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - dataloader_shuffle            : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - dataset_rank                  : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - dataset_world_size            : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - ddp_find_unused_parameters    : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - decay_steps                   : 100\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - device                        : gpu\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - disable_ckpt_quant            : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - disable_tqdm                  : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - distributed_dataloader        : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - do_eval                       : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - do_export                     : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - do_predict                    : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - do_train                      : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - dpo_benchmark                 : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - dpop_lambda                   : 50\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - dropout_warmup_steps          : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - enable_auto_parallel          : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - enable_zero_cost_checkpoint   : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - eval_accumulation_steps       : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - eval_batch_size               : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - eval_steps                    : 10000\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - evaluation_strategy           : IntervalStrategy.STEPS\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - expert_max_capacity           : 4294967296\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - expert_min_capacity           : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - expert_parallel_degree        : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - expert_tensor_parallel_degree : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - flash_device_save_steps       : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - flatten_param_grads           : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - force_reshard_pp              : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - fp16                          : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - fp16_full_eval                : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - fp16_opt_level                : O2\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - fp8_format_type               : hybrid\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - fuse_sequence_parallel_allreduce: False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - gradient_accumulation_steps   : 8\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - greater_is_better             : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - hadamard_block_size           : 32\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - hidden_dropout_prob           : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - hybrid_parallel_topo_order    : pp_first\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - ignore_data_skip              : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - ignore_load_lr_and_optim      : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - ignore_save_lr_and_optim      : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - label_names                   : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - label_smoothing               : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - layerwise_lr_decay_bound      : 1.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - lazy_data_processing          : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - learning_rate                 : 1e-05\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - load_best_model_at_end        : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - load_sharded_model            : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - local_process_index           : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - local_rank                    : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - log_level                     : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - log_level_replica             : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - log_on_each_node              : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - logging_dir                   : ./vdl_log\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - logging_first_step            : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - logging_steps                 : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - logging_strategy              : IntervalStrategy.STEPS\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - logical_process_index         : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - loss_type                     : sigmoid\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - lr_end                        : 1e-07\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - lr_scheduler_type             : SchedulerType.COSINE\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - max_estimate_samples          : 100000.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - max_evaluate_steps            : 10000\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - max_grad_norm                 : 1.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - max_steps                     : 100\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - metric_for_best_model         : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - metrics_output_path           : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - min_lr                        : 1e-06\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - minimum_eval_times            : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - multi_token_pred_lambda       : 0.3\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - no_cuda                       : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - normalize_logps               : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - num_cycles                    : 0.5\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - num_nextn_predict_layers      : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - num_of_gpus                   : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - num_train_epochs              : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - offload_optim                 : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - offset_alpha                  : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - optim                         : OptimizerNames.ADAMW\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - optim_shard_num               : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - optimizer_name_suffix         : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - ordered_save_group_size       : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - output_dir                    : ./output\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - output_signal_dir             : ./output\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - overwrite_output_dir          : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - pad_token_id                  : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - past_index                    : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - pdc_download_ckpt             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - pdc_download_timeout          : 300\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - per_device_eval_batch_size    : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - per_device_train_batch_size   : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - pipeline_parallel_config      : enable_delay_scale_loss enable_release_grads disable_partial_send_recv\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - pipeline_parallel_degree      : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - pipeline_parallel_rank        : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - power                         : 1.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - prediction_loss_only          : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - pref_loss_ratio               : 1.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - process_index                 : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - quant_input_grad              : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - quant_weight_grad             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - recompute                     : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - ref_model_update_steps        : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - reference_free                : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - refined_recompute             : {}\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - release_grads                 : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - remove_unused_columns         : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - report_to                     : ['visualdl']\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - resume_from_checkpoint        : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - run_name                      : ./output\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - save_on_each_node             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - save_rng_states               : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - save_sharded_model            : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - save_sharding_stage1_model_include_freeze_params: False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - save_steps                    : 10000000\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - save_strategy                 : IntervalStrategy.STEPS\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - save_tokenizer                : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - save_total_limit              : 5\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - scale_loss                    : 32768\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - seed                          : 23\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - sep_parallel_degree           : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - sequence_parallel             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - sequence_parallel_config      : \u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - server_tp_degree              : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - sft_benchmark                 : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - sft_loss_ratio                : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - sharding                      : []\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - sharding_comm_buffer_size_MB  : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - sharding_degree               : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - sharding_parallel_config      : \u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - sharding_parallel_degree      : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - sharding_parallel_mesh_dimension: dp\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - sharding_parallel_rank        : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - should_load_dataset           : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - should_load_sharding_stage1_model: False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - should_log                    : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - should_save                   : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - should_save_model_state       : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - should_save_model_with_tensor_fusion: False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - should_save_sharding_stage1_model: False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - simpo_gamma                   : 0.5\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - skip_data_intervals           : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - skip_memory_metrics           : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - skip_profile_timer            : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - split_inputs_sequence_dim     : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - split_norm_comm               : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - tensor_parallel_config        : \u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - tensor_parallel_degree        : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - tensor_parallel_rank          : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - tensorwise_offload_optimizer  : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - to_static                     : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - train_batch_size              : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - unified_checkpoint            : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - unified_checkpoint_config     : ['async_save']\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - use_async_save                : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - use_expert_parallel           : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - use_hybrid_parallel           : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - use_lowprecision_moment       : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - use_recompute_mtp             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - use_sp_callback               : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - wandb_api_key                 : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - wandb_http_proxy              : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - warmup_ratio                  : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - warmup_steps                  : 20\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - weight_decay                  : 0.1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - weight_name_suffix            : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - weight_quantize_algo          : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - world_size                    : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - zcc_ema_interval              : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - zcc_pipeline_hooks_capacity_usage: 0.6\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - zcc_save_ema_coef             : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - zcc_workers_num               : 3\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - \u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:54,578] [    INFO]\u001b[0m - Starting training from resume_from_checkpoint : None\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:54,585] [    INFO]\u001b[0m - [timelog] checkpoint loading time: 0.00s (2025-07-17 19:05:54) \u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:54,585] [    INFO]\u001b[0m - ***** Running training *****\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:54,585] [    INFO]\u001b[0m -   Num examples = 800\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:54,585] [    INFO]\u001b[0m -   Num Epochs = 9223372036854775807\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:54,585] [    INFO]\u001b[0m -   Instantaneous batch size per device = 1\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:54,585] [    INFO]\u001b[0m -   Total train batch size (w. parallel, distributed & accumulation) = 8\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:54,585] [    INFO]\u001b[0m -   Gradient Accumulation steps = 8\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:54,585] [    INFO]\u001b[0m -   Total optimization steps = 100\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:54,585] [    INFO]\u001b[0m -   Total num train samples = 800\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,586] [   DEBUG]\u001b[0m -   Number of trainable parameters = 360,748,032 (per device)\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:54,603] [    INFO]\u001b[0m - prepare SequenceDataset ...\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:57,381] [    INFO]\u001b[0m - prepare SequenceDataset done: total number of examples is 6000000\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:01,753] [    INFO]\u001b[0m - loss: 2.61245131, learning_rate: 5e-07, global_step: 1, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 7.1658, interval_samples_per_second: 1.1164, interval_steps_per_second: 0.1396, ppl: 13.63242723238924, progress_or_epoch: 0.01\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:03,399] [    INFO]\u001b[0m - loss: 2.57664418, learning_rate: 1e-06, global_step: 2, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.6466, interval_samples_per_second: 4.8584, interval_steps_per_second: 0.6073, ppl: 13.152925166395088, progress_or_epoch: 0.02\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:04,926] [    INFO]\u001b[0m - loss: 2.57887983, learning_rate: 1.5e-06, global_step: 3, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.5269, interval_samples_per_second: 5.2393, interval_steps_per_second: 0.6549, ppl: 13.182363398073319, progress_or_epoch: 0.03\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:06,408] [    INFO]\u001b[0m - loss: 2.64023829, learning_rate: 2e-06, global_step: 4, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.4819, interval_samples_per_second: 5.3984, interval_steps_per_second: 0.6748, ppl: 14.016543211902638, progress_or_epoch: 0.04\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:07,869] [    INFO]\u001b[0m - loss: 2.54005051, learning_rate: 2.5e-06, global_step: 5, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.4608, interval_samples_per_second: 5.4763, interval_steps_per_second: 0.6845, ppl: 12.680311437189454, progress_or_epoch: 0.05\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:09,358] [    INFO]\u001b[0m - loss: 2.52139831, learning_rate: 3e-06, global_step: 6, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.4892, interval_samples_per_second: 5.3721, interval_steps_per_second: 0.6715, ppl: 12.44598785088004, progress_or_epoch: 0.06\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:11,010] [    INFO]\u001b[0m - loss: 2.53262019, learning_rate: 3.5e-06, global_step: 7, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.6514, interval_samples_per_second: 4.8444, interval_steps_per_second: 0.6055, ppl: 12.586441837967008, progress_or_epoch: 0.07\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:12,511] [    INFO]\u001b[0m - loss: 2.51942062, learning_rate: 4e-06, global_step: 8, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.5011, interval_samples_per_second: 5.3295, interval_steps_per_second: 0.6662, ppl: 12.421397868862815, progress_or_epoch: 0.08\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:13,987] [    INFO]\u001b[0m - loss: 2.50147009, learning_rate: 4.5e-06, global_step: 9, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.4765, interval_samples_per_second: 5.4181, interval_steps_per_second: 0.6773, ppl: 12.200416493890778, progress_or_epoch: 0.09\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:15,508] [    INFO]\u001b[0m - loss: 2.34809017, learning_rate: 5e-06, global_step: 10, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.521, interval_samples_per_second: 5.2595, interval_steps_per_second: 0.6574, ppl: 10.465563179731184, progress_or_epoch: 0.1\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:17,001] [    INFO]\u001b[0m - loss: 2.38992405, learning_rate: 5.5e-06, global_step: 11, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.4932, interval_samples_per_second: 5.3578, interval_steps_per_second: 0.6697, ppl: 10.912665094652914, progress_or_epoch: 0.11\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:18,653] [    INFO]\u001b[0m - loss: 2.23173046, learning_rate: 6e-06, global_step: 12, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.6514, interval_samples_per_second: 4.8444, interval_steps_per_second: 0.6056, ppl: 9.315973057961125, progress_or_epoch: 0.12\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:20,143] [    INFO]\u001b[0m - loss: 2.09781885, learning_rate: 6.5e-06, global_step: 13, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.4899, interval_samples_per_second: 5.3696, interval_steps_per_second: 0.6712, ppl: 8.148377681878587, progress_or_epoch: 0.13\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:21,610] [    INFO]\u001b[0m - loss: 2.03945446, learning_rate: 7e-06, global_step: 14, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.4669, interval_samples_per_second: 5.4535, interval_steps_per_second: 0.6817, ppl: 7.686414808144628, progress_or_epoch: 0.14\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:23,080] [    INFO]\u001b[0m - loss: 1.93046248, learning_rate: 7.5e-06, global_step: 15, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.4709, interval_samples_per_second: 5.4389, interval_steps_per_second: 0.6799, ppl: 6.892697239182341, progress_or_epoch: 0.15\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:24,555] [    INFO]\u001b[0m - loss: 1.81210303, learning_rate: 8e-06, global_step: 16, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.4744, interval_samples_per_second: 5.4259, interval_steps_per_second: 0.6782, ppl: 6.123311408416771, progress_or_epoch: 0.16\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:26,209] [    INFO]\u001b[0m - loss: 1.70531929, learning_rate: 8.5e-06, global_step: 17, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.6541, interval_samples_per_second: 4.8365, interval_steps_per_second: 0.6046, ppl: 5.503142485093446, progress_or_epoch: 0.17\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:27,686] [    INFO]\u001b[0m - loss: 1.51051784, learning_rate: 9e-06, global_step: 18, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.4773, interval_samples_per_second: 5.4151, interval_steps_per_second: 0.6769, ppl: 4.529075523633699, progress_or_epoch: 0.18\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:29,163] [    INFO]\u001b[0m - loss: 1.29875422, learning_rate: 9.5e-06, global_step: 19, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.477, interval_samples_per_second: 5.4165, interval_steps_per_second: 0.6771, ppl: 3.664728377349803, progress_or_epoch: 0.19\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:30,638] [    INFO]\u001b[0m - loss: 1.23181963, learning_rate: 1e-05, global_step: 20, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.475, interval_samples_per_second: 5.4236, interval_steps_per_second: 0.6779, ppl: 3.4274605755645147, progress_or_epoch: 0.2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:32,258] [    INFO]\u001b[0m - loss: 1.07891762, learning_rate: 9.997e-06, global_step: 21, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.6193, interval_samples_per_second: 4.9404, interval_steps_per_second: 0.6175, ppl: 2.9414940131053307, progress_or_epoch: 0.21\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:34,029] [    INFO]\u001b[0m - loss: 0.90462917, learning_rate: 9.986e-06, global_step: 22, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.7713, interval_samples_per_second: 4.5164, interval_steps_per_second: 0.5646, ppl: 2.4710154264851587, progress_or_epoch: 0.22\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:35,540] [    INFO]\u001b[0m - loss: 0.76993722, learning_rate: 9.969e-06, global_step: 23, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.5108, interval_samples_per_second: 5.295, interval_steps_per_second: 0.6619, ppl: 2.159630667915587, progress_or_epoch: 0.23\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:37,009] [    INFO]\u001b[0m - loss: 0.65621567, learning_rate: 9.945e-06, global_step: 24, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.4696, interval_samples_per_second: 5.4438, interval_steps_per_second: 0.6805, ppl: 1.927484278496434, progress_or_epoch: 0.24\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:38,479] [    INFO]\u001b[0m - loss: 0.51416081, learning_rate: 9.914e-06, global_step: 25, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.4692, interval_samples_per_second: 5.445, interval_steps_per_second: 0.6806, ppl: 1.6722345902598585, progress_or_epoch: 0.25\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:39,975] [    INFO]\u001b[0m - loss: 0.43581983, learning_rate: 9.876e-06, global_step: 26, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.4967, interval_samples_per_second: 5.3449, interval_steps_per_second: 0.6681, ppl: 1.546230185359108, progress_or_epoch: 0.26\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:41,704] [    INFO]\u001b[0m - loss: 0.3368488, learning_rate: 9.831e-06, global_step: 27, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.7287, interval_samples_per_second: 4.6277, interval_steps_per_second: 0.5785, ppl: 1.400527288002747, progress_or_epoch: 0.27\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:43,200] [    INFO]\u001b[0m - loss: 0.27868763, learning_rate: 9.78e-06, global_step: 28, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.4957, interval_samples_per_second: 5.3487, interval_steps_per_second: 0.6686, ppl: 1.3213945153905076, progress_or_epoch: 0.28\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:44,683] [    INFO]\u001b[0m - loss: 0.20828675, learning_rate: 9.722e-06, global_step: 29, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.4836, interval_samples_per_second: 5.3923, interval_steps_per_second: 0.674, ppl: 1.231566270548672, progress_or_epoch: 0.29\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:46,147] [    INFO]\u001b[0m - loss: 0.15214896, learning_rate: 9.657e-06, global_step: 30, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.4636, interval_samples_per_second: 5.466, interval_steps_per_second: 0.6832, ppl: 1.1643336626573957, progress_or_epoch: 0.3\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:47,622] [    INFO]\u001b[0m - loss: 0.10568784, learning_rate: 9.587e-06, global_step: 31, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.4746, interval_samples_per_second: 5.4253, interval_steps_per_second: 0.6782, ppl: 1.1114748643540353, progress_or_epoch: 0.31\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:49,276] [    INFO]\u001b[0m - loss: 0.06535335, learning_rate: 9.51e-06, global_step: 32, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.6547, interval_samples_per_second: 4.8346, interval_steps_per_second: 0.6043, ppl: 1.0675361716540286, progress_or_epoch: 0.32\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:50,752] [    INFO]\u001b[0m - loss: 0.04185442, learning_rate: 9.426e-06, global_step: 33, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.4761, interval_samples_per_second: 5.4198, interval_steps_per_second: 0.6775, ppl: 1.0427426652233216, progress_or_epoch: 0.33\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:52,233] [    INFO]\u001b[0m - loss: 0.02847656, learning_rate: 9.337e-06, global_step: 34, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.4811, interval_samples_per_second: 5.4015, interval_steps_per_second: 0.6752, ppl: 1.0288858934665266, progress_or_epoch: 0.34\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:53,721] [    INFO]\u001b[0m - loss: 0.0193248, learning_rate: 9.242e-06, global_step: 35, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.4879, interval_samples_per_second: 5.3768, interval_steps_per_second: 0.6721, ppl: 1.0195127325820041, progress_or_epoch: 0.35\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:55,205] [    INFO]\u001b[0m - loss: 0.01424673, learning_rate: 9.141e-06, global_step: 36, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.4835, interval_samples_per_second: 5.3928, interval_steps_per_second: 0.6741, ppl: 1.0143486983207781, progress_or_epoch: 0.36\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:56,856] [    INFO]\u001b[0m - loss: 0.01063273, learning_rate: 9.034e-06, global_step: 37, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.6513, interval_samples_per_second: 4.8448, interval_steps_per_second: 0.6056, ppl: 1.0106894583544417, progress_or_epoch: 0.37\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:58,350] [    INFO]\u001b[0m - loss: 0.00897723, learning_rate: 8.922e-06, global_step: 38, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.4936, interval_samples_per_second: 5.3562, interval_steps_per_second: 0.6695, ppl: 1.009017646180488, progress_or_epoch: 0.38\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:59,810] [    INFO]\u001b[0m - loss: 0.00651405, learning_rate: 8.804e-06, global_step: 39, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.4607, interval_samples_per_second: 5.4768, interval_steps_per_second: 0.6846, ppl: 1.0065353125671035, progress_or_epoch: 0.39\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:01,299] [    INFO]\u001b[0m - loss: 0.00599763, learning_rate: 8.682e-06, global_step: 40, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4885, interval_samples_per_second: 5.3746, interval_steps_per_second: 0.6718, ppl: 1.0060156517941448, progress_or_epoch: 0.4\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:02,804] [    INFO]\u001b[0m - loss: 0.00479357, learning_rate: 8.555e-06, global_step: 41, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.5054, interval_samples_per_second: 5.3141, interval_steps_per_second: 0.6643, ppl: 1.0048050775367192, progress_or_epoch: 0.41\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:04,446] [    INFO]\u001b[0m - loss: 0.00418891, learning_rate: 8.423e-06, global_step: 42, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.6416, interval_samples_per_second: 4.8734, interval_steps_per_second: 0.6092, ppl: 1.004197695746778, progress_or_epoch: 0.42\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:05,956] [    INFO]\u001b[0m - loss: 0.00332835, learning_rate: 8.286e-06, global_step: 43, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.5097, interval_samples_per_second: 5.2989, interval_steps_per_second: 0.6624, ppl: 1.0033338951071737, progress_or_epoch: 0.43\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:07,490] [    INFO]\u001b[0m - loss: 0.00299198, learning_rate: 8.145e-06, global_step: 44, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.5344, interval_samples_per_second: 5.2137, interval_steps_per_second: 0.6517, ppl: 1.0029964604395076, progress_or_epoch: 0.44\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:08,950] [    INFO]\u001b[0m - loss: 0.0026643, learning_rate: 8e-06, global_step: 45, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4595, interval_samples_per_second: 5.4815, interval_steps_per_second: 0.6852, ppl: 1.002667852401432, progress_or_epoch: 0.45\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:10,438] [    INFO]\u001b[0m - loss: 0.0022808, learning_rate: 7.851e-06, global_step: 46, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4882, interval_samples_per_second: 5.3757, interval_steps_per_second: 0.672, ppl: 1.0022834030029202, progress_or_epoch: 0.46\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:12,111] [    INFO]\u001b[0m - loss: 0.0020717, learning_rate: 7.699e-06, global_step: 47, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.6736, interval_samples_per_second: 4.7802, interval_steps_per_second: 0.5975, ppl: 1.0020738474531485, progress_or_epoch: 0.47\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:13,602] [    INFO]\u001b[0m - loss: 0.00184983, learning_rate: 7.543e-06, global_step: 48, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4901, interval_samples_per_second: 5.3686, interval_steps_per_second: 0.6711, ppl: 1.0018515419909824, progress_or_epoch: 0.48\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:15,058] [    INFO]\u001b[0m - loss: 0.00168223, learning_rate: 7.384e-06, global_step: 49, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.457, interval_samples_per_second: 5.4909, interval_steps_per_second: 0.6864, ppl: 1.0016836457426435, progress_or_epoch: 0.49\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:16,532] [    INFO]\u001b[0m - loss: 0.00155611, learning_rate: 7.222e-06, global_step: 50, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4736, interval_samples_per_second: 5.429, interval_steps_per_second: 0.6786, ppl: 1.001557321367425, progress_or_epoch: 0.5\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:18,021] [    INFO]\u001b[0m - loss: 0.00141674, learning_rate: 7.058e-06, global_step: 51, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4889, interval_samples_per_second: 5.3731, interval_steps_per_second: 0.6716, ppl: 1.0014177440502172, progress_or_epoch: 0.51\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:19,669] [    INFO]\u001b[0m - loss: 0.0013008, learning_rate: 6.891e-06, global_step: 52, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.6479, interval_samples_per_second: 4.8547, interval_steps_per_second: 0.6068, ppl: 1.0013016464072824, progress_or_epoch: 0.52\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:21,164] [    INFO]\u001b[0m - loss: 0.00122136, learning_rate: 6.721e-06, global_step: 53, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4951, interval_samples_per_second: 5.3507, interval_steps_per_second: 0.6688, ppl: 1.0012221061638722, progress_or_epoch: 0.53\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:22,642] [    INFO]\u001b[0m - loss: 0.00113877, learning_rate: 6.551e-06, global_step: 54, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4777, interval_samples_per_second: 5.4138, interval_steps_per_second: 0.6767, ppl: 1.0011394186447522, progress_or_epoch: 0.54\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:24,263] [    INFO]\u001b[0m - loss: 0.00107102, learning_rate: 6.378e-06, global_step: 55, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.621, interval_samples_per_second: 4.9353, interval_steps_per_second: 0.6169, ppl: 1.0010715937467334, progress_or_epoch: 0.55\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:25,756] [    INFO]\u001b[0m - loss: 0.00099817, learning_rate: 6.204e-06, global_step: 56, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4935, interval_samples_per_second: 5.3564, interval_steps_per_second: 0.6696, ppl: 1.0009986683374692, progress_or_epoch: 0.56\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:27,442] [    INFO]\u001b[0m - loss: 0.00093717, learning_rate: 6.029e-06, global_step: 57, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.6857, interval_samples_per_second: 4.7458, interval_steps_per_second: 0.5932, ppl: 1.0009376092810207, progress_or_epoch: 0.57\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:28,937] [    INFO]\u001b[0m - loss: 0.00088327, learning_rate: 5.853e-06, global_step: 58, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4953, interval_samples_per_second: 5.3502, interval_steps_per_second: 0.6688, ppl: 1.0008836601978213, progress_or_epoch: 0.58\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:30,418] [    INFO]\u001b[0m - loss: 0.00081978, learning_rate: 5.677e-06, global_step: 59, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4805, interval_samples_per_second: 5.4036, interval_steps_per_second: 0.6755, ppl: 1.0008201161114638, progress_or_epoch: 0.59\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:31,899] [    INFO]\u001b[0m - loss: 0.00079842, learning_rate: 5.5e-06, global_step: 60, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4814, interval_samples_per_second: 5.4004, interval_steps_per_second: 0.6751, ppl: 1.0007987388220938, progress_or_epoch: 0.6\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:33,397] [    INFO]\u001b[0m - loss: 0.00075694, learning_rate: 5.323e-06, global_step: 61, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4981, interval_samples_per_second: 5.3402, interval_steps_per_second: 0.6675, ppl: 1.000757226551378, progress_or_epoch: 0.61\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:35,063] [    INFO]\u001b[0m - loss: 0.00074053, learning_rate: 5.147e-06, global_step: 62, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.6663, interval_samples_per_second: 4.801, interval_steps_per_second: 0.6001, ppl: 1.0007408042600356, progress_or_epoch: 0.62\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:36,562] [    INFO]\u001b[0m - loss: 0.0007109, learning_rate: 4.971e-06, global_step: 63, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4989, interval_samples_per_second: 5.3373, interval_steps_per_second: 0.6672, ppl: 1.0007111527492947, progress_or_epoch: 0.63\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:38,035] [    INFO]\u001b[0m - loss: 0.00068439, learning_rate: 4.796e-06, global_step: 64, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4724, interval_samples_per_second: 5.4335, interval_steps_per_second: 0.6792, ppl: 1.000684624248272, progress_or_epoch: 0.64\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:39,503] [    INFO]\u001b[0m - loss: 0.00065405, learning_rate: 4.622e-06, global_step: 65, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4682, interval_samples_per_second: 5.449, interval_steps_per_second: 0.6811, ppl: 1.0006542639373406, progress_or_epoch: 0.65\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:40,994] [    INFO]\u001b[0m - loss: 0.00062484, learning_rate: 4.449e-06, global_step: 66, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4913, interval_samples_per_second: 5.3645, interval_steps_per_second: 0.6706, ppl: 1.000625035253178, progress_or_epoch: 0.66\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:42,657] [    INFO]\u001b[0m - loss: 0.00060752, learning_rate: 4.279e-06, global_step: 67, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.6632, interval_samples_per_second: 4.8099, interval_steps_per_second: 0.6012, ppl: 1.0006077045776516, progress_or_epoch: 0.67\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:44,157] [    INFO]\u001b[0m - loss: 0.00059177, learning_rate: 4.109e-06, global_step: 68, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.5001, interval_samples_per_second: 5.3331, interval_steps_per_second: 0.6666, ppl: 1.0005919451304104, progress_or_epoch: 0.68\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:45,633] [    INFO]\u001b[0m - loss: 0.00057848, learning_rate: 3.942e-06, global_step: 69, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.476, interval_samples_per_second: 5.4199, interval_steps_per_second: 0.6775, ppl: 1.0005786473518234, progress_or_epoch: 0.69\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:47,125] [    INFO]\u001b[0m - loss: 0.00055459, learning_rate: 3.778e-06, global_step: 70, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4913, interval_samples_per_second: 5.3646, interval_steps_per_second: 0.6706, ppl: 1.0005547438134672, progress_or_epoch: 0.7\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:48,773] [    INFO]\u001b[0m - loss: 0.00054881, learning_rate: 3.616e-06, global_step: 71, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.6481, interval_samples_per_second: 4.8542, interval_steps_per_second: 0.6068, ppl: 1.0005489606237614, progress_or_epoch: 0.71\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:50,439] [    INFO]\u001b[0m - loss: 0.00052375, learning_rate: 3.457e-06, global_step: 72, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.6662, interval_samples_per_second: 4.8012, interval_steps_per_second: 0.6002, ppl: 1.0005238871809796, progress_or_epoch: 0.72\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:51,940] [    INFO]\u001b[0m - loss: 0.00052632, learning_rate: 3.301e-06, global_step: 73, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.5013, interval_samples_per_second: 5.3286, interval_steps_per_second: 0.6661, ppl: 1.000526458530674, progress_or_epoch: 0.73\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:53,402] [    INFO]\u001b[0m - loss: 0.00050112, learning_rate: 3.149e-06, global_step: 74, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4614, interval_samples_per_second: 5.4744, interval_steps_per_second: 0.6843, ppl: 1.0005012455816036, progress_or_epoch: 0.74\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:54,877] [    INFO]\u001b[0m - loss: 0.00049965, learning_rate: 3e-06, global_step: 75, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.475, interval_samples_per_second: 5.4239, interval_steps_per_second: 0.678, ppl: 1.0004997748458535, progress_or_epoch: 0.75\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:56,374] [    INFO]\u001b[0m - loss: 0.00049271, learning_rate: 2.855e-06, global_step: 76, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4973, interval_samples_per_second: 5.3429, interval_steps_per_second: 0.6679, ppl: 1.0004928314015098, progress_or_epoch: 0.76\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:58,108] [    INFO]\u001b[0m - loss: 0.0004792, learning_rate: 2.714e-06, global_step: 77, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.734, interval_samples_per_second: 4.6135, interval_steps_per_second: 0.5767, ppl: 1.0004793148346622, progress_or_epoch: 0.77\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:59,678] [    INFO]\u001b[0m - loss: 0.00048325, learning_rate: 2.577e-06, global_step: 78, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.5694, interval_samples_per_second: 5.0974, interval_steps_per_second: 0.6372, ppl: 1.0004833667840924, progress_or_epoch: 0.78\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:01,146] [    INFO]\u001b[0m - loss: 0.00047503, learning_rate: 2.445e-06, global_step: 79, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4684, interval_samples_per_second: 5.4483, interval_steps_per_second: 0.681, ppl: 1.000475142844618, progress_or_epoch: 0.79\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:02,603] [    INFO]\u001b[0m - loss: 0.00046239, learning_rate: 2.318e-06, global_step: 80, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4572, interval_samples_per_second: 5.4901, interval_steps_per_second: 0.6863, ppl: 1.0004624969187348, progress_or_epoch: 0.8\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:04,078] [    INFO]\u001b[0m - loss: 0.00046021, learning_rate: 2.196e-06, global_step: 81, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4748, interval_samples_per_second: 5.4244, interval_steps_per_second: 0.6781, ppl: 1.0004603159128689, progress_or_epoch: 0.81\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:05,732] [    INFO]\u001b[0m - loss: 0.00044189, learning_rate: 2.078e-06, global_step: 82, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.6539, interval_samples_per_second: 4.8371, interval_steps_per_second: 0.6046, ppl: 1.0004419876477688, progress_or_epoch: 0.82\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:07,234] [    INFO]\u001b[0m - loss: 0.00044303, learning_rate: 1.966e-06, global_step: 83, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.5022, interval_samples_per_second: 5.3256, interval_steps_per_second: 0.6657, ppl: 1.0004431281522848, progress_or_epoch: 0.83\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:08,720] [    INFO]\u001b[0m - loss: 0.00043664, learning_rate: 1.859e-06, global_step: 84, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4859, interval_samples_per_second: 5.3839, interval_steps_per_second: 0.673, ppl: 1.000436735341121, progress_or_epoch: 0.84\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:10,211] [    INFO]\u001b[0m - loss: 0.00044362, learning_rate: 1.758e-06, global_step: 85, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4911, interval_samples_per_second: 5.365, interval_steps_per_second: 0.6706, ppl: 1.0004437184139046, progress_or_epoch: 0.85\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:11,705] [    INFO]\u001b[0m - loss: 0.00043008, learning_rate: 1.663e-06, global_step: 86, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4937, interval_samples_per_second: 5.3559, interval_steps_per_second: 0.6695, ppl: 1.0004301724976632, progress_or_epoch: 0.86\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:13,381] [    INFO]\u001b[0m - loss: 0.00043164, learning_rate: 1.574e-06, global_step: 87, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.6764, interval_samples_per_second: 4.772, interval_steps_per_second: 0.5965, ppl: 1.0004317331699497, progress_or_epoch: 0.87\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:15,013] [    INFO]\u001b[0m - loss: 0.00043156, learning_rate: 1.49e-06, global_step: 88, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.6317, interval_samples_per_second: 4.9028, interval_steps_per_second: 0.6129, ppl: 1.0004316531354143, progress_or_epoch: 0.88\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:16,489] [    INFO]\u001b[0m - loss: 0.00041841, learning_rate: 1.413e-06, global_step: 89, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4765, interval_samples_per_second: 5.4184, interval_steps_per_second: 0.6773, ppl: 1.0004184975456736, progress_or_epoch: 0.89\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:17,973] [    INFO]\u001b[0m - loss: 0.00041201, learning_rate: 1.343e-06, global_step: 90, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 34.84359335899353, max_memory_allocated: 13.52203369140625, max_memory_reserved: 34.84359335899353, interval_runtime: 1.4833, interval_samples_per_second: 5.3934, interval_steps_per_second: 0.6742, ppl: 1.000412094887778, progress_or_epoch: 0.9\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:19,469] [    INFO]\u001b[0m - loss: 0.00041063, learning_rate: 1.278e-06, global_step: 91, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 34.84359335899353, max_memory_allocated: 13.52203369140625, max_memory_reserved: 34.84359335899353, interval_runtime: 1.4964, interval_samples_per_second: 5.3462, interval_steps_per_second: 0.6683, ppl: 1.0004107143200396, progress_or_epoch: 0.91\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:21,112] [    INFO]\u001b[0m - loss: 0.00041239, learning_rate: 1.22e-06, global_step: 92, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 34.84359335899353, max_memory_allocated: 13.52203369140625, max_memory_reserved: 34.84359335899353, interval_runtime: 1.6429, interval_samples_per_second: 4.8696, interval_steps_per_second: 0.6087, ppl: 1.000412475044446, progress_or_epoch: 0.92\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:22,589] [    INFO]\u001b[0m - loss: 0.00040777, learning_rate: 1.169e-06, global_step: 93, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 34.84359335899353, max_memory_allocated: 13.52203369140625, max_memory_reserved: 34.84359335899353, interval_runtime: 1.4775, interval_samples_per_second: 5.4146, interval_steps_per_second: 0.6768, ppl: 1.000407853149488, progress_or_epoch: 0.93\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:24,046] [    INFO]\u001b[0m - loss: 0.00040752, learning_rate: 1.124e-06, global_step: 94, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 34.84359335899353, max_memory_allocated: 13.52203369140625, max_memory_reserved: 34.84359335899353, interval_runtime: 1.457, interval_samples_per_second: 5.4907, interval_steps_per_second: 0.6863, ppl: 1.000407603047556, progress_or_epoch: 0.94\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:25,511] [    INFO]\u001b[0m - loss: 0.00040874, learning_rate: 1.086e-06, global_step: 95, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 34.84359335899353, max_memory_allocated: 13.52203369140625, max_memory_reserved: 34.84359335899353, interval_runtime: 1.4643, interval_samples_per_second: 5.4635, interval_steps_per_second: 0.6829, ppl: 1.0004088235455761, progress_or_epoch: 0.95\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:26,992] [    INFO]\u001b[0m - loss: 0.00039641, learning_rate: 1.055e-06, global_step: 96, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 34.84359335899353, max_memory_allocated: 13.52203369140625, max_memory_reserved: 34.84359335899353, interval_runtime: 1.4815, interval_samples_per_second: 5.4, interval_steps_per_second: 0.675, ppl: 1.0003964885808272, progress_or_epoch: 0.96\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:28,649] [    INFO]\u001b[0m - loss: 0.0004016, learning_rate: 1.031e-06, global_step: 97, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 34.84359335899353, max_memory_allocated: 13.52203369140625, max_memory_reserved: 34.84359335899353, interval_runtime: 1.6566, interval_samples_per_second: 4.8291, interval_steps_per_second: 0.6036, ppl: 1.0004016806520764, progress_or_epoch: 0.97\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:30,116] [    INFO]\u001b[0m - loss: 0.0004049, learning_rate: 1.014e-06, global_step: 98, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 34.84359335899353, max_memory_allocated: 13.52203369140625, max_memory_reserved: 34.84359335899353, interval_runtime: 1.4677, interval_samples_per_second: 5.4508, interval_steps_per_second: 0.6813, ppl: 1.0004049819830696, progress_or_epoch: 0.98\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:31,570] [    INFO]\u001b[0m - loss: 0.00039089, learning_rate: 1.003e-06, global_step: 99, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 34.84359335899353, max_memory_allocated: 13.52203369140625, max_memory_reserved: 34.84359335899353, interval_runtime: 1.4537, interval_samples_per_second: 5.5032, interval_steps_per_second: 0.6879, ppl: 1.0003909664074513, progress_or_epoch: 0.99\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:33,039] [    INFO]\u001b[0m - loss: 0.00038933, learning_rate: 1e-06, global_step: 100, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 34.84359335899353, max_memory_allocated: 13.52203369140625, max_memory_reserved: 34.84359335899353, interval_runtime: 1.4685, interval_samples_per_second: 5.4476, interval_steps_per_second: 0.6809, ppl: 1.000389405798761, progress_or_epoch: 1.0\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:33,039] [    INFO]\u001b[0m - \r\n",
      "Training completed. \r\n",
      "\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:33,039] [    INFO]\u001b[0m - train_runtime: 158.453, train_samples_per_second: 5.0488, train_steps_per_second: 0.6311, train_loss: 0.4931975438800873, progress_or_epoch: 1.0\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:33,040] [    INFO]\u001b[0m - Saving model checkpoint to ./output\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:33,043] [    INFO]\u001b[0m - tokenizer config file saved in ./output/tokenizer_config.json\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:33,044] [    INFO]\u001b[0m - Special tokens file saved in ./output/special_tokens_map.json\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:33,044] [    INFO]\u001b[0m - added tokens file saved in ./output/added_tokens.json\u001b[0m\r\n",
      "\u001b[33m[2025-07-17 19:08:33,054] [ WARNING]\u001b[0m - Asynchronous saving is not supported for single card environment currently.\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,837] [    INFO]\u001b[0m - Configuration saved in ./output/config.json\u001b[0m\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddleformers/generation/configuration_utils.py:316: UserWarning: The generation config instance is invalid -- `.validate()` throws warnings and/or exceptions. Fix these issues to save the configuration. This warning will be raised to an exception.\r\n",
      "\r\n",
      "Thrown during validation:\r\n",
      "using greedy search strategy. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `decode_strategy=\"greedy_search\" ` or unset `temperature`.\r\n",
      "  warnings.warn(\r\n",
      "\u001b[32m[2025-07-17 19:08:34,872] [    INFO]\u001b[0m - [timelog] model saving time: 1.83s (2025-07-17 19:08:34) \u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,872] [    INFO]\u001b[0m - ***** train metrics *****\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,872] [    INFO]\u001b[0m -   progress_or_epoch        =        1.0\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,872] [    INFO]\u001b[0m -   train_loss               =     0.4932\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,872] [    INFO]\u001b[0m -   train_runtime            = 0:02:38.45\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,872] [    INFO]\u001b[0m -   train_samples_per_second =     5.0488\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,872] [    INFO]\u001b[0m -   train_steps_per_second   =     0.6311\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,873] [    INFO]\u001b[0m - ***** Running Evaluation *****\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,873] [    INFO]\u001b[0m -   Num examples: Unknown\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,873] [    INFO]\u001b[0m -   Total prediction steps = 10000\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,873] [    INFO]\u001b[0m -   Pre device batch size = 1\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,873] [    INFO]\u001b[0m -   Total Batch size = 1\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,875] [    INFO]\u001b[0m - prepare SequenceDataset ...\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,876] [    INFO]\u001b[0m - prepare SequenceDataset done: total number of examples is 10\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,922] [    INFO]\u001b[0m - eval_loss: 4.969167232513428, eval_runtime: 0.0491, eval_samples_per_second: 203467.7235, eval_steps_per_second: 203467.7235, eval_ppl: 143.90699638950923, progress_or_epoch: 1.0\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,922] [    INFO]\u001b[0m - ***** eval metrics *****\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,922] [    INFO]\u001b[0m -   eval_loss               =      4.9692\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,922] [    INFO]\u001b[0m -   eval_ppl                =     143.907\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,922] [    INFO]\u001b[0m -   eval_runtime            =  0:00:00.04\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,923] [    INFO]\u001b[0m -   eval_samples_per_second = 203467.7235\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,923] [    INFO]\u001b[0m -   eval_steps_per_second   = 203467.7235\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,923] [    INFO]\u001b[0m -   progress_or_epoch       =         1.0\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,923] [    INFO]\u001b[0m - Saving stop info into ./vdl_log/stop_step.json\u001b[0m\r\n",
      "LAUNCH INFO 2025-07-17 19:08:36,850 Pod completed\r\n",
      "LAUNCH INFO 2025-07-17 19:08:36,850 Exit code 0\r\n"
     ]
    }
   ],
   "source": [
    "!erniekit train examples/configs/ERNIE-4.5-0.3B/sft/run_sft_8k.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 解读训练日志\n",
    "\n",
    "当训练开始后，您会看到大量的日志信息输出。学会解读这些日志是监控训练状态、判断模型是否正常收敛的关键。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们来解析其中的关键信息：\n",
    "\n",
    "*   `global_step`: 当前的总训练步数。`10/100` 表示当前是第10步，总共需要训练100步（由 `max_steps` 定义）。\n",
    "*   `epoch`: 当前的训练轮数。\n",
    "*   `loss`: **最重要的指标**。它衡量了模型预测的输出与真实 `tgt` 之间的差距。**我们期望看到 `loss` 值随着训练的进行而稳步下降**。如果 `loss` 居高不下、剧烈震荡或者变为 `NaN`，都说明训练可能出了问题（例如，学习率过高、数据有问题等）。\n",
    "*   `learning_rate`: 当前的学习率。您可以看到它在 `warmup_steps` 之后达到设定的值，然后根据 `lr_scheduler_type` 的策略进行变化。\n",
    "*   `speed` / `ips`: 训练速度。分别表示每秒处理的步数和样本数。可以用来预估总的训练时间。\n",
    "*   `eta`: 预计剩余训练时间 (Estimated Time of Arrival)。\n",
    "\n",
    "**监控要点：**\n",
    "\n",
    "1.  **Loss 是否下降**: 这是首要的健康指标。一个平稳下降的loss曲线是训练成功的标志。\n",
    "2.  **GPU 利用率和显存**: 使用 `nvidia-smi` 命令可以实时查看GPU的工作状态。确保GPU利用率尽可能高，显存占用在合理范围内。如果显存溢出 (Out of Memory, OOM)，您需要减小 `batch_size`、`max_seq_len`，或者开启 `recompute`。\n",
    "3.  **评估结果 (Eval Loss)**: 当达到 `eval_steps` 时，模型会在评估集上进行测试。我们同样期望 `eval_loss` 也能随之下降，这表明模型的泛化能力在提升。如果 `train_loss` 下降而 `eval_loss` 上升，说明模型可能发生了过拟合。\n",
    "\n",
    "训练完成后，所有微调过的模型权重和配置文件都会保存在您 `yaml` 中 `output_dir` 指定的目录下。默认情况下，会有一个名为 `checkpoint-xxx` 的文件夹，其中 `xxx` 是保存时的步数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 总结与展望\n",
    "\n",
    "恭喜您！通过本教程的学习和实践，您已经成功掌握了使用 ERNIEkit 对 ERNIE-4.5-0.3B 大语言模型进行监督微调 (SFT) 的核心技术。我们从SFT的基本概念出发，一步步完成了环境准备、数据处理、配置解析、模型训练与推理评估的全过程。\n",
    "\n",
    "### 6.1 本教程核心回顾\n",
    "\n",
    "让我们再次梳理本次旅程的关键学习点：\n",
    "\n",
    "1.  **理解了SFT的本质**：我们明确了SFT是在预训练模型基础上，通过有标签的“指令-输出”数据，教会模型如何遵循人类意图、完成特定任务的过程。它是连接通用大模型与具体应用场景的桥梁。\n",
    "2.  **掌握了ERNIEkit SFT全流程**：我们学会了使用 ERNIEkit 这一强大的工具链，从下载模型、准备数据，到配置和启动训练，再到最终的推理验证，形成了一个完整的闭环。\n",
    "3.  **精通了SFT配置**：我们深入解析了 `run_sft_8k.yaml` 配置文件中的各项参数，理解了如何通过调整学习率、batch size、序列长度、优化策略等来控制和优化SFT过程，并学会了如梯度累积、重计算 (Recompute)、混合精度等关键的显存优化技巧。\n",
    "4.  **强调了数据的重要性**：我们认识到，高质量、多样化的SFT数据是决定微调成败的基石，并学习了如何构建符合ERNIEkit要求的数据集。\n",
    "\n",
    "通过SFT，我们赋予了 ERNIE-4.5-0.3B 模型全新的、定制化的能力，使其从一个“博学的通才”向“专业的助手”迈出了坚实的一步。\n",
    "\n",
    "### 6.2 后续学习与探索方向\n",
    "\n",
    "SFT为我们打开了通往定制化大模型世界的大门，但这仅仅是一个开始。大语言模型的技术栈仍在飞速发展，以下是一些值得您进一步探索的方向：\n",
    "\n",
    "*   **参数高效微调 (PEFT - Parameter-Efficient Fine-Tuning)** ：\n",
    "    *   **LoRA (Low-Rank Adaptation)** ：全参数微调虽然效果好，但资源消耗大，且会为每个任务都保存一个完整的模型副本。LoRA是一种PEFT方法，它通过在模型的某些层中注入小的、可训练的“适配器”矩阵，冻结原始的大部分权重。这样，我们只需要训练和存储极少部分（通常不到1%）的参数，就能达到接近全参数微调的效果。ERNIEkit 对 LoRA 提供了良好的支持，您只需在配置文件中将 `fine_tuning: Full` 修改为 `fine_tuning: lora` 并配置相关参数即可尝试。\n",
    "\n",
    "*   **从人类反馈中强化学习 (RLHF - Reinforcement Learning from Human Feedback)** ：\n",
    "    *   SFT教会了模型“听话”，但如何让模型的回答更符合人类的偏好（例如，更有用、更无害、更有趣）？RLHF就是解决这个问题的关键技术。它通过收集人类对模型不同回答的偏好排序数据，训练一个“奖励模型”，然后使用强化学习算法（如PPO）来优化语言模型，使其生成的内容能获得更高的奖励分数。这是通往更高级、更对齐的AI的必经之路。\n",
    "\n",
    "*   **更先进的模型与技术** ：\n",
    "    *   持续关注文心大模型和ERNIEkit的最新进展，探索更大参数规模的模型、更先进的算法和更高效的训练框架。\n",
    "\n",
    "*   **模型部署与服务化** ：\n",
    "    *   将您微调好的模型部署成在线服务，是实现其价值的最后一公里。可以探索如Paddle Serving、FastDeploy等工具，学习如何进行模型量化、压缩，并提供高性能的推理API。\n",
    "\n",
    "大语言模型的时代充满了无限的机遇和挑战。希望本教程能成为您探索这个激动人心领域的坚实起点。持续学习，不断实践，您将能够构建出越来越强大的AI应用。祝您在AI的探索之路上行稳致远！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 问题反馈/与我联系： Wechat：G_Fuji"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
