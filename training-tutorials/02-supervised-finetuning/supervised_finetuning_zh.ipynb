{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# åŸºäº ERNIE-4.5-0.3B çš„å¤§è¯­è¨€æ¨¡å‹ç›‘ç£å¾®è°ƒ (SFT) æ•™ç¨‹\n",
    "\n",
    "## 1. å¼•è¨€\n",
    "\n",
    "æ¬¢è¿æ¥åˆ°è¿™ç¯‡å…³äºä½¿ç”¨ ERNIEkit å¯¹ ERNIE-4.5-0.3B æ¨¡å‹è¿›è¡Œç›‘ç£å¾®è°ƒ (Supervised Fine-Tuning, SFT) çš„æ•™ç¨‹ï¼åœ¨ä¸Šä¸€ç¯‡é¢„è®­ç»ƒæ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å·²ç»æ¢ç´¢äº†å¦‚ä½•ä»é›¶å¼€å§‹æ„å»ºä¸€ä¸ªè¯­è¨€æ¨¡å‹ï¼Œèµ‹äºˆå®ƒç†è§£å’Œç”Ÿæˆæ–‡æœ¬çš„åŸºç¡€èƒ½åŠ›ã€‚ç„¶è€Œï¼Œä¸€ä¸ªç»è¿‡é¢„è®­ç»ƒçš„é€šç”¨å¤§æ¨¡å‹ï¼Œå°±åƒä¸€ä¸ªçŸ¥è¯†æ¸Šåšä½†æœªç»ä¸“é—¨è®­ç»ƒçš„é€šæ‰ï¼Œå®ƒæ‹¥æœ‰æµ·é‡çš„çŸ¥è¯†ï¼Œå´ä¸ä¸€å®šèƒ½ç²¾å‡†åœ°éµå¾ªæˆ‘ä»¬çš„å…·ä½“æŒ‡ä»¤æ¥å®Œæˆç‰¹å®šä»»åŠ¡ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 ä»€ä¹ˆæ˜¯å¤§è¯­è¨€æ¨¡å‹ç›‘ç£å¾®è°ƒ (SFT)ï¼Ÿ\n",
    "\n",
    "**ç›‘ç£å¾®è°ƒ (SFT)** æ˜¯å°†é€šç”¨å¤§æ¨¡å‹è½¬åŒ–ä¸ºä¸“ä¸šåŠ©æ‰‹çš„å…³é”®æ­¥éª¤ã€‚å®ƒåœ¨é¢„è®­ç»ƒå¥½çš„æ¨¡å‹åŸºç¡€ä¸Šï¼Œåˆ©ç”¨ä¸€ä¸ªåŒ…å«â€œæŒ‡ä»¤ (Instruction/Prompt)â€å’Œâ€œæœŸæœ›è¾“å‡º (Response/Output)â€çš„æ ‡æ³¨æ•°æ®é›†ï¼Œå¯¹æ¨¡å‹è¿›è¡Œè¿›ä¸€æ­¥çš„è®­ç»ƒã€‚è¿™ä¸ªè¿‡ç¨‹å¥½æ¯”æ˜¯ä¸ºä¸€ä½åšå­¦çš„é€šæ‰æä¾›â€œå²—å‰åŸ¹è®­â€ï¼Œæ•™ä¼šå®ƒå¦‚ä½•ç†è§£å¹¶éµå¾ªäººç±»çš„æŒ‡ä»¤ï¼Œå¦‚ä½•é’ˆå¯¹ç‰¹å®šé—®é¢˜ç”Ÿæˆé«˜è´¨é‡çš„å›ç­”ï¼Œæˆ–è€…å¦‚ä½•æ¨¡ä»¿æŸç§ç‰¹å®šçš„å¯¹è¯é£æ ¼å’Œæ ¼å¼ã€‚\n",
    "\n",
    "**SFT ä¸é¢„è®­ç»ƒ (PT) çš„æ ¸å¿ƒåŒºåˆ«ï¼š**\n",
    "\n",
    "| ç‰¹æ€§ | é¢„è®­ç»ƒ (PT) | ç›‘ç£å¾®è°ƒ (SFT) |\n",
    "|---|---|---|\n",
    "| **ç›®æ ‡** | å­¦ä¹ é€šç”¨çš„è¯­è¨€è§„å¾‹ã€è¯­æ³•ç»“æ„å’Œä¸–ç•ŒçŸ¥è¯† | å­¦ä¹ éµå¾ªæŒ‡ä»¤ã€è§£å†³ç‰¹å®šä»»åŠ¡ã€å¯¹é½äººç±»æ„å›¾å’Œä»·å€¼è§‚ |\n",
    "| **æ•°æ®** | å¤§è§„æ¨¡ã€**æ— æ ‡ç­¾**çš„çº¯æ–‡æœ¬æ•°æ®ï¼ˆå¦‚ç½‘é¡µã€ä¹¦ç±ã€ä»£ç ï¼‰ | ç›¸å¯¹è¾ƒå°è§„æ¨¡ã€**æœ‰é«˜è´¨é‡æ ‡ç­¾**çš„â€œæŒ‡ä»¤-è¾“å‡ºâ€å¯¹æ•°æ® |\n",
    "| **å­¦ä¹ æ–¹å¼** | æ— ç›‘ç£æˆ–è‡ªç›‘ç£å­¦ä¹ ï¼ˆå¦‚é¢„æµ‹ä¸‹ä¸€ä¸ªè¯ï¼‰ | æœ‰ç›‘ç£å­¦ä¹ ï¼ˆå­¦ä¹ ä»è¾“å…¥æŒ‡ä»¤åˆ°æœŸæœ›è¾“å‡ºçš„æ˜ å°„ï¼‰ |\n",
    "| **è®¡ç®—èµ„æº** | é€šå¸¸éœ€æ±‚å·¨å¤§ï¼Œéœ€è¦æµ·é‡æ•°æ®å’Œè¶…é•¿è®­ç»ƒæ—¶é—´ | ç›¸å¯¹è¾ƒå°ï¼Œå¯åœ¨é¢„è®­ç»ƒæ¨¡å‹åŸºç¡€ä¸Šè¿›è¡Œé«˜æ•ˆã€å¿«é€Ÿçš„è¿­ä»£ |\n",
    "| **æ¨¡å‹è§’è‰²** | è®­ç»ƒä¸€ä¸ªâ€œåŸºç¡€æ¨¡å‹â€ (Base Model)ï¼Œå¥ å®šèƒ½åŠ›åŸºç¡€ | åœ¨â€œåŸºç¡€æ¨¡å‹â€ä¸Šè¿›è¡Œâ€œæŒ‡ä»¤è°ƒä¼˜â€ (Instruction Tuning)ï¼Œç‰¹åŒ–æ¨¡å‹è¡Œä¸º |\n",
    "\n",
    "ç®€è€Œè¨€ä¹‹ï¼Œé¢„è®­ç»ƒè®©æ¨¡å‹â€œå­¦ä¼šè¯´è¯â€ï¼Œè€Œç›‘ç£å¾®è°ƒåˆ™æ•™æ¨¡å‹â€œå¥½å¥½è¯´è¯â€ã€â€œå¬è¯åŠäº‹â€ï¼Œä½¿å…¶è¡Œä¸ºä¸äººç±»çš„æœŸæœ›å¯¹é½ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 SFT çš„åº”ç”¨åœºæ™¯å’Œæ„ä¹‰\n",
    "\n",
    "SFT æ˜¯é‡Šæ”¾å¤§è¯­è¨€æ¨¡å‹æ½œåŠ›çš„æ ¸å¿ƒæŠ€æœ¯ï¼Œå…¶æ„ä¹‰å’Œåº”ç”¨åœºæ™¯æä¸ºå¹¿æ³›ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸‹è¡¨æ¥ç›´è§‚æ„Ÿå—ï¼š\n",
    "\n",
    "|  | åº”ç”¨åœºæ™¯ | æ ¸å¿ƒæ„ä¹‰ | \n",
    "| :---: | :--- | :--- | \n",
    "| ğŸ¯ | **æå‡ç‰¹å®šä»»åŠ¡æ€§èƒ½** | é€šè¿‡åœ¨ç‰¹å®šé¢†åŸŸçš„æŒ‡ä»¤æ•°æ®ä¸Šè¿›è¡ŒSFTï¼Œå¯ä»¥æ˜¾è‘—æå‡æ¨¡å‹åœ¨å®¢æœé—®ç­”ã€ä»£ç ç”Ÿæˆã€æ³•å¾‹æ–‡ä¹¦æ‘˜è¦ã€åŒ»ç–—å’¨è¯¢ç­‰ä»»åŠ¡ä¸Šçš„ä¸“ä¸šæ€§ã€å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚ | \n",
    "| ğŸ™ | **æ¨¡å‹å¯¹é½ (Alignment)** | SFT æ˜¯å®ç°æ¨¡å‹ä¸äººç±»æ„å›¾å’Œä»·å€¼è§‚å¯¹é½çš„å…³é”®ä¸€æ­¥ã€‚é€šè¿‡ç²¾å¿ƒè®¾è®¡çš„æŒ‡ä»¤å’ŒæœŸæœ›çš„å›ç­”ï¼ˆé€šå¸¸å¼ºè°ƒæœ‰ç”¨æ€§ã€çœŸå®æ€§å’Œæ— å®³æ€§ï¼‰ï¼Œå¼•å¯¼æ¨¡å‹ç”Ÿæˆè´Ÿè´£ä»»ã€æœ‰å¸®åŠ©çš„å†…å®¹ã€‚ | \n",
    "| ğŸ’¬ | **æ„å»ºå¼ºå¤§çš„å¯¹è¯å¼AI** | æ‰€æœ‰é¡¶å°–çš„èŠå¤©æœºå™¨äººï¼Œæ— ä¸€ä¸ç»è¿‡äº†å¤§é‡çš„SFTè®­ç»ƒã€‚è¿™ä½¿å¾—å®ƒä»¬èƒ½å¤Ÿè¿›è¡Œæµç•…ã€è‡ªç„¶ã€ä¸”å¯Œæœ‰é€»è¾‘çš„å¤šè½®å¯¹è¯ï¼ŒçœŸæ­£æˆä¸ºç”¨æˆ·çš„å¾—åŠ›åŠ©æ‰‹ã€‚ | \n",
    "| ğŸ­ | **éµå¾ªç‰¹å®šé£æ ¼æˆ–æ ¼å¼** | æˆ‘ä»¬å¯ä»¥é€šè¿‡SFTè®­ç»ƒæ¨¡å‹ä»¥å›ºå®šçš„æ ¼å¼ï¼ˆå¦‚JSONã€Markdownï¼‰è¾“å‡ºï¼Œæˆ–è€…æ‰®æ¼”ç‰¹å®šçš„è§’è‰²ï¼ˆå¦‚èå£«æ¯”äºšã€æŠ€æœ¯ä¸“å®¶ï¼‰ï¼Œç”šè‡³ç”Ÿæˆå…·æœ‰ç‰¹å®šæƒ…æ„ŸåŸºè°ƒçš„æ–‡æœ¬ã€‚ | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 ä¸ºä»€ä¹ˆé€‰æ‹© ERNIE-4.5-0.3B è¿›è¡Œ SFTï¼Ÿ\n",
    "\n",
    "é€‰æ‹© `ERNIE-4.5-0.3B` ä½œä¸ºæˆ‘ä»¬SFTå®è·µçš„ä¸»è§’ï¼Œæ˜¯åŸºäºä»¥ä¸‹å‡ ç‚¹å…³é”®ä¼˜åŠ¿ï¼š\n",
    "\n",
    "|  | ä¼˜åŠ¿ | è¯¦ç»†è¯´æ˜ |\n",
    "| :---: | :--- | :--- |\n",
    "| ğŸ† | **å“è¶Šçš„é¢„è®­ç»ƒåŸºç¡€** | `ERNIE-4.5-0.3B` ä½œä¸ºæ–‡å¿ƒå¤§æ¨¡å‹çš„æœ€æ–°æˆå‘˜ï¼Œå…¶æœ¬èº«ç»è¿‡äº†æµ·é‡ã€é«˜è´¨é‡æ•°æ®çš„å……åˆ†é¢„è®­ç»ƒï¼Œå…·å¤‡äº†ä¸–ç•Œé¢†å…ˆçš„ä¸­æ–‡å¤„ç†èƒ½åŠ›å’Œé€šç”¨è¯­è¨€ç†è§£èƒ½åŠ›ã€‚è¿™æ˜¯ä¸€ä¸ªæå…¶å¼ºå¤§çš„SFTèµ·ç‚¹ã€‚ |\n",
    "| ğŸ’° | **å‚æ•°è§„æ¨¡é€‚ä¸­ï¼Œæ€§ä»·æ¯”é«˜** | 0.3Bï¼ˆ3äº¿ï¼‰çš„å‚æ•°é‡ï¼Œä½¿å¾—åœ¨æ¶ˆè´¹çº§æˆ–ä¸»æµçš„è®¡ç®—èµ„æºä¸Šè¿›è¡Œå…¨å‚æ•°SFTæˆä¸ºå¯èƒ½ã€‚è¿™æå¤§åœ°é™ä½äº†å¼€å‘è€…å’Œç ”ç©¶è€…è¿›è¡Œå®éªŒå’Œå¿«é€Ÿè¿­ä»£çš„é—¨æ§›ï¼Œæ˜¯æ¢ç´¢SFTçš„æœ€ä½³é€‰æ‹©ä¹‹ä¸€ã€‚ |\n",
    "| ğŸ› ï¸ | **ERNIEkit çš„å…¨é¢æ”¯æŒ** | ERNIEkit æ˜¯é£æ¡¨ä¸ºæ–‡å¿ƒå¤§æ¨¡å‹é‡èº«æ‰“é€ çš„å¼€å‘å¥—ä»¶ï¼Œæä¾›äº†ä»é¢„è®­ç»ƒã€SFTã€åˆ°æ¨ç†éƒ¨ç½²çš„å…¨æµç¨‹å·¥å…·ã€‚å…¶SFTè„šæœ¬ç»è¿‡ç²¾å¿ƒä¼˜åŒ–ï¼Œæ”¯æŒå…¨å‚æ•°å¾®è°ƒã€LoRAç­‰å¤šç§å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰æ–¹æ³•ï¼Œå¹¶ä¸”é…ç½®çµæ´»ï¼Œä½¿ç”¨ä¾¿æ·ã€‚ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 æœ¬æ•™ç¨‹çš„ç›®æ ‡è¯»è€…å’Œå­¦ä¹ æˆæœ\n",
    "\n",
    "æœ¬æ•™ç¨‹æ—¨åœ¨å¸®åŠ©ä¸åŒèƒŒæ™¯çš„æ‚¨ï¼Œæ·±å…¥SFTçš„ä¸–ç•Œã€‚çœ‹çœ‹æ‚¨å±äºå“ªä¸€ç±»è¯»è€…ï¼Œä»¥åŠæ‚¨å°†æ”¶è·ä»€ä¹ˆï¼š\n",
    "\n",
    "|  | ç›®æ ‡è¯»è€… | æ‚¨å°†è·å¾—çš„å­¦ä¹ æˆæœ (You Will Be Able To) |\n",
    "| :---: | :--- | :--- |\n",
    "| ğŸ§‘â€ğŸ“ | **è¿›é˜¶å­¦ä¹ è€…** | æ·±åˆ»ç†è§£SFTçš„æ ¸å¿ƒåŸç†ã€åº”ç”¨ä»·å€¼åŠå…¶ä¸é¢„è®­ç»ƒçš„æœ¬è´¨åŒºåˆ«ã€‚ |\n",
    "| ğŸ‘¨â€ğŸ’» | **å¼€å‘è€…/å·¥ç¨‹å¸ˆ** | æŒæ¡ä½¿ç”¨ ERNIEkit å¯¹ ERNIE-4.5-0.3B æ¨¡å‹è¿›è¡ŒSFTçš„å®Œæ•´æµç¨‹å’Œæœ€ä½³å®è·µã€‚ |\n",
    "| ğŸ”¬ | **ç ”ç©¶è€…** | äº†è§£SFTæ•°æ®çš„æ ‡å‡†æ ¼å¼å’Œæ„å»ºæ–¹æ³•ï¼Œå¹¶å¯¹å‚æ•°é«˜æ•ˆå¾®è°ƒ (PEFT) å¦‚LoRAæœ‰ä¸€ä¸ªåˆæ­¥çš„è®¤è¯†ã€‚ |\n",
    "| ğŸš€ | **æ‰€æœ‰è¯»è€…** | å­¦ä¼šå¦‚ä½•è§£è¯»å’Œé…ç½® ERNIEkit çš„SFT `yaml` æ–‡ä»¶ï¼Œå¯åŠ¨è®­ç»ƒä»»åŠ¡ï¼Œå¹¶åˆ†æè®­ç»ƒè¿‡ç¨‹ï¼Œæœ€ç»ˆå¯¹å¾®è°ƒåçš„æ¨¡å‹è¿›è¡Œæ¨ç†æµ‹è¯•ï¼Œç›´è§‚æ„Ÿå—SFTå¸¦æ¥çš„èƒ½åŠ›æå‡ã€‚ |\n",
    "\n",
    "ç°åœ¨ï¼Œè®©æˆ‘ä»¬ä¸€èµ·è¸ä¸Šå¾ç¨‹ï¼Œé€šè¿‡SFTæŠ€æœ¯ï¼Œå°†å¼ºå¤§çš„ ERNIE-4.5-0.3B æ¨¡å‹â€œè°ƒæ•™â€æˆæ›´æ‡‚ä½ ã€æ›´èƒ½å¹²çš„ä¸“å±AIåŠ©æ‰‹ï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ç¯å¢ƒå‡†å¤‡\n",
    "\n",
    "è¿›è¡Œç›‘ç£å¾®è°ƒ (SFT) çš„ç¬¬ä¸€æ­¥æ˜¯æ­å»ºä¸€ä¸ªç¨³å®šã€é«˜æ•ˆçš„å¼€å‘ç¯å¢ƒã€‚è¿™åŒ…æ‹¬å®‰è£…æ ¸å¿ƒçš„æ·±åº¦å­¦ä¹ æ¡†æ¶ PaddlePaddleã€æ¨¡å‹å¼€å‘å¥—ä»¶ ERNIEkitï¼Œå¹¶å‡†å¤‡å¥½æˆ‘ä»¬æœ¬æ¬¡å®è·µçš„ä¸»è§’â€”â€”ERNIE-4.5-0.3B æ¨¡å‹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 å®‰è£… PaddlePaddle å’Œ aistudio-sdk\n",
    "\n",
    "ç¡®ä¿æ‚¨å®‰è£…äº†æœ€æ–°æˆ–æ¨èç‰ˆæœ¬çš„ PaddlePaddleã€‚æ¨èä½¿ç”¨GPUç‰ˆæœ¬çš„ PaddlePaddle ä»¥è·å¾—æè‡´çš„è®­ç»ƒé€Ÿåº¦ã€‚åŒæ—¶ï¼Œæˆ‘ä»¬éœ€è¦å®‰è£… `aistudio-sdk`ï¼Œå®ƒæ˜¯ä¸€ä¸ªéå¸¸æ–¹ä¾¿çš„å·¥å…·ï¼Œå¯ä»¥å¸®åŠ©æˆ‘ä»¬è½»æ¾ä¸‹è½½AI-Studioä¸Šçš„æ¨¡å‹èµ„æºã€‚\n",
    "\n",
    "*åœ¨AI studioä¸Šè¿è¡Œæœ¬é¡¹ç›®çš„åŒå­¦ä¸éœ€è¦è¿è¡Œä¸‹æ–¹çš„ç¯å¢ƒå®‰è£…ä»£ç å—*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ç¡®ä¿ pip æ˜¯æœ€æ–°ç‰ˆæœ¬\r\n",
    "!python -m pip install --upgrade pip\r\n",
    "\r\n",
    "# å®‰è£… PaddlePaddle (GPU ç‰ˆæœ¬, æ¨èä½¿ç”¨æœ€æ–°çš„ç¨³å®šç‰ˆ)\r\n",
    "# å¦‚æœæ‚¨çš„ç¯å¢ƒï¼ˆå¦‚CUDAç‰ˆæœ¬ï¼‰ä¸åŒï¼Œè¯·è®¿é—®å®˜ç½‘è·å–å¯¹åº”æŒ‡ä»¤: https://www.paddlepaddle.org.cn/install/quick\r\n",
    "!python -m pip install paddlepaddle-gpu -i https://mirror.baidu.com/pypi/simple\r\n",
    "\r\n",
    "# å®‰è£… aistudio-sdk\r\n",
    "!pip install --upgrade aistudio-sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**éªŒè¯å®‰è£…**ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:57:48.734168Z",
     "iopub.status.busy": "2025-07-17T10:57:48.733664Z",
     "iopub.status.idle": "2025-07-17T10:57:50.521500Z",
     "shell.execute_reply": "2025-07-17T10:57:50.520994Z",
     "shell.execute_reply.started": "2025-07-17T10:57:48.734146Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/utils/cpp_extension/extension_utils.py:715: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\r\n",
      "  warnings.warn(warning_message)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PaddlePaddle Version: 3.1.0\r\n",
      "Running verify PaddlePaddle program ... \r\n",
      "PaddlePaddle works well on 1 GPU.\r\n",
      "PaddlePaddle is installed successfully! Let's start deep learning with PaddlePaddle now.\r\n",
      "PaddlePaddle GPU is available! Found 1 GPU(s).\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0717 18:57:50.384768   265 pir_interpreter.cc:1524] New Executor is Running ...\r\n",
      "W0717 18:57:50.386147   265 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.8, Runtime API Version: 12.6\r\n",
      "I0717 18:57:50.386685   265 pir_interpreter.cc:1547] pir interpreter is running by multi-thread mode ...\r\n"
     ]
    }
   ],
   "source": [
    "import paddle\r\n",
    "\r\n",
    "print(f\"PaddlePaddle Version: {paddle.__version__}\")\r\n",
    "\r\n",
    "# æ£€æŸ¥GPUæ˜¯å¦å¯ç”¨\r\n",
    "try:\r\n",
    "    paddle.utils.run_check()\r\n",
    "    if paddle.device.cuda.device_count() > 0:\r\n",
    "        print(f\"PaddlePaddle GPU is available! Found {paddle.device.cuda.device_count()} GPU(s).\")\r\n",
    "    else:\r\n",
    "        print(\"PaddlePaddle GPU check passed, but no GPU found. Will use CPU.\")\r\n",
    "except Exception as e:\r\n",
    "    print(f\"PaddlePaddle GPU check failed: {e}\")\r\n",
    "    print(\"If you intended to use GPU, please check your CUDA setup and PaddlePaddle installation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 ä¸‹è½½ ERNIEkit ä»“åº“ä»£ç å’Œ ERNIE-4.5-0.3B æ¨¡å‹\n",
    "\n",
    "ERNIEkit çš„SFTè„šæœ¬ (`train.py`) å’Œç›¸å…³çš„æ¨¡å‹ã€è®­ç»ƒé…ç½®æ–‡ä»¶éƒ½ä½äºå…¶å®˜æ–¹ä»“åº“ä¸­ã€‚åŒæ—¶ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨ `aistudio` å‘½ä»¤è¡Œå·¥å…·ä¸‹è½½ ERNIE-4.5-0.3B æ¨¡å‹æƒé‡ã€‚\n",
    "\n",
    "*åœ¨AI studioè¿è¡Œçš„åŒå­¦ä¸éœ€è¦è¿è¡Œä¸‹æ–¹ä»£ç å—*\n",
    "\n",
    "- ERNIEï¼š/home/aistudio/ERNIE-develop.zip\n",
    "- modelï¼š/home/aistudio/data/models/30654/ERNIE-4.5-0.3B-Base-Paddle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1. å…‹éš† ERNIEkit ä»“åº“\r\n",
    "# æˆ‘ä»¬å°†å…‹éš†æœ€æ–°çš„ ERNIE-develop åˆ†æ”¯ï¼Œä»¥è·å–æœ€æ–°çš„åŠŸèƒ½å’Œä¼˜åŒ–\r\n",
    "!git clone https://github.com/PaddlePaddle/ERNIE.git -b develop ERNIE-develop\r\n",
    "\r\n",
    "# 2. ä¸‹è½½ ERNIE-4.5-0.3B æ¨¡å‹æƒé‡\r\n",
    "# ä½¿ç”¨ aistudio-sdk æä¾›çš„å‘½ä»¤è¡Œå·¥å…·ä¸‹è½½\r\n",
    "# æ¨¡å‹å°†è¢«ä¸‹è½½åˆ° baidu/ERNIE-4.5-0.3B-Paddle ç›®å½•ä¸‹\r\n",
    "!aistudio download --model PaddlePaddle/ERNIE-4.5-0.3B-Paddle --local_dir baidu/ERNIE-4.5-0.3B-Paddle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**é‡è¦ç›®å½•ç»“æ„è¯´æ˜**ï¼š\n",
    "\n",
    "æ‰§è¡Œå®Œä¸Šè¿°å‘½ä»¤åï¼Œæ‚¨çš„å·¥ä½œç›®å½•ä¸‹åº”è¯¥æœ‰ç±»ä¼¼è¿™æ ·çš„ç»“æ„ï¼š\n",
    "\n",
    "```\n",
    ".\n",
    "â”œâ”€â”€ ERNIE-develop/\n",
    "â”‚   â”œâ”€â”€ examples/\n",
    "â”‚   â”‚   â”œâ”€â”€ configs/\n",
    "â”‚   â”‚   â”‚   â””â”€â”€ ERNIE-4.5-0.3B/\n",
    "â”‚   â”‚   â”‚       â””â”€â”€ sft/\n",
    "â”‚   â”‚   â”‚           â””â”€â”€ run_sft_8k.yaml  <-- è¿™æ˜¯æˆ‘ä»¬çš„SFTé…ç½®æ–‡ä»¶\n",
    "â”‚   â”‚   â””â”€â”€ data/\n",
    "â”‚   â”‚       â””â”€â”€ sft-train.jsonl        <-- è¿™æ˜¯ç¤ºä¾‹çš„SFTæ•°æ®\n",
    "â”‚   â”œâ”€â”€ train.py                     <-- è¿™æ˜¯ERNIEkitçš„è®­ç»ƒè„šæœ¬\n",
    "â”‚   â””â”€â”€ ... (å…¶ä»–ERNIEkitä»£ç )\n",
    "â””â”€â”€ baidu/\n",
    "    â””â”€â”€ ERNIE-4.5-0.3B-Paddle/       <-- è¿™é‡Œå­˜æ”¾ç€æ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶\n",
    "        â”œâ”€â”€ model_state.pdparams\n",
    "        â”œâ”€â”€ tokenizer_config.json\n",
    "        â””â”€â”€ ... (å…¶ä»–æ¨¡å‹æ–‡ä»¶)\n",
    "```\n",
    "\n",
    "Ai studioçš„åŒå­¦æ¨¡å‹ç›®å½•åˆ™åœ¨dataæ–‡ä»¶å¤¹å†…ï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åœ¨åç»­çš„æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†ä¸»è¦åœ¨ `ERNIE-develop` ç›®å½•ä¸‹è¿›è¡Œæ“ä½œï¼Œå¹¶ä½¿ç”¨ `train.py` è„šæœ¬ï¼Œç»“åˆ `examples/configs/ERNIE-4.5-0.3B/sft/run_sft_8k.yaml` é…ç½®æ–‡ä»¶ï¼Œæ¥åŠ è½½ `baidu/ERNIE-4.5-0.3B-Paddle` ç›®å½•ä¸‹çš„æ¨¡å‹è¿›è¡Œå¾®è°ƒã€‚\n",
    "\n",
    "è¯·ç¡®ä¿æ‚¨çš„ç›®å½•ç»“æ„ä¸æ­¤ä¸€è‡´ï¼Œä»¥ä¾¿é¡ºåˆ©è¿›è¡Œåç»­æ­¥éª¤ã€‚\n",
    "\n",
    "ç¯å¢ƒå’Œèµ„æºéƒ½å·²å‡†å¤‡å°±ç»ªï¼Œæ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬æ·±å…¥äº†è§£SFTçš„æ ¸å¿ƒâ€”â€”æ•°æ®ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SFT æ•°æ®å‡†å¤‡\n",
    "\n",
    "â€œGarbage in, garbage out.â€ è¿™å¥åè¨€åœ¨SFTä¸­ä½“ç°å¾—æ·‹æ¼“å°½è‡´ã€‚SFTçš„æ•ˆæœåœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå–å†³äºæ‰€ç”¨æŒ‡ä»¤æ•°æ®çš„è´¨é‡ã€‚é«˜è´¨é‡çš„æ•°æ®èƒ½å¤Ÿå¼•å¯¼æ¨¡å‹å­¦ä¹ åˆ°æ­£ç¡®çš„è¡Œä¸ºæ¨¡å¼ï¼Œè€Œä½è´¨é‡çš„æ•°æ®åˆ™å¯èƒ½å¯¼è‡´æ¨¡å‹äº§ç”Ÿæœ‰åè§ã€ä¸å‡†ç¡®ç”šè‡³æœ‰å®³çš„è¾“å‡ºã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 SFT æ•°æ®çš„ç‰¹ç‚¹ä¸æ ¼å¼\n",
    "\n",
    "SFTæ•°æ®ç”±æˆå¯¹çš„â€œæŒ‡ä»¤ (Instruction/Prompt)â€å’Œâ€œç†æƒ³è¾“å‡º (Response/Output)â€ç»„æˆã€‚ERNIEkit ä½¿ç”¨ JSON Lines (jsonl) æ ¼å¼ï¼Œå…¶ä¸­æ¯ä¸€è¡Œéƒ½æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„JSONå¯¹è±¡ï¼Œä»£è¡¨ä¸€ä¸ªè®­ç»ƒæ ·æœ¬ã€‚è¿™ç§æ ¼å¼æ¸…æ™°ã€å¯æ‰©å±•ï¼Œéå¸¸é€‚åˆå¤§è§„æ¨¡æ•°æ®é›†çš„å¤„ç†ã€‚\n",
    "\n",
    "**ERNIEkit SFT æ•°æ®æ ¼å¼è¯¦è§£ï¼š**\n",
    "\n",
    "ä¸€ä¸ªæ ‡å‡†çš„ ERNIEkit SFT æ ·æœ¬ç»“æ„å¦‚ä¸‹ï¼š\n",
    "\n",
    "```json\n",
    "{\"src\": \"ä½ å¥½\", \"tgt\": \"ä½ å¥½ï¼å¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ã€‚\"}\n",
    "{\"src\": \"è¯·å†™ä¸€é¦–å…³äºæœˆäº®çš„è¯—ã€‚\", \"tgt\": \"åºŠå‰æ˜æœˆå…‰ï¼Œç–‘æ˜¯åœ°ä¸Šéœœã€‚ä¸¾å¤´æœ›æ˜æœˆï¼Œä½å¤´æ€æ•…ä¹¡ã€‚\"}\n",
    "```\n",
    "\n",
    "*   `src` (Source): ä»£è¡¨è¾“å…¥ç»™æ¨¡å‹çš„æŒ‡ä»¤æˆ–é—®é¢˜ã€‚è¿™éƒ¨åˆ†å†…å®¹ä¼šç»è¿‡æ¨¡æ¿åŒ–å¤„ç†ï¼Œä½œä¸ºæ¨¡å‹çš„è¾“å…¥æç¤º (Prompt)ã€‚\n",
    "*   `tgt` (Target): ä»£è¡¨æœŸæœ›æ¨¡å‹ç”Ÿæˆçš„å›ç­”ã€‚è¿™æ˜¯æ¨¡å‹éœ€è¦å­¦ä¹ å’Œæ¨¡ä»¿çš„ç›®æ ‡è¾“å‡ºã€‚\n",
    "\n",
    "**å¯¹è¯æ¨¡æ¿çš„é‡è¦æ€§ï¼š**\n",
    "\n",
    "åƒ ERNIE-4.5 è¿™æ ·çš„å¯¹è¯æ¨¡å‹ï¼Œåœ¨è®­ç»ƒæ—¶é€šå¸¸ä¼šéµå¾ªä¸€ä¸ªç‰¹å®šçš„å¯¹è¯æ¨¡æ¿ã€‚è¿™ä¸ªæ¨¡æ¿å®šä¹‰äº†ç”¨æˆ· (user) å’ŒåŠ©æ‰‹ (assistant) çš„è§’è‰²ï¼Œå¹¶ä½¿ç”¨ç‰¹æ®Šçš„ token æ¥åˆ†éš”ä¸åŒçš„è½®æ¬¡ã€‚ERNIEkit çš„è®­ç»ƒè„šæœ¬ä¼šè‡ªåŠ¨å°† `src` å’Œ `tgt` åŒ…è£…æˆæ¨¡å‹é¢„è®­ç»ƒæ—¶æ‰€ä½¿ç”¨çš„æ¨¡æ¿æ ¼å¼ã€‚ä¾‹å¦‚ï¼Œä¸€ä¸ªç®€åŒ–çš„æ¨¡æ¿å¯èƒ½å¦‚ä¸‹æ‰€ç¤ºï¼š\n",
    "\n",
    "```\n",
    "<|im_start|>user\n",
    "{src}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "{tgt}<|im_end|>\n",
    "```\n",
    "\n",
    "æ¨¡å‹åœ¨è®­ç»ƒæ—¶ï¼Œå…¶ä»»åŠ¡å°±æ˜¯æ ¹æ® `user` çš„å†…å®¹ï¼Œç»­å†™å‡º `assistant` çš„éƒ¨åˆ†ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ¨¡å‹å­¦ä¼šäº†åœ¨å¯¹è¯ä¸­æ‰®æ¼”åŠ©æ‰‹çš„è§’è‰²ã€‚\n",
    "\n",
    "**é«˜è´¨é‡SFTæ•°æ®çš„å…³é”®è¦ç´ ï¼š**\n",
    "\n",
    "*   **å¤šæ ·æ€§**: æŒ‡ä»¤åº”è¦†ç›–å°½å¯èƒ½å¤šçš„ä¸»é¢˜å’ŒæŠ€èƒ½ï¼Œå¦‚é—®ç­”ã€åˆ›ä½œã€æ‘˜è¦ã€ç¿»è¯‘ã€ä»£ç ç”Ÿæˆç­‰ã€‚\n",
    "*   **å¤æ‚æ€§**: æŒ‡ä»¤åº”åŒ…å«ä¸åŒéš¾åº¦çº§åˆ«ï¼Œä»ç®€å•çš„äº‹å®é—®ç­”åˆ°éœ€è¦æ·±åº¦æ¨ç†å’Œåˆ›é€ åŠ›çš„å¤æ‚ä»»åŠ¡ã€‚\n",
    "*   **å‡†ç¡®æ€§**: `tgt` çš„å†…å®¹å¿…é¡»æ˜¯å‡†ç¡®ã€é«˜è´¨é‡ä¸”æ— å®³çš„ã€‚\n",
    "*   **ä¸€è‡´æ€§**: è¾“å‡ºçš„é£æ ¼ã€æ ¼å¼å’Œè¯¦ç»†ç¨‹åº¦åº”ä¿æŒä¸€è‡´ï¼Œé™¤éæ‚¨æœ‰æ„è®­ç»ƒæ¨¡å‹æŒæ¡å¤šç§é£æ ¼ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 ä½¿ç”¨ ERNIEkit æä¾›çš„ç¤ºä¾‹ SFT æ•°æ®é›†\n",
    "\n",
    "ERNIEkit åœ¨ `ERNIE-develop/examples/data/` ç›®å½•ä¸‹æä¾›äº†ä¸€ä¸ªåä¸º `sft-train.jsonl` çš„ç¤ºä¾‹æ•°æ®é›†ã€‚è¿™æ˜¯ä¸€ä¸ªå°å‹çš„ã€ç»è¿‡æ¸…æ´—çš„æ•°æ®é›†ï¼Œéå¸¸é€‚åˆç”¨äºå¿«é€Ÿè·‘é€šSFTæµç¨‹å’ŒåŠŸèƒ½éªŒè¯ã€‚\n",
    "\n",
    "è®©æˆ‘ä»¬æ¥æŸ¥çœ‹ä¸€ä¸‹è¿™ä¸ªç¤ºä¾‹æ•°æ®çš„å†…å®¹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T11:00:53.764115Z",
     "iopub.status.busy": "2025-07-17T11:00:53.763790Z",
     "iopub.status.idle": "2025-07-17T11:00:53.768344Z",
     "shell.execute_reply": "2025-07-17T11:00:53.767908Z",
     "shell.execute_reply.started": "2025-07-17T11:00:53.764095Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æŸ¥çœ‹ç¤ºä¾‹æ•°æ®: ./ERNIE-develop/examples/data/sft-train.jsonl\r\n",
      "---\r\n",
      "ã€æ ·æœ¬ 1ã€‘\r\n",
      "  SRC: ['æˆ‘ä»¬å¦‚ä½•åœ¨æ—¥å¸¸ç”Ÿæ´»ä¸­å‡å°‘ç”¨æ°´ï¼Ÿ']\r\n",
      "  TGT: ['1. ä½¿ç”¨èŠ‚æ°´è£…ç½®ï¼Œå¦‚èŠ‚æ°´æ·‹æµ´å–·å¤´å’Œæ°´é¾™å¤´ã€‚ \\n2. ä½¿ç”¨æ°´ç®±æˆ–æ°´æ¡¶æ”¶é›†å®¶åº­åºŸæ°´ï¼Œä¾‹å¦‚æ´—ç¢—å’Œæ´—æµ´ã€‚ \\n3. åœ¨ç¤¾åŒºä¸­æé«˜èŠ‚æ°´æ„è¯†ã€‚ \\n4. æ£€æŸ¥æ°´ç®¡å’ŒçŒæº‰ç³»ç»Ÿçš„æ¼æ°´æƒ…å†µï¼Œå¹¶åŠæ—¶ä¿®å¤å®ƒä»¬ã€‚ \\n5. æ´—æ¾¡æ—¶é—´ç¼©çŸ­ï¼Œä½¿ç”¨ä½æµé‡æ·‹æµ´å¤´èŠ‚çº¦ç”¨æ°´ã€‚ \\n6. æ”¶é›†é›¨æ°´ï¼Œç”¨äºå›­è‰ºæˆ–å…¶ä»–éé¥®ç”¨ç›®çš„ã€‚ \\n7. åˆ·ç‰™æˆ–æ“¦æ‰‹æ—¶å…³æ‰æ°´é¾™å¤´ã€‚ \\n8. å‡å°‘æµ‡æ°´è‰åªçš„æ—¶é—´ã€‚ \\n9. å°½å¯èƒ½å¤šåœ°é‡å¤ä½¿ç”¨ç°æ°´ï¼ˆæ¥è‡ªæ´—è¡£æœºã€æµ´å®¤æ°´æ§½å’Œæ·‹æµ´çš„æ°´ï¼‰ã€‚ \\n10. åªè´­ä¹°èƒ½æºæ•ˆç‡é«˜çš„æ´—ç¢—æœºå’Œæ´—è¡£æœºã€‚']\r\n",
      "\r\n",
      "ã€æ ·æœ¬ 2ã€‘\r\n",
      "  SRC: ['æ”¿åºœå¯ä»¥é‡‡å–å“ªäº›ç­–ç•¥æ¥å‡å°‘ç©ºæ°”æ±¡æŸ“ï¼Ÿ']\r\n",
      "  TGT: ['1. å®æ–½å¼ºåˆ¶çš„è½¦è¾†æ’æ”¾æ ‡å‡†å’ŒåŸºäºæ¿€åŠ±çš„è®¡åˆ’ï¼Œä»¥é™ä½è½¦è¾†çš„ç¢³è¶³è¿¹ã€‚\\n2. å¢åŠ å…¬å…±äº¤é€šå·¥å…·ï¼Œå‡å°‘å…¬ä¼—å¯¹è½¦è¾†çš„ä¾èµ–ã€‚\\n3. å¢åŠ å¯¹ç©ºæ°”æ±¡æŸ“çš„å½±å“çš„è®¤è¯†ï¼Œé¼“åŠ±å¸‚æ°‘å‡å°‘æ±¡æŸ“ç‰©çš„ç”Ÿæˆã€‚\\n4. æŠ•èµ„äºå¯å†ç”Ÿèƒ½æºçš„ç ”ç©¶å’Œå¼€å‘ï¼Œå¦‚å¤ªé˜³èƒ½å’Œé£èƒ½ã€‚\\n5. åœ¨å·¥å‚å’Œå‘ç”µå‚å®‰è£…ç©ºæ°”æ±¡æŸ“æ§åˆ¶è£…ç½®ï¼Œä¾‹å¦‚æ´—æ¶¤å™¨ã€‚\\n6. å¯¹è½¦è¾†å’Œå·¥å‚ä½¿ç”¨æ¸…æ´ç‡ƒæ–™ã€‚\\n7. å®æ–½æ›´å¥½çš„åŸå¸‚è§„åˆ’å’Œæ§åˆ¶æ‹“å±•ã€‚\\n8. æ”¹å–„å†œä¸šæ•ˆç‡ï¼Œå‡å°‘åŒ–è‚¥å’Œæ€è™«å‰‚çš„ä½¿ç”¨ã€‚\\n9. ç§æ¤æ›´å¤šçš„æ ‘æœ¨ä»¥å‡å°‘ç©ºæ°”æ±¡æŸ“ã€‚\\n10. å‡å°‘æœ¨æã€ç…¤ç‚­å’Œç”Ÿç‰©è´¨çš„ç‡ƒçƒ§ã€‚']\r\n",
      "\r\n",
      "ã€æ ·æœ¬ 3ã€‘\r\n",
      "  SRC: ['å¯å†ç”Ÿèƒ½æºçš„å­˜åœ¨å¯¹ç¯å¢ƒæœ‰ä»€ä¹ˆå½±å“ï¼Ÿ']\r\n",
      "  TGT: ['å¯å†ç”Ÿèƒ½æºçš„å­˜åœ¨å¯ä»¥å¸®åŠ©å‡å°‘ç©ºæ°”æ±¡æŸ“å’Œæ¸©å®¤æ°”ä½“æ’æ”¾ï¼Œå› ä¸ºå®ƒä»¬å‡ ä¹ä¸ä¼šæ’æ”¾äºŒæ°§åŒ–ç¢³ã€äºŒæ°§åŒ–ç¡«ç­‰ç©ºæ°”æ±¡æŸ“ç‰©ã€‚æ­¤å¤–ï¼Œä½¿ç”¨å¯å†ç”Ÿèƒ½æºå¯ä»¥ä¿ƒè¿›èƒ½æºæ•ˆç‡çš„è¿›ä¸€æ­¥æé«˜å’Œèƒ½æºåˆ©ç”¨çš„æ”¹å–„ã€‚å¯å†ç”Ÿèƒ½æºä¹Ÿå¯ä»¥å¸®åŠ©å‡å°‘å¯¹åŒ–çŸ³ç‡ƒæ–™çš„ä¾èµ–ï¼Œè¿™ä¸ä»…å¯ä»¥å‡å°‘æ’æ”¾ï¼Œè€Œä¸”è¿˜å¯ä»¥å¸®åŠ©å‡å°‘å…¨çƒæ°”å€™å˜åŒ–çš„é£é™©ã€‚æœ€åï¼Œå¯å†ç”Ÿèƒ½æºå¯ä»¥å¸®åŠ©ä¿æŠ¤è‡ªç„¶èµ„æºï¼Œå‡å°‘ä¸ºäº†èƒ½æºç”Ÿäº§è€Œå¼€å‘æ›´å¤šåœŸåœ°å’Œèµ„æºçš„éœ€è¦ã€‚']\r\n",
      "\r\n",
      "ã€æ ·æœ¬ 4ã€‘\r\n",
      "  SRC: ['è§£é‡Šç¥ç»ç½‘ç»œå¦‚ä½•å­¦ä¹ ã€‚']\r\n",
      "  TGT: ['ç¥ç»ç½‘ç»œæ˜¯ä¸€ç§æœºå™¨å­¦ä¹ ç®—æ³•ï¼Œå®ƒä½¿ç”¨è¿æ¥çš„èŠ‚ç‚¹é›†åˆæ¥è¿‘ä¼¼å¯ä»¥å°†è¾“å…¥å˜é‡æ˜ å°„åˆ°è¾“å‡ºçš„å‡½æ•°ã€‚ä¸ºäº†å­¦ä¹ ç¥ç»ç½‘ç»œçš„å‚æ•°ï¼Œè®¡ç®—æœºéœ€è¦è°ƒæ•´èŠ‚ç‚¹ä¹‹é—´è¿æ¥çš„æƒé‡ï¼Œä»¥ä¾¿ç½‘ç»œä¸ºç»™å®šè¾“å…¥äº§ç”Ÿæ­£ç¡®çš„è¾“å‡ºã€‚è¿™ä¸ªè°ƒæ•´è¿‡ç¨‹ç§°ä¸ºå­¦ä¹ ï¼Œé€šè¿‡æ¯”è¾ƒç½‘ç»œäº§ç”Ÿçš„è¾“å‡ºå’ŒæœŸæœ›çš„ç»“æœï¼Œç„¶åä½¿ç”¨ä¼˜åŒ–ç®—æ³•æ¥è°ƒæ•´æƒé‡ï¼Œä½¿å¾—ç½‘ç»œè¾“å‡ºé€¼è¿‘æœŸæœ›çš„ç»“æœã€‚è¿™ä¸ªè¿‡ç¨‹åœ¨å¤šä¸ªè¾“å…¥å’ŒæœŸæœ›çš„è¾“å‡ºä¸Šé‡å¤è¿›è¡Œå¤šæ¬¡è¿­ä»£ã€‚æœ€ç»ˆï¼Œè¿æ¥èŠ‚ç‚¹ä¹‹é—´çš„æƒé‡å°†è¢«è°ƒæ•´ï¼Œä»¥ä¾¿ç¥ç»ç½‘ç»œçš„è¾“å‡ºä¸æœŸæœ›çš„ç»“æœç›¸åŒ¹é…ï¼Œå­¦ä¹ è¿‡ç¨‹å°†å®Œæˆã€‚']\r\n",
      "\r\n",
      "ã€æ ·æœ¬ 5ã€‘\r\n",
      "  SRC: ['ç»™å‡ºä¸€ä¸ªæœºå™¨å­¦ä¹ ç®—æ³•çš„ä¾‹å­ï¼Œå¹¶è§£é‡Šå®ƒæ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚']\r\n",
      "  TGT: ['ä¸€ä¸ªæµè¡Œçš„æœºå™¨å­¦ä¹ ç®—æ³•çš„ä¾‹å­æ˜¯æ”¯æŒå‘é‡æœºï¼ˆSVMï¼‰ã€‚å®ƒæ˜¯ä¸€ä¸ªç”¨äºåˆ†ç±»å’Œå›å½’ä»»åŠ¡çš„ç›‘ç£å­¦ä¹ ç®—æ³•ã€‚å®ƒé€šè¿‡åœ¨nç»´ç©ºé—´ä¸­ç»˜åˆ¶æ•°æ®ç‚¹ï¼Œç”±ç©ºé—´ä¸­çš„å†³ç­–è¾¹ç•Œæˆ–è¶…å¹³é¢è¿›è¡Œåˆ†ç¦»ã€‚è¯¥ç®—æ³•ä½¿ç”¨æœ€å¤§è¾¹è·ï¼Œè¿™äº›è¾¹è·å°½å¯èƒ½è¿œç¦»ä¸¤ç±»æ•°æ®ç‚¹ã€‚è¿™äº›è¾¹è·æœ‰åŠ©äºåˆ›å»ºæœ€ä¼˜çš„å†³ç­–è¶…å¹³é¢ã€‚ç„¶åï¼Œç®—æ³•é€šè¿‡è€ƒè™‘åˆ†ç±»ä»»åŠ¡ä¸­å‘ç”Ÿçš„é”™è¯¯æ¥è°ƒæ•´å†³ç­–è¶…å¹³é¢ï¼Œå¹¶ç›¸åº”åœ°ä¿®æ”¹è¶…å¹³é¢ã€‚\\n\\næœ€ç»ˆï¼Œæ”¯æŒå‘é‡æœºå¯ä»¥ä½¿ç”¨æœ€ä¼˜çš„å†³ç­–è¶…å¹³é¢æ‰§è¡Œåˆ†ç±»ä»»åŠ¡ï¼Œé¢„æµ‹æ•°æ®ç‚¹çš„ç±»åˆ«ã€‚']\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "import json\r\n",
    "\r\n",
    "# å®šä¹‰ç¤ºä¾‹æ•°æ®è·¯å¾„\r\n",
    "sample_data_path = \"./ERNIE-develop/examples/data/sft-train.jsonl\"\r\n",
    "\r\n",
    "# è¯»å–å¹¶æ‰“å°å‰5æ¡æ ·æœ¬\r\n",
    "print(f\"æŸ¥çœ‹ç¤ºä¾‹æ•°æ®: {sample_data_path}\\n---\")\r\n",
    "with open(sample_data_path, 'r', encoding='utf-8') as f:\r\n",
    "    for i, line in enumerate(f):\r\n",
    "        if i >= 5:\r\n",
    "            break\r\n",
    "        data_sample = json.loads(line.strip())\r\n",
    "        print(f\"ã€æ ·æœ¬ {i+1}ã€‘\")\r\n",
    "        print(f\"  SRC: {data_sample['src']}\")\r\n",
    "        print(f\"  TGT: {data_sample['tgt']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 å¦‚ä½•å‡†å¤‡è‡ªå·±çš„ SFT æ•°æ®é›†\n",
    "\n",
    "åœ¨å®é™…åº”ç”¨ä¸­ï¼Œæ‚¨é€šå¸¸éœ€è¦æ ¹æ®è‡ªå·±çš„ç‰¹å®šéœ€æ±‚æ„å»ºæ•°æ®é›†ã€‚ä»¥ä¸‹æ˜¯æ„å»ºè‡ªå®šä¹‰SFTæ•°æ®é›†çš„ä¸€èˆ¬æ­¥éª¤ï¼š\n",
    "\n",
    "1.  **ç¡®å®šç›®æ ‡ä»»åŠ¡**: æ˜ç¡®æ‚¨å¸Œæœ›æ¨¡å‹å…·å¤‡å“ªäº›èƒ½åŠ›ã€‚æ˜¯ç”¨äºå‚ç›´é¢†åŸŸçš„æ™ºèƒ½å®¢æœï¼Œè¿˜æ˜¯ç”¨äºç”Ÿæˆç‰¹å®šé£æ ¼çš„è¥é”€æ–‡æ¡ˆï¼Ÿ\n",
    "2.  **æ”¶é›†æˆ–ç”ŸæˆåŸå§‹æ•°æ®**: \n",
    "    *   **æ”¶é›†**: ä»ç°æœ‰çš„æ–‡æ¡£ã€å·¥å•ã€FAQã€æˆ–ç”¨æˆ·æ—¥å¿—ä¸­æå–â€œé—®é¢˜-ç­”æ¡ˆâ€å¯¹ã€‚\n",
    "    *   **äººå·¥æ ‡æ³¨**: è˜è¯·é¢†åŸŸä¸“å®¶æˆ–æ ‡æ³¨äººå‘˜ï¼Œæ ¹æ®ä»»åŠ¡éœ€æ±‚ç¼–å†™é«˜è´¨é‡çš„æŒ‡ä»¤å’Œå›ç­”ã€‚\n",
    "    *   **æ¨¡å‹ç”Ÿæˆ**: ä½¿ç”¨æ›´å¼ºå¤§çš„æ¨¡å‹ï¼ˆå¦‚GPT-4ï¼‰ç”Ÿæˆåˆæ­¥çš„æŒ‡ä»¤å’Œå›ç­”ï¼Œç„¶åç”±äººå·¥è¿›è¡Œç­›é€‰å’Œç²¾ç‚¼ã€‚è¿™æ˜¯ç›®å‰æ„å»ºå¤§è§„æ¨¡SFTæ•°æ®é›†çš„ä¸»æµæ–¹æ³•ä¹‹ä¸€ã€‚\n",
    "3.  **æ¸…æ´—å’Œæ ¼å¼åŒ–**: \n",
    "    *   å»é™¤ä½è´¨é‡ã€é‡å¤æˆ–ä¸ç›¸å…³çš„æ•°æ®ã€‚\n",
    "    *   è¿›è¡Œæ•°æ®å¢å¼ºï¼Œä¾‹å¦‚ï¼Œå¯¹åŒä¸€ä¸ªæŒ‡ä»¤ï¼Œå¯ä»¥æœ‰å¤šç§ä¸åŒçš„é—®æ³•ã€‚\n",
    "    *   å°†æ•°æ®æ•´ç†æˆ ERNIEkit æ‰€éœ€çš„ `jsonl` æ ¼å¼ï¼Œå³æ¯è¡Œä¸€ä¸ªåŒ…å« `src` å’Œ `tgt` é”®çš„JSONå¯¹è±¡ã€‚\n",
    "4.  **åˆ’åˆ†æ•°æ®é›†**: å°†æ•°æ®é›†åˆ’åˆ†ä¸ºè®­ç»ƒé›† (train) å’Œè¯„ä¼°é›† (eval/dev)ã€‚è¯„ä¼°é›†ç”¨äºåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ç›‘æ§æ¨¡å‹æ€§èƒ½ï¼Œé¿å…è¿‡æ‹Ÿåˆã€‚é€šå¸¸æ¯”ä¾‹ä¸º 95%:5% æˆ– 98%:2%ã€‚\n",
    "\n",
    "å‡†å¤‡å¥½é«˜è´¨é‡çš„æ•°æ®æ˜¯SFTæˆåŠŸçš„åŸºçŸ³ã€‚ç°åœ¨æˆ‘ä»¬å·²ç»äº†è§£äº†æ•°æ®çš„å‡†å¤‡å·¥ä½œï¼Œä¸‹ä¸€æ­¥å°†æ·±å…¥å‰–æ ERNIEkit çš„SFTé…ç½®æ–‡ä»¶ï¼Œäº†è§£å¦‚ä½•é€šè¿‡å®ƒæ¥æŒæ§æ•´ä¸ªå¾®è°ƒè¿‡ç¨‹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. SFT é…ç½®è§£æ (`run_sft_8k.yaml`)\n",
    "\n",
    "ERNIEkit çš„å¼ºå¤§ä¹‹å¤„åœ¨äºå…¶çµæ´»æ€§å’Œå¯é…ç½®æ€§ã€‚æ‰€æœ‰çš„è®­ç»ƒå‚æ•°éƒ½é›†ä¸­åœ¨ `yaml` é…ç½®æ–‡ä»¶ä¸­ï¼Œé€šè¿‡ä¿®æ”¹è¿™ä¸ªæ–‡ä»¶ï¼Œæˆ‘ä»¬å¯ä»¥ç²¾ç¡®åœ°æ§åˆ¶SFTçš„æ¯ä¸€ä¸ªç¯èŠ‚ã€‚è®©æˆ‘ä»¬ä»¥ `ERNIE-develop/examples/configs/ERNIE-4.5-0.3B/sft/run_sft_8k.yaml` ä¸ºä¾‹ï¼Œé€ä¸€è§£æå…¶ä¸­çš„å…³é”®é…ç½®é¡¹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 æ•°æ®é…ç½® (Data)\n",
    "\n",
    "è¿™éƒ¨åˆ†å®šä¹‰äº†è®­ç»ƒå’Œè¯„ä¼°æ‰€ä½¿ç”¨çš„æ•°æ®é›†ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "### data\n",
    "train_dataset_type: \"erniekit\"\n",
    "eval_dataset_type: \"erniekit\"\n",
    "train_dataset_path: \"./examples/data/sft-train.jsonl\"\n",
    "train_dataset_prob: \"1.0\"\n",
    "eval_dataset_path: \"./examples/data/sft-eval.jsonl\"\n",
    "eval_dataset_prob: \"1.0\"\n",
    "max_seq_len: 8192\n",
    "num_samples_each_epoch: 6000000\n",
    "```\n",
    "\n",
    "*   `train_dataset_type`, `eval_dataset_type`: æ•°æ®é›†æ ¼å¼ç±»å‹ï¼Œè¿™é‡Œæ˜¯ `erniekit`ï¼Œè¡¨ç¤ºä½¿ç”¨æˆ‘ä»¬ä¹‹å‰è®¨è®ºçš„ `{\"src\": ..., \"tgt\": ...}` æ ¼å¼ã€‚\n",
    "*   `train_dataset_path`, `eval_dataset_path`: è®­ç»ƒå’Œè¯„ä¼°æ•°æ®é›†çš„è·¯å¾„ã€‚**è¿™é‡Œæ‚¨éœ€è¦ä¿®æ”¹ä¸ºæ‚¨è‡ªå·±çš„æ•°æ®è·¯å¾„ã€‚**\n",
    "*   `train_dataset_prob`, `eval_dataset_prob`: æ•°æ®é›†é‡‡æ ·æ¦‚ç‡ã€‚å½“æœ‰å¤šä¸ªæ•°æ®é›†æ—¶ï¼Œå¯ä»¥è®¾ç½®ä¸åŒæ¦‚ç‡è¿›è¡Œæ··åˆè®­ç»ƒã€‚\n",
    "*   `max_seq_len`: æ¨¡å‹å¤„ç†çš„æœ€å¤§åºåˆ—é•¿åº¦ã€‚`8192` (8K) æ˜¯ ERNIE-4.5 çš„ä¸€ä¸ªå¸¸ç”¨è®¾ç½®ï¼Œå¯ä»¥å¤„ç†éå¸¸é•¿çš„ä¸Šä¸‹æ–‡ã€‚å¦‚æœæ‚¨çš„GPUæ˜¾å­˜æœ‰é™ï¼Œå¯ä»¥é€‚å½“å‡å°æ­¤å€¼ï¼Œä½†è¿™å¯èƒ½ä¼šå½±å“æ¨¡å‹å¤„ç†é•¿æ–‡æœ¬çš„èƒ½åŠ›ã€‚\n",
    "*   `num_samples_each_epoch`: æ¯ä¸ªepochä¸­åŒ…å«çš„æ ·æœ¬æ•°ã€‚è¿™ä¸ªå€¼é€šå¸¸è®¾ç½®å¾—æ¯”è¾ƒå¤§ï¼Œä»¥ç¡®ä¿æ¨¡å‹åœ¨æ¯ä¸ªepochä¸­éƒ½èƒ½çœ‹åˆ°è¶³å¤Ÿå¤šçš„æ•°æ®ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 æ¨¡å‹é…ç½® (Model)\n",
    "\n",
    "è¿™éƒ¨åˆ†å®šä¹‰äº†è¦å¾®è°ƒçš„åŸºç¡€æ¨¡å‹åŠå…¶ç›¸å…³è®¾ç½®ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "### model\n",
    "model_name_or_path: baidu/ERNIE-4.5-0.3B-Paddle\n",
    "fine_tuning: Full\n",
    "fuse_rope: True\n",
    "use_sparse_head_and_loss_fn: True\n",
    "```\n",
    "\n",
    "*   `model_name_or_path`: **æ ¸å¿ƒå‚æ•°**ã€‚æŒ‡å®šåŸºç¡€æ¨¡å‹çš„è·¯å¾„ã€‚è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ä¹‹å‰ä¸‹è½½çš„ `baidu/ERNIE-4.5-0.3B-Paddle`ã€‚\n",
    "*   `fine_tuning`: å¾®è°ƒæ–¹å¼ã€‚`Full` è¡¨ç¤ºå…¨å‚æ•°å¾®è°ƒï¼Œå³æ›´æ–°æ¨¡å‹çš„æ‰€æœ‰æƒé‡ã€‚è¿™æ˜¯æœ€å½»åº•ä½†èµ„æºæ¶ˆè€—ä¹Ÿæœ€å¤§çš„æ–¹å¼ã€‚å…¶ä»–é€‰é¡¹å¦‚ `lora` å°†åœ¨åç»­ä»‹ç»ã€‚\n",
    "*   `fuse_rope`: æ˜¯å¦ä½¿ç”¨ä¼˜åŒ–çš„ Rotary Position Embeddingã€‚`True` å¯ä»¥æå‡è®¡ç®—æ•ˆç‡ã€‚\n",
    "*   `use_sparse_head_and_loss_fn`: æ˜¯å¦ä½¿ç”¨ç¨€ç–çš„å¤´éƒ¨å’ŒæŸå¤±å‡½æ•°ã€‚è¿™æ˜¯é’ˆå¯¹ç‰¹å®šæ¨¡å‹ç»“æ„çš„ä¼˜åŒ–ï¼Œä¿æŒé»˜è®¤å³å¯ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 å¾®è°ƒæ ¸å¿ƒé…ç½® (Finetuning)\n",
    "\n",
    "è¿™æ˜¯æ§åˆ¶æ•´ä¸ªè®­ç»ƒæµç¨‹çš„æ ¸å¿ƒéƒ¨åˆ†ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "### finetuning\n",
    "# base\n",
    "stage: SFT\n",
    "seed: 23\n",
    "do_train: True\n",
    "do_eval: True\n",
    "distributed_dataloader: False\n",
    "dataloader_num_workers: 1\n",
    "batch_size: 1\n",
    "num_train_epochs: 1\n",
    "max_steps: 100\n",
    "max_evaluate_steps: 10000\n",
    "eval_steps: 10000\n",
    "evaluation_strategy: steps\n",
    "save_steps: 10000000\n",
    "save_total_limit: 5\n",
    "save_strategy: steps\n",
    "logging_steps: 1\n",
    "release_grads: True\n",
    "gradient_accumulation_steps: 8\n",
    "logging_dir: ./vdl_log\n",
    "output_dir: ./output\n",
    "disable_tqdm: True\n",
    "```\n",
    "\n",
    "*   `stage`: è®­ç»ƒé˜¶æ®µï¼Œè¿™é‡Œæ˜¯ `SFT`ã€‚\n",
    "*   `seed`: éšæœºç§å­ï¼Œç”¨äºä¿è¯å®éªŒçš„å¯å¤ç°æ€§ã€‚\n",
    "*   `do_train`, `do_eval`: æ˜¯å¦æ‰§è¡Œè®­ç»ƒå’Œè¯„ä¼°ã€‚\n",
    "*   `batch_size`: **é‡è¦**ã€‚æ¯ä¸ªè®¾å¤‡ä¸Šçš„æ‰¹å¤„ç†å¤§å°ã€‚ç”±äºå¤§æ¨¡å‹éå¸¸æ¶ˆè€—æ˜¾å­˜ï¼Œ`1` æ˜¯ä¸€ä¸ªå¸¸è§çš„èµ·å§‹å€¼ã€‚\n",
    "*   `gradient_accumulation_steps`: **é‡è¦**ã€‚æ¢¯åº¦ç´¯ç§¯æ­¥æ•°ã€‚è¿™æ˜¯ä¸€ç§â€œè™šæ‹Ÿâ€æ‰©å¤§batch sizeçš„æŠ€å·§ã€‚å®é™…çš„ `batch_size` æ˜¯ `batch_size` * `gradient_accumulation_steps` * `num_gpus`ã€‚åœ¨è¿™é‡Œï¼Œç­‰æ•ˆçš„batch sizeæ˜¯ `1 * 8 = 8`ã€‚å¢åŠ æ­¤å€¼å¯ä»¥æ¨¡æ‹Ÿæ›´å¤§çš„batch sizeï¼Œæœ‰åŠ©äºç¨³å®šè®­ç»ƒï¼Œä½†ä¼šå‡æ…¢è®­ç»ƒé€Ÿåº¦ã€‚\n",
    "*   `num_train_epochs`: è®­ç»ƒçš„æ€»è½®æ•°ã€‚å¯¹äºSFTï¼Œé€šå¸¸ `1` åˆ° `3` ä¸ªepochå°±è¶³å¤Ÿäº†ã€‚\n",
    "*   `max_steps`: æœ€å¤§è®­ç»ƒæ­¥æ•°ã€‚å¦‚æœè®¾ç½®äº†æ­¤å€¼ï¼Œå°†è¦†ç›– `num_train_epochs`ã€‚å¯¹äºå¿«é€Ÿå®éªŒï¼Œå¯ä»¥è®¾ç½®ä¸ºä¸€ä¸ªè¾ƒå°çš„å€¼ï¼ˆå¦‚ `100`ï¼‰ã€‚\n",
    "*   `evaluation_strategy`, `eval_steps`: è¯„ä¼°ç­–ç•¥ã€‚`steps` è¡¨ç¤ºæ¯éš” `eval_steps` æ­¥è¿›è¡Œä¸€æ¬¡è¯„ä¼°ã€‚\n",
    "*   `save_strategy`, `save_steps`: ä¿å­˜ç­–ç•¥ã€‚`steps` è¡¨ç¤ºæ¯éš” `save_steps` æ­¥ä¿å­˜ä¸€ä¸ªcheckpointã€‚\n",
    "*   `logging_steps`: æ¯éš”å¤šå°‘æ­¥æ‰“å°ä¸€æ¬¡æ—¥å¿—ã€‚\n",
    "*   `output_dir`: è®­ç»ƒäº§ç‰©ï¼ˆå¦‚æ¨¡å‹checkpointï¼‰çš„è¾“å‡ºç›®å½•ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 è®­ç»ƒä¸ä¼˜åŒ–å™¨é…ç½® (Train & Optimizer)\n",
    "\n",
    "è¿™éƒ¨åˆ†æ§åˆ¶å­¦ä¹ ç‡ã€ä¼˜åŒ–å™¨ç­‰è¶…å‚æ•°ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "# train\n",
    "warmup_steps: 20\n",
    "learning_rate: 1.0e-5\n",
    "lr_scheduler_type: cosine\n",
    "min_lr: 1.0e-6\n",
    "\n",
    "# optimizer\n",
    "weight_decay: 0.1\n",
    "adam_epsilon: 1.0e-8\n",
    "adam_beta1: 0.9\n",
    "adam_beta2: 0.95\n",
    "offload_optim: True\n",
    "```\n",
    "\n",
    "*   `learning_rate`: **æ ¸å¿ƒè¶…å‚æ•°**ã€‚å­¦ä¹ ç‡çš„å¤§å°ç›´æ¥å½±å“æ¨¡å‹çš„æ”¶æ•›é€Ÿåº¦å’Œæœ€ç»ˆæ•ˆæœã€‚`1.0e-5` æ˜¯ä¸€ä¸ªé€‚ç”¨äºå…¨å‚æ•°å¾®è°ƒçš„å¸¸ç”¨å€¼ã€‚å¯¹äºLoRAç­‰PEFTæ–¹æ³•ï¼Œå¯èƒ½éœ€è¦æ›´å¤§çš„å­¦ä¹ ç‡ã€‚\n",
    "*   `lr_scheduler_type`: å­¦ä¹ ç‡è°ƒåº¦ç­–ç•¥ã€‚`cosine` è¡¨ç¤ºä½¿ç”¨ä½™å¼¦é€€ç«ç­–ç•¥ï¼Œæ˜¯ä¸€ç§éå¸¸æœ‰æ•ˆä¸”å¸¸ç”¨çš„ç­–ç•¥ã€‚\n",
    "*   `warmup_steps`: é¢„çƒ­æ­¥æ•°ã€‚åœ¨è®­ç»ƒåˆæœŸï¼Œå­¦ä¹ ç‡ä¼šä»ä¸€ä¸ªå¾ˆå°çš„å€¼çº¿æ€§å¢é•¿åˆ°è®¾å®šçš„ `learning_rate`ï¼Œè¿™æœ‰åŠ©äºè®­ç»ƒçš„ç¨³å®šã€‚\n",
    "*   `weight_decay`: æƒé‡è¡°å‡ï¼Œä¸€ç§é˜²æ­¢è¿‡æ‹Ÿåˆçš„æ­£åˆ™åŒ–æŠ€æœ¯ã€‚\n",
    "*   `offload_optim`: æ˜¯å¦å°†ä¼˜åŒ–å™¨çŠ¶æ€å¸è½½åˆ°CPUå†…å­˜ã€‚è¿™æ˜¯ä¸€ä¸ªèŠ‚çœæ˜¾å­˜çš„æŠ€å·§ï¼Œä½†ä¼šç•¥å¾®é™ä½è®­ç»ƒé€Ÿåº¦ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 æ€§èƒ½ä¸å¹¶è¡Œé…ç½® (Performance)\n",
    "\n",
    "è¿™éƒ¨åˆ†ç”¨äºé…ç½®åˆ†å¸ƒå¼è®­ç»ƒå’Œæ··åˆç²¾åº¦è®­ç»ƒï¼Œä»¥æå‡æ•ˆç‡å’ŒèŠ‚çœèµ„æºã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "# performance\n",
    "tensor_parallel_degree: 1\n",
    "pipeline_parallel_degree: 1\n",
    "sharding_parallel_degree: 1\n",
    "sharding: stage1\n",
    "sequence_parallel: True\n",
    "recompute: False\n",
    "compute_type: bf16\n",
    "fp16_opt_level: O2\n",
    "```\n",
    "\n",
    "*   `tensor_parallel_degree`, `pipeline_parallel_degree`, `sharding_parallel_degree`: åˆ†å¸ƒå¼è®­ç»ƒçš„å¹¶è¡Œåº¦ã€‚å¯¹äºå•å¡è®­ç»ƒï¼Œè¿™äº›éƒ½åº”ä¿æŒä¸º `1`ã€‚\n",
    "*   `sharding`: ZeROä¼˜åŒ–ç­–ç•¥ã€‚`stage1` å¯ä»¥åœ¨å¤šå¡è®­ç»ƒæ—¶æ˜¾è‘—èŠ‚çœæ˜¾å­˜ã€‚\n",
    "*   `sequence_parallel`: åºåˆ—å¹¶è¡Œï¼Œä¸€ç§é’ˆå¯¹é•¿åºåˆ—çš„æ˜¾å­˜ä¼˜åŒ–æŠ€æœ¯ã€‚\n",
    "*   `recompute` (Gradient Checkpointing): **é‡è¦**ã€‚ä¸€ç§ç”¨è®¡ç®—æ¢æ˜¾å­˜çš„æŠ€æœ¯ã€‚è®¾ç½®ä¸º `True` ä¼šåœ¨åå‘ä¼ æ’­æ—¶é‡æ–°è®¡ç®—å‰å‘ä¼ æ’­çš„ä¸­é—´ç»“æœï¼Œè€Œä¸æ˜¯å­˜å‚¨å®ƒä»¬ã€‚è¿™èƒ½å¤§å¹…é™ä½æ˜¾å­˜æ¶ˆè€—ï¼Œä½†ä¼šå¢åŠ çº¦20-30%çš„è®­ç»ƒæ—¶é—´ã€‚**å½“æ˜¾å­˜ä¸è¶³æ—¶ï¼Œå¼€å¯æ­¤é€‰é¡¹æ˜¯é¦–é€‰**ã€‚\n",
    "*   `compute_type`: è®¡ç®—ç²¾åº¦ã€‚`bf16` (BFloat16) æ˜¯ä¸€ç§ä¸“ä¸ºæ·±åº¦å­¦ä¹ è®¾è®¡çš„åŠç²¾åº¦æµ®ç‚¹æ ¼å¼ï¼Œå®ƒèƒ½å¤§å¹…é™ä½æ˜¾å­˜å ç”¨å¹¶åŠ é€Ÿè®¡ç®—ï¼ŒåŒæ—¶ä¿æŒè¾ƒå¥½çš„æ•°å€¼ç¨³å®šæ€§ã€‚æ¨èåœ¨æ”¯æŒçš„ç¡¬ä»¶ä¸Šï¼ˆå¦‚NVIDIA A100/H100, RTX 30/40ç³»åˆ—ï¼‰ä½¿ç”¨ã€‚\n",
    "*   `fp16_opt_level`: æ··åˆç²¾åº¦è®­ç»ƒç­‰çº§ã€‚`O2` æ˜¯ä¸€ä¸ªå¸¸ç”¨çš„è®¾ç½®ï¼Œå¯ä»¥ä¸ `bf16` é…åˆä½¿ç”¨ã€‚\n",
    "\n",
    "ç†è§£äº†è¿™äº›é…ç½®é¡¹ï¼Œæ‚¨å°±æ‹¥æœ‰äº†è‡ªç”±å®šåˆ¶SFTè¿‡ç¨‹çš„èƒ½åŠ›ã€‚åœ¨ä¸‹ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†æŠŠæ‰€æœ‰çŸ¥è¯†æ•´åˆèµ·æ¥ï¼Œæ­£å¼å¯åŠ¨SFTè®­ç»ƒä»»åŠ¡ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. å¯åŠ¨ SFT è®­ç»ƒ\n",
    "\n",
    "ç†è®ºå’Œé…ç½®éƒ½å·²å‡†å¤‡å°±ç»ªï¼Œç°åœ¨æ˜¯æ—¶å€™äº²æ‰‹å¯åŠ¨SFTè®­ç»ƒï¼Œè§è¯æ¨¡å‹èƒ½åŠ›èœ•å˜çš„è¿‡ç¨‹äº†ã€‚ERNIEkit é€šè¿‡ä¸€ä¸ªç®€å•çš„å‘½ä»¤å³å¯å¯åŠ¨æ•´ä¸ªè®­ç»ƒæµç¨‹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 å¯åŠ¨è®­ç»ƒå‘½ä»¤\n",
    "\n",
    "æˆ‘ä»¬å°†åœ¨ `ERNIE-develop` ç›®å½•ä¸‹ï¼Œä½¿ç”¨ `train.py` è„šæœ¬ï¼Œå¹¶æŒ‡å®šæˆ‘ä»¬çš„é…ç½®æ–‡ä»¶ `run_sft_8k.yaml`ã€‚\n",
    "\n",
    "**åœ¨ç»ˆç«¯æˆ–å‘½ä»¤è¡Œä¸­æ‰§è¡Œï¼š**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T11:04:20.529339Z",
     "iopub.status.busy": "2025-07-17T11:04:20.528900Z",
     "iopub.status.idle": "2025-07-17T11:04:20.533491Z",
     "shell.execute_reply": "2025-07-17T11:04:20.533022Z",
     "shell.execute_reply.started": "2025-07-17T11:04:20.529305Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/ERNIE-develop\r\n"
     ]
    }
   ],
   "source": [
    "# é¦–å…ˆï¼Œè¯·ç¡®ä¿æ‚¨ä½äº ERNIE-develop ç›®å½•ä¸‹\r\n",
    "%cd ./ERNIE-develop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T11:05:42.879359Z",
     "iopub.status.busy": "2025-07-17T11:05:42.879042Z",
     "iopub.status.idle": "2025-07-17T11:08:37.765662Z",
     "shell.execute_reply": "2025-07-17T11:08:37.764834Z",
     "shell.execute_reply.started": "2025-07-17T11:05:42.879339Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/utils/cpp_extension/extension_utils.py:715: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\r\n",
      "  warnings.warn(warning_message)\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/utils/cpp_extension/extension_utils.py:715: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\r\n",
      "  warnings.warn(warning_message)\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,655 -----------  Configuration  ----------------------\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 auto_cluster_config: 0\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 auto_parallel_config: None\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 auto_tuner_json: None\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 devices: 0\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 elastic_level: -1\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 elastic_timeout: 30\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 enable_gpu_log: True\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 gloo_port: 6767\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 host: None\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 ips: None\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 job_id: default\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 legacy: False\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 log_dir: erniekit_dist_log\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 log_level: INFO\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 log_overwrite: False\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 master: 127.0.0.1:8080\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 max_restart: 3\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 nnodes: 1\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 nproc_per_node: None\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 rank: -1\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 run_mode: collective\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 server_num: None\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 servers: \r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 sort_ip: False\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 start_port: 6070\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 trainer_num: None\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 trainers: \r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 training_script: /home/aistudio/ERNIE-develop/erniekit/launcher.py\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 training_script_args: ['train', 'examples/configs/ERNIE-4.5-0.3B/sft/run_sft_8k.yaml']\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 with_gloo: 1\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 --------------------------------------------------\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 Job: default, mode collective, replicas 1[1:1], elastic False\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,658 Run Pod: lpwbts, replicas 1, status ready\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,671 Watching Pod: lpwbts, replicas 1, status running\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/utils/cpp_extension/extension_utils.py:715: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\r\n",
      "  warnings.warn(warning_message)\r\n",
      "\u001b[32m[2025-07-17 19:05:50,756] [    INFO]\u001b[0m - user has defined resume_from_checkpoint: None\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:50,756] [    INFO]\u001b[0m - The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:50,789] [    INFO]\u001b[0m - Tensor_parallel_degree = 1. Set sequence_parallel to False.\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,789] [   DEBUG]\u001b[0m - ============================================================\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,789] [   DEBUG]\u001b[0m -      Model Configuration Arguments      \u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,789] [   DEBUG]\u001b[0m - paddle commit id              : cdcd76a93d1dfe767dde768198e1d7c7488b93f6\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,789] [   DEBUG]\u001b[0m - paddleformers commit id       : 053a5a5e2a72cd2d3b997cbcff81b14af9fe4d47\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,789] [   DEBUG]\u001b[0m - add_tail_layers               : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,789] [   DEBUG]\u001b[0m - continue_training             : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,789] [   DEBUG]\u001b[0m - fine_tuning                   : Full\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,789] [   DEBUG]\u001b[0m - fuse_gate_detach_matmul       : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,789] [   DEBUG]\u001b[0m - fuse_linear                   : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,789] [   DEBUG]\u001b[0m - fuse_rms_norm                 : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,789] [   DEBUG]\u001b[0m - fuse_rope                     : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,789] [   DEBUG]\u001b[0m - fuse_softmax_mask             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - fuse_swiglu                   : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - lora                          : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - lora_alpha                    : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - lora_path                     : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - lora_plus_scale               : 1.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - lora_rank                     : 8\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - model_name_or_path            : ../data/models/30654/ERNIE-4.5-0.3B-Base-Paddle\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - moe_aux_loss_lambda           : 1e-05\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - moe_group                     : dummy\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - moe_group_experts             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - moe_multimodal_dispatch_use_allgather: v2-alltoall-unpad\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - moe_orthogonal_loss_lambda    : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - moe_use_aux_free              : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - moe_use_hard_gate             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - moe_z_loss_lambda             : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - no_recompute_layers           : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - offload_recompute_inputs      : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - pp_seg_method                 : layer:Ernie4_5_DecoderLayer|EmptyLayer\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - recompute_granularity         : full\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - recompute_use_reentrant       : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - rslora                        : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - rslora_plus                   : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - stage                         : SFT\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - tensor_parallel_output        : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - use_attn_mask_start_row_indices: True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - use_flash_attention           : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - use_fused_head_and_loss_fn    : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - use_recompute_moe             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - use_sparse_flash_attn         : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - use_sparse_head_and_loss_fn   : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - virtual_pp_degree             : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - \u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - ============================================================\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m -       Data Configuration Arguments      \u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - paddle commit id              : cdcd76a93d1dfe767dde768198e1d7c7488b93f6\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - paddleformers commit id       : 053a5a5e2a72cd2d3b997cbcff81b14af9fe4d47\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - buffer_size                   : 500\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - dataset_type                  : iterable\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - eval_dataset_path             : ./examples/data/sft-eval.jsonl\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - eval_dataset_prob             : 1.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - eval_dataset_type             : erniekit\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - greedy_intokens               : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - in_tokens_batching            : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - mask_out_eos_token            : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - max_prompt_len                : 2048\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - max_seq_len                   : 8192\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,792] [   DEBUG]\u001b[0m - num_comparisons               : 6\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,792] [   DEBUG]\u001b[0m - num_samples_each_epoch        : 6000000\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,792] [   DEBUG]\u001b[0m - offline_dataset_path          : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,792] [   DEBUG]\u001b[0m - random_shuffle                : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,792] [   DEBUG]\u001b[0m - train_dataset_path            : ./examples/data/sft-train.jsonl\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,792] [   DEBUG]\u001b[0m - train_dataset_prob            : 1.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,792] [   DEBUG]\u001b[0m - train_dataset_type            : erniekit\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,792] [   DEBUG]\u001b[0m - use_cls                       : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,792] [   DEBUG]\u001b[0m - \u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:50,792] [    INFO]\u001b[0m - The global seed is set to 23, local seed is set to 24 and random seed is set to 23.\u001b[0m\r\n",
      "\u001b[33m[2025-07-17 19:05:50,792] [ WARNING]\u001b[0m - Process rank: -1, device: gpu, world_size: 1, distributed training: False, 16-bits training: True\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:50,792] [    INFO]\u001b[0m - Start to load model ...\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:50,961] [    INFO]\u001b[0m - Loading configuration file ../data/models/30654/ERNIE-4.5-0.3B-Base-Paddle/config.json\u001b[0m\r\n",
      "\u001b[33m[2025-07-17 19:05:50,964] [ WARNING]\u001b[0m - You are using a model of type ernie4_5 to instantiate a model of type ernie4_5_moe. This is not supported for all configurations of models and can yield errors.\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:50,966] [    INFO]\u001b[0m - Loading weights file ../data/models/30654/ERNIE-4.5-0.3B-Base-Paddle/model.safetensors\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:52,982] [    INFO]\u001b[0m - Loaded weights file from disk, setting weights to model.\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:52,983] [    INFO]\u001b[0m - change initializer-range from 0.02 to 0.018041293779826325\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:52,983] [    INFO]\u001b[0m - using moe-group: dummy\u001b[0m\r\n",
      "W0717 19:05:52.987658 17491 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.8, Runtime API Version: 12.6\r\n",
      "\u001b[32m[2025-07-17 19:05:53,265] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,271] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,273] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,279] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,281] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,284] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,286] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,288] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,290] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,293] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,295] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,297] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,300] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,302] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,304] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,361] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,364] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,366] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,370] [    INFO]\u001b[0m - output-weight:[103424, 1024] config.tie_word_embeddings=True\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,371] [    INFO]\u001b[0m - Use fusedRMSNorm\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,451] [    INFO]\u001b[0m - All model checkpoint weights were used when initializing Ernie4_5_MoeForCausalLM.\r\n",
      "\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,452] [    INFO]\u001b[0m - All the weights of Ernie4_5_MoeForCausalLM were initialized from the model checkpoint at ../data/models/30654/ERNIE-4.5-0.3B-Base-Paddle.\r\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use Ernie4_5_MoeForCausalLM for predictions without further training.\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,453] [    INFO]\u001b[0m - Loading configuration file ../data/models/30654/ERNIE-4.5-0.3B-Base-Paddle/generation_config.json\u001b[0m\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddleformers/generation/configuration_utils.py:250: UserWarning: using greedy search strategy. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `decode_strategy=\"greedy_search\" ` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\r\n",
      "  warnings.warn(\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddleformers/generation/configuration_utils.py:255: UserWarning: using greedy search strategy. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `decode_strategy=\"greedy_search\" ` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\r\n",
      "  warnings.warn(\r\n",
      "\u001b[32m[2025-07-17 19:05:53,467] [    INFO]\u001b[0m - Loading model successfully !\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:53,468] [   DEBUG]\u001b[0m - Model config: Ernie4_5_MoeConfig {\r\n",
      "  \"add_tail_layers\": false,\r\n",
      "  \"architectures\": [\r\n",
      "    \"Ernie4_5_ForCausalLM\"\r\n",
      "  ],\r\n",
      "  \"attention_probs_dropout_prob\": 0.0,\r\n",
      "  \"bos_token_id\": 1,\r\n",
      "  \"cachekv_quant\": false,\r\n",
      "  \"compression_ratio\": 1.0,\r\n",
      "  \"dpo_config\": null,\r\n",
      "  \"dtype\": \"bfloat16\",\r\n",
      "  \"enable_delay_scale_loss\": true,\r\n",
      "  \"enable_mtp_magic_send\": false,\r\n",
      "  \"eos_token_id\": 2,\r\n",
      "  \"fuse_gate_detach_matmul\": true,\r\n",
      "  \"fuse_linear\": false,\r\n",
      "  \"fuse_ln\": false,\r\n",
      "  \"fuse_rms_norm\": true,\r\n",
      "  \"fuse_rope\": true,\r\n",
      "  \"fuse_softmax_mask\": false,\r\n",
      "  \"fuse_swiglu\": true,\r\n",
      "  \"global_aux_loss\": false,\r\n",
      "  \"head_dim\": 128,\r\n",
      "  \"hidden_act\": \"silu\",\r\n",
      "  \"hidden_dropout_prob\": 0.0,\r\n",
      "  \"hidden_size\": 1024,\r\n",
      "  \"ignored_index\": -100,\r\n",
      "  \"initializer_range\": 0.018041293779826325,\r\n",
      "  \"intermediate_size\": 3072,\r\n",
      "  \"max_position_embeddings\": 131072,\r\n",
      "  \"max_sequence_length\": 8192,\r\n",
      "  \"micro_batch_size\": -1,\r\n",
      "  \"model_type\": \"ernie4_5_moe\",\r\n",
      "  \"moe_all_to_all_dropout\": 0.0,\r\n",
      "  \"moe_aux_loss_lambda\": 1e-05,\r\n",
      "  \"moe_capacity\": [],\r\n",
      "  \"moe_dense_experts_token_type_id\": 3,\r\n",
      "  \"moe_dropout_prob\": 0.0,\r\n",
      "  \"moe_gate\": \"topk\",\r\n",
      "  \"moe_gate_act\": \"softmax\",\r\n",
      "  \"moe_group_experts\": false,\r\n",
      "  \"moe_group_origin\": \"dummy\",\r\n",
      "  \"moe_group_orthogonal_loss\": true,\r\n",
      "  \"moe_intermediate_size\": 0,\r\n",
      "  \"moe_k\": 2,\r\n",
      "  \"moe_layer_end_index\": 17,\r\n",
      "  \"moe_layer_interval\": 2,\r\n",
      "  \"moe_layer_start_index\": 0,\r\n",
      "  \"moe_multimodal_dispatch_use_allgather\": \"v2-alltoall-unpad\",\r\n",
      "  \"moe_norm_gate_logits\": true,\r\n",
      "  \"moe_num_experts\": null,\r\n",
      "  \"moe_num_shared_experts\": 0,\r\n",
      "  \"moe_orthogonal_loss_lambda\": 0.0,\r\n",
      "  \"moe_rank\": 0,\r\n",
      "  \"moe_reverse_token_drop\": false,\r\n",
      "  \"moe_use_aux_free\": false,\r\n",
      "  \"moe_use_hard_gate\": false,\r\n",
      "  \"moe_world_size\": 1,\r\n",
      "  \"moe_z_loss_lambda\": 0.0,\r\n",
      "  \"multi_token_pred_lambda\": 0.3,\r\n",
      "  \"num_acc_steps\": 8,\r\n",
      "  \"num_attention_heads\": 16,\r\n",
      "  \"num_hidden_layers\": 18,\r\n",
      "  \"num_key_value_heads\": 2,\r\n",
      "  \"num_nextn_predict_layers\": 0,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"paddleformers_version\": \"0.1\",\r\n",
      "  \"pp_seg_method\": \"layer:Ernie4_5_DecoderLayer|EmptyLayer\",\r\n",
      "  \"recompute_granularity\": \"full\",\r\n",
      "  \"recompute_use_reentrant\": true,\r\n",
      "  \"refined_recompute\": {},\r\n",
      "  \"rms_norm_eps\": 1e-05,\r\n",
      "  \"rope_theta\": 500000,\r\n",
      "  \"sinkhorn_2gate\": true,\r\n",
      "  \"sinkhorn_temp\": 0.03,\r\n",
      "  \"skip_recompute_ops\": {},\r\n",
      "  \"tensor_parallel_degree\": -1,\r\n",
      "  \"tie_word_embeddings\": true,\r\n",
      "  \"token_balance_loss\": false,\r\n",
      "  \"token_balance_seqlen\": false,\r\n",
      "  \"use_bias\": false,\r\n",
      "  \"use_flash_attention\": true,\r\n",
      "  \"use_fused_head_and_loss_fn\": false,\r\n",
      "  \"use_recompute_lm_head\": false,\r\n",
      "  \"use_recompute_loss_fn\": false,\r\n",
      "  \"use_recompute_moe\": false,\r\n",
      "  \"use_recompute_mtp\": false,\r\n",
      "  \"use_rmsnorm\": true,\r\n",
      "  \"use_sparse_flash_attn\": true,\r\n",
      "  \"use_sparse_head_and_loss_fn\": true,\r\n",
      "  \"use_var_len_flash_attn\": false,\r\n",
      "  \"vocab_size\": 103424,\r\n",
      "  \"weight_share_add_bias\": true\r\n",
      "}\r\n",
      "\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,468] [    INFO]\u001b[0m - [timelog] basemodel loading time: 2.51s (2025-07-17 19:05:53) \u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:54,506] [    INFO]\u001b[0m - Start to create dataset ...\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:54,515] [    INFO]\u001b[0m - ./examples/data/sft-train.jsonl: task prob: 1.0, ori number of examples: 200, target_num_each_epoch: 6000000\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:54,515] [    INFO]\u001b[0m - Creating dataset successfully ...\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:54,516] [    INFO]\u001b[0m - The global seed is set to 23, local seed is set to 24 and random seed is set to 23.\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:54,555] [    INFO]\u001b[0m - max_steps is given, it will override any value given in num_train_epochs\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:54,555] [    INFO]\u001b[0m - Using half precision\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,568] [   DEBUG]\u001b[0m - ============================================================\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,568] [   DEBUG]\u001b[0m -     Training Configuration Arguments    \u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,568] [   DEBUG]\u001b[0m - paddle commit id              : cdcd76a93d1dfe767dde768198e1d7c7488b93f6\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - paddleformers commit id       : 053a5a5e2a72cd2d3b997cbcff81b14af9fe4d47\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - _no_sync_in_gradient_accumulation: True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - actscale_moving_rate          : 0.01\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - adam_beta1                    : 0.9\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - adam_beta2                    : 0.95\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - adam_epsilon                  : 1e-08\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - amp_custom_black_list         : ['reduce_sum', 'softmax_with_cross_entropy', 'c_softmax_with_cross_entropy', 'elementwise_div', 'sin', 'cos']\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - amp_custom_white_list         : ['lookup_table', 'lookup_table_v2', 'flash_attn', 'matmul', 'matmul_v2', 'fused_gemm_epilogue']\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - amp_master_grad               : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - apply_hadamard                : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - apply_online_actscale_step    : 200\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - attention_probs_dropout_prob  : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - auto_parallel_resume_form_hybrid_parallel: False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - batch_size                    : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - beta                          : 0.1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - bf16                          : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - bf16_full_eval                : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - ckpt_quant_stage              : O0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - compute_type                  : bf16\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - context_parallel_degree       : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - count_trained_tokens          : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - current_device                : gpu:0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - data_parallel_config          : \u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - data_parallel_degree          : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - data_parallel_rank            : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - dataloader_drop_last          : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - dataloader_num_workers        : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - dataloader_shuffle            : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - dataset_rank                  : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - dataset_world_size            : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - ddp_find_unused_parameters    : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - decay_steps                   : 100\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - device                        : gpu\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - disable_ckpt_quant            : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - disable_tqdm                  : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - distributed_dataloader        : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - do_eval                       : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - do_export                     : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - do_predict                    : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - do_train                      : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - dpo_benchmark                 : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - dpop_lambda                   : 50\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - dropout_warmup_steps          : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - enable_auto_parallel          : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - enable_zero_cost_checkpoint   : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - eval_accumulation_steps       : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - eval_batch_size               : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - eval_steps                    : 10000\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - evaluation_strategy           : IntervalStrategy.STEPS\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - expert_max_capacity           : 4294967296\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - expert_min_capacity           : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - expert_parallel_degree        : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - expert_tensor_parallel_degree : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - flash_device_save_steps       : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - flatten_param_grads           : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - force_reshard_pp              : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - fp16                          : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - fp16_full_eval                : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - fp16_opt_level                : O2\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - fp8_format_type               : hybrid\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - fuse_sequence_parallel_allreduce: False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - gradient_accumulation_steps   : 8\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - greater_is_better             : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - hadamard_block_size           : 32\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - hidden_dropout_prob           : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - hybrid_parallel_topo_order    : pp_first\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - ignore_data_skip              : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - ignore_load_lr_and_optim      : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - ignore_save_lr_and_optim      : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - label_names                   : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - label_smoothing               : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - layerwise_lr_decay_bound      : 1.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - lazy_data_processing          : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - learning_rate                 : 1e-05\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - load_best_model_at_end        : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - load_sharded_model            : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - local_process_index           : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - local_rank                    : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - log_level                     : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - log_level_replica             : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - log_on_each_node              : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - logging_dir                   : ./vdl_log\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - logging_first_step            : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - logging_steps                 : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - logging_strategy              : IntervalStrategy.STEPS\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - logical_process_index         : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - loss_type                     : sigmoid\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - lr_end                        : 1e-07\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - lr_scheduler_type             : SchedulerType.COSINE\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - max_estimate_samples          : 100000.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - max_evaluate_steps            : 10000\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - max_grad_norm                 : 1.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - max_steps                     : 100\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - metric_for_best_model         : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - metrics_output_path           : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - min_lr                        : 1e-06\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - minimum_eval_times            : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - multi_token_pred_lambda       : 0.3\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - no_cuda                       : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - normalize_logps               : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - num_cycles                    : 0.5\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - num_nextn_predict_layers      : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - num_of_gpus                   : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - num_train_epochs              : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - offload_optim                 : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - offset_alpha                  : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - optim                         : OptimizerNames.ADAMW\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - optim_shard_num               : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - optimizer_name_suffix         : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - ordered_save_group_size       : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - output_dir                    : ./output\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - output_signal_dir             : ./output\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - overwrite_output_dir          : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - pad_token_id                  : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - past_index                    : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - pdc_download_ckpt             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - pdc_download_timeout          : 300\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - per_device_eval_batch_size    : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - per_device_train_batch_size   : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - pipeline_parallel_config      : enable_delay_scale_loss enable_release_grads disable_partial_send_recv\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - pipeline_parallel_degree      : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - pipeline_parallel_rank        : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - power                         : 1.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - prediction_loss_only          : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - pref_loss_ratio               : 1.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - process_index                 : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - quant_input_grad              : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - quant_weight_grad             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - recompute                     : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - ref_model_update_steps        : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - reference_free                : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - refined_recompute             : {}\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - release_grads                 : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - remove_unused_columns         : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - report_to                     : ['visualdl']\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - resume_from_checkpoint        : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - run_name                      : ./output\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - save_on_each_node             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - save_rng_states               : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - save_sharded_model            : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - save_sharding_stage1_model_include_freeze_params: False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - save_steps                    : 10000000\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - save_strategy                 : IntervalStrategy.STEPS\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - save_tokenizer                : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - save_total_limit              : 5\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - scale_loss                    : 32768\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - seed                          : 23\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - sep_parallel_degree           : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - sequence_parallel             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - sequence_parallel_config      : \u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - server_tp_degree              : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - sft_benchmark                 : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - sft_loss_ratio                : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - sharding                      : []\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - sharding_comm_buffer_size_MB  : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - sharding_degree               : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - sharding_parallel_config      : \u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - sharding_parallel_degree      : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - sharding_parallel_mesh_dimension: dp\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - sharding_parallel_rank        : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - should_load_dataset           : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - should_load_sharding_stage1_model: False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - should_log                    : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - should_save                   : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - should_save_model_state       : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - should_save_model_with_tensor_fusion: False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - should_save_sharding_stage1_model: False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - simpo_gamma                   : 0.5\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - skip_data_intervals           : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - skip_memory_metrics           : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - skip_profile_timer            : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - split_inputs_sequence_dim     : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - split_norm_comm               : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - tensor_parallel_config        : \u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - tensor_parallel_degree        : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - tensor_parallel_rank          : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - tensorwise_offload_optimizer  : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - to_static                     : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - train_batch_size              : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - unified_checkpoint            : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - unified_checkpoint_config     : ['async_save']\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - use_async_save                : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - use_expert_parallel           : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - use_hybrid_parallel           : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - use_lowprecision_moment       : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - use_recompute_mtp             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - use_sp_callback               : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - wandb_api_key                 : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - wandb_http_proxy              : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - warmup_ratio                  : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - warmup_steps                  : 20\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - weight_decay                  : 0.1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - weight_name_suffix            : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - weight_quantize_algo          : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - world_size                    : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - zcc_ema_interval              : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - zcc_pipeline_hooks_capacity_usage: 0.6\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - zcc_save_ema_coef             : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - zcc_workers_num               : 3\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - \u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:54,578] [    INFO]\u001b[0m - Starting training from resume_from_checkpoint : None\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:54,585] [    INFO]\u001b[0m - [timelog] checkpoint loading time: 0.00s (2025-07-17 19:05:54) \u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:54,585] [    INFO]\u001b[0m - ***** Running training *****\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:54,585] [    INFO]\u001b[0m -   Num examples = 800\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:54,585] [    INFO]\u001b[0m -   Num Epochs = 9223372036854775807\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:54,585] [    INFO]\u001b[0m -   Instantaneous batch size per device = 1\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:54,585] [    INFO]\u001b[0m -   Total train batch size (w. parallel, distributed & accumulation) = 8\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:54,585] [    INFO]\u001b[0m -   Gradient Accumulation steps = 8\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:54,585] [    INFO]\u001b[0m -   Total optimization steps = 100\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:54,585] [    INFO]\u001b[0m -   Total num train samples = 800\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,586] [   DEBUG]\u001b[0m -   Number of trainable parameters = 360,748,032 (per device)\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:54,603] [    INFO]\u001b[0m - prepare SequenceDataset ...\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:57,381] [    INFO]\u001b[0m - prepare SequenceDataset done: total number of examples is 6000000\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:01,753] [    INFO]\u001b[0m - loss: 2.61245131, learning_rate: 5e-07, global_step: 1, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 7.1658, interval_samples_per_second: 1.1164, interval_steps_per_second: 0.1396, ppl: 13.63242723238924, progress_or_epoch: 0.01\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:03,399] [    INFO]\u001b[0m - loss: 2.57664418, learning_rate: 1e-06, global_step: 2, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.6466, interval_samples_per_second: 4.8584, interval_steps_per_second: 0.6073, ppl: 13.152925166395088, progress_or_epoch: 0.02\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:04,926] [    INFO]\u001b[0m - loss: 2.57887983, learning_rate: 1.5e-06, global_step: 3, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.5269, interval_samples_per_second: 5.2393, interval_steps_per_second: 0.6549, ppl: 13.182363398073319, progress_or_epoch: 0.03\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:06,408] [    INFO]\u001b[0m - loss: 2.64023829, learning_rate: 2e-06, global_step: 4, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.4819, interval_samples_per_second: 5.3984, interval_steps_per_second: 0.6748, ppl: 14.016543211902638, progress_or_epoch: 0.04\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:07,869] [    INFO]\u001b[0m - loss: 2.54005051, learning_rate: 2.5e-06, global_step: 5, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.4608, interval_samples_per_second: 5.4763, interval_steps_per_second: 0.6845, ppl: 12.680311437189454, progress_or_epoch: 0.05\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:09,358] [    INFO]\u001b[0m - loss: 2.52139831, learning_rate: 3e-06, global_step: 6, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.4892, interval_samples_per_second: 5.3721, interval_steps_per_second: 0.6715, ppl: 12.44598785088004, progress_or_epoch: 0.06\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:11,010] [    INFO]\u001b[0m - loss: 2.53262019, learning_rate: 3.5e-06, global_step: 7, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.6514, interval_samples_per_second: 4.8444, interval_steps_per_second: 0.6055, ppl: 12.586441837967008, progress_or_epoch: 0.07\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:12,511] [    INFO]\u001b[0m - loss: 2.51942062, learning_rate: 4e-06, global_step: 8, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.5011, interval_samples_per_second: 5.3295, interval_steps_per_second: 0.6662, ppl: 12.421397868862815, progress_or_epoch: 0.08\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:13,987] [    INFO]\u001b[0m - loss: 2.50147009, learning_rate: 4.5e-06, global_step: 9, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.4765, interval_samples_per_second: 5.4181, interval_steps_per_second: 0.6773, ppl: 12.200416493890778, progress_or_epoch: 0.09\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:15,508] [    INFO]\u001b[0m - loss: 2.34809017, learning_rate: 5e-06, global_step: 10, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.521, interval_samples_per_second: 5.2595, interval_steps_per_second: 0.6574, ppl: 10.465563179731184, progress_or_epoch: 0.1\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:17,001] [    INFO]\u001b[0m - loss: 2.38992405, learning_rate: 5.5e-06, global_step: 11, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.4932, interval_samples_per_second: 5.3578, interval_steps_per_second: 0.6697, ppl: 10.912665094652914, progress_or_epoch: 0.11\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:18,653] [    INFO]\u001b[0m - loss: 2.23173046, learning_rate: 6e-06, global_step: 12, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.6514, interval_samples_per_second: 4.8444, interval_steps_per_second: 0.6056, ppl: 9.315973057961125, progress_or_epoch: 0.12\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:20,143] [    INFO]\u001b[0m - loss: 2.09781885, learning_rate: 6.5e-06, global_step: 13, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.4899, interval_samples_per_second: 5.3696, interval_steps_per_second: 0.6712, ppl: 8.148377681878587, progress_or_epoch: 0.13\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:21,610] [    INFO]\u001b[0m - loss: 2.03945446, learning_rate: 7e-06, global_step: 14, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.4669, interval_samples_per_second: 5.4535, interval_steps_per_second: 0.6817, ppl: 7.686414808144628, progress_or_epoch: 0.14\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:23,080] [    INFO]\u001b[0m - loss: 1.93046248, learning_rate: 7.5e-06, global_step: 15, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.4709, interval_samples_per_second: 5.4389, interval_steps_per_second: 0.6799, ppl: 6.892697239182341, progress_or_epoch: 0.15\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:24,555] [    INFO]\u001b[0m - loss: 1.81210303, learning_rate: 8e-06, global_step: 16, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.4744, interval_samples_per_second: 5.4259, interval_steps_per_second: 0.6782, ppl: 6.123311408416771, progress_or_epoch: 0.16\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:26,209] [    INFO]\u001b[0m - loss: 1.70531929, learning_rate: 8.5e-06, global_step: 17, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.6541, interval_samples_per_second: 4.8365, interval_steps_per_second: 0.6046, ppl: 5.503142485093446, progress_or_epoch: 0.17\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:27,686] [    INFO]\u001b[0m - loss: 1.51051784, learning_rate: 9e-06, global_step: 18, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.4773, interval_samples_per_second: 5.4151, interval_steps_per_second: 0.6769, ppl: 4.529075523633699, progress_or_epoch: 0.18\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:29,163] [    INFO]\u001b[0m - loss: 1.29875422, learning_rate: 9.5e-06, global_step: 19, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.477, interval_samples_per_second: 5.4165, interval_steps_per_second: 0.6771, ppl: 3.664728377349803, progress_or_epoch: 0.19\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:30,638] [    INFO]\u001b[0m - loss: 1.23181963, learning_rate: 1e-05, global_step: 20, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.475, interval_samples_per_second: 5.4236, interval_steps_per_second: 0.6779, ppl: 3.4274605755645147, progress_or_epoch: 0.2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:32,258] [    INFO]\u001b[0m - loss: 1.07891762, learning_rate: 9.997e-06, global_step: 21, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.6193, interval_samples_per_second: 4.9404, interval_steps_per_second: 0.6175, ppl: 2.9414940131053307, progress_or_epoch: 0.21\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:34,029] [    INFO]\u001b[0m - loss: 0.90462917, learning_rate: 9.986e-06, global_step: 22, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.7713, interval_samples_per_second: 4.5164, interval_steps_per_second: 0.5646, ppl: 2.4710154264851587, progress_or_epoch: 0.22\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:35,540] [    INFO]\u001b[0m - loss: 0.76993722, learning_rate: 9.969e-06, global_step: 23, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.5108, interval_samples_per_second: 5.295, interval_steps_per_second: 0.6619, ppl: 2.159630667915587, progress_or_epoch: 0.23\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:37,009] [    INFO]\u001b[0m - loss: 0.65621567, learning_rate: 9.945e-06, global_step: 24, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.4696, interval_samples_per_second: 5.4438, interval_steps_per_second: 0.6805, ppl: 1.927484278496434, progress_or_epoch: 0.24\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:38,479] [    INFO]\u001b[0m - loss: 0.51416081, learning_rate: 9.914e-06, global_step: 25, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.4692, interval_samples_per_second: 5.445, interval_steps_per_second: 0.6806, ppl: 1.6722345902598585, progress_or_epoch: 0.25\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:39,975] [    INFO]\u001b[0m - loss: 0.43581983, learning_rate: 9.876e-06, global_step: 26, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.4967, interval_samples_per_second: 5.3449, interval_steps_per_second: 0.6681, ppl: 1.546230185359108, progress_or_epoch: 0.26\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:41,704] [    INFO]\u001b[0m - loss: 0.3368488, learning_rate: 9.831e-06, global_step: 27, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.7287, interval_samples_per_second: 4.6277, interval_steps_per_second: 0.5785, ppl: 1.400527288002747, progress_or_epoch: 0.27\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:43,200] [    INFO]\u001b[0m - loss: 0.27868763, learning_rate: 9.78e-06, global_step: 28, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.4957, interval_samples_per_second: 5.3487, interval_steps_per_second: 0.6686, ppl: 1.3213945153905076, progress_or_epoch: 0.28\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:44,683] [    INFO]\u001b[0m - loss: 0.20828675, learning_rate: 9.722e-06, global_step: 29, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.4836, interval_samples_per_second: 5.3923, interval_steps_per_second: 0.674, ppl: 1.231566270548672, progress_or_epoch: 0.29\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:46,147] [    INFO]\u001b[0m - loss: 0.15214896, learning_rate: 9.657e-06, global_step: 30, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.4636, interval_samples_per_second: 5.466, interval_steps_per_second: 0.6832, ppl: 1.1643336626573957, progress_or_epoch: 0.3\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:47,622] [    INFO]\u001b[0m - loss: 0.10568784, learning_rate: 9.587e-06, global_step: 31, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.4746, interval_samples_per_second: 5.4253, interval_steps_per_second: 0.6782, ppl: 1.1114748643540353, progress_or_epoch: 0.31\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:49,276] [    INFO]\u001b[0m - loss: 0.06535335, learning_rate: 9.51e-06, global_step: 32, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.6547, interval_samples_per_second: 4.8346, interval_steps_per_second: 0.6043, ppl: 1.0675361716540286, progress_or_epoch: 0.32\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:50,752] [    INFO]\u001b[0m - loss: 0.04185442, learning_rate: 9.426e-06, global_step: 33, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.4761, interval_samples_per_second: 5.4198, interval_steps_per_second: 0.6775, ppl: 1.0427426652233216, progress_or_epoch: 0.33\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:52,233] [    INFO]\u001b[0m - loss: 0.02847656, learning_rate: 9.337e-06, global_step: 34, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.4811, interval_samples_per_second: 5.4015, interval_steps_per_second: 0.6752, ppl: 1.0288858934665266, progress_or_epoch: 0.34\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:53,721] [    INFO]\u001b[0m - loss: 0.0193248, learning_rate: 9.242e-06, global_step: 35, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.4879, interval_samples_per_second: 5.3768, interval_steps_per_second: 0.6721, ppl: 1.0195127325820041, progress_or_epoch: 0.35\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:55,205] [    INFO]\u001b[0m - loss: 0.01424673, learning_rate: 9.141e-06, global_step: 36, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.4835, interval_samples_per_second: 5.3928, interval_steps_per_second: 0.6741, ppl: 1.0143486983207781, progress_or_epoch: 0.36\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:56,856] [    INFO]\u001b[0m - loss: 0.01063273, learning_rate: 9.034e-06, global_step: 37, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.6513, interval_samples_per_second: 4.8448, interval_steps_per_second: 0.6056, ppl: 1.0106894583544417, progress_or_epoch: 0.37\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:58,350] [    INFO]\u001b[0m - loss: 0.00897723, learning_rate: 8.922e-06, global_step: 38, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.4936, interval_samples_per_second: 5.3562, interval_steps_per_second: 0.6695, ppl: 1.009017646180488, progress_or_epoch: 0.38\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:59,810] [    INFO]\u001b[0m - loss: 0.00651405, learning_rate: 8.804e-06, global_step: 39, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.4607, interval_samples_per_second: 5.4768, interval_steps_per_second: 0.6846, ppl: 1.0065353125671035, progress_or_epoch: 0.39\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:01,299] [    INFO]\u001b[0m - loss: 0.00599763, learning_rate: 8.682e-06, global_step: 40, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4885, interval_samples_per_second: 5.3746, interval_steps_per_second: 0.6718, ppl: 1.0060156517941448, progress_or_epoch: 0.4\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:02,804] [    INFO]\u001b[0m - loss: 0.00479357, learning_rate: 8.555e-06, global_step: 41, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.5054, interval_samples_per_second: 5.3141, interval_steps_per_second: 0.6643, ppl: 1.0048050775367192, progress_or_epoch: 0.41\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:04,446] [    INFO]\u001b[0m - loss: 0.00418891, learning_rate: 8.423e-06, global_step: 42, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.6416, interval_samples_per_second: 4.8734, interval_steps_per_second: 0.6092, ppl: 1.004197695746778, progress_or_epoch: 0.42\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:05,956] [    INFO]\u001b[0m - loss: 0.00332835, learning_rate: 8.286e-06, global_step: 43, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.5097, interval_samples_per_second: 5.2989, interval_steps_per_second: 0.6624, ppl: 1.0033338951071737, progress_or_epoch: 0.43\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:07,490] [    INFO]\u001b[0m - loss: 0.00299198, learning_rate: 8.145e-06, global_step: 44, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.5344, interval_samples_per_second: 5.2137, interval_steps_per_second: 0.6517, ppl: 1.0029964604395076, progress_or_epoch: 0.44\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:08,950] [    INFO]\u001b[0m - loss: 0.0026643, learning_rate: 8e-06, global_step: 45, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4595, interval_samples_per_second: 5.4815, interval_steps_per_second: 0.6852, ppl: 1.002667852401432, progress_or_epoch: 0.45\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:10,438] [    INFO]\u001b[0m - loss: 0.0022808, learning_rate: 7.851e-06, global_step: 46, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4882, interval_samples_per_second: 5.3757, interval_steps_per_second: 0.672, ppl: 1.0022834030029202, progress_or_epoch: 0.46\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:12,111] [    INFO]\u001b[0m - loss: 0.0020717, learning_rate: 7.699e-06, global_step: 47, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.6736, interval_samples_per_second: 4.7802, interval_steps_per_second: 0.5975, ppl: 1.0020738474531485, progress_or_epoch: 0.47\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:13,602] [    INFO]\u001b[0m - loss: 0.00184983, learning_rate: 7.543e-06, global_step: 48, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4901, interval_samples_per_second: 5.3686, interval_steps_per_second: 0.6711, ppl: 1.0018515419909824, progress_or_epoch: 0.48\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:15,058] [    INFO]\u001b[0m - loss: 0.00168223, learning_rate: 7.384e-06, global_step: 49, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.457, interval_samples_per_second: 5.4909, interval_steps_per_second: 0.6864, ppl: 1.0016836457426435, progress_or_epoch: 0.49\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:16,532] [    INFO]\u001b[0m - loss: 0.00155611, learning_rate: 7.222e-06, global_step: 50, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4736, interval_samples_per_second: 5.429, interval_steps_per_second: 0.6786, ppl: 1.001557321367425, progress_or_epoch: 0.5\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:18,021] [    INFO]\u001b[0m - loss: 0.00141674, learning_rate: 7.058e-06, global_step: 51, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4889, interval_samples_per_second: 5.3731, interval_steps_per_second: 0.6716, ppl: 1.0014177440502172, progress_or_epoch: 0.51\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:19,669] [    INFO]\u001b[0m - loss: 0.0013008, learning_rate: 6.891e-06, global_step: 52, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.6479, interval_samples_per_second: 4.8547, interval_steps_per_second: 0.6068, ppl: 1.0013016464072824, progress_or_epoch: 0.52\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:21,164] [    INFO]\u001b[0m - loss: 0.00122136, learning_rate: 6.721e-06, global_step: 53, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4951, interval_samples_per_second: 5.3507, interval_steps_per_second: 0.6688, ppl: 1.0012221061638722, progress_or_epoch: 0.53\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:22,642] [    INFO]\u001b[0m - loss: 0.00113877, learning_rate: 6.551e-06, global_step: 54, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4777, interval_samples_per_second: 5.4138, interval_steps_per_second: 0.6767, ppl: 1.0011394186447522, progress_or_epoch: 0.54\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:24,263] [    INFO]\u001b[0m - loss: 0.00107102, learning_rate: 6.378e-06, global_step: 55, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.621, interval_samples_per_second: 4.9353, interval_steps_per_second: 0.6169, ppl: 1.0010715937467334, progress_or_epoch: 0.55\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:25,756] [    INFO]\u001b[0m - loss: 0.00099817, learning_rate: 6.204e-06, global_step: 56, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4935, interval_samples_per_second: 5.3564, interval_steps_per_second: 0.6696, ppl: 1.0009986683374692, progress_or_epoch: 0.56\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:27,442] [    INFO]\u001b[0m - loss: 0.00093717, learning_rate: 6.029e-06, global_step: 57, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.6857, interval_samples_per_second: 4.7458, interval_steps_per_second: 0.5932, ppl: 1.0009376092810207, progress_or_epoch: 0.57\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:28,937] [    INFO]\u001b[0m - loss: 0.00088327, learning_rate: 5.853e-06, global_step: 58, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4953, interval_samples_per_second: 5.3502, interval_steps_per_second: 0.6688, ppl: 1.0008836601978213, progress_or_epoch: 0.58\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:30,418] [    INFO]\u001b[0m - loss: 0.00081978, learning_rate: 5.677e-06, global_step: 59, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4805, interval_samples_per_second: 5.4036, interval_steps_per_second: 0.6755, ppl: 1.0008201161114638, progress_or_epoch: 0.59\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:31,899] [    INFO]\u001b[0m - loss: 0.00079842, learning_rate: 5.5e-06, global_step: 60, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4814, interval_samples_per_second: 5.4004, interval_steps_per_second: 0.6751, ppl: 1.0007987388220938, progress_or_epoch: 0.6\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:33,397] [    INFO]\u001b[0m - loss: 0.00075694, learning_rate: 5.323e-06, global_step: 61, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4981, interval_samples_per_second: 5.3402, interval_steps_per_second: 0.6675, ppl: 1.000757226551378, progress_or_epoch: 0.61\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:35,063] [    INFO]\u001b[0m - loss: 0.00074053, learning_rate: 5.147e-06, global_step: 62, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.6663, interval_samples_per_second: 4.801, interval_steps_per_second: 0.6001, ppl: 1.0007408042600356, progress_or_epoch: 0.62\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:36,562] [    INFO]\u001b[0m - loss: 0.0007109, learning_rate: 4.971e-06, global_step: 63, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4989, interval_samples_per_second: 5.3373, interval_steps_per_second: 0.6672, ppl: 1.0007111527492947, progress_or_epoch: 0.63\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:38,035] [    INFO]\u001b[0m - loss: 0.00068439, learning_rate: 4.796e-06, global_step: 64, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4724, interval_samples_per_second: 5.4335, interval_steps_per_second: 0.6792, ppl: 1.000684624248272, progress_or_epoch: 0.64\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:39,503] [    INFO]\u001b[0m - loss: 0.00065405, learning_rate: 4.622e-06, global_step: 65, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4682, interval_samples_per_second: 5.449, interval_steps_per_second: 0.6811, ppl: 1.0006542639373406, progress_or_epoch: 0.65\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:40,994] [    INFO]\u001b[0m - loss: 0.00062484, learning_rate: 4.449e-06, global_step: 66, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4913, interval_samples_per_second: 5.3645, interval_steps_per_second: 0.6706, ppl: 1.000625035253178, progress_or_epoch: 0.66\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:42,657] [    INFO]\u001b[0m - loss: 0.00060752, learning_rate: 4.279e-06, global_step: 67, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.6632, interval_samples_per_second: 4.8099, interval_steps_per_second: 0.6012, ppl: 1.0006077045776516, progress_or_epoch: 0.67\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:44,157] [    INFO]\u001b[0m - loss: 0.00059177, learning_rate: 4.109e-06, global_step: 68, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.5001, interval_samples_per_second: 5.3331, interval_steps_per_second: 0.6666, ppl: 1.0005919451304104, progress_or_epoch: 0.68\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:45,633] [    INFO]\u001b[0m - loss: 0.00057848, learning_rate: 3.942e-06, global_step: 69, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.476, interval_samples_per_second: 5.4199, interval_steps_per_second: 0.6775, ppl: 1.0005786473518234, progress_or_epoch: 0.69\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:47,125] [    INFO]\u001b[0m - loss: 0.00055459, learning_rate: 3.778e-06, global_step: 70, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4913, interval_samples_per_second: 5.3646, interval_steps_per_second: 0.6706, ppl: 1.0005547438134672, progress_or_epoch: 0.7\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:48,773] [    INFO]\u001b[0m - loss: 0.00054881, learning_rate: 3.616e-06, global_step: 71, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.6481, interval_samples_per_second: 4.8542, interval_steps_per_second: 0.6068, ppl: 1.0005489606237614, progress_or_epoch: 0.71\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:50,439] [    INFO]\u001b[0m - loss: 0.00052375, learning_rate: 3.457e-06, global_step: 72, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.6662, interval_samples_per_second: 4.8012, interval_steps_per_second: 0.6002, ppl: 1.0005238871809796, progress_or_epoch: 0.72\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:51,940] [    INFO]\u001b[0m - loss: 0.00052632, learning_rate: 3.301e-06, global_step: 73, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.5013, interval_samples_per_second: 5.3286, interval_steps_per_second: 0.6661, ppl: 1.000526458530674, progress_or_epoch: 0.73\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:53,402] [    INFO]\u001b[0m - loss: 0.00050112, learning_rate: 3.149e-06, global_step: 74, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4614, interval_samples_per_second: 5.4744, interval_steps_per_second: 0.6843, ppl: 1.0005012455816036, progress_or_epoch: 0.74\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:54,877] [    INFO]\u001b[0m - loss: 0.00049965, learning_rate: 3e-06, global_step: 75, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.475, interval_samples_per_second: 5.4239, interval_steps_per_second: 0.678, ppl: 1.0004997748458535, progress_or_epoch: 0.75\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:56,374] [    INFO]\u001b[0m - loss: 0.00049271, learning_rate: 2.855e-06, global_step: 76, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4973, interval_samples_per_second: 5.3429, interval_steps_per_second: 0.6679, ppl: 1.0004928314015098, progress_or_epoch: 0.76\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:58,108] [    INFO]\u001b[0m - loss: 0.0004792, learning_rate: 2.714e-06, global_step: 77, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.734, interval_samples_per_second: 4.6135, interval_steps_per_second: 0.5767, ppl: 1.0004793148346622, progress_or_epoch: 0.77\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:59,678] [    INFO]\u001b[0m - loss: 0.00048325, learning_rate: 2.577e-06, global_step: 78, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.5694, interval_samples_per_second: 5.0974, interval_steps_per_second: 0.6372, ppl: 1.0004833667840924, progress_or_epoch: 0.78\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:01,146] [    INFO]\u001b[0m - loss: 0.00047503, learning_rate: 2.445e-06, global_step: 79, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4684, interval_samples_per_second: 5.4483, interval_steps_per_second: 0.681, ppl: 1.000475142844618, progress_or_epoch: 0.79\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:02,603] [    INFO]\u001b[0m - loss: 0.00046239, learning_rate: 2.318e-06, global_step: 80, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4572, interval_samples_per_second: 5.4901, interval_steps_per_second: 0.6863, ppl: 1.0004624969187348, progress_or_epoch: 0.8\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:04,078] [    INFO]\u001b[0m - loss: 0.00046021, learning_rate: 2.196e-06, global_step: 81, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4748, interval_samples_per_second: 5.4244, interval_steps_per_second: 0.6781, ppl: 1.0004603159128689, progress_or_epoch: 0.81\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:05,732] [    INFO]\u001b[0m - loss: 0.00044189, learning_rate: 2.078e-06, global_step: 82, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.6539, interval_samples_per_second: 4.8371, interval_steps_per_second: 0.6046, ppl: 1.0004419876477688, progress_or_epoch: 0.82\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:07,234] [    INFO]\u001b[0m - loss: 0.00044303, learning_rate: 1.966e-06, global_step: 83, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.5022, interval_samples_per_second: 5.3256, interval_steps_per_second: 0.6657, ppl: 1.0004431281522848, progress_or_epoch: 0.83\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:08,720] [    INFO]\u001b[0m - loss: 0.00043664, learning_rate: 1.859e-06, global_step: 84, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4859, interval_samples_per_second: 5.3839, interval_steps_per_second: 0.673, ppl: 1.000436735341121, progress_or_epoch: 0.84\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:10,211] [    INFO]\u001b[0m - loss: 0.00044362, learning_rate: 1.758e-06, global_step: 85, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4911, interval_samples_per_second: 5.365, interval_steps_per_second: 0.6706, ppl: 1.0004437184139046, progress_or_epoch: 0.85\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:11,705] [    INFO]\u001b[0m - loss: 0.00043008, learning_rate: 1.663e-06, global_step: 86, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4937, interval_samples_per_second: 5.3559, interval_steps_per_second: 0.6695, ppl: 1.0004301724976632, progress_or_epoch: 0.86\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:13,381] [    INFO]\u001b[0m - loss: 0.00043164, learning_rate: 1.574e-06, global_step: 87, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.6764, interval_samples_per_second: 4.772, interval_steps_per_second: 0.5965, ppl: 1.0004317331699497, progress_or_epoch: 0.87\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:15,013] [    INFO]\u001b[0m - loss: 0.00043156, learning_rate: 1.49e-06, global_step: 88, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.6317, interval_samples_per_second: 4.9028, interval_steps_per_second: 0.6129, ppl: 1.0004316531354143, progress_or_epoch: 0.88\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:16,489] [    INFO]\u001b[0m - loss: 0.00041841, learning_rate: 1.413e-06, global_step: 89, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4765, interval_samples_per_second: 5.4184, interval_steps_per_second: 0.6773, ppl: 1.0004184975456736, progress_or_epoch: 0.89\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:17,973] [    INFO]\u001b[0m - loss: 0.00041201, learning_rate: 1.343e-06, global_step: 90, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 34.84359335899353, max_memory_allocated: 13.52203369140625, max_memory_reserved: 34.84359335899353, interval_runtime: 1.4833, interval_samples_per_second: 5.3934, interval_steps_per_second: 0.6742, ppl: 1.000412094887778, progress_or_epoch: 0.9\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:19,469] [    INFO]\u001b[0m - loss: 0.00041063, learning_rate: 1.278e-06, global_step: 91, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 34.84359335899353, max_memory_allocated: 13.52203369140625, max_memory_reserved: 34.84359335899353, interval_runtime: 1.4964, interval_samples_per_second: 5.3462, interval_steps_per_second: 0.6683, ppl: 1.0004107143200396, progress_or_epoch: 0.91\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:21,112] [    INFO]\u001b[0m - loss: 0.00041239, learning_rate: 1.22e-06, global_step: 92, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 34.84359335899353, max_memory_allocated: 13.52203369140625, max_memory_reserved: 34.84359335899353, interval_runtime: 1.6429, interval_samples_per_second: 4.8696, interval_steps_per_second: 0.6087, ppl: 1.000412475044446, progress_or_epoch: 0.92\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:22,589] [    INFO]\u001b[0m - loss: 0.00040777, learning_rate: 1.169e-06, global_step: 93, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 34.84359335899353, max_memory_allocated: 13.52203369140625, max_memory_reserved: 34.84359335899353, interval_runtime: 1.4775, interval_samples_per_second: 5.4146, interval_steps_per_second: 0.6768, ppl: 1.000407853149488, progress_or_epoch: 0.93\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:24,046] [    INFO]\u001b[0m - loss: 0.00040752, learning_rate: 1.124e-06, global_step: 94, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 34.84359335899353, max_memory_allocated: 13.52203369140625, max_memory_reserved: 34.84359335899353, interval_runtime: 1.457, interval_samples_per_second: 5.4907, interval_steps_per_second: 0.6863, ppl: 1.000407603047556, progress_or_epoch: 0.94\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:25,511] [    INFO]\u001b[0m - loss: 0.00040874, learning_rate: 1.086e-06, global_step: 95, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 34.84359335899353, max_memory_allocated: 13.52203369140625, max_memory_reserved: 34.84359335899353, interval_runtime: 1.4643, interval_samples_per_second: 5.4635, interval_steps_per_second: 0.6829, ppl: 1.0004088235455761, progress_or_epoch: 0.95\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:26,992] [    INFO]\u001b[0m - loss: 0.00039641, learning_rate: 1.055e-06, global_step: 96, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 34.84359335899353, max_memory_allocated: 13.52203369140625, max_memory_reserved: 34.84359335899353, interval_runtime: 1.4815, interval_samples_per_second: 5.4, interval_steps_per_second: 0.675, ppl: 1.0003964885808272, progress_or_epoch: 0.96\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:28,649] [    INFO]\u001b[0m - loss: 0.0004016, learning_rate: 1.031e-06, global_step: 97, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 34.84359335899353, max_memory_allocated: 13.52203369140625, max_memory_reserved: 34.84359335899353, interval_runtime: 1.6566, interval_samples_per_second: 4.8291, interval_steps_per_second: 0.6036, ppl: 1.0004016806520764, progress_or_epoch: 0.97\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:30,116] [    INFO]\u001b[0m - loss: 0.0004049, learning_rate: 1.014e-06, global_step: 98, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 34.84359335899353, max_memory_allocated: 13.52203369140625, max_memory_reserved: 34.84359335899353, interval_runtime: 1.4677, interval_samples_per_second: 5.4508, interval_steps_per_second: 0.6813, ppl: 1.0004049819830696, progress_or_epoch: 0.98\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:31,570] [    INFO]\u001b[0m - loss: 0.00039089, learning_rate: 1.003e-06, global_step: 99, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 34.84359335899353, max_memory_allocated: 13.52203369140625, max_memory_reserved: 34.84359335899353, interval_runtime: 1.4537, interval_samples_per_second: 5.5032, interval_steps_per_second: 0.6879, ppl: 1.0003909664074513, progress_or_epoch: 0.99\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:33,039] [    INFO]\u001b[0m - loss: 0.00038933, learning_rate: 1e-06, global_step: 100, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 34.84359335899353, max_memory_allocated: 13.52203369140625, max_memory_reserved: 34.84359335899353, interval_runtime: 1.4685, interval_samples_per_second: 5.4476, interval_steps_per_second: 0.6809, ppl: 1.000389405798761, progress_or_epoch: 1.0\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:33,039] [    INFO]\u001b[0m - \r\n",
      "Training completed. \r\n",
      "\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:33,039] [    INFO]\u001b[0m - train_runtime: 158.453, train_samples_per_second: 5.0488, train_steps_per_second: 0.6311, train_loss: 0.4931975438800873, progress_or_epoch: 1.0\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:33,040] [    INFO]\u001b[0m - Saving model checkpoint to ./output\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:33,043] [    INFO]\u001b[0m - tokenizer config file saved in ./output/tokenizer_config.json\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:33,044] [    INFO]\u001b[0m - Special tokens file saved in ./output/special_tokens_map.json\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:33,044] [    INFO]\u001b[0m - added tokens file saved in ./output/added_tokens.json\u001b[0m\r\n",
      "\u001b[33m[2025-07-17 19:08:33,054] [ WARNING]\u001b[0m - Asynchronous saving is not supported for single card environment currently.\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,837] [    INFO]\u001b[0m - Configuration saved in ./output/config.json\u001b[0m\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddleformers/generation/configuration_utils.py:316: UserWarning: The generation config instance is invalid -- `.validate()` throws warnings and/or exceptions. Fix these issues to save the configuration. This warning will be raised to an exception.\r\n",
      "\r\n",
      "Thrown during validation:\r\n",
      "using greedy search strategy. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `decode_strategy=\"greedy_search\" ` or unset `temperature`.\r\n",
      "  warnings.warn(\r\n",
      "\u001b[32m[2025-07-17 19:08:34,872] [    INFO]\u001b[0m - [timelog] model saving time: 1.83s (2025-07-17 19:08:34) \u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,872] [    INFO]\u001b[0m - ***** train metrics *****\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,872] [    INFO]\u001b[0m -   progress_or_epoch        =        1.0\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,872] [    INFO]\u001b[0m -   train_loss               =     0.4932\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,872] [    INFO]\u001b[0m -   train_runtime            = 0:02:38.45\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,872] [    INFO]\u001b[0m -   train_samples_per_second =     5.0488\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,872] [    INFO]\u001b[0m -   train_steps_per_second   =     0.6311\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,873] [    INFO]\u001b[0m - ***** Running Evaluation *****\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,873] [    INFO]\u001b[0m -   Num examples: Unknown\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,873] [    INFO]\u001b[0m -   Total prediction steps = 10000\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,873] [    INFO]\u001b[0m -   Pre device batch size = 1\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,873] [    INFO]\u001b[0m -   Total Batch size = 1\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,875] [    INFO]\u001b[0m - prepare SequenceDataset ...\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,876] [    INFO]\u001b[0m - prepare SequenceDataset done: total number of examples is 10\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,922] [    INFO]\u001b[0m - eval_loss: 4.969167232513428, eval_runtime: 0.0491, eval_samples_per_second: 203467.7235, eval_steps_per_second: 203467.7235, eval_ppl: 143.90699638950923, progress_or_epoch: 1.0\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,922] [    INFO]\u001b[0m - ***** eval metrics *****\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,922] [    INFO]\u001b[0m -   eval_loss               =      4.9692\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,922] [    INFO]\u001b[0m -   eval_ppl                =     143.907\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,922] [    INFO]\u001b[0m -   eval_runtime            =  0:00:00.04\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,923] [    INFO]\u001b[0m -   eval_samples_per_second = 203467.7235\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,923] [    INFO]\u001b[0m -   eval_steps_per_second   = 203467.7235\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,923] [    INFO]\u001b[0m -   progress_or_epoch       =         1.0\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,923] [    INFO]\u001b[0m - Saving stop info into ./vdl_log/stop_step.json\u001b[0m\r\n",
      "LAUNCH INFO 2025-07-17 19:08:36,850 Pod completed\r\n",
      "LAUNCH INFO 2025-07-17 19:08:36,850 Exit code 0\r\n"
     ]
    }
   ],
   "source": [
    "!erniekit train examples/configs/ERNIE-4.5-0.3B/sft/run_sft_8k.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 è§£è¯»è®­ç»ƒæ—¥å¿—\n",
    "\n",
    "å½“è®­ç»ƒå¼€å§‹åï¼Œæ‚¨ä¼šçœ‹åˆ°å¤§é‡çš„æ—¥å¿—ä¿¡æ¯è¾“å‡ºã€‚å­¦ä¼šè§£è¯»è¿™äº›æ—¥å¿—æ˜¯ç›‘æ§è®­ç»ƒçŠ¶æ€ã€åˆ¤æ–­æ¨¡å‹æ˜¯å¦æ­£å¸¸æ”¶æ•›çš„å…³é”®ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è®©æˆ‘ä»¬æ¥è§£æå…¶ä¸­çš„å…³é”®ä¿¡æ¯ï¼š\n",
    "\n",
    "*   `global_step`: å½“å‰çš„æ€»è®­ç»ƒæ­¥æ•°ã€‚`10/100` è¡¨ç¤ºå½“å‰æ˜¯ç¬¬10æ­¥ï¼Œæ€»å…±éœ€è¦è®­ç»ƒ100æ­¥ï¼ˆç”± `max_steps` å®šä¹‰ï¼‰ã€‚\n",
    "*   `epoch`: å½“å‰çš„è®­ç»ƒè½®æ•°ã€‚\n",
    "*   `loss`: **æœ€é‡è¦çš„æŒ‡æ ‡**ã€‚å®ƒè¡¡é‡äº†æ¨¡å‹é¢„æµ‹çš„è¾“å‡ºä¸çœŸå® `tgt` ä¹‹é—´çš„å·®è·ã€‚**æˆ‘ä»¬æœŸæœ›çœ‹åˆ° `loss` å€¼éšç€è®­ç»ƒçš„è¿›è¡Œè€Œç¨³æ­¥ä¸‹é™**ã€‚å¦‚æœ `loss` å±…é«˜ä¸ä¸‹ã€å‰§çƒˆéœ‡è¡æˆ–è€…å˜ä¸º `NaN`ï¼Œéƒ½è¯´æ˜è®­ç»ƒå¯èƒ½å‡ºäº†é—®é¢˜ï¼ˆä¾‹å¦‚ï¼Œå­¦ä¹ ç‡è¿‡é«˜ã€æ•°æ®æœ‰é—®é¢˜ç­‰ï¼‰ã€‚\n",
    "*   `learning_rate`: å½“å‰çš„å­¦ä¹ ç‡ã€‚æ‚¨å¯ä»¥çœ‹åˆ°å®ƒåœ¨ `warmup_steps` ä¹‹åè¾¾åˆ°è®¾å®šçš„å€¼ï¼Œç„¶åæ ¹æ® `lr_scheduler_type` çš„ç­–ç•¥è¿›è¡Œå˜åŒ–ã€‚\n",
    "*   `speed` / `ips`: è®­ç»ƒé€Ÿåº¦ã€‚åˆ†åˆ«è¡¨ç¤ºæ¯ç§’å¤„ç†çš„æ­¥æ•°å’Œæ ·æœ¬æ•°ã€‚å¯ä»¥ç”¨æ¥é¢„ä¼°æ€»çš„è®­ç»ƒæ—¶é—´ã€‚\n",
    "*   `eta`: é¢„è®¡å‰©ä½™è®­ç»ƒæ—¶é—´ (Estimated Time of Arrival)ã€‚\n",
    "\n",
    "**ç›‘æ§è¦ç‚¹ï¼š**\n",
    "\n",
    "1.  **Loss æ˜¯å¦ä¸‹é™**: è¿™æ˜¯é¦–è¦çš„å¥åº·æŒ‡æ ‡ã€‚ä¸€ä¸ªå¹³ç¨³ä¸‹é™çš„lossæ›²çº¿æ˜¯è®­ç»ƒæˆåŠŸçš„æ ‡å¿—ã€‚\n",
    "2.  **GPU åˆ©ç”¨ç‡å’Œæ˜¾å­˜**: ä½¿ç”¨ `nvidia-smi` å‘½ä»¤å¯ä»¥å®æ—¶æŸ¥çœ‹GPUçš„å·¥ä½œçŠ¶æ€ã€‚ç¡®ä¿GPUåˆ©ç”¨ç‡å°½å¯èƒ½é«˜ï¼Œæ˜¾å­˜å ç”¨åœ¨åˆç†èŒƒå›´å†…ã€‚å¦‚æœæ˜¾å­˜æº¢å‡º (Out of Memory, OOM)ï¼Œæ‚¨éœ€è¦å‡å° `batch_size`ã€`max_seq_len`ï¼Œæˆ–è€…å¼€å¯ `recompute`ã€‚\n",
    "3.  **è¯„ä¼°ç»“æœ (Eval Loss)**: å½“è¾¾åˆ° `eval_steps` æ—¶ï¼Œæ¨¡å‹ä¼šåœ¨è¯„ä¼°é›†ä¸Šè¿›è¡Œæµ‹è¯•ã€‚æˆ‘ä»¬åŒæ ·æœŸæœ› `eval_loss` ä¹Ÿèƒ½éšä¹‹ä¸‹é™ï¼Œè¿™è¡¨æ˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›åœ¨æå‡ã€‚å¦‚æœ `train_loss` ä¸‹é™è€Œ `eval_loss` ä¸Šå‡ï¼Œè¯´æ˜æ¨¡å‹å¯èƒ½å‘ç”Ÿäº†è¿‡æ‹Ÿåˆã€‚\n",
    "\n",
    "è®­ç»ƒå®Œæˆåï¼Œæ‰€æœ‰å¾®è°ƒè¿‡çš„æ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶éƒ½ä¼šä¿å­˜åœ¨æ‚¨ `yaml` ä¸­ `output_dir` æŒ‡å®šçš„ç›®å½•ä¸‹ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œä¼šæœ‰ä¸€ä¸ªåä¸º `checkpoint-xxx` çš„æ–‡ä»¶å¤¹ï¼Œå…¶ä¸­ `xxx` æ˜¯ä¿å­˜æ—¶çš„æ­¥æ•°ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. æ€»ç»“ä¸å±•æœ›\n",
    "\n",
    "æ­å–œæ‚¨ï¼é€šè¿‡æœ¬æ•™ç¨‹çš„å­¦ä¹ å’Œå®è·µï¼Œæ‚¨å·²ç»æˆåŠŸæŒæ¡äº†ä½¿ç”¨ ERNIEkit å¯¹ ERNIE-4.5-0.3B å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œç›‘ç£å¾®è°ƒ (SFT) çš„æ ¸å¿ƒæŠ€æœ¯ã€‚æˆ‘ä»¬ä»SFTçš„åŸºæœ¬æ¦‚å¿µå‡ºå‘ï¼Œä¸€æ­¥æ­¥å®Œæˆäº†ç¯å¢ƒå‡†å¤‡ã€æ•°æ®å¤„ç†ã€é…ç½®è§£æã€æ¨¡å‹è®­ç»ƒä¸æ¨ç†è¯„ä¼°çš„å…¨è¿‡ç¨‹ã€‚\n",
    "\n",
    "### 6.1 æœ¬æ•™ç¨‹æ ¸å¿ƒå›é¡¾\n",
    "\n",
    "è®©æˆ‘ä»¬å†æ¬¡æ¢³ç†æœ¬æ¬¡æ—…ç¨‹çš„å…³é”®å­¦ä¹ ç‚¹ï¼š\n",
    "\n",
    "1.  **ç†è§£äº†SFTçš„æœ¬è´¨**ï¼šæˆ‘ä»¬æ˜ç¡®äº†SFTæ˜¯åœ¨é¢„è®­ç»ƒæ¨¡å‹åŸºç¡€ä¸Šï¼Œé€šè¿‡æœ‰æ ‡ç­¾çš„â€œæŒ‡ä»¤-è¾“å‡ºâ€æ•°æ®ï¼Œæ•™ä¼šæ¨¡å‹å¦‚ä½•éµå¾ªäººç±»æ„å›¾ã€å®Œæˆç‰¹å®šä»»åŠ¡çš„è¿‡ç¨‹ã€‚å®ƒæ˜¯è¿æ¥é€šç”¨å¤§æ¨¡å‹ä¸å…·ä½“åº”ç”¨åœºæ™¯çš„æ¡¥æ¢ã€‚\n",
    "2.  **æŒæ¡äº†ERNIEkit SFTå…¨æµç¨‹**ï¼šæˆ‘ä»¬å­¦ä¼šäº†ä½¿ç”¨ ERNIEkit è¿™ä¸€å¼ºå¤§çš„å·¥å…·é“¾ï¼Œä»ä¸‹è½½æ¨¡å‹ã€å‡†å¤‡æ•°æ®ï¼Œåˆ°é…ç½®å’Œå¯åŠ¨è®­ç»ƒï¼Œå†åˆ°æœ€ç»ˆçš„æ¨ç†éªŒè¯ï¼Œå½¢æˆäº†ä¸€ä¸ªå®Œæ•´çš„é—­ç¯ã€‚\n",
    "3.  **ç²¾é€šäº†SFTé…ç½®**ï¼šæˆ‘ä»¬æ·±å…¥è§£æäº† `run_sft_8k.yaml` é…ç½®æ–‡ä»¶ä¸­çš„å„é¡¹å‚æ•°ï¼Œç†è§£äº†å¦‚ä½•é€šè¿‡è°ƒæ•´å­¦ä¹ ç‡ã€batch sizeã€åºåˆ—é•¿åº¦ã€ä¼˜åŒ–ç­–ç•¥ç­‰æ¥æ§åˆ¶å’Œä¼˜åŒ–SFTè¿‡ç¨‹ï¼Œå¹¶å­¦ä¼šäº†å¦‚æ¢¯åº¦ç´¯ç§¯ã€é‡è®¡ç®— (Recompute)ã€æ··åˆç²¾åº¦ç­‰å…³é”®çš„æ˜¾å­˜ä¼˜åŒ–æŠ€å·§ã€‚\n",
    "4.  **å¼ºè°ƒäº†æ•°æ®çš„é‡è¦æ€§**ï¼šæˆ‘ä»¬è®¤è¯†åˆ°ï¼Œé«˜è´¨é‡ã€å¤šæ ·åŒ–çš„SFTæ•°æ®æ˜¯å†³å®šå¾®è°ƒæˆè´¥çš„åŸºçŸ³ï¼Œå¹¶å­¦ä¹ äº†å¦‚ä½•æ„å»ºç¬¦åˆERNIEkitè¦æ±‚çš„æ•°æ®é›†ã€‚\n",
    "\n",
    "é€šè¿‡SFTï¼Œæˆ‘ä»¬èµ‹äºˆäº† ERNIE-4.5-0.3B æ¨¡å‹å…¨æ–°çš„ã€å®šåˆ¶åŒ–çš„èƒ½åŠ›ï¼Œä½¿å…¶ä»ä¸€ä¸ªâ€œåšå­¦çš„é€šæ‰â€å‘â€œä¸“ä¸šçš„åŠ©æ‰‹â€è¿ˆå‡ºäº†åšå®çš„ä¸€æ­¥ã€‚\n",
    "\n",
    "### 6.2 åç»­å­¦ä¹ ä¸æ¢ç´¢æ–¹å‘\n",
    "\n",
    "SFTä¸ºæˆ‘ä»¬æ‰“å¼€äº†é€šå¾€å®šåˆ¶åŒ–å¤§æ¨¡å‹ä¸–ç•Œçš„å¤§é—¨ï¼Œä½†è¿™ä»…ä»…æ˜¯ä¸€ä¸ªå¼€å§‹ã€‚å¤§è¯­è¨€æ¨¡å‹çš„æŠ€æœ¯æ ˆä»åœ¨é£é€Ÿå‘å±•ï¼Œä»¥ä¸‹æ˜¯ä¸€äº›å€¼å¾—æ‚¨è¿›ä¸€æ­¥æ¢ç´¢çš„æ–¹å‘ï¼š\n",
    "\n",
    "*   **å‚æ•°é«˜æ•ˆå¾®è°ƒ (PEFT - Parameter-Efficient Fine-Tuning)** ï¼š\n",
    "    *   **LoRA (Low-Rank Adaptation)** ï¼šå…¨å‚æ•°å¾®è°ƒè™½ç„¶æ•ˆæœå¥½ï¼Œä½†èµ„æºæ¶ˆè€—å¤§ï¼Œä¸”ä¼šä¸ºæ¯ä¸ªä»»åŠ¡éƒ½ä¿å­˜ä¸€ä¸ªå®Œæ•´çš„æ¨¡å‹å‰¯æœ¬ã€‚LoRAæ˜¯ä¸€ç§PEFTæ–¹æ³•ï¼Œå®ƒé€šè¿‡åœ¨æ¨¡å‹çš„æŸäº›å±‚ä¸­æ³¨å…¥å°çš„ã€å¯è®­ç»ƒçš„â€œé€‚é…å™¨â€çŸ©é˜µï¼Œå†»ç»“åŸå§‹çš„å¤§éƒ¨åˆ†æƒé‡ã€‚è¿™æ ·ï¼Œæˆ‘ä»¬åªéœ€è¦è®­ç»ƒå’Œå­˜å‚¨æå°‘éƒ¨åˆ†ï¼ˆé€šå¸¸ä¸åˆ°1%ï¼‰çš„å‚æ•°ï¼Œå°±èƒ½è¾¾åˆ°æ¥è¿‘å…¨å‚æ•°å¾®è°ƒçš„æ•ˆæœã€‚ERNIEkit å¯¹ LoRA æä¾›äº†è‰¯å¥½çš„æ”¯æŒï¼Œæ‚¨åªéœ€åœ¨é…ç½®æ–‡ä»¶ä¸­å°† `fine_tuning: Full` ä¿®æ”¹ä¸º `fine_tuning: lora` å¹¶é…ç½®ç›¸å…³å‚æ•°å³å¯å°è¯•ã€‚\n",
    "\n",
    "*   **ä»äººç±»åé¦ˆä¸­å¼ºåŒ–å­¦ä¹  (RLHF - Reinforcement Learning from Human Feedback)** ï¼š\n",
    "    *   SFTæ•™ä¼šäº†æ¨¡å‹â€œå¬è¯â€ï¼Œä½†å¦‚ä½•è®©æ¨¡å‹çš„å›ç­”æ›´ç¬¦åˆäººç±»çš„åå¥½ï¼ˆä¾‹å¦‚ï¼Œæ›´æœ‰ç”¨ã€æ›´æ— å®³ã€æ›´æœ‰è¶£ï¼‰ï¼ŸRLHFå°±æ˜¯è§£å†³è¿™ä¸ªé—®é¢˜çš„å…³é”®æŠ€æœ¯ã€‚å®ƒé€šè¿‡æ”¶é›†äººç±»å¯¹æ¨¡å‹ä¸åŒå›ç­”çš„åå¥½æ’åºæ•°æ®ï¼Œè®­ç»ƒä¸€ä¸ªâ€œå¥–åŠ±æ¨¡å‹â€ï¼Œç„¶åä½¿ç”¨å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼ˆå¦‚PPOï¼‰æ¥ä¼˜åŒ–è¯­è¨€æ¨¡å‹ï¼Œä½¿å…¶ç”Ÿæˆçš„å†…å®¹èƒ½è·å¾—æ›´é«˜çš„å¥–åŠ±åˆ†æ•°ã€‚è¿™æ˜¯é€šå¾€æ›´é«˜çº§ã€æ›´å¯¹é½çš„AIçš„å¿…ç»ä¹‹è·¯ã€‚\n",
    "\n",
    "*   **æ›´å…ˆè¿›çš„æ¨¡å‹ä¸æŠ€æœ¯** ï¼š\n",
    "    *   æŒç»­å…³æ³¨æ–‡å¿ƒå¤§æ¨¡å‹å’ŒERNIEkitçš„æœ€æ–°è¿›å±•ï¼Œæ¢ç´¢æ›´å¤§å‚æ•°è§„æ¨¡çš„æ¨¡å‹ã€æ›´å…ˆè¿›çš„ç®—æ³•å’Œæ›´é«˜æ•ˆçš„è®­ç»ƒæ¡†æ¶ã€‚\n",
    "\n",
    "*   **æ¨¡å‹éƒ¨ç½²ä¸æœåŠ¡åŒ–** ï¼š\n",
    "    *   å°†æ‚¨å¾®è°ƒå¥½çš„æ¨¡å‹éƒ¨ç½²æˆåœ¨çº¿æœåŠ¡ï¼Œæ˜¯å®ç°å…¶ä»·å€¼çš„æœ€åä¸€å…¬é‡Œã€‚å¯ä»¥æ¢ç´¢å¦‚Paddle Servingã€FastDeployç­‰å·¥å…·ï¼Œå­¦ä¹ å¦‚ä½•è¿›è¡Œæ¨¡å‹é‡åŒ–ã€å‹ç¼©ï¼Œå¹¶æä¾›é«˜æ€§èƒ½çš„æ¨ç†APIã€‚\n",
    "\n",
    "å¤§è¯­è¨€æ¨¡å‹çš„æ—¶ä»£å……æ»¡äº†æ— é™çš„æœºé‡å’ŒæŒ‘æˆ˜ã€‚å¸Œæœ›æœ¬æ•™ç¨‹èƒ½æˆä¸ºæ‚¨æ¢ç´¢è¿™ä¸ªæ¿€åŠ¨äººå¿ƒé¢†åŸŸçš„åšå®èµ·ç‚¹ã€‚æŒç»­å­¦ä¹ ï¼Œä¸æ–­å®è·µï¼Œæ‚¨å°†èƒ½å¤Ÿæ„å»ºå‡ºè¶Šæ¥è¶Šå¼ºå¤§çš„AIåº”ç”¨ã€‚ç¥æ‚¨åœ¨AIçš„æ¢ç´¢ä¹‹è·¯ä¸Šè¡Œç¨³è‡´è¿œï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# é—®é¢˜åé¦ˆ/ä¸æˆ‘è”ç³»ï¼š Wechatï¼šG_Fuji"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
