{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial on Supervised Fine-Tuning (SFT) of Large Language Models Based on ERNIE-4.5-0.3B\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "Welcome to this tutorial on supervised fine-tuning (SFT) of the ERNIE-4.5-0.3B model using ERNIEkit! In the previous pre-training tutorial, we explored how to build a language model from scratch, endowing it with the foundational ability to understand and generate text. However, a pre-trained general-purpose large model is like a well-informed but untrained generalist‚Äîit possesses vast knowledge but may not necessarily follow our specific instructions precisely to complete specific tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 What is Supervised Fine-Tuning (SFT) for Large Language Models?\n",
    "\n",
    "**Supervised Fine-Tuning (SFT)** is a critical step in transforming general-purpose large models into specialized assistants. It involves further training the model based on a pre-trained model using a labeled dataset that includes ‚Äúinstructions (Instruction/Prompt)‚Äù and ‚Äúexpected outputs (Response/Output).‚Äù This process is akin to providing ‚Äúpre-service training‚Äù for a well-rounded generalist, teaching it how to understand and follow human instructions, generate high-quality responses to specific questions, or mimic a particular conversational style and format.\n",
    "\n",
    "**Core differences between SFT and pre-training (PT):**\n",
    "\n",
    "| Feature | Pre-training (PT) | Supervised Fine-Tuning (SFT) |\n",
    "|---|---|---|\n",
    "| **Objective** | Learn general language patterns, grammatical structures, and world knowledge | Learn to follow instructions, solve specific tasks, and align with human intentions and values |\n",
    "| **Data** | Large-scale, **unlabeled** plain text data (e.g., web pages, books, code) | Relatively small-scale, **high-quality labeled** ‚Äúinstruction-output‚Äù pairs |\n",
    "| **Learning Approach** | Unsupervised or self-supervised learning (e.g., predicting the next word) | Supervised learning (learning the mapping from input instructions to desired outputs) |\n",
    "| **Computational Resources** | Typically requires massive resources, including vast amounts of data and extremely long training times | Relatively modest, enabling efficient and rapid iteration on pre-trained models |\n",
    "| **Model Role** | Train a ‚Äúbase model‚Äù (Base Model) to establish foundational capabilities | Perform ‚Äúinstruction tuning‚Äù (Instruction Tuning) on the ‚Äúbase model‚Äù to specialize model behavior |\n",
    "\n",
    "In summary, pre-training enables the model to ‚Äúlearn to speak,‚Äù while supervised fine-tuning teaches the model to ‚Äúspeak properly‚Äù and ‚Äúfollow instructions,‚Äù aligning its behavior with human expectations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Application Scenarios and Significance of SFT\n",
    "\n",
    "SFT is a core technology for unlocking the potential of large language models, with extremely broad significance and application scenarios. We can get a clear picture of this from the table below:\n",
    "\n",
    "|  | Application Scenario | Core Significance | \n",
    "| :---: | :--- | :--- | \n",
    "| üéØ | **Enhancing Task Performance** | By applying SFT on domain-specific instruction data, the model's professionalism, accuracy, and reliability can be significantly improved in tasks such as customer service Q&A, code generation, legal document summarization, and medical consultations. | \n",
    "| üôè | **Model Alignment** | SFT is a critical step in aligning the model with human intentions and values. By designing carefully crafted prompts and desired responses (typically emphasizing usefulness, authenticity, and harmlessness), we can guide the model to generate responsible and helpful content. | \n",
    "| üí¨ | **Building Robust Conversational AI** | All top-tier chatbots have undergone extensive SFT training. This enables them to engage in fluent, natural, and logically coherent multi-turn conversations, truly becoming users' reliable assistants. | \n",
    "| üé≠ | **Adhering to Specific Styles or Formats** | We can train models via SFT to output in fixed formats (e.g., JSON, Markdown), assume specific roles (e.g., Shakespeare, technical expert), or generate text with a particular emotional tone. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Why choose ERNIE-4.5-0.3B for SFT?\n",
    "\n",
    "We chose `ERNIE-4.5-0.3B` as the main model for our SFT practice based on the following key advantages:\n",
    "\n",
    "|  | Advantage | Detailed explanation |\n",
    "| :---: | :--- | :--- |\n",
    "| üèÜ | **Exceptional pre-training foundation** | As the latest member of the Wenxin large model family, `ERNIE-4.5-0.3B` has undergone extensive pre-training with massive, high-quality data, endowing it with world-leading Chinese language processing capabilities and general language understanding abilities. This serves as an exceptionally robust starting point for SFT. |\n",
    "| üí∞ | **Moderate parameter scale with high cost-effectiveness** | With 0.3B (300 million) parameters, full-parameter SFT is now feasible on consumer-grade or mainstream computing resources. This significantly lowers the barrier for developers and researchers to conduct experiments and rapid iterations, making it one of the best choices for exploring SFT. |\n",
    "| üõ†Ô∏è | **Comprehensive support from ERNIEkit** | ERNIEkit is a development kit tailored for the Wenxin large model by PaddlePaddle, offering end-to-end tools from pre-training, SFT, to inference deployment. Its SFT scripts are carefully optimized to support full-parameter fine-tuning, LoRA, and other parameter-efficient fine-tuning (PEFT) methods, with flexible configurations and user-friendly operation. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Target Audience and Learning Outcomes of This Tutorial\n",
    "\n",
    "This tutorial is designed to help readers from different backgrounds delve into the world of SFT. See which category you belong to and what you will gain:\n",
    "\n",
    "|  | Target Audience | Learning Outcomes (You Will Be Able To) |\n",
    "| :---: | :--- | :--- |\n",
    "| üßë‚Äçüéì | **Advanced Learners** | Gain a deep understanding of the core principles of SFT, its application value, and its fundamental differences from pre-training. |\n",
    "| üë®‚Äçüíª | **Developers/Engineers** | Master the complete process and best practices for conducting SFT on the ERNIE-4.5-0.3B model using ERNIEkit. |\n",
    "| üî¨ | **Researchers** | Understand the standard format and construction methods for SFT data, and gain an initial understanding of parameter-efficient fine-tuning (PEFT) techniques such as LoRA. |\n",
    "| üöÄ | **All Readers** | Learn how to interpret and configure ERNIEkit's SFT `yaml` files, launch training tasks, analyze the training process, and finally perform inference testing on the fine-tuned model to intuitively experience the enhanced capabilities brought by SFT. |\n",
    "\n",
    "Now, let‚Äôs embark on this journey together and use SFT technology to ‚Äútrain‚Äù the powerful ERNIE-4.5-0.3B model into a more intelligent and capable AI assistant tailored to your needs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Environment Preparation\n",
    "\n",
    "The first step in performing supervisory fine-tuning (SFT) is to set up a stable and efficient development environment. This includes installing the core deep learning framework PaddlePaddle, the model development kit ERNIEkit, and preparing the star of our practice‚Äîthe ERNIE-4.5-0.3B model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Install PaddlePaddle and aistudio-sdk\n",
    "\n",
    "Ensure that you have installed the latest or recommended version of PaddlePaddle. We recommend using the GPU version of PaddlePaddle for optimal training speed. Additionally, we need to install `aistudio-sdk`, a convenient tool that helps us easily download model resources from AI-Studio.\n",
    "\n",
    "*Students running this project on AI Studio do not need to run the environment installation code block below.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ensure pip is the latest version\n",
    "!python -m pip install --upgrade pip\n",
    "\n",
    "# Install PaddlePaddle (GPU version, recommended to use the latest stable version)\n",
    "# If your environment (such as CUDA version) is different, please visit the official website to obtain the corresponding instructions: https://www.paddlepaddle.org.cn/install/quick\n",
    "!python -m pip install paddlepaddle-gpu -i https://mirror.baidu.com/pypi/simple\n",
    "\n",
    "# Install aistudio-sdk\n",
    "!pip install --upgrade aistudio-sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verify installation**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:57:48.734168Z",
     "iopub.status.busy": "2025-07-17T10:57:48.733664Z",
     "iopub.status.idle": "2025-07-17T10:57:50.521500Z",
     "shell.execute_reply": "2025-07-17T10:57:50.520994Z",
     "shell.execute_reply.started": "2025-07-17T10:57:48.734146Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/utils/cpp_extension/extension_utils.py:715: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\r\n",
      "  warnings.warn(warning_message)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PaddlePaddle Version: 3.1.0\r\n",
      "Running verify PaddlePaddle program ... \r\n",
      "PaddlePaddle works well on 1 GPU.\r\n",
      "PaddlePaddle is installed successfully! Let's start deep learning with PaddlePaddle now.\r\n",
      "PaddlePaddle GPU is available! Found 1 GPU(s).\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0717 18:57:50.384768   265 pir_interpreter.cc:1524] New Executor is Running ...\r\n",
      "W0717 18:57:50.386147   265 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.8, Runtime API Version: 12.6\r\n",
      "I0717 18:57:50.386685   265 pir_interpreter.cc:1547] pir interpreter is running by multi-thread mode ...\r\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "\n",
    "print(f\"PaddlePaddle Version: {paddle.__version__}\")\n",
    "\n",
    "# Check if GPU is available\n",
    "\n",
    "try:\n",
    "    paddle.utils.run_check()\n",
    "    if paddle.device.cuda.device_count() > 0:\n",
    "        print(f\"PaddlePaddle GPU is available! Found {paddle.device.cuda.device_count()} GPU(s).\")\n",
    "    else:\n",
    "        print(\"PaddlePaddle GPU check passed, but no GPU found. Will use CPU.\")\n",
    "except Exception as e:\n",
    "    print(f\"PaddlePaddle GPU check failed: {e}\")\n",
    "    print(\"If you intended to use GPU, please check your CUDA setup and PaddlePaddle installation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Download the ERNIEkit repository code and the ERNIE-4.5-0.3B model\n",
    "\n",
    "The ERNIEkit SFT script (`train.py`) and related models and training configuration files are located in its official repository. Additionally, we need to use the `aistudio` command-line tool to download the ERNIE-4.5-0.3B model weights.\n",
    "\n",
    "*Students running AI Studio do not need to run the code block below*\n",
    "\n",
    "- ERNIE: /home/aistudio/ERNIE-develop.zip\n",
    "- model: /home/aistudio/data/models/30654/ERNIE-4.5-0.3B-Base-Paddle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1. Clone the ERNIEkit repository\n",
    "# We will clone the latest ERNIE-develop branch to get the latest features and optimizations.\n",
    "!git clone https://github.com/PaddlePaddle/ERNIE.git -b develop ERNIE-develop\n",
    "\n",
    "# 2. Download the ERNIE-4.5-0.3B model weights.\n",
    "# Use the command line tool provided by aistudio-sdk to download.\n",
    "# The model will be downloaded to the baidu/ERNIE-4.5-0.3B-Paddle directory.\n",
    "!aistudio download --model PaddlePaddle/ERNIE-4.5-0.3B-Paddle --local_dir baidu/ERNIE-4.5-0.3B-Paddle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important directory structure explanation**:\n",
    "\n",
    "After executing the above commands, your working directory should have a structure similar to the following:\n",
    "\n",
    "```.\n",
    "\n",
    "‚îú‚îÄ‚îÄ ERNIE-develop/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ examples/\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ configs/\n",
    "‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ERNIE-4.5-0.3B/\n",
    "‚îÇ   ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ sft/\n",
    "‚îÇ   ‚îÇ   ‚îÇ           ‚îî‚îÄ‚îÄ run_sft_8k.yaml  <-- This is our SFT configuration file\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ data/\n",
    "‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ sft-train.jsonl        <-- This is the example SFT data\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ train.py                     <-- This is the ERNIEkit training script\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ ... (other ERNIEkit code)\n",
    "‚îî‚îÄ‚îÄ baidu/\n",
    "    ‚îî‚îÄ‚îÄ ERNIE-4.5-0.3B-Paddle/       <-- This is where the model weights and configuration files are stored\n",
    "        ‚îú‚îÄ‚îÄ model_state.pdparams\n",
    "        ‚îú‚îÄ‚îÄ tokenizer_config.json\n",
    "        ‚îî‚îÄ‚îÄ ... (other model files)\n",
    "```\n",
    "\n",
    "For Ai Studio users, the model directory is located in the data folder!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the subsequent tutorials, we will mainly operate in the `ERNIE-develop` directory and use the `train.py` script. combined with the `examples/configs/ERNIE-4.5-0.3B/sft/run_sft_8k.yaml` configuration file, to load the model from the `baidu/ERNIE-4.5-0.3B-Paddle` directory for fine-tuning.\n",
    "\n",
    "Please ensure that your directory structure matches this to proceed smoothly with the subsequent steps.\n",
    "\n",
    "The environment and resources are now ready. Let‚Äôs delve into the core of SFT‚Äîthe data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SFT Data Preparation\n",
    "\n",
    "‚ÄúGarbage in, garbage out.‚Äù This famous saying is perfectly illustrated in SFT. The effectiveness of SFT depends largely on the quality of the instructional data used. High-quality data can guide the model to learn correct behavioral patterns, while low-quality data may cause the model to produce biased, inaccurate, or even harmful outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Characteristics and Format of SFT Data\n",
    "\n",
    "SFT data consists of paired ‚Äúinstructions (Instruction/Prompt)‚Äù and ‚Äúdesired outputs (Response/Output)‚Äù. ERNIEkit uses the JSON Lines (jsonl) format, where each line represents an independent JSON object, corresponding to a training sample. This format is clear, scalable, and highly suitable for processing large-scale datasets.\n",
    "\n",
    "** Detailed explanation of ERNIEkit SFT data format:**\n",
    "\n",
    "A standard ERNIEkit SFT sample structure is as follows:\n",
    "\n",
    "```json\n",
    "{‚Äúsrc‚Äù: ‚ÄúHello‚Äù, ‚Äòtgt‚Äô: ‚ÄúHello! It's a pleasure to serve you.‚Äù}\n",
    "{‚Äúsrc‚Äù: ‚ÄúPlease write a poem about the moon.‚Äù, ‚Äòtgt‚Äô: \"Bright moonlight before my bed, I wonder if it's frost on the ground. I lift my head to gaze at the bright moon, then lower my head to think of my hometown.\"}\n",
    "```\n",
    "\n",
    "*   `src` (Source): Represents the instructions or questions input to the model. This content undergoes templating processing and serves as the model's input prompt (Prompt).\n",
    "*   `tgt` (Target): Represents the expected response generated by the model. This is the target output that the model needs to learn and emulate.\n",
    "\n",
    "**The Importance of Dialogue Templates:**\n",
    "\n",
    "Dialogue models like ERNIE-4.5 typically follow a specific dialogue template during training. This template defines the roles of the user and assistant and uses special tokens to separate different rounds. The ERNIEkit training script automatically wraps `src` and `tgt` into the template format used during model pre-training. For example, a simplified template might look like this:\n",
    "\n",
    "```\n",
    "<|im_start|>user\n",
    "{src}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "{tgt}<|im_end|>\n",
    "```\n",
    "\n",
    "During training, the model's task is to generate the `assistant` portion based on the `user` content. Through this process, the model learns to assume the role of the assistant in the dialogue.\n",
    "\n",
    "**Key Elements of High-Quality SFT Data:**\n",
    "\n",
    "*   **Diversity**: Instructions should cover as many topics and skills as possible, such as question-answering, creation, summarization, translation, code generation, etc.\n",
    "*   **Complexity**: Instructions should include tasks of varying difficulty levels, from simple fact-based questions to complex tasks requiring deep reasoning and creativity.\n",
    "*   **Accuracy**: The content of `tgt` must be accurate, high-quality, and harmless.\n",
    "*   **Consistency**: The style, format, and level of detail of the output should remain consistent unless you intentionally train the model to master multiple styles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Using the sample SFT dataset provided by ERNIEkit\n",
    "\n",
    "ERNIEkit provides a sample dataset named `sft-train.jsonl` in the `ERNIE-develop/examples/data/` directory. This is a small, cleaned dataset that is ideal for quickly running through the SFT process and verifying functionality.\n",
    "\n",
    "Let's take a look at the contents of this sample data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T11:00:53.764115Z",
     "iopub.status.busy": "2025-07-17T11:00:53.763790Z",
     "iopub.status.idle": "2025-07-17T11:00:53.768344Z",
     "shell.execute_reply": "2025-07-17T11:00:53.767908Z",
     "shell.execute_reply.started": "2025-07-17T11:00:53.764095Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View sample data: ./ERNIE-develop/examples/data/sft-train.jsonl\r\n",
      "---\r\n",
      "„Äêsample 1„Äë\r\n",
      "  SRC: ['Êàë‰ª¨Â¶Ç‰ΩïÂú®Êó•Â∏∏ÁîüÊ¥ª‰∏≠ÂáèÂ∞ëÁî®Ê∞¥Ôºü']\r\n",
      "  TGT: ['1. ‰ΩøÁî®ËäÇÊ∞¥Ë£ÖÁΩÆÔºåÂ¶ÇËäÇÊ∞¥Ê∑ãÊµ¥Âñ∑Â§¥ÂíåÊ∞¥ÈæôÂ§¥„ÄÇ \\n2. ‰ΩøÁî®Ê∞¥ÁÆ±ÊàñÊ∞¥Ê°∂Êî∂ÈõÜÂÆ∂Â∫≠Â∫üÊ∞¥Ôºå‰æãÂ¶ÇÊ¥óÁ¢óÂíåÊ¥óÊµ¥„ÄÇ \\n3. Âú®Á§æÂå∫‰∏≠ÊèêÈ´òËäÇÊ∞¥ÊÑèËØÜ„ÄÇ \\n4. Ê£ÄÊü•Ê∞¥ÁÆ°ÂíåÁÅåÊ∫âÁ≥ªÁªüÁöÑÊºèÊ∞¥ÊÉÖÂÜµÔºåÂπ∂ÂèäÊó∂‰øÆÂ§çÂÆÉ‰ª¨„ÄÇ \\n5. Ê¥óÊæ°Êó∂Èó¥Áº©Áü≠Ôºå‰ΩøÁî®‰ΩéÊµÅÈáèÊ∑ãÊµ¥Â§¥ËäÇÁ∫¶Áî®Ê∞¥„ÄÇ \\n6. Êî∂ÈõÜÈõ®Ê∞¥ÔºåÁî®‰∫éÂõ≠Ëâ∫ÊàñÂÖ∂‰ªñÈùûÈ•ÆÁî®ÁõÆÁöÑ„ÄÇ \\n7. Âà∑ÁâôÊàñÊì¶ÊâãÊó∂ÂÖ≥ÊéâÊ∞¥ÈæôÂ§¥„ÄÇ \\n8. ÂáèÂ∞ëÊµáÊ∞¥ËçâÂù™ÁöÑÊó∂Èó¥„ÄÇ \\n9. Â∞ΩÂèØËÉΩÂ§öÂú∞ÈáçÂ§ç‰ΩøÁî®ÁÅ∞Ê∞¥ÔºàÊù•Ëá™Ê¥óË°£Êú∫„ÄÅÊµ¥ÂÆ§Ê∞¥ÊßΩÂíåÊ∑ãÊµ¥ÁöÑÊ∞¥Ôºâ„ÄÇ \\n10. Âè™Ë¥≠‰π∞ËÉΩÊ∫êÊïàÁéáÈ´òÁöÑÊ¥óÁ¢óÊú∫ÂíåÊ¥óË°£Êú∫„ÄÇ']\r\n",
      "\r\n",
      "„Äêsample 2„Äë\r\n",
      "  SRC: ['ÊîøÂ∫úÂèØ‰ª•ÈááÂèñÂì™‰∫õÁ≠ñÁï•Êù•ÂáèÂ∞ëÁ©∫Ê∞îÊ±°ÊüìÔºü']\r\n",
      "  TGT: ['1. ÂÆûÊñΩÂº∫Âà∂ÁöÑËΩ¶ËæÜÊéíÊîæÊ†áÂáÜÂíåÂü∫‰∫éÊøÄÂä±ÁöÑËÆ°ÂàíÔºå‰ª•Èôç‰ΩéËΩ¶ËæÜÁöÑÁ¢≥Ë∂≥Ëøπ„ÄÇ\\n2. Â¢ûÂä†ÂÖ¨ÂÖ±‰∫§ÈÄöÂ∑•ÂÖ∑ÔºåÂáèÂ∞ëÂÖ¨‰ºóÂØπËΩ¶ËæÜÁöÑ‰æùËµñ„ÄÇ\\n3. Â¢ûÂä†ÂØπÁ©∫Ê∞îÊ±°ÊüìÁöÑÂΩ±ÂìçÁöÑËÆ§ËØÜÔºåÈºìÂä±Â∏ÇÊ∞ëÂáèÂ∞ëÊ±°ÊüìÁâ©ÁöÑÁîüÊàê„ÄÇ\\n4. ÊäïËµÑ‰∫éÂèØÂÜçÁîüËÉΩÊ∫êÁöÑÁ†îÁ©∂ÂíåÂºÄÂèëÔºåÂ¶ÇÂ§™Èò≥ËÉΩÂíåÈ£éËÉΩ„ÄÇ\\n5. Âú®Â∑•ÂéÇÂíåÂèëÁîµÂéÇÂÆâË£ÖÁ©∫Ê∞îÊ±°ÊüìÊéßÂà∂Ë£ÖÁΩÆÔºå‰æãÂ¶ÇÊ¥óÊ∂§Âô®„ÄÇ\\n6. ÂØπËΩ¶ËæÜÂíåÂ∑•ÂéÇ‰ΩøÁî®Ê∏ÖÊ¥ÅÁáÉÊñô„ÄÇ\\n7. ÂÆûÊñΩÊõ¥Â•ΩÁöÑÂüéÂ∏ÇËßÑÂàíÂíåÊéßÂà∂ÊãìÂ±ï„ÄÇ\\n8. ÊîπÂñÑÂÜú‰∏öÊïàÁéáÔºåÂáèÂ∞ëÂåñËÇ•ÂíåÊùÄËô´ÂâÇÁöÑ‰ΩøÁî®„ÄÇ\\n9. ÁßçÊ§çÊõ¥Â§öÁöÑÊ†ëÊú®‰ª•ÂáèÂ∞ëÁ©∫Ê∞îÊ±°Êüì„ÄÇ\\n10. ÂáèÂ∞ëÊú®Êùê„ÄÅÁÖ§ÁÇ≠ÂíåÁîüÁâ©Ë¥®ÁöÑÁáÉÁÉß„ÄÇ']\r\n",
      "\r\n",
      "„Äêsample 3„Äë\r\n",
      "  SRC: ['ÂèØÂÜçÁîüËÉΩÊ∫êÁöÑÂ≠òÂú®ÂØπÁéØÂ¢ÉÊúâ‰ªÄ‰πàÂΩ±ÂìçÔºü']\r\n",
      "  TGT: ['ÂèØÂÜçÁîüËÉΩÊ∫êÁöÑÂ≠òÂú®ÂèØ‰ª•Â∏ÆÂä©ÂáèÂ∞ëÁ©∫Ê∞îÊ±°ÊüìÂíåÊ∏©ÂÆ§Ê∞î‰ΩìÊéíÊîæÔºåÂõ†‰∏∫ÂÆÉ‰ª¨Âá†‰πé‰∏ç‰ºöÊéíÊîæ‰∫åÊ∞ßÂåñÁ¢≥„ÄÅ‰∫åÊ∞ßÂåñÁ°´Á≠âÁ©∫Ê∞îÊ±°ÊüìÁâ©„ÄÇÊ≠§Â§ñÔºå‰ΩøÁî®ÂèØÂÜçÁîüËÉΩÊ∫êÂèØ‰ª•‰øÉËøõËÉΩÊ∫êÊïàÁéáÁöÑËøõ‰∏ÄÊ≠•ÊèêÈ´òÂíåËÉΩÊ∫êÂà©Áî®ÁöÑÊîπÂñÑ„ÄÇÂèØÂÜçÁîüËÉΩÊ∫ê‰πüÂèØ‰ª•Â∏ÆÂä©ÂáèÂ∞ëÂØπÂåñÁü≥ÁáÉÊñôÁöÑ‰æùËµñÔºåËøô‰∏ç‰ªÖÂèØ‰ª•ÂáèÂ∞ëÊéíÊîæÔºåËÄå‰∏îËøòÂèØ‰ª•Â∏ÆÂä©ÂáèÂ∞ëÂÖ®ÁêÉÊ∞îÂÄôÂèòÂåñÁöÑÈ£éÈô©„ÄÇÊúÄÂêéÔºåÂèØÂÜçÁîüËÉΩÊ∫êÂèØ‰ª•Â∏ÆÂä©‰øùÊä§Ëá™ÁÑ∂ËµÑÊ∫êÔºåÂáèÂ∞ë‰∏∫‰∫ÜËÉΩÊ∫êÁîü‰∫ßËÄåÂºÄÂèëÊõ¥Â§öÂúüÂú∞ÂíåËµÑÊ∫êÁöÑÈúÄË¶Å„ÄÇ']\r\n",
      "\r\n",
      "„Äêsample 4„Äë\r\n",
      "  SRC: ['Ëß£ÈáäÁ•ûÁªèÁΩëÁªúÂ¶Ç‰ΩïÂ≠¶‰π†„ÄÇ']\r\n",
      "  TGT: ['Á•ûÁªèÁΩëÁªúÊòØ‰∏ÄÁßçÊú∫Âô®Â≠¶‰π†ÁÆóÊ≥ïÔºåÂÆÉ‰ΩøÁî®ËøûÊé•ÁöÑËäÇÁÇπÈõÜÂêàÊù•Ëøë‰ººÂèØ‰ª•Â∞ÜËæìÂÖ•ÂèòÈáèÊò†Â∞ÑÂà∞ËæìÂá∫ÁöÑÂáΩÊï∞„ÄÇ‰∏∫‰∫ÜÂ≠¶‰π†Á•ûÁªèÁΩëÁªúÁöÑÂèÇÊï∞ÔºåËÆ°ÁÆóÊú∫ÈúÄË¶ÅË∞ÉÊï¥ËäÇÁÇπ‰πãÈó¥ËøûÊé•ÁöÑÊùÉÈáçÔºå‰ª•‰æøÁΩëÁªú‰∏∫ÁªôÂÆöËæìÂÖ•‰∫ßÁîüÊ≠£Á°ÆÁöÑËæìÂá∫„ÄÇËøô‰∏™Ë∞ÉÊï¥ËøáÁ®ãÁß∞‰∏∫Â≠¶‰π†ÔºåÈÄöËøáÊØîËæÉÁΩëÁªú‰∫ßÁîüÁöÑËæìÂá∫ÂíåÊúüÊúõÁöÑÁªìÊûúÔºåÁÑ∂Âêé‰ΩøÁî®‰ºòÂåñÁÆóÊ≥ïÊù•Ë∞ÉÊï¥ÊùÉÈáçÔºå‰ΩøÂæóÁΩëÁªúËæìÂá∫ÈÄºËøëÊúüÊúõÁöÑÁªìÊûú„ÄÇËøô‰∏™ËøáÁ®ãÂú®Â§ö‰∏™ËæìÂÖ•ÂíåÊúüÊúõÁöÑËæìÂá∫‰∏äÈáçÂ§çËøõË°åÂ§öÊ¨°Ëø≠‰ª£„ÄÇÊúÄÁªàÔºåËøûÊé•ËäÇÁÇπ‰πãÈó¥ÁöÑÊùÉÈáçÂ∞ÜË¢´Ë∞ÉÊï¥Ôºå‰ª•‰æøÁ•ûÁªèÁΩëÁªúÁöÑËæìÂá∫‰∏éÊúüÊúõÁöÑÁªìÊûúÁõ∏ÂåπÈÖçÔºåÂ≠¶‰π†ËøáÁ®ãÂ∞ÜÂÆåÊàê„ÄÇ']\r\n",
      "\r\n",
      "„Äêsample 5„Äë\r\n",
      "  SRC: ['ÁªôÂá∫‰∏Ä‰∏™Êú∫Âô®Â≠¶‰π†ÁÆóÊ≥ïÁöÑ‰æãÂ≠êÔºåÂπ∂Ëß£ÈáäÂÆÉÊòØÂ¶Ç‰ΩïÂ∑•‰ΩúÁöÑ„ÄÇ']\r\n",
      "  TGT: ['‰∏Ä‰∏™ÊµÅË°åÁöÑÊú∫Âô®Â≠¶‰π†ÁÆóÊ≥ïÁöÑ‰æãÂ≠êÊòØÊîØÊåÅÂêëÈáèÊú∫ÔºàSVMÔºâ„ÄÇÂÆÉÊòØ‰∏Ä‰∏™Áî®‰∫éÂàÜÁ±ªÂíåÂõûÂΩí‰ªªÂä°ÁöÑÁõëÁù£Â≠¶‰π†ÁÆóÊ≥ï„ÄÇÂÆÉÈÄöËøáÂú®nÁª¥Á©∫Èó¥‰∏≠ÁªòÂà∂Êï∞ÊçÆÁÇπÔºåÁî±Á©∫Èó¥‰∏≠ÁöÑÂÜ≥Á≠ñËæπÁïåÊàñË∂ÖÂπ≥Èù¢ËøõË°åÂàÜÁ¶ª„ÄÇËØ•ÁÆóÊ≥ï‰ΩøÁî®ÊúÄÂ§ßËæπË∑ùÔºåËøô‰∫õËæπË∑ùÂ∞ΩÂèØËÉΩËøúÁ¶ª‰∏§Á±ªÊï∞ÊçÆÁÇπ„ÄÇËøô‰∫õËæπË∑ùÊúâÂä©‰∫éÂàõÂª∫ÊúÄ‰ºòÁöÑÂÜ≥Á≠ñË∂ÖÂπ≥Èù¢„ÄÇÁÑ∂ÂêéÔºåÁÆóÊ≥ïÈÄöËøáËÄÉËôëÂàÜÁ±ª‰ªªÂä°‰∏≠ÂèëÁîüÁöÑÈîôËØØÊù•Ë∞ÉÊï¥ÂÜ≥Á≠ñË∂ÖÂπ≥Èù¢ÔºåÂπ∂Áõ∏Â∫îÂú∞‰øÆÊîπË∂ÖÂπ≥Èù¢„ÄÇ\\n\\nÊúÄÁªàÔºåÊîØÊåÅÂêëÈáèÊú∫ÂèØ‰ª•‰ΩøÁî®ÊúÄ‰ºòÁöÑÂÜ≥Á≠ñË∂ÖÂπ≥Èù¢ÊâßË°åÂàÜÁ±ª‰ªªÂä°ÔºåÈ¢ÑÊµãÊï∞ÊçÆÁÇπÁöÑÁ±ªÂà´„ÄÇ']\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Define sample data path\n",
    "sample_data_path = \"./ERNIE-develop/examples/data/sft-train.jsonl\"\n",
    "\n",
    "# Read and print the first 5 samples\n",
    "print(f\"View sample data:{sample_data_path}\\n---\")\n",
    "with open(sample_data_path, 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= 5:\n",
    "            break\n",
    "        data_sample = json.loads(line.strip())\n",
    "        print(f\"„Äêsample {i+1}„Äë\")\n",
    "        print(f\"  SRC: {data_sample['src']}\")\n",
    "        print(f\"  TGT: {data_sample['tgt']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 How to Prepare Your Own SFT Dataset\n",
    "\n",
    "In practical applications, you typically need to build a dataset tailored to your specific needs. The following are the general steps for constructing a custom SFT dataset:\n",
    "\n",
    "1.  **Define the Target Task**: Clearly identify the capabilities you want the model to possess. Is it for intelligent customer service in a vertical field, or for generating marketing copy in a specific style?\n",
    "2.  **Collect or generate raw data**:\n",
    "*   **Collect**: Extract ‚Äúquestion-answer‚Äù pairs from existing documents, tickets, FAQs, or user logs.\n",
    "*   **Manual annotation**: Hire domain experts or annotators to write high-quality prompts and responses based on task requirements.\n",
    "    *   **Model generation**: Use more powerful models (such as GPT-4) to generate preliminary instructions and answers, then have them screened and refined by humans. This is one of the mainstream methods for building large-scale SFT datasets.\n",
    "3.  **Cleaning and formatting**: \n",
    "    *   Remove low-quality, duplicate, or irrelevant data.\n",
    "    * Perform data augmentation, e.g., for the same instruction, there can be multiple different ways to phrase the question.  \n",
    "    * Organize the data into the `jsonl` format required by ERNIEkit, i.e., each line contains a JSON object with `src` and `tgt` keys.\n",
    "4.  **Split the dataset**: Split the dataset into a training set (train) and an evaluation set (eval/dev). The evaluation set is used to monitor model performance during training and prevent overfitting. The typical ratio is 95%:5% or 98%:2%.\n",
    "\n",
    "Preparing high-quality data is the cornerstone of SFT success. Now that we have covered data preparation, the next step is to delve into the ERNIEkit SFT configuration file to understand how to control the entire fine-tuning process through it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. SFT Configuration Analysis (`run_sft_8k.yaml`)\n",
    "\n",
    "The power of ERNIEkit lies in its flexibility and configurability. All training parameters are centralized in a `yaml` configuration file, and by modifying this file, we can precisely control every aspect of the SFT. Let‚Äôs take `ERNIE-develop/examples/configs/ERNIE-4.5-0.3B/sft/run_sft_8k.yaml` as an example and analyze the key configuration items one by one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Data Configuration (Data)\n",
    "\n",
    "This section defines the data sets used for training and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "### data\n",
    "train_dataset_type: ‚Äúerniekit‚Äù\n",
    "eval_dataset_type: ‚Äúerniekit‚Äù\n",
    "train_dataset_path: ‚Äú./examples/data/sft-train.jsonl‚Äù\n",
    "train_dataset_prob: ‚Äú1.0‚Äù\n",
    "eval_dataset_path: ‚Äú./examples/data/sft-eval.jsonl‚Äù\n",
    "eval_dataset_prob: ‚Äú1.0‚Äù\n",
    "max_seq_len: 8192\n",
    "num_samples_each_epoch: 6000000\n",
    "```\n",
    "\n",
    "* `train_dataset_type`, `eval_dataset_type`: Dataset format type, here it is `erniekit`, indicating the use of the previously discussed `{‚Äúsrc‚Äù: ..., ‚Äútgt‚Äù: ...}` format.\n",
    "*   `train_dataset_path`, `eval_dataset_path`: Paths to the training and evaluation datasets. **You need to modify these to your own data paths.**\n",
    "* `train_dataset_prob`, `eval_dataset_prob`: Dataset sampling probability. When there are multiple datasets, you can set different probabilities for mixed training.\n",
    "* `max_seq_len`: Maximum sequence length processed by the model. `8192` (8K) is a common setting for ERNIE-4.5, which can handle very long contexts. If your GPU memory is limited, you can reduce this value appropriately, but this may affect the model's ability to process long texts.\n",
    "*   `num_samples_each_epoch`: The number of samples included in each epoch. This value is typically set to a large number to ensure the model sees enough data in each epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Model Configuration (Model)\n",
    "\n",
    "This section defines the base model to be fine-tuned and its related settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "### model\n",
    "model_name_or_path: baidu/ERNIE-4.5-0.3B-Paddle\n",
    "fine_tuning: Full\n",
    "fuse_rope: True\n",
    "use_sparse_head_and_loss_fn: True\n",
    "```\n",
    "\n",
    "* `model_name_or_path`: **Core parameter**. Specifies the path to the base model. Here, we use the previously downloaded `baidu/ERNIE-4.5-0.3B-Paddle`.\n",
    "* `fine_tuning`: Fine-tuning method. `Full` indicates full parameter fine-tuning, i.e., updating all model weights. This is the most thorough but also the most resource-intensive method. Other options such as `lora` will be introduced later.\n",
    "* `fuse_rope`: Whether to use the optimized Rotary Position Embedding. `True` can improve computational efficiency.\n",
    "* `use_sparse_head_and_loss_fn`: Whether to use sparse head and loss functions. This is an optimization for specific model structures; keep the default setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Fine-tuning Core Configuration (Finetuning)\n",
    "\n",
    "This is the core part that controls the entire training process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "### finetuning\n",
    "# base\n",
    "stage: SFT\n",
    "seed: 23\n",
    "do_train: True\n",
    "do_eval: True\n",
    "distributed_dataloader: False\n",
    "dataloader_num_workers: 1\n",
    "batch_size: 1\n",
    "num_train_epochs: 1\n",
    "max_steps: 100\n",
    "max_evaluate_steps: 10000\n",
    "eval_steps: 10000\n",
    "evaluation_strategy: steps\n",
    "save_steps: 10000000\n",
    "save_total_limit: 5\n",
    "save_strategy: steps\n",
    "logging_steps: 1\n",
    "release_grads: True\n",
    "gradient_accumulation_steps: 8\n",
    "logging_dir: ./vdl_log\n",
    "output_dir: ./output\n",
    "disable_tqdm: True\n",
    "```\n",
    "\n",
    "* `stage`: Training stage, which is `SFT` here.\n",
    "* `seed`: Random seed, used to ensure the reproducibility of experiments.\n",
    "* `do_train`, `do_eval`: Whether to perform training and evaluation.\n",
    "* `batch_size`: **Important**. Batch size on each device. Since large models consume a lot of memory, `1` is a common starting value.\n",
    "* `gradient_accumulation_steps`: **Important**. Number of gradient accumulation steps. This is a ‚Äúvirtual‚Äù technique to increase the batch size. The actual `batch_size` is `batch_size` * `gradient_accumulation_steps` * `num_gpus`. Here, the equivalent batch size is `1 * 8 = 8`. Increasing this value can simulate a larger batch size, which helps stabilize training but slows down the training speed.\n",
    "* `num_train_epochs`: The total number of training epochs. For SFT, typically 1 to 3 epochs are sufficient.\n",
    "* `max_steps`: The maximum number of training steps. If this value is set, it will override `num_train_epochs`. For quick experiments, it can be set to a smaller value (e.g., `100`).\n",
    "* `evaluation_strategy`, `eval_steps`: Evaluation strategy. `steps` indicates that an evaluation is performed every `eval_steps` steps.\n",
    "* `save_strategy`, `save_steps`: Save strategy. `steps` indicates that a checkpoint is saved every `save_steps` steps.\n",
    "* `logging_steps`: How many steps to print a log.\n",
    "* `output_dir`: Output directory for training artifacts (such as model checkpoints)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Training and Optimizer Configuration (Train & Optimizer)\n",
    "\n",
    "This section controls hyperparameters such as learning rate and optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "# train\n",
    "warmup_steps: 20\n",
    "learning_rate: 1.0e-5\n",
    "lr_scheduler_type: cosine\n",
    "min_lr: 1.0e-6\n",
    "\n",
    "# optimizer\n",
    "weight_decay: 0.1\n",
    "adam_epsilon: 1.0e-8\n",
    "adam_beta1: 0.9\n",
    "adam_beta2: 0.95\n",
    "offload_optim: True\n",
    "```\n",
    "\n",
    "* `learning_rate`: **Core hyperparameter**. The size of the learning rate directly affects the convergence speed and final performance of the model. `1.0e-5` is a commonly used value for fine-tuning all parameters. For PEFT methods such as LoRA, a larger learning rate may be required.\n",
    "* `lr_scheduler_type`: Learning rate scheduling strategy. `cosine` indicates the use of the cosine annealing strategy, which is a highly effective and commonly used strategy.\n",
    "* `warmup_steps`: Warmup steps. During the initial training phase, the learning rate linearly increases from a very small value to the specified `learning_rate`, which helps stabilize the training process.\n",
    "* `weight_decay`: Weight decay, a regularization technique to prevent overfitting.\n",
    "* `offload_optim`: Whether to offload the optimizer state to CPU memory. This is a memory-saving technique but may slightly reduce training speed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Performance and Parallel Configuration\n",
    "\n",
    "This section is used to configure distributed training and mixed precision training to improve efficiency and save resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "# performance\n",
    "tensor_parallel_degree: 1\n",
    "pipeline_parallel_degree: 1\n",
    "sharding_parallel_degree: 1\n",
    "sharding: stage1\n",
    "sequence_parallel: True\n",
    "recompute: False\n",
    "compute_type: bf16\n",
    "fp16_opt_level: O2\n",
    "```\n",
    "\n",
    "* `tensor_parallel_degree`, `pipeline_parallel_degree`, `sharding_parallel_degree`: Parallelism degree for distributed training. For single-card training, these should all be set to `1`.\n",
    "* `sharding`: ZeRO optimization strategy. `stage1` can significantly save memory when training with multiple cards.\n",
    "* `sequence_parallel`: Sequence parallelism, a memory optimization technique for long sequences.\n",
    "* `recompute` (Gradient Checkpointing): **Important**. A technique that trades computation for memory. Setting this to `True` will recomputes intermediate results from the forward pass during backpropagation instead of storing them. This can significantly reduce memory consumption but increases training time by approximately 20-30%. **Enabling this option is recommended when memory is insufficient.**\n",
    "* `compute_type`: Computation precision. `bf16` (BFloat16) is a half-precision floating-point format designed specifically for deep learning. It significantly reduces memory usage and accelerates computation while maintaining good numerical stability. It is recommended for use on supported hardware (such as NVIDIA A100/H100, RTX 30/40 series).\n",
    "* `fp16_opt_level`: Mixed-precision training level. `O2` is a commonly used setting that can be used in conjunction with `bf16`.\n",
    "\n",
    "With an understanding of these configuration options, you now have the ability to freely customize the SFT process. In the next section, we will integrate all this knowledge and formally launch the SFT training task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Start SFT training\n",
    "\n",
    "With the theory and configuration ready, it's time to start SFT training and witness the transformation of the model's capabilities. ERNIEkit can start the entire training process with a simple command."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Start the training command\n",
    "\n",
    "We will use the `train.py` script in the `ERNIE-develop` directory and specify our configuration file `run_sft_8k.yaml`.\n",
    "\n",
    "**Execute in the terminal or command line:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T11:04:20.529339Z",
     "iopub.status.busy": "2025-07-17T11:04:20.528900Z",
     "iopub.status.idle": "2025-07-17T11:04:20.533491Z",
     "shell.execute_reply": "2025-07-17T11:04:20.533022Z",
     "shell.execute_reply.started": "2025-07-17T11:04:20.529305Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/ERNIE-develop\r\n"
     ]
    }
   ],
   "source": [
    "# First, make sure you are in the ERNIE-develop directory.\n",
    "%cd ./ERNIE-develop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T11:05:42.879359Z",
     "iopub.status.busy": "2025-07-17T11:05:42.879042Z",
     "iopub.status.idle": "2025-07-17T11:08:37.765662Z",
     "shell.execute_reply": "2025-07-17T11:08:37.764834Z",
     "shell.execute_reply.started": "2025-07-17T11:05:42.879339Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/utils/cpp_extension/extension_utils.py:715: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\r\n",
      "  warnings.warn(warning_message)\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/utils/cpp_extension/extension_utils.py:715: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\r\n",
      "  warnings.warn(warning_message)\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,655 -----------  Configuration  ----------------------\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 auto_cluster_config: 0\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 auto_parallel_config: None\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 auto_tuner_json: None\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 devices: 0\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 elastic_level: -1\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 elastic_timeout: 30\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 enable_gpu_log: True\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 gloo_port: 6767\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 host: None\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 ips: None\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 job_id: default\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 legacy: False\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 log_dir: erniekit_dist_log\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 log_level: INFO\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 log_overwrite: False\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 master: 127.0.0.1:8080\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 max_restart: 3\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 nnodes: 1\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 nproc_per_node: None\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 rank: -1\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 run_mode: collective\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 server_num: None\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 servers: \r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 sort_ip: False\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 start_port: 6070\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 trainer_num: None\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 trainers: \r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 training_script: /home/aistudio/ERNIE-develop/erniekit/launcher.py\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 training_script_args: ['train', 'examples/configs/ERNIE-4.5-0.3B/sft/run_sft_8k.yaml']\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 with_gloo: 1\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 --------------------------------------------------\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,656 Job: default, mode collective, replicas 1[1:1], elastic False\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,658 Run Pod: lpwbts, replicas 1, status ready\r\n",
      "LAUNCH INFO 2025-07-17 19:05:48,671 Watching Pod: lpwbts, replicas 1, status running\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/utils/cpp_extension/extension_utils.py:715: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\r\n",
      "  warnings.warn(warning_message)\r\n",
      "\u001b[32m[2025-07-17 19:05:50,756] [    INFO]\u001b[0m - user has defined resume_from_checkpoint: None\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:50,756] [    INFO]\u001b[0m - The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:50,789] [    INFO]\u001b[0m - Tensor_parallel_degree = 1. Set sequence_parallel to False.\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,789] [   DEBUG]\u001b[0m - ============================================================\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,789] [   DEBUG]\u001b[0m -      Model Configuration Arguments      \u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,789] [   DEBUG]\u001b[0m - paddle commit id              : cdcd76a93d1dfe767dde768198e1d7c7488b93f6\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,789] [   DEBUG]\u001b[0m - paddleformers commit id       : 053a5a5e2a72cd2d3b997cbcff81b14af9fe4d47\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,789] [   DEBUG]\u001b[0m - add_tail_layers               : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,789] [   DEBUG]\u001b[0m - continue_training             : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,789] [   DEBUG]\u001b[0m - fine_tuning                   : Full\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,789] [   DEBUG]\u001b[0m - fuse_gate_detach_matmul       : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,789] [   DEBUG]\u001b[0m - fuse_linear                   : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,789] [   DEBUG]\u001b[0m - fuse_rms_norm                 : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,789] [   DEBUG]\u001b[0m - fuse_rope                     : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,789] [   DEBUG]\u001b[0m - fuse_softmax_mask             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - fuse_swiglu                   : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - lora                          : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - lora_alpha                    : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - lora_path                     : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - lora_plus_scale               : 1.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - lora_rank                     : 8\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - model_name_or_path            : ../data/models/30654/ERNIE-4.5-0.3B-Base-Paddle\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - moe_aux_loss_lambda           : 1e-05\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - moe_group                     : dummy\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - moe_group_experts             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - moe_multimodal_dispatch_use_allgather: v2-alltoall-unpad\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - moe_orthogonal_loss_lambda    : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - moe_use_aux_free              : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - moe_use_hard_gate             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - moe_z_loss_lambda             : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - no_recompute_layers           : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - offload_recompute_inputs      : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - pp_seg_method                 : layer:Ernie4_5_DecoderLayer|EmptyLayer\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - recompute_granularity         : full\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - recompute_use_reentrant       : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - rslora                        : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - rslora_plus                   : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,790] [   DEBUG]\u001b[0m - stage                         : SFT\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - tensor_parallel_output        : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - use_attn_mask_start_row_indices: True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - use_flash_attention           : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - use_fused_head_and_loss_fn    : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - use_recompute_moe             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - use_sparse_flash_attn         : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - use_sparse_head_and_loss_fn   : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - virtual_pp_degree             : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - \u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - ============================================================\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m -       Data Configuration Arguments      \u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - paddle commit id              : cdcd76a93d1dfe767dde768198e1d7c7488b93f6\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - paddleformers commit id       : 053a5a5e2a72cd2d3b997cbcff81b14af9fe4d47\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - buffer_size                   : 500\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - dataset_type                  : iterable\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - eval_dataset_path             : ./examples/data/sft-eval.jsonl\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - eval_dataset_prob             : 1.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - eval_dataset_type             : erniekit\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - greedy_intokens               : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - in_tokens_batching            : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - mask_out_eos_token            : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - max_prompt_len                : 2048\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,791] [   DEBUG]\u001b[0m - max_seq_len                   : 8192\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,792] [   DEBUG]\u001b[0m - num_comparisons               : 6\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,792] [   DEBUG]\u001b[0m - num_samples_each_epoch        : 6000000\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,792] [   DEBUG]\u001b[0m - offline_dataset_path          : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,792] [   DEBUG]\u001b[0m - random_shuffle                : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,792] [   DEBUG]\u001b[0m - train_dataset_path            : ./examples/data/sft-train.jsonl\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,792] [   DEBUG]\u001b[0m - train_dataset_prob            : 1.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,792] [   DEBUG]\u001b[0m - train_dataset_type            : erniekit\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,792] [   DEBUG]\u001b[0m - use_cls                       : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:50,792] [   DEBUG]\u001b[0m - \u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:50,792] [    INFO]\u001b[0m - The global seed is set to 23, local seed is set to 24 and random seed is set to 23.\u001b[0m\r\n",
      "\u001b[33m[2025-07-17 19:05:50,792] [ WARNING]\u001b[0m - Process rank: -1, device: gpu, world_size: 1, distributed training: False, 16-bits training: True\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:50,792] [    INFO]\u001b[0m - Start to load model ...\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:50,961] [    INFO]\u001b[0m - Loading configuration file ../data/models/30654/ERNIE-4.5-0.3B-Base-Paddle/config.json\u001b[0m\r\n",
      "\u001b[33m[2025-07-17 19:05:50,964] [ WARNING]\u001b[0m - You are using a model of type ernie4_5 to instantiate a model of type ernie4_5_moe. This is not supported for all configurations of models and can yield errors.\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:50,966] [    INFO]\u001b[0m - Loading weights file ../data/models/30654/ERNIE-4.5-0.3B-Base-Paddle/model.safetensors\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:52,982] [    INFO]\u001b[0m - Loaded weights file from disk, setting weights to model.\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:52,983] [    INFO]\u001b[0m - change initializer-range from 0.02 to 0.018041293779826325\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:52,983] [    INFO]\u001b[0m - using moe-group: dummy\u001b[0m\r\n",
      "W0717 19:05:52.987658 17491 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.8, Runtime API Version: 12.6\r\n",
      "\u001b[32m[2025-07-17 19:05:53,265] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,271] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,273] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,279] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,281] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,284] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,286] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,288] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,290] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,293] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,295] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,297] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,300] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,302] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,304] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,361] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,364] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,366] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,370] [    INFO]\u001b[0m - output-weight:[103424, 1024] config.tie_word_embeddings=True\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,371] [    INFO]\u001b[0m - Use fusedRMSNorm\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,451] [    INFO]\u001b[0m - All model checkpoint weights were used when initializing Ernie4_5_MoeForCausalLM.\r\n",
      "\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,452] [    INFO]\u001b[0m - All the weights of Ernie4_5_MoeForCausalLM were initialized from the model checkpoint at ../data/models/30654/ERNIE-4.5-0.3B-Base-Paddle.\r\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use Ernie4_5_MoeForCausalLM for predictions without further training.\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,453] [    INFO]\u001b[0m - Loading configuration file ../data/models/30654/ERNIE-4.5-0.3B-Base-Paddle/generation_config.json\u001b[0m\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddleformers/generation/configuration_utils.py:250: UserWarning: using greedy search strategy. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `decode_strategy=\"greedy_search\" ` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\r\n",
      "  warnings.warn(\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddleformers/generation/configuration_utils.py:255: UserWarning: using greedy search strategy. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `decode_strategy=\"greedy_search\" ` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\r\n",
      "  warnings.warn(\r\n",
      "\u001b[32m[2025-07-17 19:05:53,467] [    INFO]\u001b[0m - Loading model successfully !\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:53,468] [   DEBUG]\u001b[0m - Model config: Ernie4_5_MoeConfig {\r\n",
      "  \"add_tail_layers\": false,\r\n",
      "  \"architectures\": [\r\n",
      "    \"Ernie4_5_ForCausalLM\"\r\n",
      "  ],\r\n",
      "  \"attention_probs_dropout_prob\": 0.0,\r\n",
      "  \"bos_token_id\": 1,\r\n",
      "  \"cachekv_quant\": false,\r\n",
      "  \"compression_ratio\": 1.0,\r\n",
      "  \"dpo_config\": null,\r\n",
      "  \"dtype\": \"bfloat16\",\r\n",
      "  \"enable_delay_scale_loss\": true,\r\n",
      "  \"enable_mtp_magic_send\": false,\r\n",
      "  \"eos_token_id\": 2,\r\n",
      "  \"fuse_gate_detach_matmul\": true,\r\n",
      "  \"fuse_linear\": false,\r\n",
      "  \"fuse_ln\": false,\r\n",
      "  \"fuse_rms_norm\": true,\r\n",
      "  \"fuse_rope\": true,\r\n",
      "  \"fuse_softmax_mask\": false,\r\n",
      "  \"fuse_swiglu\": true,\r\n",
      "  \"global_aux_loss\": false,\r\n",
      "  \"head_dim\": 128,\r\n",
      "  \"hidden_act\": \"silu\",\r\n",
      "  \"hidden_dropout_prob\": 0.0,\r\n",
      "  \"hidden_size\": 1024,\r\n",
      "  \"ignored_index\": -100,\r\n",
      "  \"initializer_range\": 0.018041293779826325,\r\n",
      "  \"intermediate_size\": 3072,\r\n",
      "  \"max_position_embeddings\": 131072,\r\n",
      "  \"max_sequence_length\": 8192,\r\n",
      "  \"micro_batch_size\": -1,\r\n",
      "  \"model_type\": \"ernie4_5_moe\",\r\n",
      "  \"moe_all_to_all_dropout\": 0.0,\r\n",
      "  \"moe_aux_loss_lambda\": 1e-05,\r\n",
      "  \"moe_capacity\": [],\r\n",
      "  \"moe_dense_experts_token_type_id\": 3,\r\n",
      "  \"moe_dropout_prob\": 0.0,\r\n",
      "  \"moe_gate\": \"topk\",\r\n",
      "  \"moe_gate_act\": \"softmax\",\r\n",
      "  \"moe_group_experts\": false,\r\n",
      "  \"moe_group_origin\": \"dummy\",\r\n",
      "  \"moe_group_orthogonal_loss\": true,\r\n",
      "  \"moe_intermediate_size\": 0,\r\n",
      "  \"moe_k\": 2,\r\n",
      "  \"moe_layer_end_index\": 17,\r\n",
      "  \"moe_layer_interval\": 2,\r\n",
      "  \"moe_layer_start_index\": 0,\r\n",
      "  \"moe_multimodal_dispatch_use_allgather\": \"v2-alltoall-unpad\",\r\n",
      "  \"moe_norm_gate_logits\": true,\r\n",
      "  \"moe_num_experts\": null,\r\n",
      "  \"moe_num_shared_experts\": 0,\r\n",
      "  \"moe_orthogonal_loss_lambda\": 0.0,\r\n",
      "  \"moe_rank\": 0,\r\n",
      "  \"moe_reverse_token_drop\": false,\r\n",
      "  \"moe_use_aux_free\": false,\r\n",
      "  \"moe_use_hard_gate\": false,\r\n",
      "  \"moe_world_size\": 1,\r\n",
      "  \"moe_z_loss_lambda\": 0.0,\r\n",
      "  \"multi_token_pred_lambda\": 0.3,\r\n",
      "  \"num_acc_steps\": 8,\r\n",
      "  \"num_attention_heads\": 16,\r\n",
      "  \"num_hidden_layers\": 18,\r\n",
      "  \"num_key_value_heads\": 2,\r\n",
      "  \"num_nextn_predict_layers\": 0,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"paddleformers_version\": \"0.1\",\r\n",
      "  \"pp_seg_method\": \"layer:Ernie4_5_DecoderLayer|EmptyLayer\",\r\n",
      "  \"recompute_granularity\": \"full\",\r\n",
      "  \"recompute_use_reentrant\": true,\r\n",
      "  \"refined_recompute\": {},\r\n",
      "  \"rms_norm_eps\": 1e-05,\r\n",
      "  \"rope_theta\": 500000,\r\n",
      "  \"sinkhorn_2gate\": true,\r\n",
      "  \"sinkhorn_temp\": 0.03,\r\n",
      "  \"skip_recompute_ops\": {},\r\n",
      "  \"tensor_parallel_degree\": -1,\r\n",
      "  \"tie_word_embeddings\": true,\r\n",
      "  \"token_balance_loss\": false,\r\n",
      "  \"token_balance_seqlen\": false,\r\n",
      "  \"use_bias\": false,\r\n",
      "  \"use_flash_attention\": true,\r\n",
      "  \"use_fused_head_and_loss_fn\": false,\r\n",
      "  \"use_recompute_lm_head\": false,\r\n",
      "  \"use_recompute_loss_fn\": false,\r\n",
      "  \"use_recompute_moe\": false,\r\n",
      "  \"use_recompute_mtp\": false,\r\n",
      "  \"use_rmsnorm\": true,\r\n",
      "  \"use_sparse_flash_attn\": true,\r\n",
      "  \"use_sparse_head_and_loss_fn\": true,\r\n",
      "  \"use_var_len_flash_attn\": false,\r\n",
      "  \"vocab_size\": 103424,\r\n",
      "  \"weight_share_add_bias\": true\r\n",
      "}\r\n",
      "\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:53,468] [    INFO]\u001b[0m - [timelog] basemodel loading time: 2.51s (2025-07-17 19:05:53) \u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:54,506] [    INFO]\u001b[0m - Start to create dataset ...\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:54,515] [    INFO]\u001b[0m - ./examples/data/sft-train.jsonl: task prob: 1.0, ori number of examples: 200, target_num_each_epoch: 6000000\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:54,515] [    INFO]\u001b[0m - Creating dataset successfully ...\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:54,516] [    INFO]\u001b[0m - The global seed is set to 23, local seed is set to 24 and random seed is set to 23.\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:54,555] [    INFO]\u001b[0m - max_steps is given, it will override any value given in num_train_epochs\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:54,555] [    INFO]\u001b[0m - Using half precision\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,568] [   DEBUG]\u001b[0m - ============================================================\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,568] [   DEBUG]\u001b[0m -     Training Configuration Arguments    \u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,568] [   DEBUG]\u001b[0m - paddle commit id              : cdcd76a93d1dfe767dde768198e1d7c7488b93f6\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - paddleformers commit id       : 053a5a5e2a72cd2d3b997cbcff81b14af9fe4d47\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - _no_sync_in_gradient_accumulation: True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - actscale_moving_rate          : 0.01\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - adam_beta1                    : 0.9\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - adam_beta2                    : 0.95\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - adam_epsilon                  : 1e-08\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - amp_custom_black_list         : ['reduce_sum', 'softmax_with_cross_entropy', 'c_softmax_with_cross_entropy', 'elementwise_div', 'sin', 'cos']\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - amp_custom_white_list         : ['lookup_table', 'lookup_table_v2', 'flash_attn', 'matmul', 'matmul_v2', 'fused_gemm_epilogue']\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - amp_master_grad               : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - apply_hadamard                : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - apply_online_actscale_step    : 200\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - attention_probs_dropout_prob  : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - auto_parallel_resume_form_hybrid_parallel: False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - batch_size                    : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - beta                          : 0.1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - bf16                          : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - bf16_full_eval                : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,569] [   DEBUG]\u001b[0m - ckpt_quant_stage              : O0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - compute_type                  : bf16\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - context_parallel_degree       : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - count_trained_tokens          : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - current_device                : gpu:0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - data_parallel_config          : \u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - data_parallel_degree          : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - data_parallel_rank            : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - dataloader_drop_last          : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - dataloader_num_workers        : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - dataloader_shuffle            : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - dataset_rank                  : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - dataset_world_size            : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - ddp_find_unused_parameters    : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - decay_steps                   : 100\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - device                        : gpu\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - disable_ckpt_quant            : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - disable_tqdm                  : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - distributed_dataloader        : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - do_eval                       : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - do_export                     : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - do_predict                    : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - do_train                      : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,570] [   DEBUG]\u001b[0m - dpo_benchmark                 : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - dpop_lambda                   : 50\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - dropout_warmup_steps          : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - enable_auto_parallel          : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - enable_zero_cost_checkpoint   : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - eval_accumulation_steps       : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - eval_batch_size               : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - eval_steps                    : 10000\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - evaluation_strategy           : IntervalStrategy.STEPS\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - expert_max_capacity           : 4294967296\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - expert_min_capacity           : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - expert_parallel_degree        : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - expert_tensor_parallel_degree : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - flash_device_save_steps       : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - flatten_param_grads           : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - force_reshard_pp              : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - fp16                          : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - fp16_full_eval                : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - fp16_opt_level                : O2\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - fp8_format_type               : hybrid\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - fuse_sequence_parallel_allreduce: False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - gradient_accumulation_steps   : 8\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - greater_is_better             : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - hadamard_block_size           : 32\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,571] [   DEBUG]\u001b[0m - hidden_dropout_prob           : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - hybrid_parallel_topo_order    : pp_first\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - ignore_data_skip              : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - ignore_load_lr_and_optim      : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - ignore_save_lr_and_optim      : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - label_names                   : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - label_smoothing               : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - layerwise_lr_decay_bound      : 1.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - lazy_data_processing          : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - learning_rate                 : 1e-05\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - load_best_model_at_end        : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - load_sharded_model            : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - local_process_index           : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - local_rank                    : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - log_level                     : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - log_level_replica             : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - log_on_each_node              : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - logging_dir                   : ./vdl_log\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - logging_first_step            : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - logging_steps                 : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - logging_strategy              : IntervalStrategy.STEPS\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - logical_process_index         : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - loss_type                     : sigmoid\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,572] [   DEBUG]\u001b[0m - lr_end                        : 1e-07\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - lr_scheduler_type             : SchedulerType.COSINE\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - max_estimate_samples          : 100000.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - max_evaluate_steps            : 10000\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - max_grad_norm                 : 1.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - max_steps                     : 100\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - metric_for_best_model         : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - metrics_output_path           : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - min_lr                        : 1e-06\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - minimum_eval_times            : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - multi_token_pred_lambda       : 0.3\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - no_cuda                       : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - normalize_logps               : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - num_cycles                    : 0.5\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - num_nextn_predict_layers      : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - num_of_gpus                   : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - num_train_epochs              : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - offload_optim                 : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - offset_alpha                  : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - optim                         : OptimizerNames.ADAMW\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - optim_shard_num               : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - optimizer_name_suffix         : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - ordered_save_group_size       : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,573] [   DEBUG]\u001b[0m - output_dir                    : ./output\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - output_signal_dir             : ./output\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - overwrite_output_dir          : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - pad_token_id                  : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - past_index                    : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - pdc_download_ckpt             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - pdc_download_timeout          : 300\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - per_device_eval_batch_size    : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - per_device_train_batch_size   : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - pipeline_parallel_config      : enable_delay_scale_loss enable_release_grads disable_partial_send_recv\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - pipeline_parallel_degree      : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - pipeline_parallel_rank        : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - power                         : 1.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - prediction_loss_only          : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - pref_loss_ratio               : 1.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - process_index                 : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - quant_input_grad              : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - quant_weight_grad             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - recompute                     : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - ref_model_update_steps        : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - reference_free                : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - refined_recompute             : {}\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - release_grads                 : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,574] [   DEBUG]\u001b[0m - remove_unused_columns         : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - report_to                     : ['visualdl']\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - resume_from_checkpoint        : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - run_name                      : ./output\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - save_on_each_node             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - save_rng_states               : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - save_sharded_model            : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - save_sharding_stage1_model_include_freeze_params: False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - save_steps                    : 10000000\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - save_strategy                 : IntervalStrategy.STEPS\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - save_tokenizer                : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - save_total_limit              : 5\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - scale_loss                    : 32768\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - seed                          : 23\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - sep_parallel_degree           : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - sequence_parallel             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - sequence_parallel_config      : \u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - server_tp_degree              : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - sft_benchmark                 : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - sft_loss_ratio                : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - sharding                      : []\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - sharding_comm_buffer_size_MB  : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - sharding_degree               : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - sharding_parallel_config      : \u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,575] [   DEBUG]\u001b[0m - sharding_parallel_degree      : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - sharding_parallel_mesh_dimension: dp\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - sharding_parallel_rank        : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - should_load_dataset           : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - should_load_sharding_stage1_model: False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - should_log                    : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - should_save                   : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - should_save_model_state       : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - should_save_model_with_tensor_fusion: False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - should_save_sharding_stage1_model: False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - simpo_gamma                   : 0.5\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - skip_data_intervals           : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - skip_memory_metrics           : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - skip_profile_timer            : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - split_inputs_sequence_dim     : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - split_norm_comm               : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - tensor_parallel_config        : \u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - tensor_parallel_degree        : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - tensor_parallel_rank          : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - tensorwise_offload_optimizer  : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - to_static                     : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - train_batch_size              : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - unified_checkpoint            : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,576] [   DEBUG]\u001b[0m - unified_checkpoint_config     : ['async_save']\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - use_async_save                : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - use_expert_parallel           : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - use_hybrid_parallel           : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - use_lowprecision_moment       : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - use_recompute_mtp             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - use_sp_callback               : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - wandb_api_key                 : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - wandb_http_proxy              : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - warmup_ratio                  : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - warmup_steps                  : 20\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - weight_decay                  : 0.1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - weight_name_suffix            : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - weight_quantize_algo          : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - world_size                    : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - zcc_ema_interval              : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - zcc_pipeline_hooks_capacity_usage: 0.6\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - zcc_save_ema_coef             : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - zcc_workers_num               : 3\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,577] [   DEBUG]\u001b[0m - \u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:54,578] [    INFO]\u001b[0m - Starting training from resume_from_checkpoint : None\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:54,585] [    INFO]\u001b[0m - [timelog] checkpoint loading time: 0.00s (2025-07-17 19:05:54) \u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:54,585] [    INFO]\u001b[0m - ***** Running training *****\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:54,585] [    INFO]\u001b[0m -   Num examples = 800\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:54,585] [    INFO]\u001b[0m -   Num Epochs = 9223372036854775807\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:54,585] [    INFO]\u001b[0m -   Instantaneous batch size per device = 1\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:54,585] [    INFO]\u001b[0m -   Total train batch size (w. parallel, distributed & accumulation) = 8\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:54,585] [    INFO]\u001b[0m -   Gradient Accumulation steps = 8\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:54,585] [    INFO]\u001b[0m -   Total optimization steps = 100\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:54,585] [    INFO]\u001b[0m -   Total num train samples = 800\u001b[0m\r\n",
      "\u001b[35m[2025-07-17 19:05:54,586] [   DEBUG]\u001b[0m -   Number of trainable parameters = 360,748,032 (per device)\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:54,603] [    INFO]\u001b[0m - prepare SequenceDataset ...\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:05:57,381] [    INFO]\u001b[0m - prepare SequenceDataset done: total number of examples is 6000000\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:01,753] [    INFO]\u001b[0m - loss: 2.61245131, learning_rate: 5e-07, global_step: 1, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 7.1658, interval_samples_per_second: 1.1164, interval_steps_per_second: 0.1396, ppl: 13.63242723238924, progress_or_epoch: 0.01\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:03,399] [    INFO]\u001b[0m - loss: 2.57664418, learning_rate: 1e-06, global_step: 2, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.6466, interval_samples_per_second: 4.8584, interval_steps_per_second: 0.6073, ppl: 13.152925166395088, progress_or_epoch: 0.02\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:04,926] [    INFO]\u001b[0m - loss: 2.57887983, learning_rate: 1.5e-06, global_step: 3, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.5269, interval_samples_per_second: 5.2393, interval_steps_per_second: 0.6549, ppl: 13.182363398073319, progress_or_epoch: 0.03\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:06,408] [    INFO]\u001b[0m - loss: 2.64023829, learning_rate: 2e-06, global_step: 4, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.4819, interval_samples_per_second: 5.3984, interval_steps_per_second: 0.6748, ppl: 14.016543211902638, progress_or_epoch: 0.04\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:07,869] [    INFO]\u001b[0m - loss: 2.54005051, learning_rate: 2.5e-06, global_step: 5, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.4608, interval_samples_per_second: 5.4763, interval_steps_per_second: 0.6845, ppl: 12.680311437189454, progress_or_epoch: 0.05\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:09,358] [    INFO]\u001b[0m - loss: 2.52139831, learning_rate: 3e-06, global_step: 6, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.4892, interval_samples_per_second: 5.3721, interval_steps_per_second: 0.6715, ppl: 12.44598785088004, progress_or_epoch: 0.06\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:11,010] [    INFO]\u001b[0m - loss: 2.53262019, learning_rate: 3.5e-06, global_step: 7, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.6514, interval_samples_per_second: 4.8444, interval_steps_per_second: 0.6055, ppl: 12.586441837967008, progress_or_epoch: 0.07\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:12,511] [    INFO]\u001b[0m - loss: 2.51942062, learning_rate: 4e-06, global_step: 8, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.5011, interval_samples_per_second: 5.3295, interval_steps_per_second: 0.6662, ppl: 12.421397868862815, progress_or_epoch: 0.08\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:13,987] [    INFO]\u001b[0m - loss: 2.50147009, learning_rate: 4.5e-06, global_step: 9, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.4765, interval_samples_per_second: 5.4181, interval_steps_per_second: 0.6773, ppl: 12.200416493890778, progress_or_epoch: 0.09\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:15,508] [    INFO]\u001b[0m - loss: 2.34809017, learning_rate: 5e-06, global_step: 10, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.521, interval_samples_per_second: 5.2595, interval_steps_per_second: 0.6574, ppl: 10.465563179731184, progress_or_epoch: 0.1\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:17,001] [    INFO]\u001b[0m - loss: 2.38992405, learning_rate: 5.5e-06, global_step: 11, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.4932, interval_samples_per_second: 5.3578, interval_steps_per_second: 0.6697, ppl: 10.912665094652914, progress_or_epoch: 0.11\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:18,653] [    INFO]\u001b[0m - loss: 2.23173046, learning_rate: 6e-06, global_step: 12, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.6514, interval_samples_per_second: 4.8444, interval_steps_per_second: 0.6056, ppl: 9.315973057961125, progress_or_epoch: 0.12\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:20,143] [    INFO]\u001b[0m - loss: 2.09781885, learning_rate: 6.5e-06, global_step: 13, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.4899, interval_samples_per_second: 5.3696, interval_steps_per_second: 0.6712, ppl: 8.148377681878587, progress_or_epoch: 0.13\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:21,610] [    INFO]\u001b[0m - loss: 2.03945446, learning_rate: 7e-06, global_step: 14, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.4669, interval_samples_per_second: 5.4535, interval_steps_per_second: 0.6817, ppl: 7.686414808144628, progress_or_epoch: 0.14\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:23,080] [    INFO]\u001b[0m - loss: 1.93046248, learning_rate: 7.5e-06, global_step: 15, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.4709, interval_samples_per_second: 5.4389, interval_steps_per_second: 0.6799, ppl: 6.892697239182341, progress_or_epoch: 0.15\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:24,555] [    INFO]\u001b[0m - loss: 1.81210303, learning_rate: 8e-06, global_step: 16, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.4744, interval_samples_per_second: 5.4259, interval_steps_per_second: 0.6782, ppl: 6.123311408416771, progress_or_epoch: 0.16\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:26,209] [    INFO]\u001b[0m - loss: 1.70531929, learning_rate: 8.5e-06, global_step: 17, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.6541, interval_samples_per_second: 4.8365, interval_steps_per_second: 0.6046, ppl: 5.503142485093446, progress_or_epoch: 0.17\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:27,686] [    INFO]\u001b[0m - loss: 1.51051784, learning_rate: 9e-06, global_step: 18, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.4773, interval_samples_per_second: 5.4151, interval_steps_per_second: 0.6769, ppl: 4.529075523633699, progress_or_epoch: 0.18\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:29,163] [    INFO]\u001b[0m - loss: 1.29875422, learning_rate: 9.5e-06, global_step: 19, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.477, interval_samples_per_second: 5.4165, interval_steps_per_second: 0.6771, ppl: 3.664728377349803, progress_or_epoch: 0.19\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:30,638] [    INFO]\u001b[0m - loss: 1.23181963, learning_rate: 1e-05, global_step: 20, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 19.390605688095093, max_memory_allocated: 13.450048446655273, max_memory_reserved: 19.390605688095093, interval_runtime: 1.475, interval_samples_per_second: 5.4236, interval_steps_per_second: 0.6779, ppl: 3.4274605755645147, progress_or_epoch: 0.2\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:32,258] [    INFO]\u001b[0m - loss: 1.07891762, learning_rate: 9.997e-06, global_step: 21, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.6193, interval_samples_per_second: 4.9404, interval_steps_per_second: 0.6175, ppl: 2.9414940131053307, progress_or_epoch: 0.21\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:34,029] [    INFO]\u001b[0m - loss: 0.90462917, learning_rate: 9.986e-06, global_step: 22, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.7713, interval_samples_per_second: 4.5164, interval_steps_per_second: 0.5646, ppl: 2.4710154264851587, progress_or_epoch: 0.22\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:35,540] [    INFO]\u001b[0m - loss: 0.76993722, learning_rate: 9.969e-06, global_step: 23, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.5108, interval_samples_per_second: 5.295, interval_steps_per_second: 0.6619, ppl: 2.159630667915587, progress_or_epoch: 0.23\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:37,009] [    INFO]\u001b[0m - loss: 0.65621567, learning_rate: 9.945e-06, global_step: 24, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.4696, interval_samples_per_second: 5.4438, interval_steps_per_second: 0.6805, ppl: 1.927484278496434, progress_or_epoch: 0.24\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:38,479] [    INFO]\u001b[0m - loss: 0.51416081, learning_rate: 9.914e-06, global_step: 25, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.4692, interval_samples_per_second: 5.445, interval_steps_per_second: 0.6806, ppl: 1.6722345902598585, progress_or_epoch: 0.25\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:39,975] [    INFO]\u001b[0m - loss: 0.43581983, learning_rate: 9.876e-06, global_step: 26, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.4967, interval_samples_per_second: 5.3449, interval_steps_per_second: 0.6681, ppl: 1.546230185359108, progress_or_epoch: 0.26\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:41,704] [    INFO]\u001b[0m - loss: 0.3368488, learning_rate: 9.831e-06, global_step: 27, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.7287, interval_samples_per_second: 4.6277, interval_steps_per_second: 0.5785, ppl: 1.400527288002747, progress_or_epoch: 0.27\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:43,200] [    INFO]\u001b[0m - loss: 0.27868763, learning_rate: 9.78e-06, global_step: 28, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.4957, interval_samples_per_second: 5.3487, interval_steps_per_second: 0.6686, ppl: 1.3213945153905076, progress_or_epoch: 0.28\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:44,683] [    INFO]\u001b[0m - loss: 0.20828675, learning_rate: 9.722e-06, global_step: 29, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.4836, interval_samples_per_second: 5.3923, interval_steps_per_second: 0.674, ppl: 1.231566270548672, progress_or_epoch: 0.29\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:46,147] [    INFO]\u001b[0m - loss: 0.15214896, learning_rate: 9.657e-06, global_step: 30, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.4636, interval_samples_per_second: 5.466, interval_steps_per_second: 0.6832, ppl: 1.1643336626573957, progress_or_epoch: 0.3\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:47,622] [    INFO]\u001b[0m - loss: 0.10568784, learning_rate: 9.587e-06, global_step: 31, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.4746, interval_samples_per_second: 5.4253, interval_steps_per_second: 0.6782, ppl: 1.1114748643540353, progress_or_epoch: 0.31\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:49,276] [    INFO]\u001b[0m - loss: 0.06535335, learning_rate: 9.51e-06, global_step: 32, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.6547, interval_samples_per_second: 4.8346, interval_steps_per_second: 0.6043, ppl: 1.0675361716540286, progress_or_epoch: 0.32\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:50,752] [    INFO]\u001b[0m - loss: 0.04185442, learning_rate: 9.426e-06, global_step: 33, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.4761, interval_samples_per_second: 5.4198, interval_steps_per_second: 0.6775, ppl: 1.0427426652233216, progress_or_epoch: 0.33\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:52,233] [    INFO]\u001b[0m - loss: 0.02847656, learning_rate: 9.337e-06, global_step: 34, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.4811, interval_samples_per_second: 5.4015, interval_steps_per_second: 0.6752, ppl: 1.0288858934665266, progress_or_epoch: 0.34\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:53,721] [    INFO]\u001b[0m - loss: 0.0193248, learning_rate: 9.242e-06, global_step: 35, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.4879, interval_samples_per_second: 5.3768, interval_steps_per_second: 0.6721, ppl: 1.0195127325820041, progress_or_epoch: 0.35\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:55,205] [    INFO]\u001b[0m - loss: 0.01424673, learning_rate: 9.141e-06, global_step: 36, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.4835, interval_samples_per_second: 5.3928, interval_steps_per_second: 0.6741, ppl: 1.0143486983207781, progress_or_epoch: 0.36\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:56,856] [    INFO]\u001b[0m - loss: 0.01063273, learning_rate: 9.034e-06, global_step: 37, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.6513, interval_samples_per_second: 4.8448, interval_steps_per_second: 0.6056, ppl: 1.0106894583544417, progress_or_epoch: 0.37\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:58,350] [    INFO]\u001b[0m - loss: 0.00897723, learning_rate: 8.922e-06, global_step: 38, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.4936, interval_samples_per_second: 5.3562, interval_steps_per_second: 0.6695, ppl: 1.009017646180488, progress_or_epoch: 0.38\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:06:59,810] [    INFO]\u001b[0m - loss: 0.00651405, learning_rate: 8.804e-06, global_step: 39, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 24.518741369247437, max_memory_allocated: 13.468530893325806, max_memory_reserved: 24.518741369247437, interval_runtime: 1.4607, interval_samples_per_second: 5.4768, interval_steps_per_second: 0.6846, ppl: 1.0065353125671035, progress_or_epoch: 0.39\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:01,299] [    INFO]\u001b[0m - loss: 0.00599763, learning_rate: 8.682e-06, global_step: 40, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4885, interval_samples_per_second: 5.3746, interval_steps_per_second: 0.6718, ppl: 1.0060156517941448, progress_or_epoch: 0.4\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:02,804] [    INFO]\u001b[0m - loss: 0.00479357, learning_rate: 8.555e-06, global_step: 41, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.5054, interval_samples_per_second: 5.3141, interval_steps_per_second: 0.6643, ppl: 1.0048050775367192, progress_or_epoch: 0.41\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:04,446] [    INFO]\u001b[0m - loss: 0.00418891, learning_rate: 8.423e-06, global_step: 42, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.6416, interval_samples_per_second: 4.8734, interval_steps_per_second: 0.6092, ppl: 1.004197695746778, progress_or_epoch: 0.42\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:05,956] [    INFO]\u001b[0m - loss: 0.00332835, learning_rate: 8.286e-06, global_step: 43, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.5097, interval_samples_per_second: 5.2989, interval_steps_per_second: 0.6624, ppl: 1.0033338951071737, progress_or_epoch: 0.43\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:07,490] [    INFO]\u001b[0m - loss: 0.00299198, learning_rate: 8.145e-06, global_step: 44, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.5344, interval_samples_per_second: 5.2137, interval_steps_per_second: 0.6517, ppl: 1.0029964604395076, progress_or_epoch: 0.44\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:08,950] [    INFO]\u001b[0m - loss: 0.0026643, learning_rate: 8e-06, global_step: 45, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4595, interval_samples_per_second: 5.4815, interval_steps_per_second: 0.6852, ppl: 1.002667852401432, progress_or_epoch: 0.45\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:10,438] [    INFO]\u001b[0m - loss: 0.0022808, learning_rate: 7.851e-06, global_step: 46, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4882, interval_samples_per_second: 5.3757, interval_steps_per_second: 0.672, ppl: 1.0022834030029202, progress_or_epoch: 0.46\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:12,111] [    INFO]\u001b[0m - loss: 0.0020717, learning_rate: 7.699e-06, global_step: 47, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.6736, interval_samples_per_second: 4.7802, interval_steps_per_second: 0.5975, ppl: 1.0020738474531485, progress_or_epoch: 0.47\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:13,602] [    INFO]\u001b[0m - loss: 0.00184983, learning_rate: 7.543e-06, global_step: 48, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4901, interval_samples_per_second: 5.3686, interval_steps_per_second: 0.6711, ppl: 1.0018515419909824, progress_or_epoch: 0.48\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:15,058] [    INFO]\u001b[0m - loss: 0.00168223, learning_rate: 7.384e-06, global_step: 49, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.457, interval_samples_per_second: 5.4909, interval_steps_per_second: 0.6864, ppl: 1.0016836457426435, progress_or_epoch: 0.49\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:16,532] [    INFO]\u001b[0m - loss: 0.00155611, learning_rate: 7.222e-06, global_step: 50, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4736, interval_samples_per_second: 5.429, interval_steps_per_second: 0.6786, ppl: 1.001557321367425, progress_or_epoch: 0.5\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:18,021] [    INFO]\u001b[0m - loss: 0.00141674, learning_rate: 7.058e-06, global_step: 51, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4889, interval_samples_per_second: 5.3731, interval_steps_per_second: 0.6716, ppl: 1.0014177440502172, progress_or_epoch: 0.51\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:19,669] [    INFO]\u001b[0m - loss: 0.0013008, learning_rate: 6.891e-06, global_step: 52, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.6479, interval_samples_per_second: 4.8547, interval_steps_per_second: 0.6068, ppl: 1.0013016464072824, progress_or_epoch: 0.52\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:21,164] [    INFO]\u001b[0m - loss: 0.00122136, learning_rate: 6.721e-06, global_step: 53, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4951, interval_samples_per_second: 5.3507, interval_steps_per_second: 0.6688, ppl: 1.0012221061638722, progress_or_epoch: 0.53\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:22,642] [    INFO]\u001b[0m - loss: 0.00113877, learning_rate: 6.551e-06, global_step: 54, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4777, interval_samples_per_second: 5.4138, interval_steps_per_second: 0.6767, ppl: 1.0011394186447522, progress_or_epoch: 0.54\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:24,263] [    INFO]\u001b[0m - loss: 0.00107102, learning_rate: 6.378e-06, global_step: 55, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.621, interval_samples_per_second: 4.9353, interval_steps_per_second: 0.6169, ppl: 1.0010715937467334, progress_or_epoch: 0.55\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:25,756] [    INFO]\u001b[0m - loss: 0.00099817, learning_rate: 6.204e-06, global_step: 56, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4935, interval_samples_per_second: 5.3564, interval_steps_per_second: 0.6696, ppl: 1.0009986683374692, progress_or_epoch: 0.56\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:27,442] [    INFO]\u001b[0m - loss: 0.00093717, learning_rate: 6.029e-06, global_step: 57, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.6857, interval_samples_per_second: 4.7458, interval_steps_per_second: 0.5932, ppl: 1.0009376092810207, progress_or_epoch: 0.57\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:28,937] [    INFO]\u001b[0m - loss: 0.00088327, learning_rate: 5.853e-06, global_step: 58, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4953, interval_samples_per_second: 5.3502, interval_steps_per_second: 0.6688, ppl: 1.0008836601978213, progress_or_epoch: 0.58\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:30,418] [    INFO]\u001b[0m - loss: 0.00081978, learning_rate: 5.677e-06, global_step: 59, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4805, interval_samples_per_second: 5.4036, interval_steps_per_second: 0.6755, ppl: 1.0008201161114638, progress_or_epoch: 0.59\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:31,899] [    INFO]\u001b[0m - loss: 0.00079842, learning_rate: 5.5e-06, global_step: 60, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4814, interval_samples_per_second: 5.4004, interval_steps_per_second: 0.6751, ppl: 1.0007987388220938, progress_or_epoch: 0.6\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:33,397] [    INFO]\u001b[0m - loss: 0.00075694, learning_rate: 5.323e-06, global_step: 61, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4981, interval_samples_per_second: 5.3402, interval_steps_per_second: 0.6675, ppl: 1.000757226551378, progress_or_epoch: 0.61\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:35,063] [    INFO]\u001b[0m - loss: 0.00074053, learning_rate: 5.147e-06, global_step: 62, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.6663, interval_samples_per_second: 4.801, interval_steps_per_second: 0.6001, ppl: 1.0007408042600356, progress_or_epoch: 0.62\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:36,562] [    INFO]\u001b[0m - loss: 0.0007109, learning_rate: 4.971e-06, global_step: 63, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4989, interval_samples_per_second: 5.3373, interval_steps_per_second: 0.6672, ppl: 1.0007111527492947, progress_or_epoch: 0.63\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:38,035] [    INFO]\u001b[0m - loss: 0.00068439, learning_rate: 4.796e-06, global_step: 64, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4724, interval_samples_per_second: 5.4335, interval_steps_per_second: 0.6792, ppl: 1.000684624248272, progress_or_epoch: 0.64\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:39,503] [    INFO]\u001b[0m - loss: 0.00065405, learning_rate: 4.622e-06, global_step: 65, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4682, interval_samples_per_second: 5.449, interval_steps_per_second: 0.6811, ppl: 1.0006542639373406, progress_or_epoch: 0.65\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:40,994] [    INFO]\u001b[0m - loss: 0.00062484, learning_rate: 4.449e-06, global_step: 66, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4913, interval_samples_per_second: 5.3645, interval_steps_per_second: 0.6706, ppl: 1.000625035253178, progress_or_epoch: 0.66\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:42,657] [    INFO]\u001b[0m - loss: 0.00060752, learning_rate: 4.279e-06, global_step: 67, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.6632, interval_samples_per_second: 4.8099, interval_steps_per_second: 0.6012, ppl: 1.0006077045776516, progress_or_epoch: 0.67\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:44,157] [    INFO]\u001b[0m - loss: 0.00059177, learning_rate: 4.109e-06, global_step: 68, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.5001, interval_samples_per_second: 5.3331, interval_steps_per_second: 0.6666, ppl: 1.0005919451304104, progress_or_epoch: 0.68\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:45,633] [    INFO]\u001b[0m - loss: 0.00057848, learning_rate: 3.942e-06, global_step: 69, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.476, interval_samples_per_second: 5.4199, interval_steps_per_second: 0.6775, ppl: 1.0005786473518234, progress_or_epoch: 0.69\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:47,125] [    INFO]\u001b[0m - loss: 0.00055459, learning_rate: 3.778e-06, global_step: 70, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4913, interval_samples_per_second: 5.3646, interval_steps_per_second: 0.6706, ppl: 1.0005547438134672, progress_or_epoch: 0.7\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:48,773] [    INFO]\u001b[0m - loss: 0.00054881, learning_rate: 3.616e-06, global_step: 71, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.6481, interval_samples_per_second: 4.8542, interval_steps_per_second: 0.6068, ppl: 1.0005489606237614, progress_or_epoch: 0.71\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:50,439] [    INFO]\u001b[0m - loss: 0.00052375, learning_rate: 3.457e-06, global_step: 72, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.6662, interval_samples_per_second: 4.8012, interval_steps_per_second: 0.6002, ppl: 1.0005238871809796, progress_or_epoch: 0.72\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:51,940] [    INFO]\u001b[0m - loss: 0.00052632, learning_rate: 3.301e-06, global_step: 73, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.5013, interval_samples_per_second: 5.3286, interval_steps_per_second: 0.6661, ppl: 1.000526458530674, progress_or_epoch: 0.73\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:53,402] [    INFO]\u001b[0m - loss: 0.00050112, learning_rate: 3.149e-06, global_step: 74, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4614, interval_samples_per_second: 5.4744, interval_steps_per_second: 0.6843, ppl: 1.0005012455816036, progress_or_epoch: 0.74\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:54,877] [    INFO]\u001b[0m - loss: 0.00049965, learning_rate: 3e-06, global_step: 75, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.475, interval_samples_per_second: 5.4239, interval_steps_per_second: 0.678, ppl: 1.0004997748458535, progress_or_epoch: 0.75\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:56,374] [    INFO]\u001b[0m - loss: 0.00049271, learning_rate: 2.855e-06, global_step: 76, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4973, interval_samples_per_second: 5.3429, interval_steps_per_second: 0.6679, ppl: 1.0004928314015098, progress_or_epoch: 0.76\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:58,108] [    INFO]\u001b[0m - loss: 0.0004792, learning_rate: 2.714e-06, global_step: 77, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.734, interval_samples_per_second: 4.6135, interval_steps_per_second: 0.5767, ppl: 1.0004793148346622, progress_or_epoch: 0.77\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:07:59,678] [    INFO]\u001b[0m - loss: 0.00048325, learning_rate: 2.577e-06, global_step: 78, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.5694, interval_samples_per_second: 5.0974, interval_steps_per_second: 0.6372, ppl: 1.0004833667840924, progress_or_epoch: 0.78\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:01,146] [    INFO]\u001b[0m - loss: 0.00047503, learning_rate: 2.445e-06, global_step: 79, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4684, interval_samples_per_second: 5.4483, interval_steps_per_second: 0.681, ppl: 1.000475142844618, progress_or_epoch: 0.79\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:02,603] [    INFO]\u001b[0m - loss: 0.00046239, learning_rate: 2.318e-06, global_step: 80, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4572, interval_samples_per_second: 5.4901, interval_steps_per_second: 0.6863, ppl: 1.0004624969187348, progress_or_epoch: 0.8\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:04,078] [    INFO]\u001b[0m - loss: 0.00046021, learning_rate: 2.196e-06, global_step: 81, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4748, interval_samples_per_second: 5.4244, interval_steps_per_second: 0.6781, ppl: 1.0004603159128689, progress_or_epoch: 0.81\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:05,732] [    INFO]\u001b[0m - loss: 0.00044189, learning_rate: 2.078e-06, global_step: 82, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.6539, interval_samples_per_second: 4.8371, interval_steps_per_second: 0.6046, ppl: 1.0004419876477688, progress_or_epoch: 0.82\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:07,234] [    INFO]\u001b[0m - loss: 0.00044303, learning_rate: 1.966e-06, global_step: 83, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.5022, interval_samples_per_second: 5.3256, interval_steps_per_second: 0.6657, ppl: 1.0004431281522848, progress_or_epoch: 0.83\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:08,720] [    INFO]\u001b[0m - loss: 0.00043664, learning_rate: 1.859e-06, global_step: 84, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4859, interval_samples_per_second: 5.3839, interval_steps_per_second: 0.673, ppl: 1.000436735341121, progress_or_epoch: 0.84\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:10,211] [    INFO]\u001b[0m - loss: 0.00044362, learning_rate: 1.758e-06, global_step: 85, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4911, interval_samples_per_second: 5.365, interval_steps_per_second: 0.6706, ppl: 1.0004437184139046, progress_or_epoch: 0.85\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:11,705] [    INFO]\u001b[0m - loss: 0.00043008, learning_rate: 1.663e-06, global_step: 86, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4937, interval_samples_per_second: 5.3559, interval_steps_per_second: 0.6695, ppl: 1.0004301724976632, progress_or_epoch: 0.86\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:13,381] [    INFO]\u001b[0m - loss: 0.00043164, learning_rate: 1.574e-06, global_step: 87, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.6764, interval_samples_per_second: 4.772, interval_steps_per_second: 0.5965, ppl: 1.0004317331699497, progress_or_epoch: 0.87\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:15,013] [    INFO]\u001b[0m - loss: 0.00043156, learning_rate: 1.49e-06, global_step: 88, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.6317, interval_samples_per_second: 4.9028, interval_steps_per_second: 0.6129, ppl: 1.0004316531354143, progress_or_epoch: 0.88\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:16,489] [    INFO]\u001b[0m - loss: 0.00041841, learning_rate: 1.413e-06, global_step: 89, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 29.673076391220093, max_memory_allocated: 13.501605987548828, max_memory_reserved: 29.673076391220093, interval_runtime: 1.4765, interval_samples_per_second: 5.4184, interval_steps_per_second: 0.6773, ppl: 1.0004184975456736, progress_or_epoch: 0.89\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:17,973] [    INFO]\u001b[0m - loss: 0.00041201, learning_rate: 1.343e-06, global_step: 90, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 34.84359335899353, max_memory_allocated: 13.52203369140625, max_memory_reserved: 34.84359335899353, interval_runtime: 1.4833, interval_samples_per_second: 5.3934, interval_steps_per_second: 0.6742, ppl: 1.000412094887778, progress_or_epoch: 0.9\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:19,469] [    INFO]\u001b[0m - loss: 0.00041063, learning_rate: 1.278e-06, global_step: 91, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 34.84359335899353, max_memory_allocated: 13.52203369140625, max_memory_reserved: 34.84359335899353, interval_runtime: 1.4964, interval_samples_per_second: 5.3462, interval_steps_per_second: 0.6683, ppl: 1.0004107143200396, progress_or_epoch: 0.91\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:21,112] [    INFO]\u001b[0m - loss: 0.00041239, learning_rate: 1.22e-06, global_step: 92, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 34.84359335899353, max_memory_allocated: 13.52203369140625, max_memory_reserved: 34.84359335899353, interval_runtime: 1.6429, interval_samples_per_second: 4.8696, interval_steps_per_second: 0.6087, ppl: 1.000412475044446, progress_or_epoch: 0.92\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:22,589] [    INFO]\u001b[0m - loss: 0.00040777, learning_rate: 1.169e-06, global_step: 93, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 34.84359335899353, max_memory_allocated: 13.52203369140625, max_memory_reserved: 34.84359335899353, interval_runtime: 1.4775, interval_samples_per_second: 5.4146, interval_steps_per_second: 0.6768, ppl: 1.000407853149488, progress_or_epoch: 0.93\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:24,046] [    INFO]\u001b[0m - loss: 0.00040752, learning_rate: 1.124e-06, global_step: 94, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 34.84359335899353, max_memory_allocated: 13.52203369140625, max_memory_reserved: 34.84359335899353, interval_runtime: 1.457, interval_samples_per_second: 5.4907, interval_steps_per_second: 0.6863, ppl: 1.000407603047556, progress_or_epoch: 0.94\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:25,511] [    INFO]\u001b[0m - loss: 0.00040874, learning_rate: 1.086e-06, global_step: 95, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 34.84359335899353, max_memory_allocated: 13.52203369140625, max_memory_reserved: 34.84359335899353, interval_runtime: 1.4643, interval_samples_per_second: 5.4635, interval_steps_per_second: 0.6829, ppl: 1.0004088235455761, progress_or_epoch: 0.95\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:26,992] [    INFO]\u001b[0m - loss: 0.00039641, learning_rate: 1.055e-06, global_step: 96, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 34.84359335899353, max_memory_allocated: 13.52203369140625, max_memory_reserved: 34.84359335899353, interval_runtime: 1.4815, interval_samples_per_second: 5.4, interval_steps_per_second: 0.675, ppl: 1.0003964885808272, progress_or_epoch: 0.96\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:28,649] [    INFO]\u001b[0m - loss: 0.0004016, learning_rate: 1.031e-06, global_step: 97, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 34.84359335899353, max_memory_allocated: 13.52203369140625, max_memory_reserved: 34.84359335899353, interval_runtime: 1.6566, interval_samples_per_second: 4.8291, interval_steps_per_second: 0.6036, ppl: 1.0004016806520764, progress_or_epoch: 0.97\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:30,116] [    INFO]\u001b[0m - loss: 0.0004049, learning_rate: 1.014e-06, global_step: 98, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 34.84359335899353, max_memory_allocated: 13.52203369140625, max_memory_reserved: 34.84359335899353, interval_runtime: 1.4677, interval_samples_per_second: 5.4508, interval_steps_per_second: 0.6813, ppl: 1.0004049819830696, progress_or_epoch: 0.98\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:31,570] [    INFO]\u001b[0m - loss: 0.00039089, learning_rate: 1.003e-06, global_step: 99, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 34.84359335899353, max_memory_allocated: 13.52203369140625, max_memory_reserved: 34.84359335899353, interval_runtime: 1.4537, interval_samples_per_second: 5.5032, interval_steps_per_second: 0.6879, ppl: 1.0003909664074513, progress_or_epoch: 0.99\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:33,039] [    INFO]\u001b[0m - loss: 0.00038933, learning_rate: 1e-06, global_step: 100, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 34.84359335899353, max_memory_allocated: 13.52203369140625, max_memory_reserved: 34.84359335899353, interval_runtime: 1.4685, interval_samples_per_second: 5.4476, interval_steps_per_second: 0.6809, ppl: 1.000389405798761, progress_or_epoch: 1.0\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:33,039] [    INFO]\u001b[0m - \r\n",
      "Training completed. \r\n",
      "\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:33,039] [    INFO]\u001b[0m - train_runtime: 158.453, train_samples_per_second: 5.0488, train_steps_per_second: 0.6311, train_loss: 0.4931975438800873, progress_or_epoch: 1.0\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:33,040] [    INFO]\u001b[0m - Saving model checkpoint to ./output\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:33,043] [    INFO]\u001b[0m - tokenizer config file saved in ./output/tokenizer_config.json\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:33,044] [    INFO]\u001b[0m - Special tokens file saved in ./output/special_tokens_map.json\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:33,044] [    INFO]\u001b[0m - added tokens file saved in ./output/added_tokens.json\u001b[0m\r\n",
      "\u001b[33m[2025-07-17 19:08:33,054] [ WARNING]\u001b[0m - Asynchronous saving is not supported for single card environment currently.\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,837] [    INFO]\u001b[0m - Configuration saved in ./output/config.json\u001b[0m\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddleformers/generation/configuration_utils.py:316: UserWarning: The generation config instance is invalid -- `.validate()` throws warnings and/or exceptions. Fix these issues to save the configuration. This warning will be raised to an exception.\r\n",
      "\r\n",
      "Thrown during validation:\r\n",
      "using greedy search strategy. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `decode_strategy=\"greedy_search\" ` or unset `temperature`.\r\n",
      "  warnings.warn(\r\n",
      "\u001b[32m[2025-07-17 19:08:34,872] [    INFO]\u001b[0m - [timelog] model saving time: 1.83s (2025-07-17 19:08:34) \u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,872] [    INFO]\u001b[0m - ***** train metrics *****\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,872] [    INFO]\u001b[0m -   progress_or_epoch        =        1.0\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,872] [    INFO]\u001b[0m -   train_loss               =     0.4932\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,872] [    INFO]\u001b[0m -   train_runtime            = 0:02:38.45\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,872] [    INFO]\u001b[0m -   train_samples_per_second =     5.0488\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,872] [    INFO]\u001b[0m -   train_steps_per_second   =     0.6311\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,873] [    INFO]\u001b[0m - ***** Running Evaluation *****\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,873] [    INFO]\u001b[0m -   Num examples: Unknown\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,873] [    INFO]\u001b[0m -   Total prediction steps = 10000\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,873] [    INFO]\u001b[0m -   Pre device batch size = 1\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,873] [    INFO]\u001b[0m -   Total Batch size = 1\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,875] [    INFO]\u001b[0m - prepare SequenceDataset ...\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,876] [    INFO]\u001b[0m - prepare SequenceDataset done: total number of examples is 10\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,922] [    INFO]\u001b[0m - eval_loss: 4.969167232513428, eval_runtime: 0.0491, eval_samples_per_second: 203467.7235, eval_steps_per_second: 203467.7235, eval_ppl: 143.90699638950923, progress_or_epoch: 1.0\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,922] [    INFO]\u001b[0m - ***** eval metrics *****\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,922] [    INFO]\u001b[0m -   eval_loss               =      4.9692\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,922] [    INFO]\u001b[0m -   eval_ppl                =     143.907\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,922] [    INFO]\u001b[0m -   eval_runtime            =  0:00:00.04\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,923] [    INFO]\u001b[0m -   eval_samples_per_second = 203467.7235\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,923] [    INFO]\u001b[0m -   eval_steps_per_second   = 203467.7235\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,923] [    INFO]\u001b[0m -   progress_or_epoch       =         1.0\u001b[0m\r\n",
      "\u001b[32m[2025-07-17 19:08:34,923] [    INFO]\u001b[0m - Saving stop info into ./vdl_log/stop_step.json\u001b[0m\r\n",
      "LAUNCH INFO 2025-07-17 19:08:36,850 Pod completed\r\n",
      "LAUNCH INFO 2025-07-17 19:08:36,850 Exit code 0\r\n"
     ]
    }
   ],
   "source": [
    "!erniekit train examples/configs/ERNIE-4.5-0.3B/sft/run_sft_8k.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Interpreting Training Logs\n",
    "\n",
    "Once training begins, you will see a large amount of log information output. Learning to interpret these logs is key to monitoring the training status and determining whether the model is converging normally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break down the key information:\n",
    "\n",
    "* `global_step`: The current total number of training steps. `10/100` indicates that the current step is the 10th step, with a total of 100 steps required for training (defined by `max_steps`).\n",
    "* `epoch`: The current number of training epochs.\n",
    "* `loss`: **The most important metric**. It measures the gap between the model's predicted output and the actual `tgt`. **We expect to see the `loss` value steadily decrease as training progresses**. If the `loss` remains high, fluctuates wildly, or becomes `NaN`, it indicates that there may be a problem with the training (e.g., learning rate is too high, data is problematic, etc.).\n",
    "* `learning_rate`: The current learning rate. You can see it reaches the set value after `warmup_steps`, then changes according to the strategy of `lr_scheduler_type`.\n",
    "* `speed` / `ips`: Training speed. These represent the number of steps and samples processed per second, respectively. They can be used to estimate the total training time.\n",
    "* `eta`: Estimated remaining training time (Estimated Time of Arrival).\n",
    "\n",
    "**Monitoring points:**\n",
    "\n",
    "1.  **Is the loss decreasing?**: This is the primary health indicator. A steadily decreasing loss curve is a sign of successful training.\n",
    "2.  **GPU utilization and memory**: Use the `nvidia-smi` command to view the GPU's working status in real time. Ensure that GPU utilization is as high as possible and that memory usage is within a reasonable range. If memory overflow (Out of Memory, OOM) occurs, you need to reduce `batch_size`, `max_seq_len`, or enable `recompute`.\n",
    "3.  **Evaluation Results (Eval Loss)**: When `eval_steps` is reached, the model is tested on the evaluation set. We also expect `eval_loss` to decrease, indicating that the model's generalization ability is improving. If `train_loss` decreases while `eval_loss` increases, it indicates that the model may be overfitting.\n",
    "\n",
    "After training is complete, all fine-tuned model weights and configuration files will be saved in the directory specified by `output_dir` in your `yaml` file. By default, there will be a folder named `checkpoint-xxx`, where `xxx` is the step number at the time of saving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary and Outlook\n",
    "\n",
    "Congratulations! Through studying and practicing this tutorial, you have successfully mastered the core techniques of supervised fine-tuning (SFT) of the ERNIE-4.5-0.3B large language model using ERNIEkit. Starting from the basic concepts of SFT, we have completed the entire process of environment preparation, data processing, configuration parsing, model training, and inference evaluation step by step.\n",
    "\n",
    "### 6.1 Core Review of This Tutorial\n",
    "\n",
    "Let‚Äôs recap the key learning points from this journey:\n",
    "\n",
    "1.  **Understood the essence of SFT**: We clarified that SFT is the process of teaching a model to follow human intent and complete specific tasks by using labeled ‚Äúinstruction-output‚Äù data on top of a pre-trained model. It serves as a bridge connecting general-purpose large models with specific application scenarios.\n",
    "2.  **Mastered the ERNIEkit SFT workflow**: We learned to use the powerful ERNIEkit toolchain to form a complete closed-loop process, from downloading models and preparing data, to configuring and starting training, and finally to inference verification.\n",
    "3.  **Mastered SFT configuration**: We thoroughly analyzed the parameters in the `run_sft_8k.yaml` configuration file, understood how to control and optimize the SFT process by adjusting parameters such as learning rate, batch size, sequence length, and optimization strategy, and learned key memory optimization techniques such as gradient accumulation, recomputation, and mixed precision.\n",
    "4.  **Emphasized the importance of data**: We recognized that high-quality, diverse SFT data is the cornerstone of fine-tuning success and learned how to build datasets that meet ERNIEkit requirements.\n",
    "\n",
    "Through SFT, we have endowed the ERNIE-4.5-0.3B model with new, customized capabilities, taking a solid step toward transforming it from a ‚Äúwell-rounded generalist‚Äù into a ‚Äúspecialized assistant.‚Äù\n",
    "\n",
    "### 6.2 Future Learning and Exploration Directions\n",
    "\n",
    "SFT has opened the door to the world of customized large models, but this is just the beginning. The technical stack of large language models is still evolving rapidly, and here are some directions worth exploring further:\n",
    "\n",
    "*   **Parameter-Efficient Fine-Tuning (PEFT)**:\n",
    "    *   **LoRA (Low-Rank Adaptation)**: While full-parameter fine-tuning yields good results, it consumes significant resources and requires storing a complete model copy for each task. LoRA is a PEFT method that freezes most of the original weights by injecting small, trainable ‚Äúadapter‚Äù matrices into certain layers of the model. This way, we only need to train and store a very small portion (typically less than 1%) of the parameters to achieve results close to full parameter fine-tuning. ERNIEkit provides excellent support for LoRA. You can try it by modifying `fine_tuning: Full` to `fine_tuning: lora` in the configuration file and configuring the relevant parameters.\n",
    "\n",
    "*   **Reinforcement Learning from Human Feedback (RLHF)**:\n",
    "*   SFT teaches the model to ‚Äúobey,‚Äù but how can we make the model's responses more aligned with human preferences (e.g., more useful, less harmful, more interesting)? RLHF is the key technology to address this challenge. It collects data on human preferences for different model responses to train a ‚Äúreward model,‚Äù then uses reinforcement learning algorithms (such as PPO) to optimize the language model so that the content it generates achieves higher reward scores. This is the necessary path toward more advanced and aligned AI.\n",
    "\n",
    "*   **More advanced models and technologies**:  \n",
    "    *   Keep an eye on the latest developments in Wenxin large models and ERNIEkit, exploring models with larger parameter scales, more advanced algorithms, and more efficient training frameworks.\n",
    "\n",
    "*   **Model deployment and serviceization**:  \n",
    "    *   Deploying your fine-tuned model as an online service is the final step in realizing its value. Explore tools like Paddle Serving and FastDeploy to learn how to perform model quantization and compression, and provide high-performance inference APIs.\n",
    "\n",
    "The era of large language models is filled with endless opportunities and challenges. We hope this tutorial serves as a solid starting point for your exploration of this exciting field. Through continuous learning and practice, you will be able to build increasingly powerful AI applications. Wishing you steady progress on your AI exploration journey!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedback/Contact me: WeChat: G_Fuji"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
