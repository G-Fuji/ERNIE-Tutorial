{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ERNIE-4.5-0.3B ä¸­æ–‡æƒ…æ„Ÿåˆ†æå®æˆ˜æ•™ç¨‹\n",
    "\n",
    "## 1. å¼•è¨€\n",
    "\n",
    "æ¬¢è¿æ¥åˆ° ERNIE-4.5-0.3B å®æˆ˜æ•™ç¨‹ç³»åˆ—ï¼åœ¨ä¹‹å‰çš„å­¦ä¹ ä¸­ï¼Œæˆ‘ä»¬å·²ç»æŒæ¡äº†é¢„è®­ç»ƒï¼ˆPTï¼‰ã€ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰å’Œç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰ç­‰æ ¸å¿ƒæŠ€æœ¯ï¼Œè¿™äº›æ„æˆäº†å¤§æ¨¡å‹å¼€å‘çš„åŸºç¡€ã€‚ç°åœ¨ï¼Œæ˜¯æ—¶å€™å°†ç†è®ºä»˜è¯¸å®è·µï¼Œè§£å†³ä¸€ä¸ªçœŸå®ä¸–ç•Œçš„é—®é¢˜äº†ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 ä¸ºä»€ä¹ˆé€‰æ‹©æƒ…æ„Ÿåˆ†æä½œä¸ºç¬¬ä¸€ä¸ªå®æˆ˜é¡¹ç›®ï¼Ÿ\n",
    "\n",
    "ç†è®ºå­¦ä¹ å¥½æ¯”å­¦ä¹ å†…åŠŸå¿ƒæ³•ï¼Œè€Œå®æˆ˜é¡¹ç›®åˆ™æ˜¯ä¿®ç‚¼å…·ä½“çš„æ­¦åŠŸæ‹›å¼ã€‚æƒ…æ„Ÿåˆ†æä»»åŠ¡ï¼Œå°±æ˜¯æˆ‘ä»¬é€‰æ‹©çš„ç¬¬ä¸€æ‹›ã€‚ä¸ºä»€ä¹ˆæ˜¯å®ƒï¼Ÿ\n",
    "\n",
    "*   **æ‰¿ä¸Šå¯ä¸‹ï¼Œå·©å›ºSFTæŠ€èƒ½**ï¼šæƒ…æ„Ÿåˆ†ææœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªæ–‡æœ¬åˆ†ç±»ä»»åŠ¡ï¼Œæ˜¯ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰æœ€ç›´æ¥ã€æœ€ç»å…¸çš„åº”ç”¨åœºæ™¯ã€‚é€šè¿‡è¿™ä¸ªé¡¹ç›®ï¼Œæˆ‘ä»¬å¯ä»¥å°†å­¦åˆ°çš„SFTçŸ¥è¯†èä¼šè´¯é€šï¼Œæ·±åˆ»ç†è§£å¦‚ä½•å°†ä¸€ä¸ªé€šç”¨çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œè°ƒæ•™æˆç‰¹å®šé¢†åŸŸçš„ä¸“å®¶ã€‚\n",
    "*   **éœ€æ±‚å¹¿æ³›ï¼Œå•†ä¸šä»·å€¼å·¨å¤§**ï¼šä»åˆ†æç”¨æˆ·è¯„è®ºã€ç›‘æ§å“ç‰Œå£ç¢‘ï¼Œåˆ°ç†è§£ç¤¾ä¼šèˆ†æƒ…ï¼Œæƒ…æ„Ÿåˆ†ææ˜¯æ— æ•°AIåº”ç”¨ä¸å¯æˆ–ç¼ºçš„åŸºçŸ³ã€‚æŒæ¡å®ƒï¼Œå°±ç­‰äºæŒæ¡äº†ä¸€é¡¹èƒ½åˆ›é€ å·¨å¤§å•†ä¸šä»·å€¼çš„æ ¸å¿ƒæŠ€èƒ½ã€‚\n",
    "*   **ç®€å•ç›´è§‚ï¼Œæ˜“äºä¸Šæ‰‹**ï¼šç›¸æ¯”äºå¤æ‚çš„ç”Ÿæˆä»»åŠ¡æˆ–å¯¹è¯ç³»ç»Ÿï¼Œæƒ…æ„Ÿåˆ†æçš„ç›®æ ‡æ˜ç¡®ï¼ˆåˆ¤æ–­æ­£é¢/è´Ÿé¢ï¼‰ï¼Œç»“æœæ˜“äºè¯„ä¼°ï¼ˆå‡†ç¡®ç‡ï¼‰ï¼Œéå¸¸é€‚åˆä½œä¸ºä»ç†è®ºåˆ°å®è·µçš„â€œç¬¬ä¸€åº§æ¡¥æ¢â€ã€‚\n",
    "\n",
    "å› æ­¤ï¼Œæœ¬æ•™ç¨‹å°†ä»¥ä¸­æ–‡æƒ…æ„Ÿåˆ†æä¸ºé¶ï¼Œå¸¦é¢†æ‚¨å®Œæ•´åœ°èµ°ä¸€éâ€œæ•°æ®å‡†å¤‡ -> æ¨¡å‹å¾®è°ƒ -> è¯„ä¼°é¢„æµ‹â€çš„å®æˆ˜æµç¨‹ï¼ŒçœŸæ­£å°†ERNIE-4.5-0.3Bçš„å¼ºå¤§èƒ½åŠ›ï¼Œåº”ç”¨åˆ°è§£å†³å®é™…é—®é¢˜ä¸­æ¥ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 ä»€ä¹ˆæ˜¯æƒ…æ„Ÿåˆ†æï¼Ÿ\n",
    "\n",
    "æƒ…æ„Ÿåˆ†æï¼Œåˆç§°ä¸ºæ„è§æŒ–æ˜ (Opinion Mining)ï¼Œæ˜¯åˆ©ç”¨è‡ªç„¶è¯­è¨€å¤„ç†ã€æ–‡æœ¬åˆ†æå’Œè®¡ç®—è¯­è¨€å­¦ç­‰æ–¹æ³•ï¼Œå¯¹å¸¦æœ‰æƒ…æ„Ÿè‰²å½©çš„ä¸»è§‚æ€§æ–‡æœ¬è¿›è¡Œæå–ã€åˆ†æã€å½’çº³å’Œæ¨ç†çš„è¿‡ç¨‹ã€‚ç®€å•æ¥è¯´ï¼Œå®ƒçš„ç›®æ ‡å°±æ˜¯**è¯†åˆ«å’Œåˆ¤æ–­ä¸€æ®µæ–‡æœ¬æ‰€è¡¨è¾¾çš„æƒ…æ„Ÿæ˜¯ç§¯æçš„ï¼ˆæ­£é¢ï¼‰ã€æ¶ˆæçš„ï¼ˆè´Ÿé¢ï¼‰ï¼Œè¿˜æ˜¯ä¸­æ€§çš„**ã€‚\n",
    "\n",
    "ä¾‹å¦‚ï¼Œç»™å®šä¸€æ¡ç”¨æˆ·è¯„ä»·ï¼šâ€œè¿™å®¶é¤å…çš„çƒ¤é¸­å‘³é“ç»äº†ï¼Œç¯å¢ƒä¹Ÿå¾ˆæ£’ï¼â€ï¼Œæƒ…æ„Ÿåˆ†æç³»ç»Ÿåº”è¯¥èƒ½åˆ¤æ–­å‡ºè¿™æ˜¯ä¸€æ¡**ç§¯æ**çš„è¯„ä»·ã€‚è€Œå¯¹äºâ€œç­‰äº†åŠä¸ªå¤šå°æ—¶æ‰ä¸Šèœï¼Œå‘³é“ä¹Ÿå¾ˆä¸€èˆ¬â€ï¼Œåˆ™åº”åˆ¤æ–­ä¸º**æ¶ˆæ**ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 æƒ…æ„Ÿåˆ†æçš„åº”ç”¨åœºæ™¯å’Œé¡¹ç›®æ„ä¹‰\n",
    "\n",
    "æƒ…æ„Ÿåˆ†ææŠ€æœ¯åœ¨å•†ä¸šå’Œç ”ç©¶é¢†åŸŸéƒ½æœ‰ç€å·¨å¤§çš„åº”ç”¨ä»·å€¼ï¼Œæ˜¯è®¸å¤šæ™ºèƒ½åº”ç”¨çš„åŸºç¡€æ¨¡å—ã€‚\n",
    "\n",
    "| åº”ç”¨é¢†åŸŸ       | å…·ä½“åœºæ™¯                                                     | é¡¹ç›®æ„ä¹‰                                       |\n",
    "| -------------- | ------------------------------------------------------------ | ---------------------------------------------- |\n",
    "| **å•†ä¸šæ™ºèƒ½**   | èˆ†æƒ…ç›‘æ§ã€å“ç‰Œå£°èª‰ç®¡ç†ã€äº§å“è¯„ä»·åˆ†æ                         | å®æ—¶äº†è§£å…¬ä¼—æƒ…ç»ªï¼Œä¼˜åŒ–äº§å“ï¼Œè¿›è¡Œå±æœºå…¬å…³         |\n",
    "| **å®¢æˆ·å…³ç³»**   | åˆ†æå®¢æœå¯¹è¯ã€æœåŠ¡å·¥å•ã€ç”¨æˆ·æ»¡æ„åº¦é—®å·                       | è‡ªåŠ¨è¯„ä¼°å®¢æˆ·æ»¡æ„åº¦ï¼Œå‘ç°æœåŠ¡ç—›ç‚¹ï¼Œæå‡æœåŠ¡è´¨é‡ |\n",
    "| **é‡‘èç§‘æŠ€**   | åˆ†æè´¢ç»æ–°é—»ã€ç¤¾äº¤åª’ä½“æƒ…ç»ªã€è‚¡è¯„                           | è¾…åŠ©é‡åŒ–äº¤æ˜“å’ŒæŠ•èµ„å†³ç­–                         |\n",
    "| **ç¤¾ä¼šç§‘å­¦**   | åˆ†æå…¬ä¼—å¯¹ç‰¹å®šç¤¾ä¼šäº‹ä»¶æˆ–æ”¿ç­–çš„æƒ…æ„Ÿå€¾å‘                       | ä¸ºç¤¾ä¼šå­¦ã€ä¼ æ’­å­¦ç­‰é¢†åŸŸçš„ç ”ç©¶æä¾›æ•°æ®å‚è€ƒ         |\n",
    "\n",
    "æœ¬é¡¹ç›®æ—¨åœ¨é€šè¿‡ä¸€ä¸ªå®Œæ•´çš„å®æˆ˜æ¡ˆä¾‹ï¼Œè®©æ‚¨æŒæ¡å¦‚ä½•åˆ©ç”¨æœ€æ–°çš„ERNIE-4.5-0.3Bæ¨¡å‹è§£å†³çœŸå®åœºæ™¯ä¸‹çš„æ–‡æœ¬åˆ†ç±»é—®é¢˜ï¼Œä¸ºæ‚¨åœ¨è‡ªå·±çš„ä¸šåŠ¡æˆ–ç ”ç©¶ä¸­åº”ç”¨NLPæŠ€æœ¯æ‰“ä¸‹åšå®çš„åŸºç¡€ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 ä¸ºä»€ä¹ˆé€‰æ‹© ERNIE-4.5-0.3B æ¨¡å‹ï¼Ÿ\n",
    "\n",
    "ERNIE 4.5 å¹¶éå•ä¸€æ¨¡å‹ï¼Œè€Œæ˜¯ä¸€ä¸ªåŒ…å«å¤šç§è§„æ¨¡å’Œé’ˆå¯¹ä¸åŒåœºæ™¯ä¼˜åŒ–çš„æ¨¡å‹å®¶æ—ã€‚ä¸ºäº†å¸®åŠ©æ‚¨æ›´å¥½åœ°ç†è§£æˆ‘ä»¬ä¸ºä»€ä¹ˆé€‰æ‹© ERNIE-4.5-0.3Bï¼Œä¸‹è¡¨ä¾æ®å®˜æ–¹ `ERNIE-develop` ä»“åº“æ–‡æ¡£ï¼Œå¯¹ç³»åˆ—å†…çš„ä¸»è¦æ¨¡å‹è¿›è¡Œäº†å¯¹æ¯”ï¼š\n",
    "\n",
    "| æ¨¡å‹åç§° | æ”¯æŒçš„å¾®è°ƒæ–¹æ³• | æ”¯æŒçš„åºåˆ—é•¿åº¦ | æœ€ä½èµ„æºéœ€æ±‚ (SFT) |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **ERNIE-4.5-0.3B** | SFT, SFT-LoRA, DPO, DPO-LoRA | 8k, 32k, 128k | **1x 80G A/H GPU** |\n",
    "| ERNIE-4.5-21B-A3B | SFT, SFT-LoRA, DPO, DPO-LoRA | 8k, 32k, 128k | 8x 80G A/H GPUs |\n",
    "| ERNIE-4.5-300B-A47B | SFT, SFT(FP8), SFT-LoRA, DPO, DPO-LoRA | 8k, 32k | 96x 80G A/H GPUs (SFT) <br> 16x 80G H GPUs (SFT with FP8) |\n",
    "\n",
    "*è¡¨æ ¼ä¿¡æ¯æ¥æºï¼šERNIE-develop/docs/erniekit.md* \n",
    "\n",
    "<br>\n",
    "\n",
    "**ä¸ºä»€ä¹ˆé€‰æ‹© ERNIE-4.5-0.3Bï¼Ÿ**\n",
    "\n",
    "å¯¹äºæœ¬æ¬¡æƒ…æ„Ÿåˆ†æå®æˆ˜æ•™ç¨‹ï¼ŒERNIE-4.5-0.3B æ˜¯ä¸€ä¸ªç†æƒ³çš„é€‰æ‹©ï¼ŒåŸå› å¦‚ä¸‹ï¼š\n",
    "\n",
    "*   **èµ„æºå‹å¥½ï¼Œè§¦æ‰‹å¯åŠ**ï¼šä»ä¸Šè¡¨å¯ä»¥æ˜ç¡®çœ‹åˆ°ï¼Œ`ERNIE-4.5-0.3B` çš„å…¨å‚æ•°å¾®è°ƒï¼ˆSFTï¼‰ä»…éœ€**å•å¼ 80Gçš„A/Hç³»åˆ—GPU**å³å¯å®Œæˆï¼Œè¿™æå¤§åœ°é™ä½äº†å­¦ä¹ å’Œå®è·µå¤§æ¨¡å‹çš„ç¡¬ä»¶é—¨æ§›ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œå…¶ä»–æ›´å¤§è§„æ¨¡çš„æ¨¡å‹åŠ¨è¾„éœ€è¦æ•°åç”šè‡³ä¸Šç™¾å¼ GPUï¼Œå¯¹äºä¸ªäººå¼€å‘è€…å’Œå¤§å¤šæ•°å­¦ä¹ åœºæ™¯æ¥è¯´æ˜¯ä¸ç°å®çš„ã€‚\n",
    "*   **åŠŸèƒ½å®Œæ•´ï¼Œä½“éªŒå…¨é¢**ï¼šå°½ç®¡æ¨¡å‹è§„æ¨¡è¾ƒå°ï¼Œä½† `ERNIE-4.5-0.3B` æ”¯æŒåŒ…æ‹¬SFTã€LoRAã€DPOåœ¨å†…çš„å…¨å¥—å¾®è°ƒæŠ€æœ¯ï¼Œè®©æˆ‘ä»¬å¯ä»¥ç”¨æœ€ç»æµçš„æ–¹å¼ï¼Œå®Œæ•´åœ°ä½“éªŒå’Œå­¦ä¹ å¤§æ¨¡å‹å¼€å‘çš„æ•´ä¸ªæµç¨‹ã€‚\n",
    "*   **æ€§èƒ½ä¼˜å¼‚ï¼Œè¶³ä»¥èƒœä»»**ï¼šå¯¹äºæƒ…æ„Ÿåˆ†æè¿™ç±»ç›¸å¯¹æˆç†Ÿçš„NLPä»»åŠ¡ï¼Œ`ERNIE-4.5-0.3B` ç»§æ‰¿äº†ERNIEç³»åˆ—å¼ºå¤§çš„è¯­ä¹‰ç†è§£èƒ½åŠ›ï¼Œå…¶æ€§èƒ½å®Œå…¨èƒ½å¤Ÿæ»¡è¶³é«˜ç²¾åº¦åˆ†ç±»çš„éœ€æ±‚ã€‚æˆ‘ä»¬æ— éœ€åŠ¨ç”¨â€œæ€ç‰›åˆ€â€ï¼Œå³å¯é«˜æ•ˆåœ°è§£å†³é—®é¢˜ã€‚\n",
    "\n",
    "ERNIE-4.5-0.3B åœ¨**å­¦ä¹ æˆæœ¬ã€åŠŸèƒ½å®Œæ•´æ€§å’Œä»»åŠ¡æ€§èƒ½**ä¹‹é—´å–å¾—äº†ç»ä½³çš„å¹³è¡¡ï¼Œæ˜¯å…¥é—¨å’Œå®è·µå¤§æ¨¡å‹æƒ…æ„Ÿåˆ†æä»»åŠ¡çš„**å®˜æ–¹æ¨èå’Œæœ€ä½³é€‰æ‹©**ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 æœ¬æ•™ç¨‹çš„ç›®æ ‡ä¸å†…å®¹\n",
    "\n",
    "æœ¬æ•™ç¨‹é¢å‘å¯¹NLPå’Œæ·±åº¦å­¦ä¹ æœ‰åŸºæœ¬äº†è§£ï¼Œå¹¶å¸Œæœ›åŠ¨æ‰‹å®è·µè§£å†³çœŸå®é—®é¢˜çš„å¼€å‘è€…å’Œå­¦ä¹ è€…ã€‚é€šè¿‡æœ¬æ•™ç¨‹ï¼Œæ‚¨å°†æ”¶è·æ»¡æ»¡ï¼š\n",
    "\n",
    "| å­¦ä¹ ç›®æ ‡ | æ ¸å¿ƒæŠ€èƒ½ç‚¹ | æ‚¨å°†æŒæ¡ | \n",
    "|:---:|:---|:---| \n",
    "| ğŸ¯ **ç†è§£ä»»åŠ¡** | æƒ…æ„Ÿåˆ†æåŸºæœ¬æµç¨‹ | èƒ½å¤Ÿæ¸…æ™°åœ°æè¿°æƒ…æ„Ÿåˆ†æä»»åŠ¡çš„è¾“å…¥ã€è¾“å‡ºå’Œè¯„ä¼°æŒ‡æ ‡ | \n",
    "| ğŸ› ï¸ **æŒæ¡å·¥å…·** | ERNIEkitçš„ä½¿ç”¨ | ç†Ÿç»ƒä½¿ç”¨ERNIEkitè¿›è¡Œæ•°æ®å¤„ç†ã€æ¨¡å‹åŠ è½½å’Œé…ç½® | \n",
    "| ğŸ”¥ **æ ¸å¿ƒå®æˆ˜** | ERNIE-4.5-0.3Bå¾®è°ƒ | ä»é›¶å¼€å§‹ï¼Œè®­ç»ƒä¸€ä¸ªé«˜ç²¾åº¦çš„ä¸­æ–‡æƒ…æ„Ÿåˆ†ææ¨¡å‹ | \n",
    "| ğŸ“Š **å­¦ä¼šè¯„ä¼°** | æ¨¡å‹æ€§èƒ½è¯„ä¼°ä¸é¢„æµ‹ | èƒ½å¤Ÿç§‘å­¦åœ°è¯„ä¼°æ¨¡å‹æ•ˆæœï¼Œå¹¶ä½¿ç”¨æ¨¡å‹è¿›è¡Œæ¨ç†é¢„æµ‹ | \n",
    "\n",
    "è®©æˆ‘ä»¬å¼€å§‹å§ï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ERNIEkitç®€ä»‹ï¼šä¸€ç«™å¼å¤§æ¨¡å‹å¼€å‘åˆ©å™¨\n",
    "\n",
    "åœ¨æ­£å¼å¼€å§‹åŠ¨æ‰‹ä¹‹å‰ï¼Œæˆ‘ä»¬æœ‰å¿…è¦å…ˆè®¤è¯†ä¸€ä¸‹æœ¬æ¬¡å®æˆ˜çš„â€œä¸»è§’â€ä¹‹ä¸€â€”â€”ERNIEkitã€‚ç®€å•æ¥è¯´ï¼Œ**ERNIEkit æ˜¯ä¸€ä¸ªä¸ºERNIEç³»åˆ—å¤§æ¨¡å‹é‡èº«æ‰“é€ çš„å…¨æµç¨‹å¼€å‘å·¥å…·åŒ…**ã€‚\n",
    "\n",
    "å¦‚æœæ‚¨ä¹‹å‰æœ‰è¿‡ä½¿ç”¨ `PaddleNLP` æˆ– `Hugging Face Transformers` çš„ç»éªŒï¼Œæ‚¨å¯ä»¥å°† `ERNIEkit` ç†è§£ä¸ºä¸€ä¸ªæ›´åŠ èšç„¦å’Œé«˜æ•ˆçš„æ›¿ä»£å“ã€‚å®ƒå°†å¤§æ¨¡å‹å¼€å‘çš„å¤æ‚æµç¨‹ï¼Œå¦‚æ•°æ®å¤„ç†ã€æ¨¡å‹è®­ç»ƒã€æ€§èƒ½ä¼˜åŒ–ã€è¯„ä¼°å’Œéƒ¨ç½²ç­‰ï¼Œéƒ½å°è£…æˆäº†ç®€æ´çš„å‘½ä»¤è¡Œå·¥å…·å’Œé…ç½®æ–‡ä»¶ï¼Œæ—¨åœ¨ä¸ºå¼€å‘è€…æä¾›â€œå¼€ç®±å³ç”¨â€çš„æè‡´ä½“éªŒã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 ERNIEkitçš„æ ¸å¿ƒè®¾è®¡ç†å¿µ\n",
    "\n",
    "ERNIEkitçš„è®¾è®¡å“²å­¦å¯ä»¥æ¦‚æ‹¬ä¸ºâ€œ**çº¦å®šä¼˜äºé…ç½®**â€ (Convention over Configuration)ã€‚å®ƒä¸ºå¤§æ¨¡å‹çš„ä¸åŒåº”ç”¨åœºæ™¯ï¼ˆå¦‚SFTã€DPOã€é¢„è®­ç»ƒç­‰ï¼‰æä¾›äº†æœ€ä½³å®è·µèŒƒæœ¬å’Œé»˜è®¤é…ç½®ã€‚å¼€å‘è€…ä¸å†éœ€è¦ç¼–å†™å†—é•¿çš„è®­ç»ƒè„šæœ¬ï¼Œåªéœ€ï¼š\n",
    "\n",
    "1.  **å‡†å¤‡æ•°æ®**ï¼šæŒ‰ç…§çº¦å®šæ ¼å¼å‡†å¤‡å¥½æ‚¨çš„æ•°æ®ã€‚\n",
    "2.  **ä¿®æ”¹é…ç½®**ï¼šåœ¨ä¸€ä¸ª`yaml`é…ç½®æ–‡ä»¶ä¸­ï¼Œåƒå¡«ç©ºä¸€æ ·ä¿®æ”¹å‡ ä¸ªæ ¸å¿ƒå‚æ•°ï¼ˆå¦‚æ¨¡å‹è·¯å¾„ã€æ•°æ®è·¯å¾„ã€å­¦ä¹ ç‡ç­‰ï¼‰ã€‚\n",
    "3.  **æ‰§è¡Œå‘½ä»¤**ï¼šè¿è¡Œä¸€æ¡ç®€å•çš„å‘½ä»¤ï¼ˆå¦‚ `erniekit train`ï¼‰ï¼Œå³å¯å¯åŠ¨ä¸€ä¸ªç»è¿‡æ·±åº¦ä¼˜åŒ–çš„è®­ç»ƒæµç¨‹ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 ERNIEkitçš„æ ¸å¿ƒä¼˜åŠ¿\n",
    "\n",
    "| ä¼˜åŠ¿ç‰¹æ€§ | å…·ä½“ä½“ç° | ä¸ºå¼€å‘è€…å¸¦æ¥çš„ä»·å€¼ |\n",
    "|:---:|:---|:---|\n",
    "| ğŸš€ **æè‡´æ˜“ç”¨** | `é…ç½®æ–‡ä»¶` + `å‘½ä»¤è¡Œ` çš„å¼€å‘æ¨¡å¼ | å¤§å¹…é™ä½å¤§æ¨¡å‹å¼€å‘é—¨æ§›ï¼Œæ— éœ€ç¼–å†™å¤æ‚ä»£ç  |\n",
    "| âš¡ **æ€§èƒ½å“è¶Š** | å†…ç½®å¤šç§å¹¶è¡Œç­–ç•¥ã€æ··åˆç²¾åº¦ã€ç®—å­èåˆç­‰ä¼˜åŒ– | æ— éœ€æ‰‹åŠ¨ä¼˜åŒ–ï¼Œå³å¯è·å¾—é«˜æ€§èƒ½çš„è®­ç»ƒå’Œæ¨ç†é€Ÿåº¦ |\n",
    "| ğŸ“¦ **åŠŸèƒ½å…¨é¢** | è¦†ç›–æ•°æ®å¤„ç†ã€è®­ç»ƒã€è¯„ä¼°ã€æ¨ç†ã€éƒ¨ç½²å…¨æµç¨‹ | æä¾›ä¸€ç«™å¼è§£å†³æ–¹æ¡ˆï¼Œç®€åŒ–å¼€å‘æµç¨‹ |\n",
    "| ğŸ”§ **çµæ´»æ‰©å±•** | æ”¯æŒè‡ªå®šä¹‰æ¨¡å‹ã€æ•°æ®ã€è®­ç»ƒæµç¨‹ | æ—¢èƒ½å¼€ç®±å³ç”¨ï¼Œä¹Ÿä¸ºé«˜é˜¶ç”¨æˆ·ä¿ç•™äº†è¶³å¤Ÿçš„çµæ´»æ€§ |\n",
    "\n",
    "é€šè¿‡æœ¬æ•™ç¨‹ï¼Œæ‚¨å°†äº²èº«ä½“éªŒåˆ°ä½¿ç”¨ERNIEkitè¿›è¡Œå¤§æ¨¡å‹å¼€å‘çš„ä¾¿æ·ä¸é«˜æ•ˆã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ç¯å¢ƒå‡†å¤‡\n",
    "\n",
    "é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦ç¡®ä¿å®‰è£…äº†å¿…éœ€çš„åº“ã€‚æœ¬æ•™ç¨‹ä¸»è¦ä¾èµ– ERNIEkit å’Œ aistudio-sdkã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# å®‰è£…æœ€æ–°ç‰ˆæœ¬çš„ERNIEkitå’Œaistudio-sdk\r\n",
    "!pip install --upgrade aistudio-sdk\r\n",
    "\r\n",
    "# ä¸‹è½½ERNIE-4.5-0.3Bæ¨¡å‹\r\n",
    "!aistudio download --model PaddlePaddle/ERNIE-4.5-0.3B-Paddle --local_dir baidu/ERNIE-4.5-0.3B-Paddle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å®‰è£…å®Œæˆåï¼Œæˆ‘ä»¬å¯ä»¥å¯¼å…¥å¹¶æ£€æŸ¥ç‰ˆæœ¬ä¿¡æ¯ï¼Œä»¥ç¡®ä¿ç¯å¢ƒé…ç½®æ­£ç¡®ã€‚  Ai studioè¿è¡Œçš„åŒå­¦ä¸éœ€è¦è¿è¡Œè¿™ä»£ç å—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T07:16:41.583798Z",
     "iopub.status.busy": "2025-07-18T07:16:41.583484Z",
     "iopub.status.idle": "2025-07-18T07:16:43.037416Z",
     "shell.execute_reply": "2025-07-18T07:16:43.036888Z",
     "shell.execute_reply.started": "2025-07-18T07:16:41.583779Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/utils/cpp_extension/extension_utils.py:715: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\r\n",
      "  warnings.warn(warning_message)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PaddlePaddle is compiled with CUDA and GPU is available.\r\n"
     ]
    }
   ],
   "source": [
    "# æ£€æŸ¥GPUæ˜¯å¦å¯ç”¨\r\n",
    "import paddle\r\n",
    "if paddle.is_compiled_with_cuda():\r\n",
    "    print(\"PaddlePaddle is compiled with CUDA and GPU is available.\")\r\n",
    "else:\r\n",
    "    print(\"PaddlePaddle is not compiled with CUDA. It will use CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç¯å¢ƒå‡†å¤‡éå¸¸ç®€å•ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†åŠ è½½ç”¨äºæœ¬æ¬¡ä»»åŠ¡çš„æ•°æ®é›†ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. æ•°æ®å‡†å¤‡\n",
    "\n",
    "å¯¹äºæƒ…æ„Ÿåˆ†æä»»åŠ¡ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ª**å·²æ ‡æ³¨**çš„æ•°æ®é›†ï¼Œå…¶ä¸­æ¯æ¡æ–‡æœ¬éƒ½å¯¹åº”ä¸€ä¸ªæƒ…æ„Ÿæ ‡ç­¾ï¼ˆå¦‚\"ç§¯æ\"æˆ–\"æ¶ˆæ\"ï¼‰ã€‚\n",
    "\n",
    "### 3.1 æ•°æ®é›†æ ¼å¼è¯´æ˜\n",
    "\n",
    "ERNIEkit ä½¿ç”¨ `jsonl` æ ¼å¼ä½œä¸ºæ ‡å‡†çš„æ•°æ®è¾“å…¥æ ¼å¼ã€‚æ¯ä¸€è¡Œéƒ½æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„JSONå¯¹è±¡ï¼ŒåŒ…å«äº†è®­ç»ƒæ‰€éœ€çš„æ•°æ®ã€‚å¯¹äºæƒ…æ„Ÿåˆ†æä»»åŠ¡ï¼Œæˆ‘ä»¬éœ€è¦å‡†å¤‡ä»¥ä¸‹æ ¼å¼çš„æ•°æ®ï¼š\n",
    "\n",
    "```json\n",
    "{\"text\": \"è¿™å®¶é¤å…çš„çƒ¤é¸­å‘³é“ç»äº†ï¼Œç¯å¢ƒä¹Ÿå¾ˆæ£’ï¼\", \"label\": 1}\n",
    "{\"text\": \"ç­‰äº†åŠä¸ªå¤šå°æ—¶æ‰ä¸Šèœï¼Œå‘³é“ä¹Ÿå¾ˆä¸€èˆ¬\", \"label\": 0}\n",
    "```\n",
    "\n",
    "å…¶ä¸­ï¼š\n",
    "- `text`: è¡¨ç¤ºè¾“å…¥çš„æ–‡æœ¬å†…å®¹ã€‚\n",
    "- `label`: è¡¨ç¤ºæƒ…æ„Ÿæ ‡ç­¾ï¼Œ`1` ä»£è¡¨ç§¯æï¼Œ`0` ä»£è¡¨æ¶ˆæã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 åˆ›å»ºç¤ºä¾‹æ•°æ®\n",
    "\n",
    "ä¸ºäº†æ–¹ä¾¿æ¼”ç¤ºï¼Œæˆ‘ä»¬æ‰‹åŠ¨åˆ›å»ºä¸¤ä¸ª`jsonl`æ–‡ä»¶ï¼Œåˆ†åˆ«ä½œä¸ºè®­ç»ƒé›†å’Œè¯„ä¼°é›†ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T07:43:59.478943Z",
     "iopub.status.busy": "2025-07-18T07:43:59.478622Z",
     "iopub.status.idle": "2025-07-18T07:43:59.485958Z",
     "shell.execute_reply": "2025-07-18T07:43:59.485388Z",
     "shell.execute_reply.started": "2025-07-18T07:43:59.478923Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç¬¦åˆERNIEkitæ ¼å¼çš„ç¤ºä¾‹æ•°æ®åˆ›å»ºæˆåŠŸï¼sft-train.jsonl å’Œ sft-eval.jsonl å·²ç”Ÿæˆã€‚\r\n"
     ]
    }
   ],
   "source": [
    "import json\r\n",
    "\r\n",
    "# å®šä¹‰æ ‡ç­¾æ˜ å°„\r\n",
    "label_map = {1: \"æ­£é¢æƒ…æ„Ÿ\", 0: \"è´Ÿé¢æƒ…æ„Ÿ\"}\r\n",
    "\r\n",
    "# åˆ›å»ºç¬¦åˆERNIEkit SFTæ ¼å¼çš„è®­ç»ƒæ•°æ®\r\n",
    "train_data = [\r\n",
    "    # æ­£é¢è¯„ä»·\r\n",
    "    {\"src\": [\"è¿™å®¶é¤å…çš„çƒ¤é¸­å‘³é“ç»äº†ï¼Œç¯å¢ƒä¹Ÿå¾ˆæ£’ï¼\"], \"tgt\": [label_map[1]]},\r\n",
    "    {\"src\": [\"æœåŠ¡å‘˜æ€åº¦å¾ˆå¥½ï¼Œä¸‹æ¬¡è¿˜ä¼šå†æ¥\"], \"tgt\": [label_map[1]]},\r\n",
    "    {\"src\": [\"ç”µå½±ç‰¹æ•ˆéå¸¸éœ‡æ’¼ï¼Œæ•…äº‹æƒ…èŠ‚ä¹Ÿå¾ˆå¸å¼•äººã€‚\"], \"tgt\": [label_map[1]]},\r\n",
    "    {\"src\": [\"è¿™æ¬¾æ‰‹æœºæ‹ç…§æ•ˆæœçœŸä¸é”™ï¼Œç”µæ± ä¹Ÿè€ç”¨ã€‚\"], \"tgt\": [label_map[1]]},\r\n",
    "    \r\n",
    "    # è´Ÿé¢è¯„ä»·\r\n",
    "    {\"src\": [\"ç­‰äº†åŠä¸ªå¤šå°æ—¶æ‰ä¸Šèœï¼Œå‘³é“ä¹Ÿå¾ˆä¸€èˆ¬\"], \"tgt\": [label_map[0]]},\r\n",
    "    {\"src\": [\"æˆ¿é—´éš”éŸ³å¤ªå·®äº†ï¼Œæ™šä¸Šæ ¹æœ¬ç¡ä¸ç€\"], \"tgt\": [label_map[0]]},\r\n",
    "    {\"src\": [\"æ–°ä¹°çš„é‹å­ç©¿äº†ä¸€å¤©å°±å¼€èƒ¶äº†ï¼Œè´¨é‡å¤ªå·®äº†ã€‚\"], \"tgt\": [label_map[0]]},\r\n",
    "    {\"src\": [\"å®¢æœç”µè¯ä¸€ç›´æ‰“ä¸é€šï¼Œé—®é¢˜è§£å†³ä¸äº†ï¼Œä½“éªŒæå·®ã€‚\"], \"tgt\": [label_map[0]]}\r\n",
    "]\r\n",
    "\r\n",
    "with open('sft-train.jsonl', 'w', encoding='utf-8') as f:\r\n",
    "    for item in train_data:\r\n",
    "        # ERNIEkitè¦æ±‚srcå’Œtgtæ˜¯åˆ—è¡¨\r\n",
    "        f.write(json.dumps(item, ensure_ascii=False) + '\\n')\r\n",
    "\r\n",
    "# åˆ›å»ºç¬¦åˆERNIEkit SFTæ ¼å¼çš„è¯„ä¼°æ•°æ®\r\n",
    "eval_data = [\r\n",
    "    {\"src\": [\"é£æ™¯ä¸é”™ï¼Œå°±æ˜¯äººå¤ªå¤šäº†\"], \"tgt\": [label_map[1]]},\r\n",
    "    {\"src\": [\"é…’åº—ä½ç½®å¾ˆéš¾æ‰¾ï¼Œæ€§ä»·æ¯”ä¸é«˜\"], \"tgt\": [label_map[0]]}\r\n",
    "]\r\n",
    "\r\n",
    "with open('sft-eval.jsonl', 'w', encoding='utf-8') as f:\r\n",
    "    for item in eval_data:\r\n",
    "        f.write(json.dumps(item, ensure_ascii=False) + '\\n')\r\n",
    "\r\n",
    "print(\"ç¬¦åˆERNIEkitæ ¼å¼çš„ç¤ºä¾‹æ•°æ®åˆ›å»ºæˆåŠŸï¼sft-train.jsonl å’Œ sft-eval.jsonl å·²ç”Ÿæˆã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 é…ç½®æ•°æ®è·¯å¾„\n",
    "\n",
    "åœ¨ERNIEkitä¸­ï¼Œæˆ‘ä»¬é€šè¿‡ä¿®æ”¹é…ç½®æ–‡ä»¶æ¥æŒ‡å®šæ•°æ®é›†çš„è·¯å¾„ã€‚æ‰“å¼€ `examples/configs/ERNIE-4.5-0.3B/sft/run_sft_8k.yaml` æ–‡ä»¶ï¼Œæ‰¾åˆ°ä»¥ä¸‹éƒ¨åˆ†å¹¶ä¿®æ”¹ï¼š\n",
    "\n",
    "```yaml\n",
    "### data\n",
    "train_dataset_path: \"./sft-train.jsonl\"\n",
    "eval_dataset_path: \"./sft-eval.jsonl\"\n",
    "```\n",
    "\n",
    "è¿™æ ·ï¼ŒERNIEkitåœ¨è®­ç»ƒæ—¶å°±ä¼šè‡ªåŠ¨åŠ è½½æˆ‘ä»¬å‡†å¤‡å¥½çš„æ•°æ®ã€‚\n",
    "\n",
    "è‡³æ­¤ï¼Œæ•°æ®å‡†å¤‡çš„å…¨éƒ¨å·¥ä½œå·²ç»å®Œæˆã€‚æˆ‘ä»¬æ‹¥æœ‰äº†å¯ä»¥éšæ—¶é€å…¥æ¨¡å‹è¿›è¡Œè®­ç»ƒçš„æ•°æ®ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. æ¨¡å‹ä¸å¾®è°ƒåŸç†\n",
    "\n",
    "åœ¨æ•°æ®å‡†å¤‡å°±ç»ªåï¼Œæˆ‘ä»¬éœ€è¦ç†è§£æˆ‘ä»¬å°†è¦ä½¿ç”¨çš„æ¨¡å‹ä»¥åŠå¦‚ä½•è®©å®ƒé€‚åº”æˆ‘ä»¬çš„æƒ…æ„Ÿåˆ†æä»»åŠ¡ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 ERNIE-4.5-0.3B æ¨¡å‹ç®€ä»‹ï¼šä¸€ä½æ‡‚çŸ¥è¯†çš„è¯­è¨€å¤§å¸ˆ\n",
    "\n",
    "æ­£å¦‚å¼•è¨€ä¸­æ‰€è¯´ï¼ŒERNIE-4.5-0.3B æ˜¯ä¸€ä¸ªæ›´\"æ‡‚\"ä¸­æ–‡çš„æ¨¡å‹ã€‚å®ƒçš„æ ¸å¿ƒä¼˜åŠ¿åœ¨äºå…¶ç‹¬ç‰¹çš„**çŸ¥è¯†æ•´åˆé¢„è®­ç»ƒä»»åŠ¡**ã€‚\n",
    "\n",
    "*   **ä¸€ä¸ªæ›´æ·±å…¥çš„æ¯”å–»**ï¼š\n",
    "    æƒ³è±¡ä¸€ä¸ªå­¦ç”Ÿï¼ˆå…¶ä»–æ¨¡å‹ï¼‰åœ¨å­¦ä¹ ä¸€å¥è¯ï¼š\"ä¸­å›½å››å¤§å‘æ˜ä¹‹ä¸€çš„æ´»å­—å°åˆ·æœ¯æ˜¯ç”±æ¯•æ˜‡å‘æ˜çš„ã€‚\"\n",
    "    è¿™ä¸ªå­¦ç”Ÿå¯èƒ½é€šè¿‡\"å•å­—å¡«ç©º\"å­¦ä¼šäº†\"ï¼ˆæ´»ï¼‰å­—å°åˆ·æœ¯\"å’Œ\"æ¯•ï¼ˆæ˜‡ï¼‰\"è¿™äº›å­—ã€‚\n",
    "    \n",
    "    è€ŒERNIEè¿™ä½\"å­¦éœ¸\"åˆ™ä¸åŒï¼Œè€å¸ˆä¼šç›´æ¥å°†\"**æ´»å­—å°åˆ·æœ¯**\"å’Œ\"**æ¯•æ˜‡**\"è¿™ä¸¤ä¸ªå®Œæ•´çš„çŸ¥è¯†å•å…ƒç›–ä½ï¼Œè®©ä»–å»é¢„æµ‹ã€‚ä¸ºäº†èƒ½ç­”å¯¹ï¼ŒERNIEä¸ä»…ä»…è¦å­¦ä¹ è¯­è¨€çš„æµç•…æ€§ï¼Œæ›´è¢«è¿«å»ç†è§£\"æ´»å­—å°åˆ·æœ¯\"æ˜¯ä¸€ä¸ªå®Œæ•´çš„æŠ€æœ¯æ¦‚å¿µï¼Œ\"æ¯•æ˜‡\"æ˜¯ä¸€ä¸ªäººåï¼Œå¹¶ä¸”è¿™ä¸¤ä¸ªçŸ¥è¯†å•å…ƒä¹‹é—´å­˜åœ¨\"å‘æ˜\"çš„å…³è”ã€‚\n",
    "    \n",
    "    é€šè¿‡åœ¨æµ·é‡æ–‡æœ¬ä¸Šè¿›è¡Œè¿™ç§\"çŸ¥è¯†ç‚¹æŒ–æ˜\"å¼çš„å­¦ä¹ ï¼ŒERNIEæ„å»ºäº†æ›´æ·±å±‚æ¬¡çš„è¯­ä¹‰ç†è§£èƒ½åŠ›ï¼Œè€Œä¸ä»…ä»…æ˜¯è¡¨é¢çš„æ–‡å­—ç»„åˆã€‚\n",
    "\n",
    "è¿™å°±æ˜¯ä¸ºä»€ä¹ˆERNIEåœ¨éœ€è¦ç†è§£å¥å­æ·±å±‚å«ä¹‰çš„ä»»åŠ¡ï¼ˆå¦‚æƒ…æ„Ÿåˆ†æï¼‰ä¸Šé€šå¸¸è¡¨ç°å¾—æ›´å¥½çš„åŸå› ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 å¾®è°ƒ (Fine-tuning) åŸç†ï¼šä¸ºè¯­è¨€å¤§å¸ˆé…ä¸Š\"æƒ…æ„Ÿåˆ†æçœ¼é•œ\"\n",
    "\n",
    "æˆ‘ä»¬åŠ è½½çš„ `ERNIE-4.5-0.3B` æ¨¡å‹æ˜¯ä¸€ä½åšå­¦çš„\"é€šæ‰\"ï¼Œå®ƒæ‡‚å¾—è¯­è¨€çš„å„ç§çŸ¥è¯†ï¼Œä½†é»˜è®¤æƒ…å†µä¸‹ï¼Œå®ƒå¹¶ä¸çŸ¥é“è‡ªå·±éœ€è¦åš\"æƒ…æ„Ÿåˆ†æ\"è¿™é¡¹å…·ä½“å·¥ä½œã€‚**å¾®è°ƒ (Fine-tuning)** çš„è¿‡ç¨‹ï¼Œå°±å¥½æ¯”æ˜¯ä¸ºè¿™ä½è¯­è¨€å¤§å¸ˆé…ä¸Šä¸€å‰¯ç‰¹åˆ¶çš„\"æƒ…æ„Ÿåˆ†æçœ¼é•œ\"ï¼Œå¹¶æŒ‡å¯¼ä»–å¦‚ä½•ä½¿ç”¨ã€‚\n",
    "\n",
    "è¿™ä¸ªè¿‡ç¨‹åˆ†ä¸ºå‡ æ­¥ï¼š\n",
    "\n",
    "1.  **è·å–å¥å­çš„\"çµé­‚\"â€”â€”[CLS]è¾“å‡º**ï¼š\n",
    "    *   æˆ‘ä»¬å°†ä¸€æ¡è¯„è®ºæ–‡æœ¬ï¼ˆä¾‹å¦‚\"è¿™å®¶åº—çš„æ‹‰é¢çœŸå¥½åƒï¼\"ï¼‰é€å…¥ERNIEæ¨¡å‹ã€‚åœ¨é€å…¥å‰ï¼Œæˆ‘ä»¬åœ¨æ–‡æœ¬æœ€å‰é¢åŠ ä¸Šä¸€ä¸ªç‰¹æ®Šçš„æ ‡å¿— `[CLS]` (Classification)ã€‚\n",
    "    *   ç»è¿‡ERNIEå†…éƒ¨å¤æ‚çš„è®¡ç®—ï¼ˆå¤šå±‚Transformerï¼‰ï¼Œæ¯ä¸ªå­—è¯éƒ½ä¼šå¾—åˆ°ä¸€ä¸ªå¯Œå«ä¸Šä¸‹æ–‡ä¿¡æ¯çš„å‘é‡ã€‚è€Œè¿™ä¸ªç‰¹æ®Šçš„ `[CLS]` æ ‡å¿—ï¼Œåœ¨ç»è¿‡æ•´ä¸ªæ¨¡å‹åï¼Œå®ƒå¯¹åº”çš„è¾“å‡ºå‘é‡ (`pooled_output`) å°±è¢«è®¾è®¡ä¸ºå‡èšäº†æ•´ä¸ªå¥å­çš„æ ¸å¿ƒè¯­ä¹‰ã€‚æˆ‘ä»¬å¯ä»¥æŠŠå®ƒæ¯”ä½œERNIEè¯»å®Œä¸€å¥è¯åï¼Œåœ¨è„‘æµ·ä¸­å½¢æˆçš„å¯¹è¿™å¥è¯çš„\"æ•´ä½“å°è±¡\"æˆ–\"çµé­‚\"å‘é‡ã€‚\n",
    "\n",
    "2.  **å®‰è£…\"æƒ…æ„Ÿåˆ†æé•œç‰‡\"â€”â€”æ·»åŠ åˆ†ç±»å¤´**ï¼š\n",
    "    *   è¿™ä¸ª\"çµé­‚\"å‘é‡ï¼ˆä¾‹å¦‚ä¸€ä¸ª768ç»´çš„å‘é‡ï¼‰æœ¬èº«è¿˜åªæ˜¯ä¸€ä¸²æ•°å­—ï¼Œä¸ç›´æ¥ä»£è¡¨\"ç§¯æ\"æˆ–\"æ¶ˆæ\"ã€‚\n",
    "    *   æˆ‘ä»¬åœ¨è¿™ä¸²æ•°å­—åé¢æ¥ä¸Šä¸€ä¸ªéå¸¸ç®€å•çš„\"é•œç‰‡\"â€”â€”ä¸€ä¸ª**å…¨è¿æ¥å±‚ (Linear Layer)**ã€‚è¿™ä¸ªå…¨è¿æ¥å±‚å°±æ˜¯\"åˆ†ç±»å¤´\"ï¼Œå®ƒçš„ä»»åŠ¡éå¸¸ä¸“ä¸€ï¼šæ¥æ”¶ä»£è¡¨å¥å­çµé­‚çš„å‘é‡ï¼Œç„¶åå°†å…¶è½¬æ¢ä¸ºå¯¹æˆ‘ä»¬ä»»åŠ¡æœ‰æ„ä¹‰çš„è¾“å‡ºã€‚\n",
    "    *   åœ¨æˆ‘ä»¬çš„äºŒåˆ†ç±»ä»»åŠ¡ä¸­ï¼Œè¿™ä¸ª\"é•œç‰‡\"æœ‰ä¸¤ä¸ªè¾“å‡ºç¥ç»å…ƒï¼Œä¸€ä¸ªä»£è¡¨\"æ¶ˆæ\"çš„å¯èƒ½æ€§ï¼Œä¸€ä¸ªä»£è¡¨\"ç§¯æ\"çš„å¯èƒ½æ€§ã€‚\n",
    "\n",
    "3.  **\"æ ¡å‡†çœ¼é•œ\"â€”â€”è®­ç»ƒä¸åå‘ä¼ æ’­**ï¼š\n",
    "    *   ç°åœ¨ï¼Œæˆ‘ä»¬æœ‰äº†ä¸€ä¸ªæˆ´ç€\"æƒ…æ„Ÿåˆ†æçœ¼é•œ\"çš„ERNIEæ¨¡å‹ã€‚æˆ‘ä»¬æŠŠå‡†å¤‡å¥½çš„æ ‡æ³¨æ•°æ®ï¼ˆæˆåƒä¸Šä¸‡æ¡å·²çŸ¥æƒ…æ„Ÿçš„è¯„è®ºï¼‰å–‚ç»™å®ƒã€‚\n",
    "    *   å¯¹äºæ¯æ¡è¯„è®ºï¼Œæ¨¡å‹ä¼šé€šè¿‡\"çœ¼é•œ\"ç»™å‡ºä¸€ä¸ªåˆæ­¥çš„åˆ¤æ–­ï¼ˆä¾‹å¦‚ï¼Œ\"æ¶ˆæ\"å¾—åˆ†0.1ï¼Œ\"ç§¯æ\"å¾—åˆ†0.9ï¼‰ã€‚\n",
    "    *   æˆ‘ä»¬æ‹¿è¿™ä¸ªåˆ¤æ–­å’ŒçœŸå®æ ‡ç­¾ï¼ˆæ¯”å¦‚è¿™æ¡è¯„è®ºçš„çœŸå®æ ‡ç­¾æ˜¯\"ç§¯æ\"ï¼‰å»æ¯”è¾ƒã€‚å¦‚æœåˆ¤æ–­å‡†ç¡®ï¼Œè¯´æ˜\"çœ¼é•œ\"æ ¡å‡†å¾—ä¸é”™ï¼›å¦‚æœåˆ¤æ–­é”™è¯¯ï¼Œå°±è®¡ç®—å‡ºä¸€ä¸ª\"è¯¯å·®\"ï¼ˆå³**äº¤å‰ç†µæŸå¤±**ï¼‰ã€‚\n",
    "    *   è¿™ä¸ª\"è¯¯å·®\"ä¿¡å·ä¼šåå‘ä¼ æ’­ï¼Œåƒä¸€ä¸ªæ ¡å‡†æŒ‡ä»¤ä¸€æ ·ï¼Œä¸ä»…ä¼šå¾®è°ƒ\"é•œç‰‡\"ï¼ˆåˆ†ç±»å¤´ï¼‰çš„å‚æ•°ï¼Œè®©å®ƒåˆ¤æ–­å¾—æ›´å‡†ï¼Œ**æ›´é‡è¦çš„æ˜¯ï¼Œå®ƒä¹Ÿä¼šå¾®è°ƒERNIEè¿™ä½è¯­è¨€å¤§å¸ˆæœ¬èº«çš„å‚æ•°**ï¼Œè®©ä»–ä»¥ååœ¨é˜…è¯»æ–‡æœ¬æ—¶ï¼Œèƒ½æ›´ä¾§é‡äºé‚£äº›ä¸æƒ…æ„Ÿç›¸å…³çš„è¯­ä¹‰ä¿¡æ¯ã€‚\n",
    "\n",
    "ç»è¿‡æˆåƒä¸Šä¸‡æ¬¡è¿™æ ·çš„\"æ ¡å‡†\"ï¼ŒERNIEå¤§å¸ˆå’Œä»–çš„\"æƒ…æ„Ÿåˆ†æçœ¼é•œ\"å°±é…åˆå¾—å¤©è¡£æ— ç¼äº†ã€‚ä»–ä¸ä»…èƒ½è¯»æ‡‚å¥å­çš„æ„æ€ï¼Œè¿˜èƒ½å‡†ç¡®åœ°åˆ¤æ–­å‡ºå…¶ä¸­è•´å«çš„æƒ…æ„Ÿã€‚\n",
    "\n",
    "\n",
    "æˆ‘ä»¬æœ¬æ•™ç¨‹é‡‡ç”¨çš„æ˜¯ **SFT (Supervised Fine-Tuning)**ï¼Œä¹Ÿç§°ä¸º**å…¨å‚æ•°å¾®è°ƒ**ã€‚è¿™æ„å‘³ç€åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä¼šæ›´æ–°ERNIEæ¨¡å‹çš„æ‰€æœ‰å‚æ•°ä»¥åŠæ–°æ·»åŠ çš„åˆ†ç±»å¤´ï¼Œè®©æ•´ä¸ªæ¨¡å‹éƒ½æ¥é€‚é…æˆ‘ä»¬çš„æƒ…æ„Ÿåˆ†æä»»åŠ¡ã€‚\n",
    "\n",
    "å¹¸è¿çš„æ˜¯ï¼ŒERNIEkit å·²ç»å¸®æˆ‘ä»¬å®Œæˆäº†\"è£…é…çœ¼é•œ\"çš„å·¥ä½œã€‚æˆ‘ä»¬åªéœ€è¦åŠ è½½æ¨¡å‹ï¼Œå®ƒå°±ä¼šè‡ªåŠ¨ä¸ºæˆ‘ä»¬æ­å»ºå¥½\"ERNIEå¤§å¸ˆ + åˆ†ç±»å¤´\"çš„ç»“æ„ï¼Œè®©æˆ‘ä»¬èƒ½ä¸“æ³¨äº\"æ ¡å‡†çœ¼é•œ\"çš„è®­ç»ƒè¿‡ç¨‹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. æ¨¡å‹å¾®è°ƒ\n",
    "\n",
    "ç°åœ¨ï¼Œæˆ‘ä»¬å°†æ‰€æœ‰éƒ¨åˆ†ç»„åˆèµ·æ¥ï¼Œå¼€å§‹è®­ç»ƒæˆ‘ä»¬çš„æƒ…æ„Ÿåˆ†ææ¨¡å‹ã€‚åœ¨ERNIEkitä¸­ï¼Œæˆ‘ä»¬é€šè¿‡é…ç½®æ–‡ä»¶æ¥ç®¡ç†æ‰€æœ‰çš„è®­ç»ƒå‚æ•°ï¼Œå¹¶é€šè¿‡ä¸€æ¡ç®€å•çš„å‘½ä»¤æ¥å¯åŠ¨è®­ç»ƒã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 é…ç½®è®­ç»ƒå‚æ•°\n",
    "\n",
    "æ‰“å¼€ `examples/configs/ERNIE-4.5-0.3B/sft/run_sft_8k.yaml` æ–‡ä»¶ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ‰€æœ‰çš„è®­ç»ƒå‚æ•°ã€‚è¿™é‡Œæˆ‘ä»¬å¯¹ä¸€äº›æ ¸å¿ƒå‚æ•°è¿›è¡Œè¯´æ˜ï¼š\n",
    "\n",
    "```yaml\n",
    "### model\n",
    "model_name_or_path: baidu/ERNIE-4.5-0.3B-Paddle  # æŒ‡å®šæˆ‘ä»¬ä¸‹è½½çš„æ¨¡å‹è·¯å¾„\n",
    "fine_tuning: Full                                # å…¨å‚æ•°å¾®è°ƒ\n",
    "\n",
    "### finetuning\n",
    "stage: SFT                                       # æŒ‡å®šè®­ç»ƒé˜¶æ®µä¸ºSFT\n",
    "seed: 23                                         # éšæœºç§å­ï¼Œä¿è¯å®éªŒå¯å¤ç°\n",
    "do_train: True                                   # æ˜¯å¦è¿›è¡Œè®­ç»ƒ\n",
    "do_eval: True                                    # æ˜¯å¦è¿›è¡Œè¯„ä¼°\n",
    "batch_size: 1                                    # æ¯ä¸ªGPUä¸Šçš„æ‰¹å¤§å°\n",
    "num_train_epochs: 1                              # è®­ç»ƒè½®æ•°\n",
    "max_steps: 100                                   # æœ€å¤§è®­ç»ƒæ­¥æ•°\n",
    "learning_rate: 1.0e-5                            # å­¦ä¹ ç‡\n",
    "output_dir: ./output                             # æ¨¡å‹ä¿å­˜è·¯å¾„\n",
    "\n",
    "### performance\n",
    "compute_type: bf16                               # ä½¿ç”¨bf16æ··åˆç²¾åº¦è®­ç»ƒï¼ŒåŠ é€Ÿè®­ç»ƒ\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 å¯åŠ¨è®­ç»ƒ\n",
    "\n",
    "é…ç½®å¥½å‚æ•°åï¼Œæˆ‘ä»¬å°±å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¯åŠ¨è®­ç»ƒï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T07:44:07.840269Z",
     "iopub.status.busy": "2025-07-18T07:44:07.839871Z",
     "iopub.status.idle": "2025-07-18T07:46:57.138005Z",
     "shell.execute_reply": "2025-07-18T07:46:57.137361Z",
     "shell.execute_reply.started": "2025-07-18T07:44:07.840248Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/utils/cpp_extension/extension_utils.py:715: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\r\n",
      "  warnings.warn(warning_message)\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/utils/cpp_extension/extension_utils.py:715: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\r\n",
      "  warnings.warn(warning_message)\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 -----------  Configuration  ----------------------\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 auto_cluster_config: 0\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 auto_parallel_config: None\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 auto_tuner_json: None\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 devices: 0\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 elastic_level: -1\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 elastic_timeout: 30\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 enable_gpu_log: True\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 gloo_port: 6767\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 host: None\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 ips: None\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 job_id: default\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 legacy: False\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 log_dir: erniekit_dist_log\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 log_level: INFO\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 log_overwrite: False\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 master: 127.0.0.1:8080\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 max_restart: 3\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 nnodes: 1\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 nproc_per_node: None\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 rank: -1\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 run_mode: collective\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 server_num: None\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 servers: \r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 sort_ip: False\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 start_port: 6070\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 trainer_num: None\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 trainers: \r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 training_script: /home/ERNIEKit/erniekit/launcher.py\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 training_script_args: ['train', 'ERNIE-develop/examples/configs/ERNIE-4.5-0.3B/sft/run_sft_8k.yaml']\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 with_gloo: 1\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 --------------------------------------------------\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,201 Job: default, mode collective, replicas 1[1:1], elastic False\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,202 Run Pod: xiidtm, replicas 1, status ready\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,217 Watching Pod: xiidtm, replicas 1, status running\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/utils/cpp_extension/extension_utils.py:715: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\r\n",
      "  warnings.warn(warning_message)\r\n",
      "\u001b[32m[2025-07-18 15:44:15,281] [    INFO]\u001b[0m - user has defined resume_from_checkpoint: None\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,281] [    INFO]\u001b[0m - The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,341] [    INFO]\u001b[0m - Tensor_parallel_degree = 1. Set sequence_parallel to False.\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,341] [   DEBUG]\u001b[0m - ============================================================\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,341] [   DEBUG]\u001b[0m -      Model Configuration Arguments      \u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,342] [   DEBUG]\u001b[0m - paddle commit id              : cdcd76a93d1dfe767dde768198e1d7c7488b93f6\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,342] [   DEBUG]\u001b[0m - paddleformers commit id       : 053a5a5e2a72cd2d3b997cbcff81b14af9fe4d47\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,342] [   DEBUG]\u001b[0m - add_tail_layers               : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,342] [   DEBUG]\u001b[0m - continue_training             : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,342] [   DEBUG]\u001b[0m - fine_tuning                   : Full\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,342] [   DEBUG]\u001b[0m - fuse_gate_detach_matmul       : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,342] [   DEBUG]\u001b[0m - fuse_linear                   : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,342] [   DEBUG]\u001b[0m - fuse_rms_norm                 : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,342] [   DEBUG]\u001b[0m - fuse_rope                     : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,342] [   DEBUG]\u001b[0m - fuse_softmax_mask             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,342] [   DEBUG]\u001b[0m - fuse_swiglu                   : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,342] [   DEBUG]\u001b[0m - lora                          : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,342] [   DEBUG]\u001b[0m - lora_alpha                    : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,342] [   DEBUG]\u001b[0m - lora_path                     : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,342] [   DEBUG]\u001b[0m - lora_plus_scale               : 1.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,342] [   DEBUG]\u001b[0m - lora_rank                     : 8\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,342] [   DEBUG]\u001b[0m - model_name_or_path            : ./data/models/30656/ERNIE-4.5-0.3B-Paddle\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,342] [   DEBUG]\u001b[0m - moe_aux_loss_lambda           : 1e-05\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,342] [   DEBUG]\u001b[0m - moe_group                     : dummy\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,342] [   DEBUG]\u001b[0m - moe_group_experts             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,342] [   DEBUG]\u001b[0m - moe_multimodal_dispatch_use_allgather: v2-alltoall-unpad\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,343] [   DEBUG]\u001b[0m - moe_orthogonal_loss_lambda    : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,343] [   DEBUG]\u001b[0m - moe_use_aux_free              : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,343] [   DEBUG]\u001b[0m - moe_use_hard_gate             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,343] [   DEBUG]\u001b[0m - moe_z_loss_lambda             : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,343] [   DEBUG]\u001b[0m - no_recompute_layers           : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,343] [   DEBUG]\u001b[0m - offload_recompute_inputs      : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,343] [   DEBUG]\u001b[0m - pp_seg_method                 : layer:Ernie4_5_DecoderLayer|EmptyLayer\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,343] [   DEBUG]\u001b[0m - recompute_granularity         : full\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,343] [   DEBUG]\u001b[0m - recompute_use_reentrant       : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,343] [   DEBUG]\u001b[0m - rslora                        : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,343] [   DEBUG]\u001b[0m - rslora_plus                   : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,343] [   DEBUG]\u001b[0m - stage                         : SFT\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,343] [   DEBUG]\u001b[0m - tensor_parallel_output        : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,343] [   DEBUG]\u001b[0m - use_attn_mask_start_row_indices: True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,343] [   DEBUG]\u001b[0m - use_flash_attention           : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,343] [   DEBUG]\u001b[0m - use_fused_head_and_loss_fn    : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,343] [   DEBUG]\u001b[0m - use_recompute_moe             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,343] [   DEBUG]\u001b[0m - use_sparse_flash_attn         : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,343] [   DEBUG]\u001b[0m - use_sparse_head_and_loss_fn   : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,343] [   DEBUG]\u001b[0m - virtual_pp_degree             : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,343] [   DEBUG]\u001b[0m - \u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,343] [   DEBUG]\u001b[0m - ============================================================\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,343] [   DEBUG]\u001b[0m -       Data Configuration Arguments      \u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,344] [   DEBUG]\u001b[0m - paddle commit id              : cdcd76a93d1dfe767dde768198e1d7c7488b93f6\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,344] [   DEBUG]\u001b[0m - paddleformers commit id       : 053a5a5e2a72cd2d3b997cbcff81b14af9fe4d47\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,344] [   DEBUG]\u001b[0m - buffer_size                   : 500\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,344] [   DEBUG]\u001b[0m - dataset_type                  : iterable\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,344] [   DEBUG]\u001b[0m - eval_dataset_path             : ./sft-eval.jsonl\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,344] [   DEBUG]\u001b[0m - eval_dataset_prob             : 1.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,344] [   DEBUG]\u001b[0m - eval_dataset_type             : erniekit\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,344] [   DEBUG]\u001b[0m - greedy_intokens               : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,344] [   DEBUG]\u001b[0m - in_tokens_batching            : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,344] [   DEBUG]\u001b[0m - mask_out_eos_token            : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,344] [   DEBUG]\u001b[0m - max_prompt_len                : 2048\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,344] [   DEBUG]\u001b[0m - max_seq_len                   : 8192\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,344] [   DEBUG]\u001b[0m - num_comparisons               : 6\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,344] [   DEBUG]\u001b[0m - num_samples_each_epoch        : 6000000\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,344] [   DEBUG]\u001b[0m - offline_dataset_path          : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,344] [   DEBUG]\u001b[0m - random_shuffle                : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,344] [   DEBUG]\u001b[0m - train_dataset_path            : ./sft-train.jsonl\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,344] [   DEBUG]\u001b[0m - train_dataset_prob            : 1.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,344] [   DEBUG]\u001b[0m - train_dataset_type            : erniekit\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,344] [   DEBUG]\u001b[0m - use_cls                       : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,344] [   DEBUG]\u001b[0m - \u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,345] [    INFO]\u001b[0m - The global seed is set to 23, local seed is set to 24 and random seed is set to 23.\u001b[0m\r\n",
      "\u001b[33m[2025-07-18 15:44:15,345] [ WARNING]\u001b[0m - Process rank: -1, device: gpu, world_size: 1, distributed training: False, 16-bits training: True\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,345] [    INFO]\u001b[0m - Start to load model ...\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,494] [    INFO]\u001b[0m - Loading configuration file ./data/models/30656/ERNIE-4.5-0.3B-Paddle/config.json\u001b[0m\r\n",
      "\u001b[33m[2025-07-18 15:44:15,496] [ WARNING]\u001b[0m - You are using a model of type ernie4_5 to instantiate a model of type ernie4_5_moe. This is not supported for all configurations of models and can yield errors.\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,497] [    INFO]\u001b[0m - Loading weights file ./data/models/30656/ERNIE-4.5-0.3B-Paddle/model.safetensors\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,845] [    INFO]\u001b[0m - Loaded weights file from disk, setting weights to model.\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,846] [    INFO]\u001b[0m - change initializer-range from 0.02 to 0.018041293779826325\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,846] [    INFO]\u001b[0m - using moe-group: dummy\u001b[0m\r\n",
      "W0718 15:44:15.853309 93184 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.8, Runtime API Version: 12.6\r\n",
      "\u001b[32m[2025-07-18 15:44:15,855] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,859] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,861] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,863] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,866] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,868] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,870] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,872] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,875] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,877] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,879] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,881] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,884] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,886] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,889] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,950] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,953] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,955] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,959] [    INFO]\u001b[0m - output-weight:[103424, 1024] config.tie_word_embeddings=True\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,960] [    INFO]\u001b[0m - Use fusedRMSNorm\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:16,039] [    INFO]\u001b[0m - All model checkpoint weights were used when initializing Ernie4_5_MoeForCausalLM.\r\n",
      "\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:16,040] [    INFO]\u001b[0m - All the weights of Ernie4_5_MoeForCausalLM were initialized from the model checkpoint at ./data/models/30656/ERNIE-4.5-0.3B-Paddle.\r\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use Ernie4_5_MoeForCausalLM for predictions without further training.\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:16,041] [    INFO]\u001b[0m - Loading configuration file ./data/models/30656/ERNIE-4.5-0.3B-Paddle/generation_config.json\u001b[0m\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddleformers/generation/configuration_utils.py:250: UserWarning: using greedy search strategy. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `decode_strategy=\"greedy_search\" ` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\r\n",
      "  warnings.warn(\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddleformers/generation/configuration_utils.py:255: UserWarning: using greedy search strategy. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `decode_strategy=\"greedy_search\" ` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\r\n",
      "  warnings.warn(\r\n",
      "\u001b[32m[2025-07-18 15:44:16,052] [    INFO]\u001b[0m - Loading model successfully !\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:16,054] [   DEBUG]\u001b[0m - Model config: Ernie4_5_MoeConfig {\r\n",
      "  \"add_tail_layers\": false,\r\n",
      "  \"architectures\": [\r\n",
      "    \"Ernie4_5_ForCausalLM\"\r\n",
      "  ],\r\n",
      "  \"attention_probs_dropout_prob\": 0.0,\r\n",
      "  \"bos_token_id\": 1,\r\n",
      "  \"cachekv_quant\": false,\r\n",
      "  \"compression_ratio\": 1.0,\r\n",
      "  \"dpo_config\": null,\r\n",
      "  \"dtype\": \"bfloat16\",\r\n",
      "  \"enable_delay_scale_loss\": true,\r\n",
      "  \"enable_mtp_magic_send\": false,\r\n",
      "  \"eos_token_id\": 2,\r\n",
      "  \"fuse_gate_detach_matmul\": true,\r\n",
      "  \"fuse_linear\": false,\r\n",
      "  \"fuse_ln\": false,\r\n",
      "  \"fuse_rms_norm\": true,\r\n",
      "  \"fuse_rope\": true,\r\n",
      "  \"fuse_softmax_mask\": false,\r\n",
      "  \"fuse_swiglu\": true,\r\n",
      "  \"global_aux_loss\": false,\r\n",
      "  \"head_dim\": 128,\r\n",
      "  \"hidden_act\": \"silu\",\r\n",
      "  \"hidden_dropout_prob\": 0.0,\r\n",
      "  \"hidden_size\": 1024,\r\n",
      "  \"ignored_index\": -100,\r\n",
      "  \"initializer_range\": 0.018041293779826325,\r\n",
      "  \"intermediate_size\": 3072,\r\n",
      "  \"max_position_embeddings\": 131072,\r\n",
      "  \"max_sequence_length\": 8192,\r\n",
      "  \"micro_batch_size\": -1,\r\n",
      "  \"model_type\": \"ernie4_5_moe\",\r\n",
      "  \"moe_all_to_all_dropout\": 0.0,\r\n",
      "  \"moe_aux_loss_lambda\": 1e-05,\r\n",
      "  \"moe_capacity\": [],\r\n",
      "  \"moe_dense_experts_token_type_id\": 3,\r\n",
      "  \"moe_dropout_prob\": 0.0,\r\n",
      "  \"moe_gate\": \"topk\",\r\n",
      "  \"moe_gate_act\": \"softmax\",\r\n",
      "  \"moe_group_experts\": false,\r\n",
      "  \"moe_group_origin\": \"dummy\",\r\n",
      "  \"moe_group_orthogonal_loss\": true,\r\n",
      "  \"moe_intermediate_size\": 0,\r\n",
      "  \"moe_k\": 2,\r\n",
      "  \"moe_layer_end_index\": 17,\r\n",
      "  \"moe_layer_interval\": 2,\r\n",
      "  \"moe_layer_start_index\": 0,\r\n",
      "  \"moe_multimodal_dispatch_use_allgather\": \"v2-alltoall-unpad\",\r\n",
      "  \"moe_norm_gate_logits\": true,\r\n",
      "  \"moe_num_experts\": null,\r\n",
      "  \"moe_num_shared_experts\": 0,\r\n",
      "  \"moe_orthogonal_loss_lambda\": 0.0,\r\n",
      "  \"moe_rank\": 0,\r\n",
      "  \"moe_reverse_token_drop\": false,\r\n",
      "  \"moe_use_aux_free\": false,\r\n",
      "  \"moe_use_hard_gate\": false,\r\n",
      "  \"moe_world_size\": 1,\r\n",
      "  \"moe_z_loss_lambda\": 0.0,\r\n",
      "  \"multi_token_pred_lambda\": 0.3,\r\n",
      "  \"num_acc_steps\": 8,\r\n",
      "  \"num_attention_heads\": 16,\r\n",
      "  \"num_hidden_layers\": 18,\r\n",
      "  \"num_key_value_heads\": 2,\r\n",
      "  \"num_nextn_predict_layers\": 0,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"paddleformers_version\": \"0.1\",\r\n",
      "  \"pp_seg_method\": \"layer:Ernie4_5_DecoderLayer|EmptyLayer\",\r\n",
      "  \"recompute_granularity\": \"full\",\r\n",
      "  \"recompute_use_reentrant\": true,\r\n",
      "  \"refined_recompute\": {},\r\n",
      "  \"rms_norm_eps\": 1e-05,\r\n",
      "  \"rope_theta\": 500000,\r\n",
      "  \"sinkhorn_2gate\": true,\r\n",
      "  \"sinkhorn_temp\": 0.03,\r\n",
      "  \"skip_recompute_ops\": {},\r\n",
      "  \"tensor_parallel_degree\": -1,\r\n",
      "  \"tie_word_embeddings\": true,\r\n",
      "  \"token_balance_loss\": false,\r\n",
      "  \"token_balance_seqlen\": false,\r\n",
      "  \"use_bias\": false,\r\n",
      "  \"use_flash_attention\": true,\r\n",
      "  \"use_fused_head_and_loss_fn\": false,\r\n",
      "  \"use_recompute_lm_head\": false,\r\n",
      "  \"use_recompute_loss_fn\": false,\r\n",
      "  \"use_recompute_moe\": false,\r\n",
      "  \"use_recompute_mtp\": false,\r\n",
      "  \"use_rmsnorm\": true,\r\n",
      "  \"use_sparse_flash_attn\": true,\r\n",
      "  \"use_sparse_head_and_loss_fn\": true,\r\n",
      "  \"use_var_len_flash_attn\": false,\r\n",
      "  \"vocab_size\": 103424,\r\n",
      "  \"weight_share_add_bias\": true\r\n",
      "}\r\n",
      "\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:16,054] [    INFO]\u001b[0m - [timelog] basemodel loading time: 0.56s (2025-07-18 15:44:16) \u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:16,973] [    INFO]\u001b[0m - Start to create dataset ...\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:16,975] [    INFO]\u001b[0m - ./sft-train.jsonl: task prob: 1.0, ori number of examples: 8, target_num_each_epoch: 6000000\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:16,975] [    INFO]\u001b[0m - Creating dataset successfully ...\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:16,975] [    INFO]\u001b[0m - The global seed is set to 23, local seed is set to 24 and random seed is set to 23.\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:17,012] [    INFO]\u001b[0m - max_steps is given, it will override any value given in num_train_epochs\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:17,013] [    INFO]\u001b[0m - Using half precision\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,025] [   DEBUG]\u001b[0m - ============================================================\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,025] [   DEBUG]\u001b[0m -     Training Configuration Arguments    \u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,025] [   DEBUG]\u001b[0m - paddle commit id              : cdcd76a93d1dfe767dde768198e1d7c7488b93f6\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,025] [   DEBUG]\u001b[0m - paddleformers commit id       : 053a5a5e2a72cd2d3b997cbcff81b14af9fe4d47\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,025] [   DEBUG]\u001b[0m - _no_sync_in_gradient_accumulation: True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,025] [   DEBUG]\u001b[0m - actscale_moving_rate          : 0.01\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,025] [   DEBUG]\u001b[0m - adam_beta1                    : 0.9\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,025] [   DEBUG]\u001b[0m - adam_beta2                    : 0.95\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,025] [   DEBUG]\u001b[0m - adam_epsilon                  : 1e-08\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,025] [   DEBUG]\u001b[0m - amp_custom_black_list         : ['reduce_sum', 'softmax_with_cross_entropy', 'c_softmax_with_cross_entropy', 'elementwise_div', 'sin', 'cos']\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,025] [   DEBUG]\u001b[0m - amp_custom_white_list         : ['lookup_table', 'lookup_table_v2', 'flash_attn', 'matmul', 'matmul_v2', 'fused_gemm_epilogue']\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,025] [   DEBUG]\u001b[0m - amp_master_grad               : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,026] [   DEBUG]\u001b[0m - apply_hadamard                : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,026] [   DEBUG]\u001b[0m - apply_online_actscale_step    : 200\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,026] [   DEBUG]\u001b[0m - attention_probs_dropout_prob  : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,026] [   DEBUG]\u001b[0m - auto_parallel_resume_form_hybrid_parallel: False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,026] [   DEBUG]\u001b[0m - batch_size                    : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,026] [   DEBUG]\u001b[0m - beta                          : 0.1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,026] [   DEBUG]\u001b[0m - bf16                          : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,026] [   DEBUG]\u001b[0m - bf16_full_eval                : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,026] [   DEBUG]\u001b[0m - ckpt_quant_stage              : O0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,026] [   DEBUG]\u001b[0m - compute_type                  : bf16\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,026] [   DEBUG]\u001b[0m - context_parallel_degree       : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,026] [   DEBUG]\u001b[0m - count_trained_tokens          : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,026] [   DEBUG]\u001b[0m - current_device                : gpu:0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,026] [   DEBUG]\u001b[0m - data_parallel_config          : \u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,026] [   DEBUG]\u001b[0m - data_parallel_degree          : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,026] [   DEBUG]\u001b[0m - data_parallel_rank            : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,026] [   DEBUG]\u001b[0m - dataloader_drop_last          : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,026] [   DEBUG]\u001b[0m - dataloader_num_workers        : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,026] [   DEBUG]\u001b[0m - dataloader_shuffle            : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,026] [   DEBUG]\u001b[0m - dataset_rank                  : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,026] [   DEBUG]\u001b[0m - dataset_world_size            : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,027] [   DEBUG]\u001b[0m - ddp_find_unused_parameters    : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,027] [   DEBUG]\u001b[0m - decay_steps                   : 100\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,027] [   DEBUG]\u001b[0m - device                        : gpu\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,027] [   DEBUG]\u001b[0m - disable_ckpt_quant            : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,027] [   DEBUG]\u001b[0m - disable_tqdm                  : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,027] [   DEBUG]\u001b[0m - distributed_dataloader        : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,027] [   DEBUG]\u001b[0m - do_eval                       : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,027] [   DEBUG]\u001b[0m - do_export                     : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,027] [   DEBUG]\u001b[0m - do_predict                    : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,027] [   DEBUG]\u001b[0m - do_train                      : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,027] [   DEBUG]\u001b[0m - dpo_benchmark                 : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,027] [   DEBUG]\u001b[0m - dpop_lambda                   : 50\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,027] [   DEBUG]\u001b[0m - dropout_warmup_steps          : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,027] [   DEBUG]\u001b[0m - enable_auto_parallel          : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,027] [   DEBUG]\u001b[0m - enable_zero_cost_checkpoint   : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,027] [   DEBUG]\u001b[0m - eval_accumulation_steps       : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,027] [   DEBUG]\u001b[0m - eval_batch_size               : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,027] [   DEBUG]\u001b[0m - eval_steps                    : 10000\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,027] [   DEBUG]\u001b[0m - evaluation_strategy           : IntervalStrategy.STEPS\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,027] [   DEBUG]\u001b[0m - expert_max_capacity           : 4294967296\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,027] [   DEBUG]\u001b[0m - expert_min_capacity           : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,027] [   DEBUG]\u001b[0m - expert_parallel_degree        : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,027] [   DEBUG]\u001b[0m - expert_tensor_parallel_degree : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,028] [   DEBUG]\u001b[0m - flash_device_save_steps       : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,028] [   DEBUG]\u001b[0m - flatten_param_grads           : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,028] [   DEBUG]\u001b[0m - force_reshard_pp              : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,028] [   DEBUG]\u001b[0m - fp16                          : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,028] [   DEBUG]\u001b[0m - fp16_full_eval                : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,028] [   DEBUG]\u001b[0m - fp16_opt_level                : O2\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,028] [   DEBUG]\u001b[0m - fp8_format_type               : hybrid\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,028] [   DEBUG]\u001b[0m - fuse_sequence_parallel_allreduce: False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,028] [   DEBUG]\u001b[0m - gradient_accumulation_steps   : 8\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,028] [   DEBUG]\u001b[0m - greater_is_better             : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,028] [   DEBUG]\u001b[0m - hadamard_block_size           : 32\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,028] [   DEBUG]\u001b[0m - hidden_dropout_prob           : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,028] [   DEBUG]\u001b[0m - hybrid_parallel_topo_order    : pp_first\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,028] [   DEBUG]\u001b[0m - ignore_data_skip              : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,028] [   DEBUG]\u001b[0m - ignore_load_lr_and_optim      : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,028] [   DEBUG]\u001b[0m - ignore_save_lr_and_optim      : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,028] [   DEBUG]\u001b[0m - label_names                   : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,028] [   DEBUG]\u001b[0m - label_smoothing               : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,028] [   DEBUG]\u001b[0m - layerwise_lr_decay_bound      : 1.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,028] [   DEBUG]\u001b[0m - lazy_data_processing          : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,028] [   DEBUG]\u001b[0m - learning_rate                 : 1e-05\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,028] [   DEBUG]\u001b[0m - load_best_model_at_end        : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,028] [   DEBUG]\u001b[0m - load_sharded_model            : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,029] [   DEBUG]\u001b[0m - local_process_index           : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,029] [   DEBUG]\u001b[0m - local_rank                    : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,029] [   DEBUG]\u001b[0m - log_level                     : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,029] [   DEBUG]\u001b[0m - log_level_replica             : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,029] [   DEBUG]\u001b[0m - log_on_each_node              : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,029] [   DEBUG]\u001b[0m - logging_dir                   : ./vdl_log\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,029] [   DEBUG]\u001b[0m - logging_first_step            : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,029] [   DEBUG]\u001b[0m - logging_steps                 : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,029] [   DEBUG]\u001b[0m - logging_strategy              : IntervalStrategy.STEPS\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,029] [   DEBUG]\u001b[0m - logical_process_index         : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,029] [   DEBUG]\u001b[0m - loss_type                     : sigmoid\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,029] [   DEBUG]\u001b[0m - lr_end                        : 1e-07\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,029] [   DEBUG]\u001b[0m - lr_scheduler_type             : SchedulerType.COSINE\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,029] [   DEBUG]\u001b[0m - max_estimate_samples          : 100000.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,029] [   DEBUG]\u001b[0m - max_evaluate_steps            : 10000\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,029] [   DEBUG]\u001b[0m - max_grad_norm                 : 1.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,029] [   DEBUG]\u001b[0m - max_steps                     : 100\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,029] [   DEBUG]\u001b[0m - metric_for_best_model         : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,029] [   DEBUG]\u001b[0m - metrics_output_path           : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,029] [   DEBUG]\u001b[0m - min_lr                        : 1e-06\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,029] [   DEBUG]\u001b[0m - minimum_eval_times            : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,029] [   DEBUG]\u001b[0m - multi_token_pred_lambda       : 0.3\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,030] [   DEBUG]\u001b[0m - no_cuda                       : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,030] [   DEBUG]\u001b[0m - normalize_logps               : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,030] [   DEBUG]\u001b[0m - num_cycles                    : 0.5\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,030] [   DEBUG]\u001b[0m - num_nextn_predict_layers      : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,030] [   DEBUG]\u001b[0m - num_of_gpus                   : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,030] [   DEBUG]\u001b[0m - num_train_epochs              : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,030] [   DEBUG]\u001b[0m - offload_optim                 : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,030] [   DEBUG]\u001b[0m - offset_alpha                  : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,030] [   DEBUG]\u001b[0m - optim                         : OptimizerNames.ADAMW\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,030] [   DEBUG]\u001b[0m - optim_shard_num               : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,030] [   DEBUG]\u001b[0m - optimizer_name_suffix         : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,030] [   DEBUG]\u001b[0m - ordered_save_group_size       : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,030] [   DEBUG]\u001b[0m - output_dir                    : ./output\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,030] [   DEBUG]\u001b[0m - output_signal_dir             : ./output\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,030] [   DEBUG]\u001b[0m - overwrite_output_dir          : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,030] [   DEBUG]\u001b[0m - pad_token_id                  : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,030] [   DEBUG]\u001b[0m - past_index                    : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,030] [   DEBUG]\u001b[0m - pdc_download_ckpt             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,030] [   DEBUG]\u001b[0m - pdc_download_timeout          : 300\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,030] [   DEBUG]\u001b[0m - per_device_eval_batch_size    : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,030] [   DEBUG]\u001b[0m - per_device_train_batch_size   : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,030] [   DEBUG]\u001b[0m - pipeline_parallel_config      : enable_delay_scale_loss enable_release_grads disable_partial_send_recv\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,030] [   DEBUG]\u001b[0m - pipeline_parallel_degree      : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,031] [   DEBUG]\u001b[0m - pipeline_parallel_rank        : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,031] [   DEBUG]\u001b[0m - power                         : 1.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,031] [   DEBUG]\u001b[0m - prediction_loss_only          : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,031] [   DEBUG]\u001b[0m - pref_loss_ratio               : 1.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,031] [   DEBUG]\u001b[0m - process_index                 : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,031] [   DEBUG]\u001b[0m - quant_input_grad              : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,031] [   DEBUG]\u001b[0m - quant_weight_grad             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,031] [   DEBUG]\u001b[0m - recompute                     : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,031] [   DEBUG]\u001b[0m - ref_model_update_steps        : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,031] [   DEBUG]\u001b[0m - reference_free                : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,031] [   DEBUG]\u001b[0m - refined_recompute             : {}\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,031] [   DEBUG]\u001b[0m - release_grads                 : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,031] [   DEBUG]\u001b[0m - remove_unused_columns         : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,031] [   DEBUG]\u001b[0m - report_to                     : ['visualdl']\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,031] [   DEBUG]\u001b[0m - resume_from_checkpoint        : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,031] [   DEBUG]\u001b[0m - run_name                      : ./output\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,031] [   DEBUG]\u001b[0m - save_on_each_node             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,031] [   DEBUG]\u001b[0m - save_rng_states               : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,031] [   DEBUG]\u001b[0m - save_sharded_model            : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,031] [   DEBUG]\u001b[0m - save_sharding_stage1_model_include_freeze_params: False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,031] [   DEBUG]\u001b[0m - save_steps                    : 10000000\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,031] [   DEBUG]\u001b[0m - save_strategy                 : IntervalStrategy.STEPS\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,031] [   DEBUG]\u001b[0m - save_tokenizer                : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,032] [   DEBUG]\u001b[0m - save_total_limit              : 5\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,032] [   DEBUG]\u001b[0m - scale_loss                    : 32768\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,032] [   DEBUG]\u001b[0m - seed                          : 23\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,032] [   DEBUG]\u001b[0m - sep_parallel_degree           : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,032] [   DEBUG]\u001b[0m - sequence_parallel             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,032] [   DEBUG]\u001b[0m - sequence_parallel_config      : \u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,032] [   DEBUG]\u001b[0m - server_tp_degree              : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,032] [   DEBUG]\u001b[0m - sft_benchmark                 : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,032] [   DEBUG]\u001b[0m - sft_loss_ratio                : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,032] [   DEBUG]\u001b[0m - sharding                      : []\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,032] [   DEBUG]\u001b[0m - sharding_comm_buffer_size_MB  : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,032] [   DEBUG]\u001b[0m - sharding_degree               : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,032] [   DEBUG]\u001b[0m - sharding_parallel_config      : \u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,032] [   DEBUG]\u001b[0m - sharding_parallel_degree      : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,032] [   DEBUG]\u001b[0m - sharding_parallel_mesh_dimension: dp\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,032] [   DEBUG]\u001b[0m - sharding_parallel_rank        : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,032] [   DEBUG]\u001b[0m - should_load_dataset           : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,032] [   DEBUG]\u001b[0m - should_load_sharding_stage1_model: False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,032] [   DEBUG]\u001b[0m - should_log                    : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,032] [   DEBUG]\u001b[0m - should_save                   : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,032] [   DEBUG]\u001b[0m - should_save_model_state       : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,032] [   DEBUG]\u001b[0m - should_save_model_with_tensor_fusion: False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,032] [   DEBUG]\u001b[0m - should_save_sharding_stage1_model: False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,033] [   DEBUG]\u001b[0m - simpo_gamma                   : 0.5\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,033] [   DEBUG]\u001b[0m - skip_data_intervals           : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,033] [   DEBUG]\u001b[0m - skip_memory_metrics           : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,033] [   DEBUG]\u001b[0m - skip_profile_timer            : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,033] [   DEBUG]\u001b[0m - split_inputs_sequence_dim     : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,033] [   DEBUG]\u001b[0m - split_norm_comm               : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,033] [   DEBUG]\u001b[0m - tensor_parallel_config        : \u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,033] [   DEBUG]\u001b[0m - tensor_parallel_degree        : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,033] [   DEBUG]\u001b[0m - tensor_parallel_rank          : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,033] [   DEBUG]\u001b[0m - tensorwise_offload_optimizer  : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,033] [   DEBUG]\u001b[0m - to_static                     : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,033] [   DEBUG]\u001b[0m - train_batch_size              : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,033] [   DEBUG]\u001b[0m - unified_checkpoint            : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,033] [   DEBUG]\u001b[0m - unified_checkpoint_config     : ['async_save']\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,033] [   DEBUG]\u001b[0m - use_async_save                : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,033] [   DEBUG]\u001b[0m - use_expert_parallel           : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,033] [   DEBUG]\u001b[0m - use_hybrid_parallel           : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,033] [   DEBUG]\u001b[0m - use_lowprecision_moment       : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,033] [   DEBUG]\u001b[0m - use_recompute_mtp             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,033] [   DEBUG]\u001b[0m - use_sp_callback               : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,033] [   DEBUG]\u001b[0m - wandb_api_key                 : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,033] [   DEBUG]\u001b[0m - wandb_http_proxy              : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,033] [   DEBUG]\u001b[0m - warmup_ratio                  : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,034] [   DEBUG]\u001b[0m - warmup_steps                  : 20\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,034] [   DEBUG]\u001b[0m - weight_decay                  : 0.1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,034] [   DEBUG]\u001b[0m - weight_name_suffix            : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,034] [   DEBUG]\u001b[0m - weight_quantize_algo          : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,034] [   DEBUG]\u001b[0m - world_size                    : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,034] [   DEBUG]\u001b[0m - zcc_ema_interval              : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,034] [   DEBUG]\u001b[0m - zcc_pipeline_hooks_capacity_usage: 0.6\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,034] [   DEBUG]\u001b[0m - zcc_save_ema_coef             : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,034] [   DEBUG]\u001b[0m - zcc_workers_num               : 3\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,034] [   DEBUG]\u001b[0m - \u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:17,034] [    INFO]\u001b[0m - Starting training from resume_from_checkpoint : None\u001b[0m\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/distributed/parallel.py:450: UserWarning: The program will return to single-card operation. Please check 1, whether you use spawn or fleetrun to start the program. 2, Whether it is a multi-card program. 3, Is the current environment multi-card.\r\n",
      "  warnings.warn(\r\n",
      "\u001b[32m[2025-07-18 15:44:17,042] [    INFO]\u001b[0m - [timelog] checkpoint loading time: 0.00s (2025-07-18 15:44:17) \u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:17,042] [    INFO]\u001b[0m - ***** Running training *****\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:17,042] [    INFO]\u001b[0m -   Num examples = 800\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:17,042] [    INFO]\u001b[0m -   Num Epochs = 9223372036854775807\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:17,042] [    INFO]\u001b[0m -   Instantaneous batch size per device = 1\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:17,042] [    INFO]\u001b[0m -   Total train batch size (w. parallel, distributed & accumulation) = 8\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:17,042] [    INFO]\u001b[0m -   Gradient Accumulation steps = 8\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:17,042] [    INFO]\u001b[0m -   Total optimization steps = 100\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:17,042] [    INFO]\u001b[0m -   Total num train samples = 800\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,043] [   DEBUG]\u001b[0m -   Number of trainable parameters = 360,748,032 (per device)\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:17,060] [    INFO]\u001b[0m - prepare SequenceDataset ...\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:20,120] [    INFO]\u001b[0m - prepare SequenceDataset done: total number of examples is 6000000\u001b[0m\r\n",
      "W0718 15:44:21.237807 93184 multiply_fwd_func.cc:76] got different data type, run type promotion automatically, this may cause data type been changed.\r\n",
      "\u001b[32m[2025-07-18 15:44:24,412] [    INFO]\u001b[0m - loss: 10.39164352, learning_rate: 5e-07, global_step: 1, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 11.897777318954468, max_memory_allocated: 10.45703935623169, max_memory_reserved: 11.897777318954468, interval_runtime: 7.3676, interval_samples_per_second: 1.0858, interval_steps_per_second: 0.1357, ppl: 32586.178986822717, progress_or_epoch: 0.01\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:25,911] [    INFO]\u001b[0m - loss: 10.39015293, learning_rate: 1e-06, global_step: 2, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 11.897777318954468, max_memory_allocated: 10.45703935623169, max_memory_reserved: 11.897777318954468, interval_runtime: 1.4993, interval_samples_per_second: 5.3358, interval_steps_per_second: 0.667, ppl: 32537.642537246655, progress_or_epoch: 0.02\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:27,566] [    INFO]\u001b[0m - loss: 10.3223896, learning_rate: 1.5e-06, global_step: 3, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 12.813213109970093, max_memory_allocated: 10.462876796722412, max_memory_reserved: 12.813213109970093, interval_runtime: 1.6552, interval_samples_per_second: 4.8331, interval_steps_per_second: 0.6041, ppl: 30405.828621905155, progress_or_epoch: 0.03\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:29,042] [    INFO]\u001b[0m - loss: 10.25313473, learning_rate: 2e-06, global_step: 4, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 13.730960607528687, max_memory_allocated: 10.465795040130615, max_memory_reserved: 13.730960607528687, interval_runtime: 1.4758, interval_samples_per_second: 5.4207, interval_steps_per_second: 0.6776, ppl: 28371.339157937142, progress_or_epoch: 0.04\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:30,509] [    INFO]\u001b[0m - loss: 9.72236824, learning_rate: 2.5e-06, global_step: 5, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 13.730960607528687, max_memory_allocated: 10.465795040130615, max_memory_reserved: 13.730960607528687, interval_runtime: 1.4673, interval_samples_per_second: 5.4522, interval_steps_per_second: 0.6815, ppl: 16686.716120719335, progress_or_epoch: 0.05\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:31,984] [    INFO]\u001b[0m - loss: 8.23078442, learning_rate: 3e-06, global_step: 6, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 13.730960607528687, max_memory_allocated: 10.465795040130615, max_memory_reserved: 13.730960607528687, interval_runtime: 1.4745, interval_samples_per_second: 5.4256, interval_steps_per_second: 0.6782, ppl: 3754.777920103064, progress_or_epoch: 0.06\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:33,447] [    INFO]\u001b[0m - loss: 7.72773361, learning_rate: 3.5e-06, global_step: 7, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 13.730960607528687, max_memory_allocated: 10.465795040130615, max_memory_reserved: 13.730960607528687, interval_runtime: 1.4627, interval_samples_per_second: 5.4694, interval_steps_per_second: 0.6837, ppl: 2270.4506386450303, progress_or_epoch: 0.07\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:34,910] [    INFO]\u001b[0m - loss: 4.5312953, learning_rate: 4e-06, global_step: 8, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 13.730960607528687, max_memory_allocated: 10.465795040130615, max_memory_reserved: 13.730960607528687, interval_runtime: 1.4636, interval_samples_per_second: 5.466, interval_steps_per_second: 0.6833, ppl: 92.87878909514416, progress_or_epoch: 0.08\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:36,378] [    INFO]\u001b[0m - loss: 3.88533902, learning_rate: 4.5e-06, global_step: 9, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 13.730960607528687, max_memory_allocated: 10.465795040130615, max_memory_reserved: 13.730960607528687, interval_runtime: 1.4675, interval_samples_per_second: 5.4514, interval_steps_per_second: 0.6814, ppl: 48.68344432339593, progress_or_epoch: 0.09\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:38,080] [    INFO]\u001b[0m - loss: 1.43456924, learning_rate: 5e-06, global_step: 10, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 13.730960607528687, max_memory_allocated: 10.465795040130615, max_memory_reserved: 13.730960607528687, interval_runtime: 1.7024, interval_samples_per_second: 4.6992, interval_steps_per_second: 0.5874, ppl: 4.197836359278837, progress_or_epoch: 0.1\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:39,544] [    INFO]\u001b[0m - loss: 1.06942534, learning_rate: 5.5e-06, global_step: 11, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 13.730960607528687, max_memory_allocated: 10.465795040130615, max_memory_reserved: 13.730960607528687, interval_runtime: 1.464, interval_samples_per_second: 5.4646, interval_steps_per_second: 0.6831, ppl: 2.913704629280229, progress_or_epoch: 0.11\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:41,009] [    INFO]\u001b[0m - loss: 0.463714, learning_rate: 6e-06, global_step: 12, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 13.730960607528687, max_memory_allocated: 10.465795040130615, max_memory_reserved: 13.730960607528687, interval_runtime: 1.4649, interval_samples_per_second: 5.4611, interval_steps_per_second: 0.6826, ppl: 1.5899681745094114, progress_or_epoch: 0.12\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:42,480] [    INFO]\u001b[0m - loss: 0.05802114, learning_rate: 6.5e-06, global_step: 13, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 13.730960607528687, max_memory_allocated: 10.465795040130615, max_memory_reserved: 13.730960607528687, interval_runtime: 1.4712, interval_samples_per_second: 5.4377, interval_steps_per_second: 0.6797, ppl: 1.0597373983220915, progress_or_epoch: 0.13\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:43,952] [    INFO]\u001b[0m - loss: 0.02088747, learning_rate: 7e-06, global_step: 14, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 13.730960607528687, max_memory_allocated: 10.465795040130615, max_memory_reserved: 13.730960607528687, interval_runtime: 1.472, interval_samples_per_second: 5.4347, interval_steps_per_second: 0.6793, ppl: 1.0211071399856833, progress_or_epoch: 0.14\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:45,416] [    INFO]\u001b[0m - loss: 0.0037058, learning_rate: 7.5e-06, global_step: 15, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 13.730960607528687, max_memory_allocated: 10.465795040130615, max_memory_reserved: 13.730960607528687, interval_runtime: 1.464, interval_samples_per_second: 5.4646, interval_steps_per_second: 0.6831, ppl: 1.0037126749666139, progress_or_epoch: 0.15\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:46,883] [    INFO]\u001b[0m - loss: 0.00050533, learning_rate: 8e-06, global_step: 16, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 13.730960607528687, max_memory_allocated: 10.465795040130615, max_memory_reserved: 13.730960607528687, interval_runtime: 1.4669, interval_samples_per_second: 5.4537, interval_steps_per_second: 0.6817, ppl: 1.000505457700714, progress_or_epoch: 0.16\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:48,493] [    INFO]\u001b[0m - loss: 0.00019829, learning_rate: 8.5e-06, global_step: 17, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 13.730960607528687, max_memory_allocated: 10.465795040130615, max_memory_reserved: 13.730960607528687, interval_runtime: 1.6096, interval_samples_per_second: 4.9701, interval_steps_per_second: 0.6213, ppl: 1.0001983096607616, progress_or_epoch: 0.17\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:49,965] [    INFO]\u001b[0m - loss: 4.877e-05, learning_rate: 9e-06, global_step: 18, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 14.651019811630249, max_memory_allocated: 10.465795040130615, max_memory_reserved: 14.651019811630249, interval_runtime: 1.4724, interval_samples_per_second: 5.4334, interval_steps_per_second: 0.6792, ppl: 1.0000487711892758, progress_or_epoch: 0.18\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:51,428] [    INFO]\u001b[0m - loss: 9.17e-06, learning_rate: 9.5e-06, global_step: 19, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 14.651019811630249, max_memory_allocated: 10.465795040130615, max_memory_reserved: 14.651019811630249, interval_runtime: 1.4627, interval_samples_per_second: 5.4693, interval_steps_per_second: 0.6837, ppl: 1.0000091700420446, progress_or_epoch: 0.19\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:52,885] [    INFO]\u001b[0m - loss: 3.71e-06, learning_rate: 1e-05, global_step: 20, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 14.651019811630249, max_memory_allocated: 10.465795040130615, max_memory_reserved: 14.651019811630249, interval_runtime: 1.4569, interval_samples_per_second: 5.4911, interval_steps_per_second: 0.6864, ppl: 1.0000037100068822, progress_or_epoch: 0.2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:54,355] [    INFO]\u001b[0m - loss: 2.1e-06, learning_rate: 9.997e-06, global_step: 21, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 14.651019811630249, max_memory_allocated: 10.465795040130615, max_memory_reserved: 14.651019811630249, interval_runtime: 1.4707, interval_samples_per_second: 5.4398, interval_steps_per_second: 0.68, ppl: 1.000002100002205, progress_or_epoch: 0.21\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:55,824] [    INFO]\u001b[0m - loss: 1.4e-06, learning_rate: 9.986e-06, global_step: 22, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 14.651019811630249, max_memory_allocated: 10.465795040130615, max_memory_reserved: 14.651019811630249, interval_runtime: 1.4686, interval_samples_per_second: 5.4475, interval_steps_per_second: 0.6809, ppl: 1.00000140000098, progress_or_epoch: 0.22\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:57,290] [    INFO]\u001b[0m - loss: 1.01e-06, learning_rate: 9.969e-06, global_step: 23, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 14.651019811630249, max_memory_allocated: 10.465795040130615, max_memory_reserved: 14.651019811630249, interval_runtime: 1.4658, interval_samples_per_second: 5.4579, interval_steps_per_second: 0.6822, ppl: 1.0000010100005101, progress_or_epoch: 0.23\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:58,758] [    INFO]\u001b[0m - loss: 7.9e-07, learning_rate: 9.945e-06, global_step: 24, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 14.651019811630249, max_memory_allocated: 10.465795040130615, max_memory_reserved: 14.651019811630249, interval_runtime: 1.4686, interval_samples_per_second: 5.4475, interval_steps_per_second: 0.6809, ppl: 1.000000790000312, progress_or_epoch: 0.24\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:00,223] [    INFO]\u001b[0m - loss: 6.8e-07, learning_rate: 9.914e-06, global_step: 25, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 14.651019811630249, max_memory_allocated: 10.465795040130615, max_memory_reserved: 14.651019811630249, interval_runtime: 1.4652, interval_samples_per_second: 5.4601, interval_steps_per_second: 0.6825, ppl: 1.0000006800002312, progress_or_epoch: 0.25\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:01,693] [    INFO]\u001b[0m - loss: 6e-07, learning_rate: 9.876e-06, global_step: 26, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 14.651019811630249, max_memory_allocated: 10.465795040130615, max_memory_reserved: 14.651019811630249, interval_runtime: 1.4694, interval_samples_per_second: 5.4444, interval_steps_per_second: 0.6805, ppl: 1.00000060000018, progress_or_epoch: 0.26\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:03,159] [    INFO]\u001b[0m - loss: 6.2e-07, learning_rate: 9.831e-06, global_step: 27, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 14.651019811630249, max_memory_allocated: 10.465795040130615, max_memory_reserved: 14.651019811630249, interval_runtime: 1.4657, interval_samples_per_second: 5.458, interval_steps_per_second: 0.6822, ppl: 1.0000006200001923, progress_or_epoch: 0.27\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:04,623] [    INFO]\u001b[0m - loss: 6e-07, learning_rate: 9.78e-06, global_step: 28, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 14.651019811630249, max_memory_allocated: 10.465795040130615, max_memory_reserved: 14.651019811630249, interval_runtime: 1.464, interval_samples_per_second: 5.4646, interval_steps_per_second: 0.6831, ppl: 1.00000060000018, progress_or_epoch: 0.28\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:06,102] [    INFO]\u001b[0m - loss: 5.5e-07, learning_rate: 9.722e-06, global_step: 29, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4797, interval_samples_per_second: 5.4066, interval_steps_per_second: 0.6758, ppl: 1.0000005500001512, progress_or_epoch: 0.29\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:07,573] [    INFO]\u001b[0m - loss: 5.2e-07, learning_rate: 9.657e-06, global_step: 30, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.471, interval_samples_per_second: 5.4386, interval_steps_per_second: 0.6798, ppl: 1.0000005200001352, progress_or_epoch: 0.3\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:09,041] [    INFO]\u001b[0m - loss: 5e-07, learning_rate: 9.587e-06, global_step: 31, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.468, interval_samples_per_second: 5.4495, interval_steps_per_second: 0.6812, ppl: 1.000000500000125, progress_or_epoch: 0.31\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:10,671] [    INFO]\u001b[0m - loss: 4.9e-07, learning_rate: 9.51e-06, global_step: 32, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.6298, interval_samples_per_second: 4.9087, interval_steps_per_second: 0.6136, ppl: 1.00000049000012, progress_or_epoch: 0.32\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:12,147] [    INFO]\u001b[0m - loss: 5e-07, learning_rate: 9.426e-06, global_step: 33, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4758, interval_samples_per_second: 5.4207, interval_steps_per_second: 0.6776, ppl: 1.000000500000125, progress_or_epoch: 0.33\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:13,621] [    INFO]\u001b[0m - loss: 4.6e-07, learning_rate: 9.337e-06, global_step: 34, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4738, interval_samples_per_second: 5.428, interval_steps_per_second: 0.6785, ppl: 1.0000004600001058, progress_or_epoch: 0.34\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:15,096] [    INFO]\u001b[0m - loss: 4.6e-07, learning_rate: 9.242e-06, global_step: 35, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4748, interval_samples_per_second: 5.4243, interval_steps_per_second: 0.678, ppl: 1.0000004600001058, progress_or_epoch: 0.35\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:16,560] [    INFO]\u001b[0m - loss: 4.5e-07, learning_rate: 9.141e-06, global_step: 36, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4646, interval_samples_per_second: 5.4623, interval_steps_per_second: 0.6828, ppl: 1.0000004500001012, progress_or_epoch: 0.36\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:18,035] [    INFO]\u001b[0m - loss: 4.4e-07, learning_rate: 9.034e-06, global_step: 37, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4752, interval_samples_per_second: 5.4231, interval_steps_per_second: 0.6779, ppl: 1.0000004400000968, progress_or_epoch: 0.37\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:19,509] [    INFO]\u001b[0m - loss: 4.3e-07, learning_rate: 8.922e-06, global_step: 38, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4741, interval_samples_per_second: 5.4272, interval_steps_per_second: 0.6784, ppl: 1.0000004300000924, progress_or_epoch: 0.38\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:21,118] [    INFO]\u001b[0m - loss: 4e-07, learning_rate: 8.804e-06, global_step: 39, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.6084, interval_samples_per_second: 4.974, interval_steps_per_second: 0.6218, ppl: 1.00000040000008, progress_or_epoch: 0.39\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:22,578] [    INFO]\u001b[0m - loss: 3.8e-07, learning_rate: 8.682e-06, global_step: 40, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4604, interval_samples_per_second: 5.478, interval_steps_per_second: 0.6848, ppl: 1.0000003800000723, progress_or_epoch: 0.4\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:24,046] [    INFO]\u001b[0m - loss: 3.8e-07, learning_rate: 8.555e-06, global_step: 41, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4674, interval_samples_per_second: 5.452, interval_steps_per_second: 0.6815, ppl: 1.0000003800000723, progress_or_epoch: 0.41\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:25,527] [    INFO]\u001b[0m - loss: 3.7e-07, learning_rate: 8.423e-06, global_step: 42, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4812, interval_samples_per_second: 5.4012, interval_steps_per_second: 0.6751, ppl: 1.0000003700000684, progress_or_epoch: 0.42\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:27,006] [    INFO]\u001b[0m - loss: 3.5e-07, learning_rate: 8.286e-06, global_step: 43, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4791, interval_samples_per_second: 5.4086, interval_steps_per_second: 0.6761, ppl: 1.0000003500000612, progress_or_epoch: 0.43\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:28,469] [    INFO]\u001b[0m - loss: 3.7e-07, learning_rate: 8.145e-06, global_step: 44, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4636, interval_samples_per_second: 5.4659, interval_steps_per_second: 0.6832, ppl: 1.0000003700000684, progress_or_epoch: 0.44\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:29,938] [    INFO]\u001b[0m - loss: 3.4e-07, learning_rate: 8e-06, global_step: 45, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4683, interval_samples_per_second: 5.4486, interval_steps_per_second: 0.6811, ppl: 1.0000003400000579, progress_or_epoch: 0.45\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:31,550] [    INFO]\u001b[0m - loss: 3.2e-07, learning_rate: 7.851e-06, global_step: 46, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.6125, interval_samples_per_second: 4.9611, interval_steps_per_second: 0.6201, ppl: 1.0000003200000511, progress_or_epoch: 0.46\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:33,019] [    INFO]\u001b[0m - loss: 3.2e-07, learning_rate: 7.699e-06, global_step: 47, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4691, interval_samples_per_second: 5.4453, interval_steps_per_second: 0.6807, ppl: 1.0000003200000511, progress_or_epoch: 0.47\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:34,491] [    INFO]\u001b[0m - loss: 2.8e-07, learning_rate: 7.543e-06, global_step: 48, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4718, interval_samples_per_second: 5.4355, interval_steps_per_second: 0.6794, ppl: 1.0000002800000392, progress_or_epoch: 0.48\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:35,963] [    INFO]\u001b[0m - loss: 2.7e-07, learning_rate: 7.384e-06, global_step: 49, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4715, interval_samples_per_second: 5.4368, interval_steps_per_second: 0.6796, ppl: 1.0000002700000366, progress_or_epoch: 0.49\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:37,432] [    INFO]\u001b[0m - loss: 2.6e-07, learning_rate: 7.222e-06, global_step: 50, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4693, interval_samples_per_second: 5.4447, interval_steps_per_second: 0.6806, ppl: 1.0000002600000337, progress_or_epoch: 0.5\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:38,900] [    INFO]\u001b[0m - loss: 2.4e-07, learning_rate: 7.058e-06, global_step: 51, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4684, interval_samples_per_second: 5.4483, interval_steps_per_second: 0.681, ppl: 1.0000002400000287, progress_or_epoch: 0.51\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:40,368] [    INFO]\u001b[0m - loss: 2.3e-07, learning_rate: 6.891e-06, global_step: 52, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4676, interval_samples_per_second: 5.4512, interval_steps_per_second: 0.6814, ppl: 1.0000002300000264, progress_or_epoch: 0.52\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:41,836] [    INFO]\u001b[0m - loss: 2.2e-07, learning_rate: 6.721e-06, global_step: 53, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4681, interval_samples_per_second: 5.4492, interval_steps_per_second: 0.6812, ppl: 1.0000002200000242, progress_or_epoch: 0.53\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:43,301] [    INFO]\u001b[0m - loss: 2e-07, learning_rate: 6.551e-06, global_step: 54, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4649, interval_samples_per_second: 5.461, interval_steps_per_second: 0.6826, ppl: 1.00000020000002, progress_or_epoch: 0.54\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:44,770] [    INFO]\u001b[0m - loss: 1.9e-07, learning_rate: 6.378e-06, global_step: 55, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4692, interval_samples_per_second: 5.4451, interval_steps_per_second: 0.6806, ppl: 1.000000190000018, progress_or_epoch: 0.55\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:46,237] [    INFO]\u001b[0m - loss: 1.8e-07, learning_rate: 6.204e-06, global_step: 56, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4669, interval_samples_per_second: 5.4536, interval_steps_per_second: 0.6817, ppl: 1.0000001800000162, progress_or_epoch: 0.56\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:47,705] [    INFO]\u001b[0m - loss: 1.7e-07, learning_rate: 6.029e-06, global_step: 57, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4678, interval_samples_per_second: 5.4502, interval_steps_per_second: 0.6813, ppl: 1.0000001700000145, progress_or_epoch: 0.57\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:49,173] [    INFO]\u001b[0m - loss: 1.6e-07, learning_rate: 5.853e-06, global_step: 58, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4678, interval_samples_per_second: 5.4503, interval_steps_per_second: 0.6813, ppl: 1.0000001600000128, progress_or_epoch: 0.58\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:50,651] [    INFO]\u001b[0m - loss: 1.6e-07, learning_rate: 5.677e-06, global_step: 59, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4786, interval_samples_per_second: 5.4106, interval_steps_per_second: 0.6763, ppl: 1.0000001600000128, progress_or_epoch: 0.59\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:52,118] [    INFO]\u001b[0m - loss: 1.5e-07, learning_rate: 5.5e-06, global_step: 60, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4666, interval_samples_per_second: 5.4548, interval_steps_per_second: 0.6818, ppl: 1.0000001500000113, progress_or_epoch: 0.6\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:53,744] [    INFO]\u001b[0m - loss: 1.4e-07, learning_rate: 5.323e-06, global_step: 61, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.6264, interval_samples_per_second: 4.9188, interval_steps_per_second: 0.6148, ppl: 1.0000001400000098, progress_or_epoch: 0.61\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:55,217] [    INFO]\u001b[0m - loss: 1.3e-07, learning_rate: 5.147e-06, global_step: 62, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4722, interval_samples_per_second: 5.4341, interval_steps_per_second: 0.6793, ppl: 1.0000001300000085, progress_or_epoch: 0.62\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:56,688] [    INFO]\u001b[0m - loss: 1.3e-07, learning_rate: 4.971e-06, global_step: 63, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4718, interval_samples_per_second: 5.4356, interval_steps_per_second: 0.6794, ppl: 1.0000001300000085, progress_or_epoch: 0.63\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:58,160] [    INFO]\u001b[0m - loss: 1.3e-07, learning_rate: 4.796e-06, global_step: 64, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4713, interval_samples_per_second: 5.4374, interval_steps_per_second: 0.6797, ppl: 1.0000001300000085, progress_or_epoch: 0.64\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:59,637] [    INFO]\u001b[0m - loss: 1.2e-07, learning_rate: 4.622e-06, global_step: 65, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4777, interval_samples_per_second: 5.4139, interval_steps_per_second: 0.6767, ppl: 1.0000001200000073, progress_or_epoch: 0.65\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:01,101] [    INFO]\u001b[0m - loss: 1.1e-07, learning_rate: 4.449e-06, global_step: 66, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4638, interval_samples_per_second: 5.4653, interval_steps_per_second: 0.6832, ppl: 1.000000110000006, progress_or_epoch: 0.66\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:02,574] [    INFO]\u001b[0m - loss: 1.2e-07, learning_rate: 4.279e-06, global_step: 67, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4729, interval_samples_per_second: 5.4314, interval_steps_per_second: 0.6789, ppl: 1.0000001200000073, progress_or_epoch: 0.67\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:04,191] [    INFO]\u001b[0m - loss: 1.1e-07, learning_rate: 4.109e-06, global_step: 68, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.6164, interval_samples_per_second: 4.9493, interval_steps_per_second: 0.6187, ppl: 1.000000110000006, progress_or_epoch: 0.68\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:05,656] [    INFO]\u001b[0m - loss: 1.1e-07, learning_rate: 3.942e-06, global_step: 69, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4655, interval_samples_per_second: 5.459, interval_steps_per_second: 0.6824, ppl: 1.000000110000006, progress_or_epoch: 0.69\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:07,123] [    INFO]\u001b[0m - loss: 1.1e-07, learning_rate: 3.778e-06, global_step: 70, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4669, interval_samples_per_second: 5.4535, interval_steps_per_second: 0.6817, ppl: 1.000000110000006, progress_or_epoch: 0.7\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:08,594] [    INFO]\u001b[0m - loss: 1e-07, learning_rate: 3.616e-06, global_step: 71, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.471, interval_samples_per_second: 5.4385, interval_steps_per_second: 0.6798, ppl: 1.000000100000005, progress_or_epoch: 0.71\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:10,068] [    INFO]\u001b[0m - loss: 1e-07, learning_rate: 3.457e-06, global_step: 72, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4738, interval_samples_per_second: 5.428, interval_steps_per_second: 0.6785, ppl: 1.000000100000005, progress_or_epoch: 0.72\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:11,640] [    INFO]\u001b[0m - loss: 1e-07, learning_rate: 3.301e-06, global_step: 73, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.5718, interval_samples_per_second: 5.0896, interval_steps_per_second: 0.6362, ppl: 1.000000100000005, progress_or_epoch: 0.73\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:13,103] [    INFO]\u001b[0m - loss: 1e-07, learning_rate: 3.149e-06, global_step: 74, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4632, interval_samples_per_second: 5.4675, interval_steps_per_second: 0.6834, ppl: 1.000000100000005, progress_or_epoch: 0.74\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:14,738] [    INFO]\u001b[0m - loss: 9e-08, learning_rate: 3e-06, global_step: 75, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.6352, interval_samples_per_second: 4.8923, interval_steps_per_second: 0.6115, ppl: 1.0000000900000041, progress_or_epoch: 0.75\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:16,211] [    INFO]\u001b[0m - loss: 9e-08, learning_rate: 2.855e-06, global_step: 76, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4733, interval_samples_per_second: 5.43, interval_steps_per_second: 0.6788, ppl: 1.0000000900000041, progress_or_epoch: 0.76\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:17,682] [    INFO]\u001b[0m - loss: 9e-08, learning_rate: 2.714e-06, global_step: 77, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4703, interval_samples_per_second: 5.4412, interval_steps_per_second: 0.6801, ppl: 1.0000000900000041, progress_or_epoch: 0.77\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:19,144] [    INFO]\u001b[0m - loss: 8e-08, learning_rate: 2.577e-06, global_step: 78, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.462, interval_samples_per_second: 5.472, interval_steps_per_second: 0.684, ppl: 1.0000000800000033, progress_or_epoch: 0.78\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:20,608] [    INFO]\u001b[0m - loss: 9e-08, learning_rate: 2.445e-06, global_step: 79, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4647, interval_samples_per_second: 5.462, interval_steps_per_second: 0.6827, ppl: 1.0000000900000041, progress_or_epoch: 0.79\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:22,088] [    INFO]\u001b[0m - loss: 9e-08, learning_rate: 2.318e-06, global_step: 80, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4794, interval_samples_per_second: 5.4078, interval_steps_per_second: 0.676, ppl: 1.0000000900000041, progress_or_epoch: 0.8\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:23,561] [    INFO]\u001b[0m - loss: 8e-08, learning_rate: 2.196e-06, global_step: 81, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4732, interval_samples_per_second: 5.4305, interval_steps_per_second: 0.6788, ppl: 1.0000000800000033, progress_or_epoch: 0.81\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:25,039] [    INFO]\u001b[0m - loss: 8e-08, learning_rate: 2.078e-06, global_step: 82, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4782, interval_samples_per_second: 5.4119, interval_steps_per_second: 0.6765, ppl: 1.0000000800000033, progress_or_epoch: 0.82\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:26,503] [    INFO]\u001b[0m - loss: 8e-08, learning_rate: 1.966e-06, global_step: 83, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4644, interval_samples_per_second: 5.4631, interval_steps_per_second: 0.6829, ppl: 1.0000000800000033, progress_or_epoch: 0.83\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:27,973] [    INFO]\u001b[0m - loss: 8e-08, learning_rate: 1.859e-06, global_step: 84, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4695, interval_samples_per_second: 5.4441, interval_steps_per_second: 0.6805, ppl: 1.0000000800000033, progress_or_epoch: 0.84\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:29,438] [    INFO]\u001b[0m - loss: 8e-08, learning_rate: 1.758e-06, global_step: 85, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4652, interval_samples_per_second: 5.4599, interval_steps_per_second: 0.6825, ppl: 1.0000000800000033, progress_or_epoch: 0.85\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:30,907] [    INFO]\u001b[0m - loss: 8e-08, learning_rate: 1.663e-06, global_step: 86, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4687, interval_samples_per_second: 5.4471, interval_steps_per_second: 0.6809, ppl: 1.0000000800000033, progress_or_epoch: 0.86\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:32,374] [    INFO]\u001b[0m - loss: 8e-08, learning_rate: 1.574e-06, global_step: 87, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4668, interval_samples_per_second: 5.4542, interval_steps_per_second: 0.6818, ppl: 1.0000000800000033, progress_or_epoch: 0.87\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:33,836] [    INFO]\u001b[0m - loss: 8e-08, learning_rate: 1.49e-06, global_step: 88, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4624, interval_samples_per_second: 5.4704, interval_steps_per_second: 0.6838, ppl: 1.0000000800000033, progress_or_epoch: 0.88\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:35,303] [    INFO]\u001b[0m - loss: 8e-08, learning_rate: 1.413e-06, global_step: 89, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.467, interval_samples_per_second: 5.4532, interval_steps_per_second: 0.6816, ppl: 1.0000000800000033, progress_or_epoch: 0.89\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:36,913] [    INFO]\u001b[0m - loss: 8e-08, learning_rate: 1.343e-06, global_step: 90, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.6096, interval_samples_per_second: 4.9702, interval_steps_per_second: 0.6213, ppl: 1.0000000800000033, progress_or_epoch: 0.9\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:38,379] [    INFO]\u001b[0m - loss: 7e-08, learning_rate: 1.278e-06, global_step: 91, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4659, interval_samples_per_second: 5.4573, interval_steps_per_second: 0.6822, ppl: 1.0000000700000025, progress_or_epoch: 0.91\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:39,853] [    INFO]\u001b[0m - loss: 7e-08, learning_rate: 1.22e-06, global_step: 92, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4744, interval_samples_per_second: 5.4261, interval_steps_per_second: 0.6783, ppl: 1.0000000700000025, progress_or_epoch: 0.92\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:41,323] [    INFO]\u001b[0m - loss: 7e-08, learning_rate: 1.169e-06, global_step: 93, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4703, interval_samples_per_second: 5.4412, interval_steps_per_second: 0.6802, ppl: 1.0000000700000025, progress_or_epoch: 0.93\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:42,789] [    INFO]\u001b[0m - loss: 7e-08, learning_rate: 1.124e-06, global_step: 94, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4653, interval_samples_per_second: 5.4595, interval_steps_per_second: 0.6824, ppl: 1.0000000700000025, progress_or_epoch: 0.94\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:44,256] [    INFO]\u001b[0m - loss: 7e-08, learning_rate: 1.086e-06, global_step: 95, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4675, interval_samples_per_second: 5.4514, interval_steps_per_second: 0.6814, ppl: 1.0000000700000025, progress_or_epoch: 0.95\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:45,716] [    INFO]\u001b[0m - loss: 7e-08, learning_rate: 1.055e-06, global_step: 96, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4599, interval_samples_per_second: 5.4797, interval_steps_per_second: 0.685, ppl: 1.0000000700000025, progress_or_epoch: 0.96\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:47,329] [    INFO]\u001b[0m - loss: 7e-08, learning_rate: 1.031e-06, global_step: 97, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.6133, interval_samples_per_second: 4.9589, interval_steps_per_second: 0.6199, ppl: 1.0000000700000025, progress_or_epoch: 0.97\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:48,791] [    INFO]\u001b[0m - loss: 7e-08, learning_rate: 1.014e-06, global_step: 98, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4619, interval_samples_per_second: 5.4722, interval_steps_per_second: 0.684, ppl: 1.0000000700000025, progress_or_epoch: 0.98\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:50,254] [    INFO]\u001b[0m - loss: 7e-08, learning_rate: 1.003e-06, global_step: 99, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4627, interval_samples_per_second: 5.4692, interval_steps_per_second: 0.6837, ppl: 1.0000000700000025, progress_or_epoch: 0.99\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:51,728] [    INFO]\u001b[0m - loss: 6e-08, learning_rate: 1e-06, global_step: 100, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4744, interval_samples_per_second: 5.4258, interval_steps_per_second: 0.6782, ppl: 1.0000000600000019, progress_or_epoch: 1.0\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:51,729] [    INFO]\u001b[0m - \r\n",
      "Training completed. \r\n",
      "\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:51,729] [    INFO]\u001b[0m - train_runtime: 154.6855, train_samples_per_second: 5.1718, train_steps_per_second: 0.6465, train_loss: 0.7850595176554402, progress_or_epoch: 1.0\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:51,730] [    INFO]\u001b[0m - Saving model checkpoint to ./output\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:51,733] [    INFO]\u001b[0m - tokenizer config file saved in ./output/tokenizer_config.json\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:51,734] [    INFO]\u001b[0m - Special tokens file saved in ./output/special_tokens_map.json\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:51,734] [    INFO]\u001b[0m - added tokens file saved in ./output/added_tokens.json\u001b[0m\r\n",
      "\u001b[33m[2025-07-18 15:46:51,745] [ WARNING]\u001b[0m - Asynchronous saving is not supported for single card environment currently.\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:53,736] [    INFO]\u001b[0m - Configuration saved in ./output/config.json\u001b[0m\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddleformers/generation/configuration_utils.py:316: UserWarning: The generation config instance is invalid -- `.validate()` throws warnings and/or exceptions. Fix these issues to save the configuration. This warning will be raised to an exception.\r\n",
      "\r\n",
      "Thrown during validation:\r\n",
      "using greedy search strategy. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `decode_strategy=\"greedy_search\" ` or unset `temperature`.\r\n",
      "  warnings.warn(\r\n",
      "\u001b[32m[2025-07-18 15:46:53,783] [    INFO]\u001b[0m - [timelog] model saving time: 2.05s (2025-07-18 15:46:53) \u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:53,783] [    INFO]\u001b[0m - ***** train metrics *****\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:53,783] [    INFO]\u001b[0m -   progress_or_epoch        =        1.0\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:53,783] [    INFO]\u001b[0m -   train_loss               =     0.7851\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:53,783] [    INFO]\u001b[0m -   train_runtime            = 0:02:34.68\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:53,783] [    INFO]\u001b[0m -   train_samples_per_second =     5.1718\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:53,783] [    INFO]\u001b[0m -   train_steps_per_second   =     0.6465\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:53,784] [    INFO]\u001b[0m - ***** Running Evaluation *****\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:53,784] [    INFO]\u001b[0m -   Num examples: Unknown\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:53,784] [    INFO]\u001b[0m -   Total prediction steps = 10000\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:53,784] [    INFO]\u001b[0m -   Pre device batch size = 1\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:53,784] [    INFO]\u001b[0m -   Total Batch size = 1\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:53,786] [    INFO]\u001b[0m - prepare SequenceDataset ...\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:53,786] [    INFO]\u001b[0m - prepare SequenceDataset done: total number of examples is 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:53,841] [    INFO]\u001b[0m - eval_loss: 0.09614189714193344, eval_runtime: 0.0576, eval_samples_per_second: 173468.878, eval_steps_per_second: 173468.878, eval_ppl: 1.1009152696414224, progress_or_epoch: 1.0\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:53,842] [    INFO]\u001b[0m - ***** eval metrics *****\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:53,842] [    INFO]\u001b[0m -   eval_loss               =     0.0961\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:53,842] [    INFO]\u001b[0m -   eval_ppl                =     1.1009\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:53,842] [    INFO]\u001b[0m -   eval_runtime            = 0:00:00.05\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:53,842] [    INFO]\u001b[0m -   eval_samples_per_second = 173468.878\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:53,842] [    INFO]\u001b[0m -   eval_steps_per_second   = 173468.878\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:53,842] [    INFO]\u001b[0m -   progress_or_epoch       =        1.0\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:53,842] [    INFO]\u001b[0m - Saving stop info into ./vdl_log/stop_step.json\u001b[0m\r\n",
      "LAUNCH INFO 2025-07-18 15:46:56,395 Pod completed\r\n",
      "LAUNCH INFO 2025-07-18 15:46:56,396 Exit code 0\r\n"
     ]
    }
   ],
   "source": [
    "!erniekit train ERNIE-develop/examples/configs/ERNIE-4.5-0.3B/sft/run_sft_8k.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ERNIEkitä¼šè‡ªåŠ¨åŠ è½½æ¨¡å‹å’Œæ•°æ®ï¼Œå¹¶æ ¹æ®é…ç½®æ–‡ä»¶ä¸­çš„å‚æ•°è¿›è¡Œè®­ç»ƒã€‚è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä¼šè‡ªåŠ¨æ‰“å°æ—¥å¿—ï¼Œæ˜¾ç¤ºå½“å‰çš„è®­ç»ƒæ­¥æ•°ã€æŸå¤±ã€å­¦ä¹ ç‡ç­‰ä¿¡æ¯ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 è®­ç»ƒè¿‡ç¨‹è§£è¯»\n",
    "\n",
    "è®­ç»ƒæ—¥å¿—ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥å…³æ³¨ä»¥ä¸‹å‡ ä¸ªå…³é”®æŒ‡æ ‡ï¼š\n",
    "\n",
    "- **loss**: æŸå¤±å€¼ï¼Œåæ˜ äº†æ¨¡å‹é¢„æµ‹å€¼ä¸çœŸå®å€¼ä¹‹é—´çš„å·®è·ï¼Œè¿™ä¸ªå€¼è¶Šå°è¶Šå¥½ã€‚\n",
    "- **learning_rate**: å­¦ä¹ ç‡ï¼Œè¡¨ç¤ºæ¨¡å‹å‚æ•°æ›´æ–°çš„å¹…åº¦ã€‚\n",
    "- **eval_loss**: è¯„ä¼°é›†ä¸Šçš„æŸå¤±å€¼ï¼Œå¯ä»¥ç”¨æ¥åˆ¤æ–­æ¨¡å‹æ˜¯å¦è¿‡æ‹Ÿåˆã€‚\n",
    "- **eval_accuracy**: è¯„ä¼°é›†ä¸Šçš„å‡†ç¡®ç‡ï¼Œç›´è§‚åœ°åæ˜ äº†æ¨¡å‹åœ¨æƒ…æ„Ÿåˆ†æä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚\n",
    "\n",
    "è®­ç»ƒå®Œæˆåï¼Œæ¨¡å‹ä¼šè‡ªåŠ¨ä¿å­˜åœ¨ `output_dir` æŒ‡å®šçš„ç›®å½•ä¸­ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. æ¨¡å‹è¯„ä¼°ä¸é¢„æµ‹\n",
    "\n",
    "è®­ç»ƒå®Œæˆåï¼Œæˆ‘ä»¬éœ€è¦è¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ï¼Œå¹¶ä½¿ç”¨å®ƒæ¥é¢„æµ‹æ–°çš„æ–‡æœ¬ã€‚ERNIEkitæä¾›äº†æ–¹ä¾¿çš„å·¥å…·æ¥å®Œæˆè¿™äº›ä»»åŠ¡ã€‚\n",
    "\n",
    "### 6.1 æ¨¡å‹è¯„ä¼°ï¼šå®šé‡åˆ†æ\n",
    "\n",
    "åœ¨SFTï¼ˆæœ‰ç›‘ç£å¾®è°ƒï¼‰ä¸­ï¼Œå½“æˆ‘ä»¬å°†ä»»åŠ¡è½¬åŒ–ä¸ºä¸€ä¸ªç”Ÿæˆä»»åŠ¡åï¼ˆå³æ¨¡å‹ç”Ÿæˆâ€œæ­£é¢æƒ…æ„Ÿâ€æˆ–â€œè´Ÿé¢æƒ…æ„Ÿâ€æ–‡æœ¬ï¼‰ï¼Œè¯„ä¼°çš„æ ¸å¿ƒå˜æˆäº†**è¡¡é‡æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬ä¸æˆ‘ä»¬æœŸæœ›çš„æ ‡ç­¾æ–‡æœ¬æ˜¯å¦ä¸€è‡´**ã€‚\n",
    "æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ `erniekit eval` å‘½ä»¤æ¥å®Œæˆè¿™ä¸ªè¿‡ç¨‹ã€‚è¿™ä¸ªå‘½ä»¤ä¼šåœ¨è¯„ä¼°æ•°æ®é›†ä¸Šè¿è¡Œæ¨¡å‹ï¼Œå¹¶ç”Ÿæˆä¸€ä¸ªåŒ…å«æ¨¡å‹è¾“å‡ºçš„é¢„æµ‹æ–‡ä»¶ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T08:24:53.730475Z",
     "iopub.status.busy": "2025-07-18T08:24:53.730152Z",
     "iopub.status.idle": "2025-07-18T08:25:06.501120Z",
     "shell.execute_reply": "2025-07-18T08:25:06.500536Z",
     "shell.execute_reply.started": "2025-07-18T08:24:53.730455Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/utils/cpp_extension/extension_utils.py:715: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\r\n",
      "  warnings.warn(warning_message)\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/utils/cpp_extension/extension_utils.py:715: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\r\n",
      "  warnings.warn(warning_message)\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,631 -----------  Configuration  ----------------------\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,631 auto_cluster_config: 0\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,631 auto_parallel_config: None\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,631 auto_tuner_json: None\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,631 devices: 0\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,631 elastic_level: -1\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,631 elastic_timeout: 30\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,631 enable_gpu_log: True\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,631 gloo_port: 6767\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,631 host: None\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,631 ips: None\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,631 job_id: default\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,631 legacy: False\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,631 log_dir: erniekit_dist_log\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,631 log_level: INFO\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,631 log_overwrite: False\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,631 master: 127.0.0.1:8080\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,631 max_restart: 3\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,631 nnodes: 1\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,631 nproc_per_node: None\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,631 rank: -1\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,631 run_mode: collective\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,632 server_num: None\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,632 servers: \r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,632 sort_ip: False\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,632 start_port: 6070\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,632 trainer_num: None\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,632 trainers: \r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,632 training_script: /home/ERNIEKit/erniekit/launcher.py\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,632 training_script_args: ['eval', 'ERNIE-develop/examples/configs/ERNIE-4.5-0.3B/sft/run_sft_8k.yaml']\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,632 with_gloo: 1\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,632 --------------------------------------------------\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,632 Job: default, mode collective, replicas 1[1:1], elastic False\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,634 Run Pod: dyjrny, replicas 1, status ready\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,645 Watching Pod: dyjrny, replicas 1, status running\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/utils/cpp_extension/extension_utils.py:715: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\r\n",
      "  warnings.warn(warning_message)\r\n",
      "\u001b[32m[2025-07-18 16:25:01,881] [    INFO]\u001b[0m - user has defined resume_from_checkpoint: None\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:01,881] [    INFO]\u001b[0m - The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:01,882] [    INFO]\u001b[0m - Tensor_parallel_degree = 1. Set sequence_parallel to False.\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,882] [   DEBUG]\u001b[0m - ============================================================\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,882] [   DEBUG]\u001b[0m -      Model Configuration Arguments      \u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,882] [   DEBUG]\u001b[0m - paddle commit id              : cdcd76a93d1dfe767dde768198e1d7c7488b93f6\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,882] [   DEBUG]\u001b[0m - paddleformers commit id       : 053a5a5e2a72cd2d3b997cbcff81b14af9fe4d47\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,882] [   DEBUG]\u001b[0m - add_tail_layers               : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,882] [   DEBUG]\u001b[0m - continue_training             : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,882] [   DEBUG]\u001b[0m - fine_tuning                   : Full\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,882] [   DEBUG]\u001b[0m - fuse_gate_detach_matmul       : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,882] [   DEBUG]\u001b[0m - fuse_linear                   : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,882] [   DEBUG]\u001b[0m - fuse_rms_norm                 : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,882] [   DEBUG]\u001b[0m - fuse_rope                     : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,882] [   DEBUG]\u001b[0m - fuse_softmax_mask             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,882] [   DEBUG]\u001b[0m - fuse_swiglu                   : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,882] [   DEBUG]\u001b[0m - lora                          : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,882] [   DEBUG]\u001b[0m - lora_alpha                    : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,882] [   DEBUG]\u001b[0m - lora_path                     : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,882] [   DEBUG]\u001b[0m - lora_plus_scale               : 1.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,882] [   DEBUG]\u001b[0m - lora_rank                     : 8\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,882] [   DEBUG]\u001b[0m - model_name_or_path            : ./data/models/30656/ERNIE-4.5-0.3B-Paddle\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,882] [   DEBUG]\u001b[0m - moe_aux_loss_lambda           : 1e-05\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,883] [   DEBUG]\u001b[0m - moe_group                     : dummy\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,883] [   DEBUG]\u001b[0m - moe_group_experts             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,883] [   DEBUG]\u001b[0m - moe_multimodal_dispatch_use_allgather: v2-alltoall-unpad\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,883] [   DEBUG]\u001b[0m - moe_orthogonal_loss_lambda    : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,883] [   DEBUG]\u001b[0m - moe_use_aux_free              : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,883] [   DEBUG]\u001b[0m - moe_use_hard_gate             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,883] [   DEBUG]\u001b[0m - moe_z_loss_lambda             : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,883] [   DEBUG]\u001b[0m - no_recompute_layers           : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,883] [   DEBUG]\u001b[0m - offload_recompute_inputs      : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,883] [   DEBUG]\u001b[0m - pp_seg_method                 : layer:Ernie4_5_DecoderLayer|EmptyLayer\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,883] [   DEBUG]\u001b[0m - recompute_granularity         : full\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,883] [   DEBUG]\u001b[0m - recompute_use_reentrant       : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,883] [   DEBUG]\u001b[0m - rslora                        : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,883] [   DEBUG]\u001b[0m - rslora_plus                   : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,883] [   DEBUG]\u001b[0m - stage                         : SFT\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,883] [   DEBUG]\u001b[0m - tensor_parallel_output        : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,883] [   DEBUG]\u001b[0m - use_attn_mask_start_row_indices: True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,883] [   DEBUG]\u001b[0m - use_flash_attention           : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,883] [   DEBUG]\u001b[0m - use_fused_head_and_loss_fn    : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,883] [   DEBUG]\u001b[0m - use_recompute_moe             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,883] [   DEBUG]\u001b[0m - use_sparse_flash_attn         : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,883] [   DEBUG]\u001b[0m - use_sparse_head_and_loss_fn   : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,884] [   DEBUG]\u001b[0m - virtual_pp_degree             : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,884] [   DEBUG]\u001b[0m - \u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,884] [   DEBUG]\u001b[0m - ============================================================\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,884] [   DEBUG]\u001b[0m -       Data Configuration Arguments      \u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,884] [   DEBUG]\u001b[0m - paddle commit id              : cdcd76a93d1dfe767dde768198e1d7c7488b93f6\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,884] [   DEBUG]\u001b[0m - paddleformers commit id       : 053a5a5e2a72cd2d3b997cbcff81b14af9fe4d47\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,884] [   DEBUG]\u001b[0m - buffer_size                   : 500\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,884] [   DEBUG]\u001b[0m - dataset_type                  : iterable\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,884] [   DEBUG]\u001b[0m - eval_dataset_path             : ./sft-eval.jsonl\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,884] [   DEBUG]\u001b[0m - eval_dataset_prob             : 1.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,884] [   DEBUG]\u001b[0m - eval_dataset_type             : erniekit\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,884] [   DEBUG]\u001b[0m - greedy_intokens               : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,884] [   DEBUG]\u001b[0m - in_tokens_batching            : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,884] [   DEBUG]\u001b[0m - mask_out_eos_token            : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,884] [   DEBUG]\u001b[0m - max_prompt_len                : 2048\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,884] [   DEBUG]\u001b[0m - max_seq_len                   : 8192\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,884] [   DEBUG]\u001b[0m - num_comparisons               : 6\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,884] [   DEBUG]\u001b[0m - num_samples_each_epoch        : 6000000\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,884] [   DEBUG]\u001b[0m - offline_dataset_path          : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,884] [   DEBUG]\u001b[0m - random_shuffle                : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,884] [   DEBUG]\u001b[0m - train_dataset_path            : ./sft-train.jsonl\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,884] [   DEBUG]\u001b[0m - train_dataset_prob            : 1.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,884] [   DEBUG]\u001b[0m - train_dataset_type            : erniekit\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,885] [   DEBUG]\u001b[0m - use_cls                       : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,885] [   DEBUG]\u001b[0m - \u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:01,885] [    INFO]\u001b[0m - The global seed is set to 23, local seed is set to 24 and random seed is set to 23.\u001b[0m\r\n",
      "\u001b[33m[2025-07-18 16:25:01,885] [ WARNING]\u001b[0m - Process rank: -1, device: gpu, world_size: 1, distributed training: False, 16-bits training: True\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:01,885] [    INFO]\u001b[0m - Start to load model ...\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,035] [    INFO]\u001b[0m - Loading configuration file ./data/models/30656/ERNIE-4.5-0.3B-Paddle/config.json\u001b[0m\r\n",
      "\u001b[33m[2025-07-18 16:25:02,038] [ WARNING]\u001b[0m - You are using a model of type ernie4_5 to instantiate a model of type ernie4_5_moe. This is not supported for all configurations of models and can yield errors.\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,038] [    INFO]\u001b[0m - Loading weights file ./data/models/30656/ERNIE-4.5-0.3B-Paddle/model.safetensors\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,342] [    INFO]\u001b[0m - Loaded weights file from disk, setting weights to model.\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,342] [    INFO]\u001b[0m - change initializer-range from 0.02 to 0.018041293779826325\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,342] [    INFO]\u001b[0m - using moe-group: dummy\u001b[0m\r\n",
      "W0718 16:25:02.347047 166592 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.8, Runtime API Version: 12.6\r\n",
      "\u001b[32m[2025-07-18 16:25:02,348] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,352] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,354] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,356] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,359] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,361] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,363] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,365] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,368] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,370] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,372] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,375] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,377] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,380] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,382] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,439] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,442] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,445] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,449] [    INFO]\u001b[0m - output-weight:[103424, 1024] config.tie_word_embeddings=True\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,449] [    INFO]\u001b[0m - Use fusedRMSNorm\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,528] [    INFO]\u001b[0m - All model checkpoint weights were used when initializing Ernie4_5_MoeForCausalLM.\r\n",
      "\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,528] [    INFO]\u001b[0m - All the weights of Ernie4_5_MoeForCausalLM were initialized from the model checkpoint at ./data/models/30656/ERNIE-4.5-0.3B-Paddle.\r\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use Ernie4_5_MoeForCausalLM for predictions without further training.\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,530] [    INFO]\u001b[0m - Loading configuration file ./data/models/30656/ERNIE-4.5-0.3B-Paddle/generation_config.json\u001b[0m\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddleformers/generation/configuration_utils.py:250: UserWarning: using greedy search strategy. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `decode_strategy=\"greedy_search\" ` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\r\n",
      "  warnings.warn(\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddleformers/generation/configuration_utils.py:255: UserWarning: using greedy search strategy. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `decode_strategy=\"greedy_search\" ` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\r\n",
      "  warnings.warn(\r\n",
      "\u001b[32m[2025-07-18 16:25:02,540] [    INFO]\u001b[0m - Loading model successfully !\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:02,541] [   DEBUG]\u001b[0m - Model config: Ernie4_5_MoeConfig {\r\n",
      "  \"add_tail_layers\": false,\r\n",
      "  \"architectures\": [\r\n",
      "    \"Ernie4_5_ForCausalLM\"\r\n",
      "  ],\r\n",
      "  \"attention_probs_dropout_prob\": 0.0,\r\n",
      "  \"bos_token_id\": 1,\r\n",
      "  \"cachekv_quant\": false,\r\n",
      "  \"compression_ratio\": 1.0,\r\n",
      "  \"dpo_config\": null,\r\n",
      "  \"dtype\": \"bfloat16\",\r\n",
      "  \"enable_delay_scale_loss\": true,\r\n",
      "  \"enable_mtp_magic_send\": false,\r\n",
      "  \"eos_token_id\": 2,\r\n",
      "  \"fuse_gate_detach_matmul\": true,\r\n",
      "  \"fuse_linear\": false,\r\n",
      "  \"fuse_ln\": false,\r\n",
      "  \"fuse_rms_norm\": true,\r\n",
      "  \"fuse_rope\": true,\r\n",
      "  \"fuse_softmax_mask\": false,\r\n",
      "  \"fuse_swiglu\": true,\r\n",
      "  \"global_aux_loss\": false,\r\n",
      "  \"head_dim\": 128,\r\n",
      "  \"hidden_act\": \"silu\",\r\n",
      "  \"hidden_dropout_prob\": 0.0,\r\n",
      "  \"hidden_size\": 1024,\r\n",
      "  \"ignored_index\": -100,\r\n",
      "  \"initializer_range\": 0.018041293779826325,\r\n",
      "  \"intermediate_size\": 3072,\r\n",
      "  \"max_position_embeddings\": 131072,\r\n",
      "  \"max_sequence_length\": 8192,\r\n",
      "  \"micro_batch_size\": -1,\r\n",
      "  \"model_type\": \"ernie4_5_moe\",\r\n",
      "  \"moe_all_to_all_dropout\": 0.0,\r\n",
      "  \"moe_aux_loss_lambda\": 1e-05,\r\n",
      "  \"moe_capacity\": [],\r\n",
      "  \"moe_dense_experts_token_type_id\": 3,\r\n",
      "  \"moe_dropout_prob\": 0.0,\r\n",
      "  \"moe_gate\": \"topk\",\r\n",
      "  \"moe_gate_act\": \"softmax\",\r\n",
      "  \"moe_group_experts\": false,\r\n",
      "  \"moe_group_origin\": \"dummy\",\r\n",
      "  \"moe_group_orthogonal_loss\": true,\r\n",
      "  \"moe_intermediate_size\": 0,\r\n",
      "  \"moe_k\": 2,\r\n",
      "  \"moe_layer_end_index\": 17,\r\n",
      "  \"moe_layer_interval\": 2,\r\n",
      "  \"moe_layer_start_index\": 0,\r\n",
      "  \"moe_multimodal_dispatch_use_allgather\": \"v2-alltoall-unpad\",\r\n",
      "  \"moe_norm_gate_logits\": true,\r\n",
      "  \"moe_num_experts\": null,\r\n",
      "  \"moe_num_shared_experts\": 0,\r\n",
      "  \"moe_orthogonal_loss_lambda\": 0.0,\r\n",
      "  \"moe_rank\": 0,\r\n",
      "  \"moe_reverse_token_drop\": false,\r\n",
      "  \"moe_use_aux_free\": false,\r\n",
      "  \"moe_use_hard_gate\": false,\r\n",
      "  \"moe_world_size\": 1,\r\n",
      "  \"moe_z_loss_lambda\": 0.0,\r\n",
      "  \"multi_token_pred_lambda\": 0.3,\r\n",
      "  \"num_acc_steps\": 8,\r\n",
      "  \"num_attention_heads\": 16,\r\n",
      "  \"num_hidden_layers\": 18,\r\n",
      "  \"num_key_value_heads\": 2,\r\n",
      "  \"num_nextn_predict_layers\": 0,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"paddleformers_version\": \"0.1\",\r\n",
      "  \"pp_seg_method\": \"layer:Ernie4_5_DecoderLayer|EmptyLayer\",\r\n",
      "  \"recompute_granularity\": \"full\",\r\n",
      "  \"recompute_use_reentrant\": true,\r\n",
      "  \"refined_recompute\": {},\r\n",
      "  \"rms_norm_eps\": 1e-05,\r\n",
      "  \"rope_theta\": 500000,\r\n",
      "  \"sinkhorn_2gate\": true,\r\n",
      "  \"sinkhorn_temp\": 0.03,\r\n",
      "  \"skip_recompute_ops\": {},\r\n",
      "  \"tensor_parallel_degree\": -1,\r\n",
      "  \"tie_word_embeddings\": true,\r\n",
      "  \"token_balance_loss\": false,\r\n",
      "  \"token_balance_seqlen\": false,\r\n",
      "  \"use_bias\": false,\r\n",
      "  \"use_flash_attention\": true,\r\n",
      "  \"use_fused_head_and_loss_fn\": false,\r\n",
      "  \"use_recompute_lm_head\": false,\r\n",
      "  \"use_recompute_loss_fn\": false,\r\n",
      "  \"use_recompute_moe\": false,\r\n",
      "  \"use_recompute_mtp\": false,\r\n",
      "  \"use_rmsnorm\": true,\r\n",
      "  \"use_sparse_flash_attn\": true,\r\n",
      "  \"use_sparse_head_and_loss_fn\": true,\r\n",
      "  \"use_var_len_flash_attn\": false,\r\n",
      "  \"vocab_size\": 103424,\r\n",
      "  \"weight_share_add_bias\": true\r\n",
      "}\r\n",
      "\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,541] [    INFO]\u001b[0m - [timelog] basemodel loading time: 0.51s (2025-07-18 16:25:02) \u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:03,590] [    INFO]\u001b[0m - Start to create dataset ...\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:03,592] [    INFO]\u001b[0m - Creating dataset successfully ...\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:03,592] [    INFO]\u001b[0m - The global seed is set to 23, local seed is set to 24 and random seed is set to 23.\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:03,630] [    INFO]\u001b[0m - max_steps is given, it will override any value given in num_train_epochs\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:03,630] [    INFO]\u001b[0m - Using half precision\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,644] [   DEBUG]\u001b[0m - ============================================================\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,645] [   DEBUG]\u001b[0m -     Training Configuration Arguments    \u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,645] [   DEBUG]\u001b[0m - paddle commit id              : cdcd76a93d1dfe767dde768198e1d7c7488b93f6\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,645] [   DEBUG]\u001b[0m - paddleformers commit id       : 053a5a5e2a72cd2d3b997cbcff81b14af9fe4d47\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,645] [   DEBUG]\u001b[0m - _no_sync_in_gradient_accumulation: True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,645] [   DEBUG]\u001b[0m - actscale_moving_rate          : 0.01\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,645] [   DEBUG]\u001b[0m - adam_beta1                    : 0.9\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,645] [   DEBUG]\u001b[0m - adam_beta2                    : 0.95\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,645] [   DEBUG]\u001b[0m - adam_epsilon                  : 1e-08\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,645] [   DEBUG]\u001b[0m - amp_custom_black_list         : ['reduce_sum', 'softmax_with_cross_entropy', 'c_softmax_with_cross_entropy', 'elementwise_div', 'sin', 'cos']\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,645] [   DEBUG]\u001b[0m - amp_custom_white_list         : ['lookup_table', 'lookup_table_v2', 'flash_attn', 'matmul', 'matmul_v2', 'fused_gemm_epilogue']\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,645] [   DEBUG]\u001b[0m - amp_master_grad               : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,645] [   DEBUG]\u001b[0m - apply_hadamard                : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,645] [   DEBUG]\u001b[0m - apply_online_actscale_step    : 200\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,645] [   DEBUG]\u001b[0m - attention_probs_dropout_prob  : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,645] [   DEBUG]\u001b[0m - auto_parallel_resume_form_hybrid_parallel: False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,645] [   DEBUG]\u001b[0m - batch_size                    : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,646] [   DEBUG]\u001b[0m - beta                          : 0.1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,646] [   DEBUG]\u001b[0m - bf16                          : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,646] [   DEBUG]\u001b[0m - bf16_full_eval                : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,646] [   DEBUG]\u001b[0m - ckpt_quant_stage              : O0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,646] [   DEBUG]\u001b[0m - compute_type                  : bf16\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,646] [   DEBUG]\u001b[0m - context_parallel_degree       : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,646] [   DEBUG]\u001b[0m - count_trained_tokens          : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,646] [   DEBUG]\u001b[0m - current_device                : gpu:0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,646] [   DEBUG]\u001b[0m - data_parallel_config          : \u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,646] [   DEBUG]\u001b[0m - data_parallel_degree          : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,646] [   DEBUG]\u001b[0m - data_parallel_rank            : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,646] [   DEBUG]\u001b[0m - dataloader_drop_last          : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,646] [   DEBUG]\u001b[0m - dataloader_num_workers        : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,646] [   DEBUG]\u001b[0m - dataloader_shuffle            : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,646] [   DEBUG]\u001b[0m - dataset_rank                  : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,646] [   DEBUG]\u001b[0m - dataset_world_size            : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,646] [   DEBUG]\u001b[0m - ddp_find_unused_parameters    : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,646] [   DEBUG]\u001b[0m - decay_steps                   : 100\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,646] [   DEBUG]\u001b[0m - device                        : gpu\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,646] [   DEBUG]\u001b[0m - disable_ckpt_quant            : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,646] [   DEBUG]\u001b[0m - disable_tqdm                  : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,646] [   DEBUG]\u001b[0m - distributed_dataloader        : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,647] [   DEBUG]\u001b[0m - do_eval                       : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,647] [   DEBUG]\u001b[0m - do_export                     : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,647] [   DEBUG]\u001b[0m - do_predict                    : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,647] [   DEBUG]\u001b[0m - do_train                      : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,647] [   DEBUG]\u001b[0m - dpo_benchmark                 : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,647] [   DEBUG]\u001b[0m - dpop_lambda                   : 50\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,647] [   DEBUG]\u001b[0m - dropout_warmup_steps          : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,647] [   DEBUG]\u001b[0m - enable_auto_parallel          : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,647] [   DEBUG]\u001b[0m - enable_zero_cost_checkpoint   : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,647] [   DEBUG]\u001b[0m - eval_accumulation_steps       : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,647] [   DEBUG]\u001b[0m - eval_batch_size               : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,647] [   DEBUG]\u001b[0m - eval_steps                    : 10000\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,647] [   DEBUG]\u001b[0m - evaluation_strategy           : IntervalStrategy.STEPS\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,647] [   DEBUG]\u001b[0m - expert_max_capacity           : 4294967296\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,647] [   DEBUG]\u001b[0m - expert_min_capacity           : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,647] [   DEBUG]\u001b[0m - expert_parallel_degree        : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,647] [   DEBUG]\u001b[0m - expert_tensor_parallel_degree : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,647] [   DEBUG]\u001b[0m - flash_device_save_steps       : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,647] [   DEBUG]\u001b[0m - flatten_param_grads           : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,647] [   DEBUG]\u001b[0m - force_reshard_pp              : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,647] [   DEBUG]\u001b[0m - fp16                          : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,647] [   DEBUG]\u001b[0m - fp16_full_eval                : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,647] [   DEBUG]\u001b[0m - fp16_opt_level                : O2\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,648] [   DEBUG]\u001b[0m - fp8_format_type               : hybrid\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,648] [   DEBUG]\u001b[0m - fuse_sequence_parallel_allreduce: False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,648] [   DEBUG]\u001b[0m - gradient_accumulation_steps   : 8\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,648] [   DEBUG]\u001b[0m - greater_is_better             : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,648] [   DEBUG]\u001b[0m - hadamard_block_size           : 32\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,648] [   DEBUG]\u001b[0m - hidden_dropout_prob           : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,648] [   DEBUG]\u001b[0m - hybrid_parallel_topo_order    : pp_first\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,648] [   DEBUG]\u001b[0m - ignore_data_skip              : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,648] [   DEBUG]\u001b[0m - ignore_load_lr_and_optim      : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,648] [   DEBUG]\u001b[0m - ignore_save_lr_and_optim      : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,648] [   DEBUG]\u001b[0m - label_names                   : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,648] [   DEBUG]\u001b[0m - label_smoothing               : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,648] [   DEBUG]\u001b[0m - layerwise_lr_decay_bound      : 1.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,648] [   DEBUG]\u001b[0m - lazy_data_processing          : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,648] [   DEBUG]\u001b[0m - learning_rate                 : 1e-05\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,648] [   DEBUG]\u001b[0m - load_best_model_at_end        : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,648] [   DEBUG]\u001b[0m - load_sharded_model            : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,648] [   DEBUG]\u001b[0m - local_process_index           : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,648] [   DEBUG]\u001b[0m - local_rank                    : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,648] [   DEBUG]\u001b[0m - log_level                     : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,648] [   DEBUG]\u001b[0m - log_level_replica             : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,648] [   DEBUG]\u001b[0m - log_on_each_node              : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,649] [   DEBUG]\u001b[0m - logging_dir                   : ./vdl_log\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,649] [   DEBUG]\u001b[0m - logging_first_step            : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,649] [   DEBUG]\u001b[0m - logging_steps                 : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,649] [   DEBUG]\u001b[0m - logging_strategy              : IntervalStrategy.STEPS\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,649] [   DEBUG]\u001b[0m - logical_process_index         : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,649] [   DEBUG]\u001b[0m - loss_type                     : sigmoid\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,649] [   DEBUG]\u001b[0m - lr_end                        : 1e-07\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,649] [   DEBUG]\u001b[0m - lr_scheduler_type             : SchedulerType.COSINE\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,649] [   DEBUG]\u001b[0m - max_estimate_samples          : 100000.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,649] [   DEBUG]\u001b[0m - max_evaluate_steps            : 10000\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,649] [   DEBUG]\u001b[0m - max_grad_norm                 : 1.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,649] [   DEBUG]\u001b[0m - max_steps                     : 100\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,649] [   DEBUG]\u001b[0m - metric_for_best_model         : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,649] [   DEBUG]\u001b[0m - metrics_output_path           : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,649] [   DEBUG]\u001b[0m - min_lr                        : 1e-06\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,649] [   DEBUG]\u001b[0m - minimum_eval_times            : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,649] [   DEBUG]\u001b[0m - multi_token_pred_lambda       : 0.3\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,649] [   DEBUG]\u001b[0m - no_cuda                       : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,649] [   DEBUG]\u001b[0m - normalize_logps               : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,649] [   DEBUG]\u001b[0m - num_cycles                    : 0.5\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,649] [   DEBUG]\u001b[0m - num_nextn_predict_layers      : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,649] [   DEBUG]\u001b[0m - num_of_gpus                   : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,650] [   DEBUG]\u001b[0m - num_train_epochs              : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,650] [   DEBUG]\u001b[0m - offload_optim                 : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,650] [   DEBUG]\u001b[0m - offset_alpha                  : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,650] [   DEBUG]\u001b[0m - optim                         : OptimizerNames.ADAMW\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,650] [   DEBUG]\u001b[0m - optim_shard_num               : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,650] [   DEBUG]\u001b[0m - optimizer_name_suffix         : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,650] [   DEBUG]\u001b[0m - ordered_save_group_size       : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,650] [   DEBUG]\u001b[0m - output_dir                    : ./output\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,650] [   DEBUG]\u001b[0m - output_signal_dir             : ./output\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,650] [   DEBUG]\u001b[0m - overwrite_output_dir          : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,650] [   DEBUG]\u001b[0m - pad_token_id                  : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,650] [   DEBUG]\u001b[0m - past_index                    : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,650] [   DEBUG]\u001b[0m - pdc_download_ckpt             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,650] [   DEBUG]\u001b[0m - pdc_download_timeout          : 300\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,650] [   DEBUG]\u001b[0m - per_device_eval_batch_size    : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,650] [   DEBUG]\u001b[0m - per_device_train_batch_size   : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,650] [   DEBUG]\u001b[0m - pipeline_parallel_config      : enable_delay_scale_loss enable_release_grads disable_partial_send_recv\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,650] [   DEBUG]\u001b[0m - pipeline_parallel_degree      : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,650] [   DEBUG]\u001b[0m - pipeline_parallel_rank        : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,650] [   DEBUG]\u001b[0m - power                         : 1.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,650] [   DEBUG]\u001b[0m - prediction_loss_only          : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,650] [   DEBUG]\u001b[0m - pref_loss_ratio               : 1.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,650] [   DEBUG]\u001b[0m - process_index                 : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,651] [   DEBUG]\u001b[0m - quant_input_grad              : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,651] [   DEBUG]\u001b[0m - quant_weight_grad             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,651] [   DEBUG]\u001b[0m - recompute                     : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,651] [   DEBUG]\u001b[0m - ref_model_update_steps        : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,651] [   DEBUG]\u001b[0m - reference_free                : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,651] [   DEBUG]\u001b[0m - refined_recompute             : {}\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,651] [   DEBUG]\u001b[0m - release_grads                 : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,651] [   DEBUG]\u001b[0m - remove_unused_columns         : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,651] [   DEBUG]\u001b[0m - report_to                     : ['visualdl']\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,651] [   DEBUG]\u001b[0m - resume_from_checkpoint        : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,651] [   DEBUG]\u001b[0m - run_name                      : ./output\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,651] [   DEBUG]\u001b[0m - save_on_each_node             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,651] [   DEBUG]\u001b[0m - save_rng_states               : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,651] [   DEBUG]\u001b[0m - save_sharded_model            : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,651] [   DEBUG]\u001b[0m - save_sharding_stage1_model_include_freeze_params: False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,651] [   DEBUG]\u001b[0m - save_steps                    : 10000000\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,651] [   DEBUG]\u001b[0m - save_strategy                 : IntervalStrategy.STEPS\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,651] [   DEBUG]\u001b[0m - save_tokenizer                : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,651] [   DEBUG]\u001b[0m - save_total_limit              : 5\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,651] [   DEBUG]\u001b[0m - scale_loss                    : 32768\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,651] [   DEBUG]\u001b[0m - seed                          : 23\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,651] [   DEBUG]\u001b[0m - sep_parallel_degree           : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,651] [   DEBUG]\u001b[0m - sequence_parallel             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,652] [   DEBUG]\u001b[0m - sequence_parallel_config      : \u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,652] [   DEBUG]\u001b[0m - server_tp_degree              : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,652] [   DEBUG]\u001b[0m - sft_benchmark                 : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,652] [   DEBUG]\u001b[0m - sft_loss_ratio                : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,652] [   DEBUG]\u001b[0m - sharding                      : []\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,652] [   DEBUG]\u001b[0m - sharding_comm_buffer_size_MB  : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,652] [   DEBUG]\u001b[0m - sharding_degree               : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,652] [   DEBUG]\u001b[0m - sharding_parallel_config      : \u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,652] [   DEBUG]\u001b[0m - sharding_parallel_degree      : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,652] [   DEBUG]\u001b[0m - sharding_parallel_mesh_dimension: dp\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,652] [   DEBUG]\u001b[0m - sharding_parallel_rank        : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,652] [   DEBUG]\u001b[0m - should_load_dataset           : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,652] [   DEBUG]\u001b[0m - should_load_sharding_stage1_model: False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,652] [   DEBUG]\u001b[0m - should_log                    : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,652] [   DEBUG]\u001b[0m - should_save                   : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,652] [   DEBUG]\u001b[0m - should_save_model_state       : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,652] [   DEBUG]\u001b[0m - should_save_model_with_tensor_fusion: False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,652] [   DEBUG]\u001b[0m - should_save_sharding_stage1_model: False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,652] [   DEBUG]\u001b[0m - simpo_gamma                   : 0.5\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,652] [   DEBUG]\u001b[0m - skip_data_intervals           : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,652] [   DEBUG]\u001b[0m - skip_memory_metrics           : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,652] [   DEBUG]\u001b[0m - skip_profile_timer            : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,652] [   DEBUG]\u001b[0m - split_inputs_sequence_dim     : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,653] [   DEBUG]\u001b[0m - split_norm_comm               : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,653] [   DEBUG]\u001b[0m - tensor_parallel_config        : \u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,653] [   DEBUG]\u001b[0m - tensor_parallel_degree        : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,653] [   DEBUG]\u001b[0m - tensor_parallel_rank          : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,653] [   DEBUG]\u001b[0m - tensorwise_offload_optimizer  : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,653] [   DEBUG]\u001b[0m - to_static                     : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,653] [   DEBUG]\u001b[0m - train_batch_size              : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,653] [   DEBUG]\u001b[0m - unified_checkpoint            : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,653] [   DEBUG]\u001b[0m - unified_checkpoint_config     : ['async_save']\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,653] [   DEBUG]\u001b[0m - use_async_save                : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,653] [   DEBUG]\u001b[0m - use_expert_parallel           : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,653] [   DEBUG]\u001b[0m - use_hybrid_parallel           : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,653] [   DEBUG]\u001b[0m - use_lowprecision_moment       : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,653] [   DEBUG]\u001b[0m - use_recompute_mtp             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,653] [   DEBUG]\u001b[0m - use_sp_callback               : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,653] [   DEBUG]\u001b[0m - wandb_api_key                 : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,653] [   DEBUG]\u001b[0m - wandb_http_proxy              : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,653] [   DEBUG]\u001b[0m - warmup_ratio                  : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,653] [   DEBUG]\u001b[0m - warmup_steps                  : 20\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,653] [   DEBUG]\u001b[0m - weight_decay                  : 0.1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,653] [   DEBUG]\u001b[0m - weight_name_suffix            : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,653] [   DEBUG]\u001b[0m - weight_quantize_algo          : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,654] [   DEBUG]\u001b[0m - world_size                    : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,654] [   DEBUG]\u001b[0m - zcc_ema_interval              : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,654] [   DEBUG]\u001b[0m - zcc_pipeline_hooks_capacity_usage: 0.6\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,654] [   DEBUG]\u001b[0m - zcc_save_ema_coef             : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,654] [   DEBUG]\u001b[0m - zcc_workers_num               : 3\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,654] [   DEBUG]\u001b[0m - \u001b[0m\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/distributed/parallel.py:450: UserWarning: The program will return to single-card operation. Please check 1, whether you use spawn or fleetrun to start the program. 2, Whether it is a multi-card program. 3, Is the current environment multi-card.\r\n",
      "  warnings.warn(\r\n",
      "\u001b[32m[2025-07-18 16:25:03,662] [    INFO]\u001b[0m - ***** Running Evaluation *****\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:03,662] [    INFO]\u001b[0m -   Num examples: Unknown\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:03,662] [    INFO]\u001b[0m -   Total prediction steps = 10000\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:03,662] [    INFO]\u001b[0m -   Pre device batch size = 1\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:03,663] [    INFO]\u001b[0m -   Total Batch size = 1\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:03,664] [    INFO]\u001b[0m - prepare SequenceDataset ...\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:03,664] [    INFO]\u001b[0m - prepare SequenceDataset done: total number of examples is 2\u001b[0m\r\n",
      "W0718 16:25:04.358070 166592 multiply_fwd_func.cc:76] got different data type, run type promotion automatically, this may cause data type been changed.\r\n",
      "\u001b[32m[2025-07-18 16:25:04,663] [    INFO]\u001b[0m - eval_loss: 9.515118598937988, eval_runtime: 1.0008, eval_samples_per_second: 9992.3098, eval_steps_per_second: 9992.3098, eval_ppl: 13563.241735167847\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:04,663] [    INFO]\u001b[0m - ***** eval metrics *****\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:04,663] [    INFO]\u001b[0m -   eval_loss               =     9.5151\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:04,664] [    INFO]\u001b[0m -   eval_ppl                = 13563.2417\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:04,664] [    INFO]\u001b[0m -   eval_runtime            = 0:00:01.00\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:04,664] [    INFO]\u001b[0m -   eval_samples_per_second =  9992.3098\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:04,664] [    INFO]\u001b[0m -   eval_steps_per_second   =  9992.3098\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:04,664] [    INFO]\u001b[0m - Saving stop info into ./vdl_log/stop_step.json\u001b[0m\r\n",
      "LAUNCH INFO 2025-07-18 16:25:05,654 Pod completed\r\n",
      "LAUNCH INFO 2025-07-18 16:25:05,654 Exit code 0\r\n"
     ]
    }
   ],
   "source": [
    "!erniekit eval ERNIE-develop/examples/configs/ERNIE-4.5-0.3B/sft/run_sft_8k.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**é‡è¦æç¤ºï¼šå…³äº `eval` å‘½ä»¤çš„æ—¥å¿—è¾“å‡º**\n",
    "\n",
    "å½“æ‚¨è¿è¡Œ `erniekit eval` å‘½ä»¤æ—¶ï¼Œæ‚¨ä¼šçœ‹åˆ°ç»ˆç«¯è¾“å‡ºäº†å¤§é‡çš„æ—¥å¿—ä¿¡æ¯ï¼Œç±»ä¼¼äºæ‚¨åœ¨è®­ç»ƒæ—¶çœ‹åˆ°çš„å†…å®¹ã€‚**è¿™æ˜¯å®Œå…¨æ­£å¸¸çš„è¡Œä¸º**ã€‚å› ä¸º `erniekit eval` æœ¬è´¨ä¸Šæ˜¯å¯åŠ¨äº†ä¸€ä¸ªåˆ†å¸ƒå¼çš„è¯„ä¼°ä»»åŠ¡ï¼Œå®ƒéœ€è¦åŠ è½½åˆ†å¸ƒå¼ç¯å¢ƒã€è§£æå®Œæ•´çš„æ¨¡å‹å’Œæ•°æ®é…ç½®ã€åŠ è½½æ¨¡å‹æƒé‡ç­‰ï¼Œè¿™äº›è¿‡ç¨‹éƒ½ä¼šè¢«è¯¦ç»†åœ°è®°å½•ä¸‹æ¥ã€‚\n",
    "\n",
    "åœ¨æ—¥å¿—è¾“å‡ºä¸­ï¼Œæ‚¨éœ€è¦é‡ç‚¹å…³æ³¨ä»¥ä¸‹å†…å®¹ï¼š\n",
    "\n",
    "1. **å‘½ä»¤æ‰§è¡ŒçŠ¶æ€**ï¼šæœ€ç»ˆæ˜¯å¦æ˜¾ç¤º `Exit code 0`ï¼Œè¡¨ç¤ºè¯„ä¼°ä»»åŠ¡æˆåŠŸå®Œæˆ\n",
    "\n",
    "2. **å…³é”®è¯„ä¼°æŒ‡æ ‡**ï¼š\n",
    "   - `eval_loss`ï¼šè¯„ä¼°æŸå¤±å€¼ï¼Œåæ˜ æ¨¡å‹é¢„æµ‹çš„å‡†ç¡®ç¨‹åº¦ï¼Œå€¼è¶Šå°è¶Šå¥½\n",
    "   - `eval_ppl`ï¼šå›°æƒ‘åº¦ï¼Œç”¨äºè¡¡é‡ç”Ÿæˆä»»åŠ¡çš„æ€§èƒ½ï¼Œå€¼è¶Šå°è¡¨ç¤ºæ¨¡å‹è¡¨ç°è¶Šå¥½\n",
    "   - `eval_runtime`ï¼šè¯„ä¼°è€—æ—¶\n",
    "   - `eval_samples_per_second`ï¼šæ¯ç§’å¤„ç†æ ·æœ¬æ•°ï¼Œåæ˜ è¯„ä¼°é€Ÿåº¦"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 æ€§èƒ½ä¼˜åŒ–å»ºè®®\n",
    "\n",
    "å¦‚æœæ‚¨åœ¨å®é™…åº”ç”¨ä¸­éœ€è¦æ›´å¥½çš„æ€§èƒ½ï¼Œå¯ä»¥å‚è€ƒä»¥ä¸‹ä¼˜åŒ–æ–¹æ¡ˆè¡¨æ ¼ã€‚æˆ‘ä»¬ä»æ•°æ®ã€è®­ç»ƒã€æ¨¡å‹å’Œéƒ¨ç½²å››ä¸ªç»´åº¦ï¼Œæä¾›äº†è¯¦ç»†çš„ä¼˜åŒ–å»ºè®®å’Œå…·ä½“æ“ä½œæ–¹æ³•ï¼š\n",
    "\n",
    "#### 6.2.1 ä¼˜åŒ–æ–¹æ¡ˆå…¨æ™¯å›¾\n",
    "\n",
    "| ä¼˜åŒ–ç»´åº¦ | å…·ä½“æªæ–½ | æ“ä½œå»ºè®® | é¢„æœŸæ•ˆæœ | é€‚ç”¨åœºæ™¯ |\n",
    "|:---:|:---|:---|:---|:---|\n",
    "| ğŸ“Š **æ•°æ®ä¼˜åŒ–** | â€¢ æ‰©å……æ•°æ®è§„æ¨¡<br>â€¢ æå‡æ•°æ®è´¨é‡<br>â€¢ é¢†åŸŸæ•°æ®å¢å¼º | â€¢ ä½¿ç”¨æ•°æ®å¢å¼ºæŠ€æœ¯<br>â€¢ å¼•å…¥äººå·¥å®¡æ ¸æœºåˆ¶<br>â€¢ æ”¶é›†ç›®æ ‡é¢†åŸŸæ•°æ® | â€¢ æå‡æ¨¡å‹æ³›åŒ–èƒ½åŠ›<br>â€¢ é™ä½è¿‡æ‹Ÿåˆé£é™©<br>â€¢ æé«˜é¢†åŸŸé€‚åº”æ€§ | â€¢ æ•°æ®é‡ä¸è¶³<br>â€¢ æ ‡æ³¨è´¨é‡å‚å·®<br>â€¢ é¢†åŸŸè¿ç§»åœºæ™¯ |\n",
    "| âš™ï¸ **è®­ç»ƒä¼˜åŒ–** | â€¢ å­¦ä¹ ç‡è°ƒä¼˜<br>â€¢ æ‰¹å¤§å°ä¼˜åŒ–<br>â€¢ è®­ç»ƒç­–ç•¥æ”¹è¿› | â€¢ ä½¿ç”¨å­¦ä¹ ç‡é¢„çƒ­<br>â€¢ å°è¯•æ¢¯åº¦ç´¯ç§¯<br>â€¢ é‡‡ç”¨æ—©åœç­–ç•¥ | â€¢ åŠ å¿«æ”¶æ•›é€Ÿåº¦<br>â€¢ æå‡è®­ç»ƒç¨³å®šæ€§<br>â€¢ èŠ‚çœè®¡ç®—èµ„æº | â€¢ è®­ç»ƒä¸ç¨³å®š<br>â€¢ æ˜¾å­˜å—é™<br>â€¢ è¿‡æ‹Ÿåˆä¸¥é‡ |\n",
    "| ğŸ§  **æ¨¡å‹ä¼˜åŒ–** | â€¢ æ¨¡å‹é€‰å‹<br>â€¢ é‡åŒ–åŠ é€Ÿ<br>â€¢ çŸ¥è¯†è’¸é¦ | â€¢ å°è¯•æ›´å¤§/å°æ¨¡å‹<br>â€¢ ä½¿ç”¨INT8/BF16é‡åŒ–<br>â€¢ åº”ç”¨æ•™å¸ˆ-å­¦ç”Ÿè’¸é¦ | â€¢ å¹³è¡¡æ€§èƒ½å’Œæ•ˆç‡<br>â€¢ åŠ é€Ÿæ¨ç†é€Ÿåº¦<br>â€¢ å‡å°æ¨¡å‹ä½“ç§¯ | â€¢ æ€§èƒ½ç“¶é¢ˆ<br>â€¢ æ¨ç†å»¶è¿Ÿé«˜<br>â€¢ èµ„æºå—é™ |\n",
    "| ğŸš€ **éƒ¨ç½²ä¼˜åŒ–** | â€¢ æ–‡æœ¬å¤„ç†åŠ é€Ÿ<br>â€¢ æ¨ç†æ€§èƒ½æå‡<br>â€¢ æ‰¹å¤„ç†ä¼˜åŒ– | â€¢ å¯ç”¨FastTokenizer<br>â€¢ å¼€å¯æ¨ç†ä¼˜åŒ–é€‰é¡¹<br>â€¢ å®ç°è¯·æ±‚æ‰¹å¤„ç† | â€¢ é™ä½å¤„ç†å»¶è¿Ÿ<br>â€¢ æå‡æ¨ç†é€Ÿåº¦<br>â€¢ å¢åŠ ç³»ç»Ÿåå | â€¢ åœ¨çº¿æœåŠ¡<br>â€¢ é«˜å¹¶å‘åœºæ™¯<br>â€¢ å»¶è¿Ÿæ•æ„Ÿ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. æ€»ç»“ä¸å±•æœ›\n",
    "\n",
    "æ­å–œæ‚¨å®Œæˆäº†æœ¬æ¬¡ ERNIE-4.5-0.3B ä¸­æ–‡æƒ…æ„Ÿåˆ†æå®æˆ˜æ•™ç¨‹ï¼\n",
    "\n",
    "åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä»é›¶å¼€å§‹ï¼Œå­¦ä¹ äº†å¦‚ä½•ä½¿ç”¨ ERNIEkit å¯¹ ERNIE-4.5-0.3B æ¨¡å‹è¿›è¡Œç›‘ç£å¾®è°ƒï¼Œå¹¶å°†å…¶åº”ç”¨äºæƒ…æ„Ÿåˆ†æä»»åŠ¡ã€‚æˆ‘ä»¬ç»å†äº†ä»ç¯å¢ƒå‡†å¤‡ã€æ•°æ®å¤„ç†ã€æ¨¡å‹å¾®è°ƒåˆ°è¯„ä¼°é¢„æµ‹çš„å®Œæ•´æµç¨‹ï¼Œå¹¶æ·±å…¥æ¢è®¨äº† ERNIE-4.5-0.3B æ¨¡å‹çš„ä¼˜åŠ¿å’Œå¾®è°ƒåŸç†ã€‚\n",
    "\n",
    "é€šè¿‡æœ¬æ•™ç¨‹ï¼Œæ‚¨åº”è¯¥å·²ç»æŒæ¡äº†ä»¥ä¸‹æ ¸å¿ƒæŠ€èƒ½ï¼š\n",
    "\n",
    "- **ä½¿ç”¨ ERNIEkit è¿›è¡Œæ¨¡å‹è®­ç»ƒ**ï¼šå­¦ä¼šäº†é€šè¿‡é…ç½®æ–‡ä»¶ç®¡ç†è®­ç»ƒå‚æ•°ï¼Œå¹¶ä½¿ç”¨ç®€å•çš„å‘½ä»¤å¯åŠ¨è®­ç»ƒã€è¯„ä¼°å’Œé¢„æµ‹ã€‚\n",
    "- **å¤„ç†è‡ªå®šä¹‰æ•°æ®é›†**ï¼šæŒæ¡äº†å¦‚ä½•å°†è‡ªå·±çš„æ•°æ®è½¬æ¢ä¸º ERNIEkit æ‰€éœ€çš„æ ¼å¼ï¼Œå¹¶è¿›è¡Œæœ‰æ•ˆçš„è®­ç»ƒã€‚\n",
    "- **ç†è§£å’Œåº”ç”¨ SFT**ï¼šæ·±å…¥ç†è§£äº†ç›‘ç£å¾®è°ƒçš„åŸç†ï¼Œå¹¶èƒ½å°†å…¶åº”ç”¨äºå®é™…çš„ NLP ä»»åŠ¡ä¸­ã€‚\n",
    "- **è¯„ä¼°å’Œä¼˜åŒ–æ¨¡å‹**ï¼šå­¦ä¼šäº†å¦‚ä½•è¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼Œå¹¶æŒæ¡äº†å¤šç§ä¼˜åŒ–ç­–ç•¥æ¥æå‡æ¨¡å‹æ•ˆæœã€‚\n",
    "\n",
    "### 7.1 æœªæ¥å±•æœ›\n",
    "\n",
    "æƒ…æ„Ÿåˆ†ææ˜¯ä¸€ä¸ªä¸æ–­å‘å±•çš„é¢†åŸŸï¼Œéšç€æŠ€æœ¯çš„è¿›æ­¥ï¼Œæˆ‘ä»¬å¯ä»¥æ¢ç´¢æ›´å¤šæœ‰è¶£çš„æ–¹å‘ï¼š\n",
    "\n",
    "- **å¤šæ¨¡æ€æƒ…æ„Ÿåˆ†æ**ï¼šç»“åˆæ–‡æœ¬ã€å›¾åƒå’Œå£°éŸ³ï¼Œæ›´å…¨é¢åœ°ç†è§£ç”¨æˆ·çš„æƒ…æ„Ÿã€‚\n",
    "- **ç»†ç²’åº¦æƒ…æ„Ÿåˆ†æ**ï¼šä¸ä»…è¯†åˆ«æƒ…æ„Ÿçš„ææ€§ï¼Œè¿˜èƒ½åˆ†ææƒ…æ„Ÿçš„å¼ºåº¦ã€åŸå› å’Œå¯¹è±¡ã€‚\n",
    "- **è·¨é¢†åŸŸæƒ…æ„Ÿåˆ†æ**ï¼šå°†åœ¨ä¸€ä¸ªé¢†åŸŸè®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œåº”ç”¨äºå¦ä¸€ä¸ªæ–°çš„é¢†åŸŸã€‚\n",
    "- **å°æ ·æœ¬æƒ…æ„Ÿåˆ†æ**ï¼šåœ¨æ•°æ®é‡æœ‰é™çš„æƒ…å†µä¸‹ï¼Œå¦‚ä½•æœ‰æ•ˆåœ°è®­ç»ƒæƒ…æ„Ÿåˆ†ææ¨¡å‹ã€‚\n",
    "\n",
    "ERNIE-4.5-0.3B ä½œä¸ºä¸€ä¸ªå¼ºå¤§çš„åŸºç¡€æ¨¡å‹ï¼Œä¸ºè¿™äº›å‰æ²¿ç ”ç©¶æä¾›äº†åšå®çš„åŸºç¡€ã€‚æˆ‘ä»¬é¼“åŠ±æ‚¨åœ¨æœ¬æ¬¡æ•™ç¨‹çš„åŸºç¡€ä¸Šï¼Œç»§ç»­æ¢ç´¢å’Œå®è·µï¼Œå°†æ‰€å­¦çŸ¥è¯†åº”ç”¨äºæ›´å¹¿é˜”çš„é¢†åŸŸã€‚\n",
    "\n",
    "æ„Ÿè°¢æ‚¨çš„å­¦ä¹ ï¼å¦‚æœæ‚¨æœ‰ä»»ä½•é—®é¢˜æˆ–å»ºè®®ï¼Œæ¬¢è¿éšæ—¶ä¸æˆ‘ä»¬äº¤æµã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# é—®é¢˜åé¦ˆ/ä¸æˆ‘è”ç³»ï¼š Wechatï¼šG_Fuji"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
