{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ERNIE-4.5-0.3B Chinese Sentiment Analysis Practical Tutorial\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "Welcome to the ERNIE-4.5-0.3B Practical Tutorial Series! In previous lessons, we have mastered core technologies such as pre-training (PT), supervised fine-tuning (SFT), and direct preference optimization (DPO), which form the foundation of large-scale model development. Now it is time to put theory into practice and tackle a real-world problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Why choose sentiment analysis as the first practical project?\n",
    "\n",
    "Theoretical learning is like learning internal martial arts techniques, while practical projects are like practicing specific martial arts moves. Sentiment analysis is the first move we have chosen. Why this one?\n",
    "\n",
    "*   **Building on previous knowledge and reinforcing SFT skills**: Sentiment analysis is fundamentally a text classification task, making it the most direct and classic application scenario for supervised fine-tuning (SFT). Through this project, we can integrate the SFT knowledge we have learned, gaining a deep understanding of how to fine-tune a general pre-trained model into a domain-specific expert model.\n",
    "* **Widespread demand and significant commercial value**: From analyzing user reviews and monitoring brand reputation to understanding social sentiment, sentiment analysis is an indispensable foundation for countless AI applications. Mastering it means mastering a core skill that can create significant commercial value.\n",
    "* **Simple, intuitive, and easy to get started**: Compared to complex generation tasks or dialogue systems, sentiment analysis has a clear objective (determining positive/negative sentiment) and results that are easy to evaluate (accuracy rate), making it an ideal ‚Äúfirst bridge‚Äù from theory to practice.\n",
    "\n",
    "Therefore, this tutorial will focus on Chinese sentiment analysis, guiding you through the entire practical process of ‚Äúdata preparation -> model fine-tuning -> evaluation and prediction,‚Äù truly leveraging the powerful capabilities of ERNIE-4.5-0.3B to address real-world problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 What is sentiment analysis?\n",
    "\n",
    "Sentiment analysis, also known as opinion mining, is the process of extracting, analyzing, summarizing, and inferring subjective text with emotional connotations using methods such as natural language processing, text analysis, and computational linguistics. Simply put, its goal is to **identify and determine whether the sentiment expressed in a piece of text is positive (upbeat), negative (downbeat), or neutral**.\n",
    "\n",
    "For example, given a user review such as, ‚ÄúThe roast duck at this restaurant is absolutely delicious, and the atmosphere is great too!‚Äù, the sentiment analysis system should be able to determine that this is a **positive** review. On the other hand, for a review like, ‚ÄúWe waited over half an hour for the food to arrive, and the taste was just average,‚Äù it should be classified as **negative**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Application Scenarios and Project Significance of Sentiment Analysis\n",
    "\n",
    "Sentiment analysis technology has enormous application value in both commercial and research fields and is a fundamental module for many intelligent applications.\n",
    "\n",
    "| Application Field       | Specific Scenario                                                     | Project Significance                                       |\n",
    "| -------------- | ------------------------------------------------------------ | ---------------------------------------------- |\n",
    "| **Business Intelligence**   | Public opinion monitoring, brand reputation management, product review analysis                         | Real-time understanding of public sentiment, product optimization, crisis public relations         |\n",
    "| **Customer Relations**   | Analysis of customer service conversations, service tickets, user satisfaction surveys                       | Automatic assessment of customer satisfaction, identification of service pain points, improvement of service quality |\n",
    "| **Financial Technology**   | Analyze financial news, social media sentiment, and stock commentary                           | Assist in quantitative trading and investment decisions                         |\n",
    "| **Social Sciences**   | Analyze public sentiment toward specific social events or policies                       | Provide data references for research in sociology, communication studies, and other fields         |\n",
    "\n",
    "This project aims to provide a comprehensive practical case study to help you master how to use the latest ERNIE-4.5-0.3B model to solve text classification problems in real-world scenarios, laying a solid foundation for applying NLP technology in your own business or research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Why choose the ERNIE-4.5-0.3B model?\n",
    "\n",
    "ERNIE 4.5 is not a single model, but rather a family of models that span various scales and are optimized for different scenarios. To help you better understand why we chose ERNIE-4.5-0.3B, the following table compares the main models in the family, based on the official `ERNIE-develop` repository documentation:\n",
    "\n",
    "| Model Name | Supported Fine-tuning Methods | Supported Sequence Length | Minimum Resource Requirement (SFT) |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **ERNIE-4.5-0.3B** | SFT, SFT-LoRA, DPO, DPO-LoRA | 8k, 32k, 128k | **1x 80G A/H GPU** |\n",
    "| ERNIE-4.5-21B-A3B | SFT, SFT-LoRA, DPO, DPO-LoRA | 8k, 32k, 128k | 8x 80G A/H GPUs |\n",
    "| ERNIE-4.5-300B-A47B | SFT, SFT(FP8), SFT-LoRA, DPO, DPO-LoRA | 8k, 32k | 96x 80GB A/H GPUs (SFT) <br> 16x 80GB H GPUs (SFT with FP8) |\n",
    "\n",
    "*Table information source: ERNIE-develop/docs/erniekit.md*\n",
    "\n",
    "<br>\n",
    "\n",
    "**Why choose ERNIE-4.5-0.3B?**\n",
    "\n",
    "ERNIE-4.5-0.3B is an ideal choice for this sentiment analysis tutorial for the following reasons:\n",
    "\n",
    "* **Resource-friendly and accessible**: As the table above clearly shows, full parameter fine-tuning (SFT) on ERNIE-4.5-0.3B can be completed on a single 80GB A/H series GPU, significantly lowering the hardware barrier to learning and implementing large models. In contrast, other larger models often require dozens or even hundreds of GPUs, making them impractical for individual developers and most learning scenarios.\n",
    "\n",
    "* **Complete functionality, comprehensive experience**: Despite its smaller model size, `ERNIE-4.5-0.3B` supports a full suite of fine-tuning techniques, including SFT, LoRA, and DPO, allowing us to fully experience and learn the entire process of developing large models in the most economical way.\n",
    "* **Excellent performance**: For relatively mature NLP tasks like sentiment analysis, `ERNIE-4.5-0.3B` inherits the powerful semantic understanding capabilities of the ERNIE series, providing performance that fully meets the requirements of high-precision classification. We can efficiently solve the problem without resorting to overkill.\n",
    "\n",
    "ERNIE-4.5-0.3B strikes an excellent balance between **learning cost, complete functionality, and task performance**, making it the **official recommendation** and best choice** for getting started and practicing large-scale sentiment analysis tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Tutorial Objectives and Content\n",
    "\n",
    "This tutorial is designed for developers and learners who have a basic understanding of NLP and deep learning and want to get hands-on experience solving real-world problems. You will gain a lot from this tutorial:\n",
    "\n",
    "| Learning Objectives | Core Skills | You Will Master |\n",
    "|:---:|:---|:---|\n",
    "| üéØ **Understand the Task** | Basic Sentiment Analysis Process | Be able to clearly describe the input, output, and evaluation metrics of sentiment analysis tasks |\n",
    "| üõ†Ô∏è **Master the Tools** | Use ERNIEkit | Become proficient in using ERNIEkit for data processing, model loading, and configuration |\n",
    "| üî• **Core Practice** | Fine-tuning ERNIE-4.5-0.3B | Training a High-Accuracy Chinese Sentiment Analysis Model from Scratch |\n",
    "| üìä **Learn Evaluation** | Model Performance Evaluation and Prediction | Be able to scientifically evaluate model performance and use the model for inference and prediction |\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Introduction to ERNIEkit: A One-Stop Tool for Large-Scale Model Development\n",
    "\n",
    "Before we officially begin, it's important to first introduce one of the \"stars\" of this practical exercise‚ÄîERNIEkit. Simply put, ERNIEkit is a full-process development toolkit tailored for the ERNIE series of large models.\n",
    "\n",
    "If you've previously used PaddleNLP or Hugging Face Transformers, you can consider ERNIEkit a more focused and efficient alternative. It encapsulates the complex process of large-scale model development, including data processing, model training, performance optimization, evaluation, and deployment, into concise command-line tools and configuration files, providing developers with an ultimate \"out-of-the-box\" experience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 ERNIEkit's Core Design Philosophy\n",
    "\n",
    "ERNIEkit's design philosophy can be summarized as \"Convention over Configuration.\" It provides best practices and default configurations for various large-scale model applications (such as SFT, DPO, and pre-training). Developers no longer need to write lengthy training scripts; instead, they simply:\n",
    "\n",
    "1. **Data Preparation**: Prepare your data according to the specified format.\n",
    "\n",
    "2. **Configuration Modification**: Fill in the blanks in a `yaml` configuration file to modify several core parameters (such as the model path, data path, and learning rate).\n",
    "\n",
    "3. **Execute Command**: Run a simple command (such as `erniekit train`) to initiate a highly optimized training process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Core Advantages of ERNIEkit\n",
    "\n",
    "| Advantages and Features | Specific Features | Value for Developers |\n",
    "|:---:|:---|:---|\n",
    "| üöÄ **Extreme Ease of Use** | `Configuration File` + `Command Line` Development Model | Significantly Lowers the Bar for Developing Large Models, Eliminating the Need for Complex Code |\n",
    "| ‚ö° **Excellent Performance** | Built-in Optimizations such as Multiple Parallelism Strategies, Mixed Precision, and Operator Fusion | Achieve High-Performance Training and Inference Speeds without Manual Optimization |\n",
    "| üì¶ **Comprehensive Features** | Covers the entire process of data processing, training, evaluation, inference, and deployment | Provides a One-Stop Solution to Simplify the Development Process |\n",
    "| üîß **Flexible Extensibility** | Supports Custom Models, Data, and Training Processes | Out-of-the-Box Operation While Retaining Sufficient Flexibility for Advanced Users |\n",
    "\n",
    "Through this tutorial, you will personally experience the convenience and efficiency of using ERNIEkit for developing large models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Environment Preparation\n",
    "\n",
    "First, we need to ensure that the necessary libraries are installed. This tutorial primarily relies on ERNIEkit and aistudio-sdk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install the latest version of ERNIEkit and aistudio-sdk\n",
    "!pip install --upgrade aistudio-sdk\n",
    "\n",
    "# Download the ERNIE-4.5-0.3B model\n",
    "!aistudio download --model PaddlePaddle/ERNIE-4.5-0.3B-Paddle --local_dir baidu/ERNIE-4.5-0.3B-Paddle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the installation is complete, we can import and check the version information to ensure that the environment is configured correctly. Students running Ai studio do not need to run this code block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T07:16:41.583798Z",
     "iopub.status.busy": "2025-07-18T07:16:41.583484Z",
     "iopub.status.idle": "2025-07-18T07:16:43.037416Z",
     "shell.execute_reply": "2025-07-18T07:16:43.036888Z",
     "shell.execute_reply.started": "2025-07-18T07:16:41.583779Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/utils/cpp_extension/extension_utils.py:715: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\r\n",
      "  warnings.warn(warning_message)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PaddlePaddle is compiled with CUDA and GPU is available.\r\n"
     ]
    }
   ],
   "source": [
    "# check if paddlepaddle is compiled with cuda\n",
    "\n",
    "import paddle\n",
    "if paddle.is_compiled_with_cuda():\n",
    "    print(\"PaddlePaddle is compiled with CUDA and GPU is available.\")\n",
    "else:\n",
    "    print(\"PaddlePaddle is not compiled with CUDA. It will use CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environment preparation is very simple. Next, we will load the dataset for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preparation\n",
    "\n",
    "For sentiment analysis, we need a labeled dataset where each piece of text is assigned a sentiment label (e.g., \"positive\" or \"negative\").\n",
    "\n",
    "### 3.1 Dataset Format\n",
    "\n",
    "ERNIEkit uses the `jsonl` format as its standard data input format. Each line is a separate JSON object containing the data needed for training. For sentiment analysis, we need to prepare data in the following format:\n",
    "\n",
    "```json\n",
    "{\"text\": \"This restaurant's roast duck is amazing, and the ambiance is great!\", \"label\": 1}\n",
    "{\"text\": \"We waited over half an hour for our food, and the food was average.\", \"label\": 0}\n",
    "```\n",
    "\n",
    "Where:\n",
    "- `text`: Represents the input text.\n",
    "- `label`: Represents the sentiment label, with `1` representing positive and `0` representing negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Creating Sample Data\n",
    "\n",
    "For demonstration purposes, we manually create two `jsonl` files, one for the training set and one for the evaluation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T07:43:59.478943Z",
     "iopub.status.busy": "2025-07-18T07:43:59.478622Z",
     "iopub.status.idle": "2025-07-18T07:43:59.485958Z",
     "shell.execute_reply": "2025-07-18T07:43:59.485388Z",
     "shell.execute_reply.started": "2025-07-18T07:43:59.478923Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sample data in ERNIEkit format was created successfully! sft-train.jsonl and sft-eval.jsonl were generated.\r\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Defining label mappings\n",
    "label_map = {1: \"Positive\", 0: \"Negative\"}\n",
    "\n",
    "# Create training data in ERNIEkit SFT format\n",
    "train_data = [\n",
    "    # Positive\n",
    "    {\"src\": [\"The roast duck in this restaurant is amazing and the environment is great too!\"], \"tgt\": [label_map[1]]},\n",
    "    {\"src\": [\"The service staff is very friendly and helpful.\"], \"tgt\": [label_map[1]]},\n",
    "    {\"src\": [\"The movie effects are very impressive and the plot is also very captivating.\"], \"tgt\": [label_map[1]]},\n",
    "    {\"src\": [\"This phone has a great camera and a long-lasting battery.\"], \"tgt\": [label_map[1]]},\n",
    "    \n",
    "    # Negative\n",
    "    {\"src\": [\"I waited for more than half an hour before the food was served, and the taste was also average.\"], \"tgt\": [label_map[0]]},\n",
    "    {\"src\": [\"The room acoustics were really bad, and it was really hard to sleep at night.\"], \"tgt\": [label_map[0]]},\n",
    "    {\"src\": [\"I bought a new pair of shoes, and they opened up after just one day. The quality is really bad.\"], \"tgt\": [label_map[0]]},\n",
    "    {\"src\": [\"The customer service phone was always unresponsive, and the problem couldn't be solved. The experience was really bad.\"], \"tgt\": [label_map[0]]}\n",
    "]\n",
    "\n",
    "with open('sft-train.jsonl', 'w', encoding='utf-8') as f:\n",
    "    for item in train_data:\n",
    "        # ERNIEkit requires src and tgt to be lists\n",
    "        f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
    "\n",
    "# Create evaluation data in the ERNIEkit SFT format\n",
    "eval_data = [\n",
    "    {\"src\": [\"Nice scenery, but too many people.\"], \"tgt\": [label_map[1]]},\n",
    "    {\"src\": [\"The hotel location is really hard to find, and the price is not very reasonable.\"], \"tgt\": [label_map[0]]}\n",
    "]\n",
    "\n",
    "with open('sft-eval.jsonl', 'w', encoding='utf-8') as f:\n",
    "    for item in eval_data:\n",
    "        f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
    "\n",
    "print(\"The sample data in ERNIEkit format was created successfully! sft-train.jsonl and sft-eval.jsonl were generated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Configuring the Data Path\n",
    "\n",
    "In ERNIEkit, we specify the dataset path by modifying the configuration file. Open `examples/configs/ERNIE-4.5-0.3B/sft/run_sft_8k.yaml`, find the following section, and modify it:\n",
    "\n",
    "```yaml\n",
    "### data\n",
    "train_dataset_path: \"./sft-train.jsonl\"\n",
    "eval_dataset_path: \"./sft-eval.jsonl\"\n",
    "```\n",
    "\n",
    "This way, ERNIEkit will automatically load the prepared data during training.\n",
    "\n",
    "At this point, all data preparation is complete. We now have data that can be fed into the model for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model and Fine-tuning Principles\n",
    "\n",
    "Once the data is ready, we need to understand the model we will use and how to adapt it to our sentiment analysis task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Introduction to the ERNIE-4.5-0.3B Model: A Language Master Who Understands Knowledge\n",
    "\n",
    "As mentioned in the introduction, ERNIE-4.5-0.3B is a model that \"understands\" Chinese more deeply. Its core advantage lies in its unique **knowledge integration pre-training task**.\n",
    "\n",
    "* **A deeper analogy**:\n",
    "Imagine a student (other models) learning the sentence: \"One of China's Four Great Inventions, movable type printing, was invented by Bi Sheng.\"\n",
    "\n",
    "This student might have learned the characters \"(movable) type printing\" and \"Bi (sheng)\" through \"fill-in-the-blank\" learning.\n",
    "\n",
    "Unlike ERNIE, the \"student master,\" the teacher would simply cover up two complete knowledge units, \"**movable type printing**\" and \"**Bi Sheng**,\" and ask him to predict them. To answer correctly, ERNIE must not only learn linguistic fluency but also compel it to understand that \"movable type printing\" is a complete technical concept, \"Bi Sheng\" is a personal name, and that the two knowledge units share a connection of \"invention.\"\n",
    "\n",
    "By conducting this \"knowledge point mining\" approach on massive amounts of text, ERNIE develops a deeper level of semantic understanding, going beyond superficial word combinations.\n",
    "\n",
    "This is why ERNIE typically performs better on tasks that require understanding the deeper meaning of sentences, such as sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Fine-tuning Principle: Equipping a Language Master with Sentiment Analysis Glasses\n",
    "\n",
    "The `ERNIE-4.5-0.3B` model we loaded is a learned generalist. It understands a wide range of linguistic knowledge, but by default, it doesn't know it needs to perform the specific task of \"sentiment analysis.\" The **fine-tuning** process is like fitting this language master with a pair of custom-made \"sentiment analysis glasses\" and instructing him on how to use them.\n",
    "\n",
    "This process consists of several steps:\n",
    "\n",
    "1. **Obtaining the \"Soul\" of the Sentence‚Äî[CLS] Output**:\n",
    "* We feed a review text (e.g., \"This restaurant's ramen is delicious!\") into the ERNIE model. Before feeding it, we prepend the text with a special marker `[CLS]` (Classification).\n",
    "* After ERNIE's complex internal computations (multi-layer Transformer layers), each word is given a vector rich in contextual information. After passing through the entire model, the corresponding output vector (pooled_output) for this special `[CLS]` flag is designed to capture the core semantics of the entire sentence. We can compare it to the \"overall impression\" or \"soul\" vector that ERNIE forms in its mind after reading a sentence.\n",
    "\n",
    "2. **Install the \"Sentiment Analysis Lens\" - Adding a Classification Head**:\n",
    "* This \"soul\" vector (e.g., a 768-dimensional vector) is simply a string of numbers and does not directly represent \"positive\" or \"negative.\"\n",
    "* We attach a very simple \"lens\" to this string of numbers‚Äîa **fully connected layer**. This fully connected layer is the \"classification head,\" and its task is very specific: to receive the vector representing the soul of the sentence and convert it into an output meaningful to our task.\n",
    "* In our binary classification task, this \"lens\" has two output neurons: one representing the probability of \"negativity\" and the other representing the probability of \"positivity.\"\n",
    "\n",
    "3. **\"Calibrating the Glasses\" ‚Äî Training and Backpropagation**:\n",
    "* Now, we have an ERNIE model wearing \"sentiment analysis glasses.\" We feed it the prepared labeled data (tens of thousands of reviews with known sentiment).\n",
    "* For each review, the model uses the \"glasses\" to generate a preliminary judgment (e.g., a score of 0.1 for \"negative\" and 0.9 for \"positive\").\n",
    "* We compare this judgment with the true label (for example, the true label for this review is \"positive\"). If the judgment is accurate, the \"glasses\" are well calibrated; if the judgment is incorrect, an \"error\" (i.e., the **cross-entropy loss**) is calculated.\n",
    "* This \"error\" signal is backpropagated, acting like a calibration instruction. It not only fine-tunes the parameters of the \"lenses\" (the classification head) to make judgments more accurate, but **more importantly, it also fine-tunes the parameters of ERNIE itself, the language master**, so that it can focus more on semantic information related to sentiment when reading text in the future.\n",
    "\n",
    "After thousands of such \"calibrations,\" ERNIE and its \"sentiment analysis glasses\" work seamlessly together. Not only can it understand the meaning of sentences, but it can also accurately determine the sentiment implied.\n",
    "\n",
    "In this tutorial, we use **SFT (Supervised Fine-Tuning**), also known as **full parameter fine-tuning**. This means that during training, we update all parameters of the ERNIE model and the newly added classification head to adapt the entire model to our sentiment analysis task.\n",
    "\n",
    "Luckily, ERNIEkit has already done the \"glasses fitting\" for us. Simply load the model, and it will automatically build the \"ERNIE Master + classification head\" structure for you, allowing you to focus on the training process of \"calibrating the glasses.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Fine-tuning\n",
    "\n",
    "Now, we'll put all the pieces together and begin training our sentiment analysis model. In ERNIEkit, we manage all training parameters using a configuration file and start training with a simple command."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Configuring Training Parameters\n",
    "\n",
    "Open the `examples/configs/ERNIE-4.5-0.3B/sft/run_sft_8k.yaml` file to view all training parameters. Here we explain some of the core parameters:\n",
    "\n",
    "```yaml\n",
    "### model\n",
    "model_name_or_path: baidu/ERNIE-4.5-0.3B-Paddle  # Specify the model path we downloaded\n",
    "fine_tuning: Full                                # Full parameter fine-tuning\n",
    "\n",
    "### finetuning\n",
    "stage: SFT                                       # Specify the training stage as SFT\n",
    "seed: 23                                         # Random seed to ensure reproducibility\n",
    "do_train: True                                   # Whether to perform training\n",
    "do_eval: True                                    # Whether to perform evaluation\n",
    "batch_size: 1                                    # Batch size per GPU\n",
    "num_train_epochs: 1                              # Number of training epochs\n",
    "max_steps: 100                                   # Maximum number of training steps\n",
    "learning_rate: 1.0e-5                            # Learning rate\n",
    "output_dir: ./output                             # Model save path\n",
    "\n",
    "### performance\n",
    "compute_type: bf16                               # Use bf16 mixed precision training to accelerate training\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Starting Training\n",
    "\n",
    "After configuring the parameters, we can start training using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T07:44:07.840269Z",
     "iopub.status.busy": "2025-07-18T07:44:07.839871Z",
     "iopub.status.idle": "2025-07-18T07:46:57.138005Z",
     "shell.execute_reply": "2025-07-18T07:46:57.137361Z",
     "shell.execute_reply.started": "2025-07-18T07:44:07.840248Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/utils/cpp_extension/extension_utils.py:715: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\r\n",
      "  warnings.warn(warning_message)\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/utils/cpp_extension/extension_utils.py:715: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\r\n",
      "  warnings.warn(warning_message)\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 -----------  Configuration  ----------------------\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 auto_cluster_config: 0\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 auto_parallel_config: None\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 auto_tuner_json: None\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 devices: 0\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 elastic_level: -1\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 elastic_timeout: 30\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 enable_gpu_log: True\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 gloo_port: 6767\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 host: None\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 ips: None\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 job_id: default\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 legacy: False\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 log_dir: erniekit_dist_log\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 log_level: INFO\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 log_overwrite: False\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 master: 127.0.0.1:8080\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 max_restart: 3\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 nnodes: 1\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 nproc_per_node: None\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 rank: -1\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 run_mode: collective\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 server_num: None\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 servers: \r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 sort_ip: False\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 start_port: 6070\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 trainer_num: None\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 trainers: \r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 training_script: /home/ERNIEKit/erniekit/launcher.py\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 training_script_args: ['train', 'ERNIE-develop/examples/configs/ERNIE-4.5-0.3B/sft/run_sft_8k.yaml']\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 with_gloo: 1\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,200 --------------------------------------------------\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,201 Job: default, mode collective, replicas 1[1:1], elastic False\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,202 Run Pod: xiidtm, replicas 1, status ready\r\n",
      "LAUNCH INFO 2025-07-18 15:44:13,217 Watching Pod: xiidtm, replicas 1, status running\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/utils/cpp_extension/extension_utils.py:715: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\r\n",
      "  warnings.warn(warning_message)\r\n",
      "\u001b[32m[2025-07-18 15:44:15,281] [    INFO]\u001b[0m - user has defined resume_from_checkpoint: None\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,281] [    INFO]\u001b[0m - The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,341] [    INFO]\u001b[0m - Tensor_parallel_degree = 1. Set sequence_parallel to False.\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,341] [   DEBUG]\u001b[0m - ============================================================\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,341] [   DEBUG]\u001b[0m -      Model Configuration Arguments      \u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,342] [   DEBUG]\u001b[0m - paddle commit id              : cdcd76a93d1dfe767dde768198e1d7c7488b93f6\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,342] [   DEBUG]\u001b[0m - paddleformers commit id       : 053a5a5e2a72cd2d3b997cbcff81b14af9fe4d47\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,342] [   DEBUG]\u001b[0m - add_tail_layers               : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,342] [   DEBUG]\u001b[0m - continue_training             : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,342] [   DEBUG]\u001b[0m - fine_tuning                   : Full\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,342] [   DEBUG]\u001b[0m - fuse_gate_detach_matmul       : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,342] [   DEBUG]\u001b[0m - fuse_linear                   : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,342] [   DEBUG]\u001b[0m - fuse_rms_norm                 : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,342] [   DEBUG]\u001b[0m - fuse_rope                     : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,342] [   DEBUG]\u001b[0m - fuse_softmax_mask             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,342] [   DEBUG]\u001b[0m - fuse_swiglu                   : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,342] [   DEBUG]\u001b[0m - lora                          : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,342] [   DEBUG]\u001b[0m - lora_alpha                    : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,342] [   DEBUG]\u001b[0m - lora_path                     : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,342] [   DEBUG]\u001b[0m - lora_plus_scale               : 1.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,342] [   DEBUG]\u001b[0m - lora_rank                     : 8\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,342] [   DEBUG]\u001b[0m - model_name_or_path            : ./data/models/30656/ERNIE-4.5-0.3B-Paddle\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,342] [   DEBUG]\u001b[0m - moe_aux_loss_lambda           : 1e-05\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,342] [   DEBUG]\u001b[0m - moe_group                     : dummy\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,342] [   DEBUG]\u001b[0m - moe_group_experts             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,342] [   DEBUG]\u001b[0m - moe_multimodal_dispatch_use_allgather: v2-alltoall-unpad\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,343] [   DEBUG]\u001b[0m - moe_orthogonal_loss_lambda    : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,343] [   DEBUG]\u001b[0m - moe_use_aux_free              : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,343] [   DEBUG]\u001b[0m - moe_use_hard_gate             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,343] [   DEBUG]\u001b[0m - moe_z_loss_lambda             : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,343] [   DEBUG]\u001b[0m - no_recompute_layers           : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,343] [   DEBUG]\u001b[0m - offload_recompute_inputs      : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,343] [   DEBUG]\u001b[0m - pp_seg_method                 : layer:Ernie4_5_DecoderLayer|EmptyLayer\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,343] [   DEBUG]\u001b[0m - recompute_granularity         : full\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,343] [   DEBUG]\u001b[0m - recompute_use_reentrant       : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,343] [   DEBUG]\u001b[0m - rslora                        : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,343] [   DEBUG]\u001b[0m - rslora_plus                   : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,343] [   DEBUG]\u001b[0m - stage                         : SFT\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,343] [   DEBUG]\u001b[0m - tensor_parallel_output        : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,343] [   DEBUG]\u001b[0m - use_attn_mask_start_row_indices: True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,343] [   DEBUG]\u001b[0m - use_flash_attention           : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,343] [   DEBUG]\u001b[0m - use_fused_head_and_loss_fn    : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,343] [   DEBUG]\u001b[0m - use_recompute_moe             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,343] [   DEBUG]\u001b[0m - use_sparse_flash_attn         : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,343] [   DEBUG]\u001b[0m - use_sparse_head_and_loss_fn   : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,343] [   DEBUG]\u001b[0m - virtual_pp_degree             : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,343] [   DEBUG]\u001b[0m - \u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,343] [   DEBUG]\u001b[0m - ============================================================\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,343] [   DEBUG]\u001b[0m -       Data Configuration Arguments      \u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,344] [   DEBUG]\u001b[0m - paddle commit id              : cdcd76a93d1dfe767dde768198e1d7c7488b93f6\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,344] [   DEBUG]\u001b[0m - paddleformers commit id       : 053a5a5e2a72cd2d3b997cbcff81b14af9fe4d47\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,344] [   DEBUG]\u001b[0m - buffer_size                   : 500\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,344] [   DEBUG]\u001b[0m - dataset_type                  : iterable\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,344] [   DEBUG]\u001b[0m - eval_dataset_path             : ./sft-eval.jsonl\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,344] [   DEBUG]\u001b[0m - eval_dataset_prob             : 1.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,344] [   DEBUG]\u001b[0m - eval_dataset_type             : erniekit\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,344] [   DEBUG]\u001b[0m - greedy_intokens               : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,344] [   DEBUG]\u001b[0m - in_tokens_batching            : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,344] [   DEBUG]\u001b[0m - mask_out_eos_token            : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,344] [   DEBUG]\u001b[0m - max_prompt_len                : 2048\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,344] [   DEBUG]\u001b[0m - max_seq_len                   : 8192\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,344] [   DEBUG]\u001b[0m - num_comparisons               : 6\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,344] [   DEBUG]\u001b[0m - num_samples_each_epoch        : 6000000\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,344] [   DEBUG]\u001b[0m - offline_dataset_path          : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,344] [   DEBUG]\u001b[0m - random_shuffle                : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,344] [   DEBUG]\u001b[0m - train_dataset_path            : ./sft-train.jsonl\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,344] [   DEBUG]\u001b[0m - train_dataset_prob            : 1.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,344] [   DEBUG]\u001b[0m - train_dataset_type            : erniekit\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,344] [   DEBUG]\u001b[0m - use_cls                       : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:15,344] [   DEBUG]\u001b[0m - \u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,345] [    INFO]\u001b[0m - The global seed is set to 23, local seed is set to 24 and random seed is set to 23.\u001b[0m\r\n",
      "\u001b[33m[2025-07-18 15:44:15,345] [ WARNING]\u001b[0m - Process rank: -1, device: gpu, world_size: 1, distributed training: False, 16-bits training: True\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,345] [    INFO]\u001b[0m - Start to load model ...\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,494] [    INFO]\u001b[0m - Loading configuration file ./data/models/30656/ERNIE-4.5-0.3B-Paddle/config.json\u001b[0m\r\n",
      "\u001b[33m[2025-07-18 15:44:15,496] [ WARNING]\u001b[0m - You are using a model of type ernie4_5 to instantiate a model of type ernie4_5_moe. This is not supported for all configurations of models and can yield errors.\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,497] [    INFO]\u001b[0m - Loading weights file ./data/models/30656/ERNIE-4.5-0.3B-Paddle/model.safetensors\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,845] [    INFO]\u001b[0m - Loaded weights file from disk, setting weights to model.\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,846] [    INFO]\u001b[0m - change initializer-range from 0.02 to 0.018041293779826325\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,846] [    INFO]\u001b[0m - using moe-group: dummy\u001b[0m\r\n",
      "W0718 15:44:15.853309 93184 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.8, Runtime API Version: 12.6\r\n",
      "\u001b[32m[2025-07-18 15:44:15,855] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,859] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,861] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,863] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,866] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,868] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,870] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,872] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,875] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,877] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,879] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,881] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,884] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,886] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,889] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,950] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,953] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,955] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,959] [    INFO]\u001b[0m - output-weight:[103424, 1024] config.tie_word_embeddings=True\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:15,960] [    INFO]\u001b[0m - Use fusedRMSNorm\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:16,039] [    INFO]\u001b[0m - All model checkpoint weights were used when initializing Ernie4_5_MoeForCausalLM.\r\n",
      "\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:16,040] [    INFO]\u001b[0m - All the weights of Ernie4_5_MoeForCausalLM were initialized from the model checkpoint at ./data/models/30656/ERNIE-4.5-0.3B-Paddle.\r\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use Ernie4_5_MoeForCausalLM for predictions without further training.\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:16,041] [    INFO]\u001b[0m - Loading configuration file ./data/models/30656/ERNIE-4.5-0.3B-Paddle/generation_config.json\u001b[0m\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddleformers/generation/configuration_utils.py:250: UserWarning: using greedy search strategy. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `decode_strategy=\"greedy_search\" ` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\r\n",
      "  warnings.warn(\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddleformers/generation/configuration_utils.py:255: UserWarning: using greedy search strategy. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `decode_strategy=\"greedy_search\" ` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\r\n",
      "  warnings.warn(\r\n",
      "\u001b[32m[2025-07-18 15:44:16,052] [    INFO]\u001b[0m - Loading model successfully !\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:16,054] [   DEBUG]\u001b[0m - Model config: Ernie4_5_MoeConfig {\r\n",
      "  \"add_tail_layers\": false,\r\n",
      "  \"architectures\": [\r\n",
      "    \"Ernie4_5_ForCausalLM\"\r\n",
      "  ],\r\n",
      "  \"attention_probs_dropout_prob\": 0.0,\r\n",
      "  \"bos_token_id\": 1,\r\n",
      "  \"cachekv_quant\": false,\r\n",
      "  \"compression_ratio\": 1.0,\r\n",
      "  \"dpo_config\": null,\r\n",
      "  \"dtype\": \"bfloat16\",\r\n",
      "  \"enable_delay_scale_loss\": true,\r\n",
      "  \"enable_mtp_magic_send\": false,\r\n",
      "  \"eos_token_id\": 2,\r\n",
      "  \"fuse_gate_detach_matmul\": true,\r\n",
      "  \"fuse_linear\": false,\r\n",
      "  \"fuse_ln\": false,\r\n",
      "  \"fuse_rms_norm\": true,\r\n",
      "  \"fuse_rope\": true,\r\n",
      "  \"fuse_softmax_mask\": false,\r\n",
      "  \"fuse_swiglu\": true,\r\n",
      "  \"global_aux_loss\": false,\r\n",
      "  \"head_dim\": 128,\r\n",
      "  \"hidden_act\": \"silu\",\r\n",
      "  \"hidden_dropout_prob\": 0.0,\r\n",
      "  \"hidden_size\": 1024,\r\n",
      "  \"ignored_index\": -100,\r\n",
      "  \"initializer_range\": 0.018041293779826325,\r\n",
      "  \"intermediate_size\": 3072,\r\n",
      "  \"max_position_embeddings\": 131072,\r\n",
      "  \"max_sequence_length\": 8192,\r\n",
      "  \"micro_batch_size\": -1,\r\n",
      "  \"model_type\": \"ernie4_5_moe\",\r\n",
      "  \"moe_all_to_all_dropout\": 0.0,\r\n",
      "  \"moe_aux_loss_lambda\": 1e-05,\r\n",
      "  \"moe_capacity\": [],\r\n",
      "  \"moe_dense_experts_token_type_id\": 3,\r\n",
      "  \"moe_dropout_prob\": 0.0,\r\n",
      "  \"moe_gate\": \"topk\",\r\n",
      "  \"moe_gate_act\": \"softmax\",\r\n",
      "  \"moe_group_experts\": false,\r\n",
      "  \"moe_group_origin\": \"dummy\",\r\n",
      "  \"moe_group_orthogonal_loss\": true,\r\n",
      "  \"moe_intermediate_size\": 0,\r\n",
      "  \"moe_k\": 2,\r\n",
      "  \"moe_layer_end_index\": 17,\r\n",
      "  \"moe_layer_interval\": 2,\r\n",
      "  \"moe_layer_start_index\": 0,\r\n",
      "  \"moe_multimodal_dispatch_use_allgather\": \"v2-alltoall-unpad\",\r\n",
      "  \"moe_norm_gate_logits\": true,\r\n",
      "  \"moe_num_experts\": null,\r\n",
      "  \"moe_num_shared_experts\": 0,\r\n",
      "  \"moe_orthogonal_loss_lambda\": 0.0,\r\n",
      "  \"moe_rank\": 0,\r\n",
      "  \"moe_reverse_token_drop\": false,\r\n",
      "  \"moe_use_aux_free\": false,\r\n",
      "  \"moe_use_hard_gate\": false,\r\n",
      "  \"moe_world_size\": 1,\r\n",
      "  \"moe_z_loss_lambda\": 0.0,\r\n",
      "  \"multi_token_pred_lambda\": 0.3,\r\n",
      "  \"num_acc_steps\": 8,\r\n",
      "  \"num_attention_heads\": 16,\r\n",
      "  \"num_hidden_layers\": 18,\r\n",
      "  \"num_key_value_heads\": 2,\r\n",
      "  \"num_nextn_predict_layers\": 0,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"paddleformers_version\": \"0.1\",\r\n",
      "  \"pp_seg_method\": \"layer:Ernie4_5_DecoderLayer|EmptyLayer\",\r\n",
      "  \"recompute_granularity\": \"full\",\r\n",
      "  \"recompute_use_reentrant\": true,\r\n",
      "  \"refined_recompute\": {},\r\n",
      "  \"rms_norm_eps\": 1e-05,\r\n",
      "  \"rope_theta\": 500000,\r\n",
      "  \"sinkhorn_2gate\": true,\r\n",
      "  \"sinkhorn_temp\": 0.03,\r\n",
      "  \"skip_recompute_ops\": {},\r\n",
      "  \"tensor_parallel_degree\": -1,\r\n",
      "  \"tie_word_embeddings\": true,\r\n",
      "  \"token_balance_loss\": false,\r\n",
      "  \"token_balance_seqlen\": false,\r\n",
      "  \"use_bias\": false,\r\n",
      "  \"use_flash_attention\": true,\r\n",
      "  \"use_fused_head_and_loss_fn\": false,\r\n",
      "  \"use_recompute_lm_head\": false,\r\n",
      "  \"use_recompute_loss_fn\": false,\r\n",
      "  \"use_recompute_moe\": false,\r\n",
      "  \"use_recompute_mtp\": false,\r\n",
      "  \"use_rmsnorm\": true,\r\n",
      "  \"use_sparse_flash_attn\": true,\r\n",
      "  \"use_sparse_head_and_loss_fn\": true,\r\n",
      "  \"use_var_len_flash_attn\": false,\r\n",
      "  \"vocab_size\": 103424,\r\n",
      "  \"weight_share_add_bias\": true\r\n",
      "}\r\n",
      "\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:16,054] [    INFO]\u001b[0m - [timelog] basemodel loading time: 0.56s (2025-07-18 15:44:16) \u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:16,973] [    INFO]\u001b[0m - Start to create dataset ...\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:16,975] [    INFO]\u001b[0m - ./sft-train.jsonl: task prob: 1.0, ori number of examples: 8, target_num_each_epoch: 6000000\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:16,975] [    INFO]\u001b[0m - Creating dataset successfully ...\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:16,975] [    INFO]\u001b[0m - The global seed is set to 23, local seed is set to 24 and random seed is set to 23.\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:17,012] [    INFO]\u001b[0m - max_steps is given, it will override any value given in num_train_epochs\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:17,013] [    INFO]\u001b[0m - Using half precision\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,025] [   DEBUG]\u001b[0m - ============================================================\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,025] [   DEBUG]\u001b[0m -     Training Configuration Arguments    \u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,025] [   DEBUG]\u001b[0m - paddle commit id              : cdcd76a93d1dfe767dde768198e1d7c7488b93f6\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,025] [   DEBUG]\u001b[0m - paddleformers commit id       : 053a5a5e2a72cd2d3b997cbcff81b14af9fe4d47\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,025] [   DEBUG]\u001b[0m - _no_sync_in_gradient_accumulation: True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,025] [   DEBUG]\u001b[0m - actscale_moving_rate          : 0.01\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,025] [   DEBUG]\u001b[0m - adam_beta1                    : 0.9\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,025] [   DEBUG]\u001b[0m - adam_beta2                    : 0.95\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,025] [   DEBUG]\u001b[0m - adam_epsilon                  : 1e-08\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,025] [   DEBUG]\u001b[0m - amp_custom_black_list         : ['reduce_sum', 'softmax_with_cross_entropy', 'c_softmax_with_cross_entropy', 'elementwise_div', 'sin', 'cos']\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,025] [   DEBUG]\u001b[0m - amp_custom_white_list         : ['lookup_table', 'lookup_table_v2', 'flash_attn', 'matmul', 'matmul_v2', 'fused_gemm_epilogue']\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,025] [   DEBUG]\u001b[0m - amp_master_grad               : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,026] [   DEBUG]\u001b[0m - apply_hadamard                : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,026] [   DEBUG]\u001b[0m - apply_online_actscale_step    : 200\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,026] [   DEBUG]\u001b[0m - attention_probs_dropout_prob  : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,026] [   DEBUG]\u001b[0m - auto_parallel_resume_form_hybrid_parallel: False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,026] [   DEBUG]\u001b[0m - batch_size                    : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,026] [   DEBUG]\u001b[0m - beta                          : 0.1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,026] [   DEBUG]\u001b[0m - bf16                          : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,026] [   DEBUG]\u001b[0m - bf16_full_eval                : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,026] [   DEBUG]\u001b[0m - ckpt_quant_stage              : O0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,026] [   DEBUG]\u001b[0m - compute_type                  : bf16\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,026] [   DEBUG]\u001b[0m - context_parallel_degree       : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,026] [   DEBUG]\u001b[0m - count_trained_tokens          : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,026] [   DEBUG]\u001b[0m - current_device                : gpu:0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,026] [   DEBUG]\u001b[0m - data_parallel_config          : \u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,026] [   DEBUG]\u001b[0m - data_parallel_degree          : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,026] [   DEBUG]\u001b[0m - data_parallel_rank            : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,026] [   DEBUG]\u001b[0m - dataloader_drop_last          : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,026] [   DEBUG]\u001b[0m - dataloader_num_workers        : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,026] [   DEBUG]\u001b[0m - dataloader_shuffle            : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,026] [   DEBUG]\u001b[0m - dataset_rank                  : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,026] [   DEBUG]\u001b[0m - dataset_world_size            : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,027] [   DEBUG]\u001b[0m - ddp_find_unused_parameters    : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,027] [   DEBUG]\u001b[0m - decay_steps                   : 100\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,027] [   DEBUG]\u001b[0m - device                        : gpu\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,027] [   DEBUG]\u001b[0m - disable_ckpt_quant            : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,027] [   DEBUG]\u001b[0m - disable_tqdm                  : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,027] [   DEBUG]\u001b[0m - distributed_dataloader        : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,027] [   DEBUG]\u001b[0m - do_eval                       : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,027] [   DEBUG]\u001b[0m - do_export                     : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,027] [   DEBUG]\u001b[0m - do_predict                    : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,027] [   DEBUG]\u001b[0m - do_train                      : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,027] [   DEBUG]\u001b[0m - dpo_benchmark                 : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,027] [   DEBUG]\u001b[0m - dpop_lambda                   : 50\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,027] [   DEBUG]\u001b[0m - dropout_warmup_steps          : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,027] [   DEBUG]\u001b[0m - enable_auto_parallel          : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,027] [   DEBUG]\u001b[0m - enable_zero_cost_checkpoint   : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,027] [   DEBUG]\u001b[0m - eval_accumulation_steps       : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,027] [   DEBUG]\u001b[0m - eval_batch_size               : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,027] [   DEBUG]\u001b[0m - eval_steps                    : 10000\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,027] [   DEBUG]\u001b[0m - evaluation_strategy           : IntervalStrategy.STEPS\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,027] [   DEBUG]\u001b[0m - expert_max_capacity           : 4294967296\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,027] [   DEBUG]\u001b[0m - expert_min_capacity           : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,027] [   DEBUG]\u001b[0m - expert_parallel_degree        : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,027] [   DEBUG]\u001b[0m - expert_tensor_parallel_degree : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,028] [   DEBUG]\u001b[0m - flash_device_save_steps       : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,028] [   DEBUG]\u001b[0m - flatten_param_grads           : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,028] [   DEBUG]\u001b[0m - force_reshard_pp              : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,028] [   DEBUG]\u001b[0m - fp16                          : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,028] [   DEBUG]\u001b[0m - fp16_full_eval                : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,028] [   DEBUG]\u001b[0m - fp16_opt_level                : O2\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,028] [   DEBUG]\u001b[0m - fp8_format_type               : hybrid\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,028] [   DEBUG]\u001b[0m - fuse_sequence_parallel_allreduce: False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,028] [   DEBUG]\u001b[0m - gradient_accumulation_steps   : 8\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,028] [   DEBUG]\u001b[0m - greater_is_better             : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,028] [   DEBUG]\u001b[0m - hadamard_block_size           : 32\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,028] [   DEBUG]\u001b[0m - hidden_dropout_prob           : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,028] [   DEBUG]\u001b[0m - hybrid_parallel_topo_order    : pp_first\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,028] [   DEBUG]\u001b[0m - ignore_data_skip              : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,028] [   DEBUG]\u001b[0m - ignore_load_lr_and_optim      : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,028] [   DEBUG]\u001b[0m - ignore_save_lr_and_optim      : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,028] [   DEBUG]\u001b[0m - label_names                   : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,028] [   DEBUG]\u001b[0m - label_smoothing               : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,028] [   DEBUG]\u001b[0m - layerwise_lr_decay_bound      : 1.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,028] [   DEBUG]\u001b[0m - lazy_data_processing          : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,028] [   DEBUG]\u001b[0m - learning_rate                 : 1e-05\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,028] [   DEBUG]\u001b[0m - load_best_model_at_end        : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,028] [   DEBUG]\u001b[0m - load_sharded_model            : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,029] [   DEBUG]\u001b[0m - local_process_index           : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,029] [   DEBUG]\u001b[0m - local_rank                    : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,029] [   DEBUG]\u001b[0m - log_level                     : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,029] [   DEBUG]\u001b[0m - log_level_replica             : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,029] [   DEBUG]\u001b[0m - log_on_each_node              : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,029] [   DEBUG]\u001b[0m - logging_dir                   : ./vdl_log\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,029] [   DEBUG]\u001b[0m - logging_first_step            : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,029] [   DEBUG]\u001b[0m - logging_steps                 : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,029] [   DEBUG]\u001b[0m - logging_strategy              : IntervalStrategy.STEPS\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,029] [   DEBUG]\u001b[0m - logical_process_index         : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,029] [   DEBUG]\u001b[0m - loss_type                     : sigmoid\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,029] [   DEBUG]\u001b[0m - lr_end                        : 1e-07\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,029] [   DEBUG]\u001b[0m - lr_scheduler_type             : SchedulerType.COSINE\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,029] [   DEBUG]\u001b[0m - max_estimate_samples          : 100000.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,029] [   DEBUG]\u001b[0m - max_evaluate_steps            : 10000\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,029] [   DEBUG]\u001b[0m - max_grad_norm                 : 1.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,029] [   DEBUG]\u001b[0m - max_steps                     : 100\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,029] [   DEBUG]\u001b[0m - metric_for_best_model         : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,029] [   DEBUG]\u001b[0m - metrics_output_path           : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,029] [   DEBUG]\u001b[0m - min_lr                        : 1e-06\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,029] [   DEBUG]\u001b[0m - minimum_eval_times            : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,029] [   DEBUG]\u001b[0m - multi_token_pred_lambda       : 0.3\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,030] [   DEBUG]\u001b[0m - no_cuda                       : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,030] [   DEBUG]\u001b[0m - normalize_logps               : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,030] [   DEBUG]\u001b[0m - num_cycles                    : 0.5\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,030] [   DEBUG]\u001b[0m - num_nextn_predict_layers      : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,030] [   DEBUG]\u001b[0m - num_of_gpus                   : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,030] [   DEBUG]\u001b[0m - num_train_epochs              : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,030] [   DEBUG]\u001b[0m - offload_optim                 : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,030] [   DEBUG]\u001b[0m - offset_alpha                  : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,030] [   DEBUG]\u001b[0m - optim                         : OptimizerNames.ADAMW\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,030] [   DEBUG]\u001b[0m - optim_shard_num               : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,030] [   DEBUG]\u001b[0m - optimizer_name_suffix         : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,030] [   DEBUG]\u001b[0m - ordered_save_group_size       : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,030] [   DEBUG]\u001b[0m - output_dir                    : ./output\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,030] [   DEBUG]\u001b[0m - output_signal_dir             : ./output\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,030] [   DEBUG]\u001b[0m - overwrite_output_dir          : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,030] [   DEBUG]\u001b[0m - pad_token_id                  : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,030] [   DEBUG]\u001b[0m - past_index                    : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,030] [   DEBUG]\u001b[0m - pdc_download_ckpt             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,030] [   DEBUG]\u001b[0m - pdc_download_timeout          : 300\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,030] [   DEBUG]\u001b[0m - per_device_eval_batch_size    : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,030] [   DEBUG]\u001b[0m - per_device_train_batch_size   : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,030] [   DEBUG]\u001b[0m - pipeline_parallel_config      : enable_delay_scale_loss enable_release_grads disable_partial_send_recv\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,030] [   DEBUG]\u001b[0m - pipeline_parallel_degree      : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,031] [   DEBUG]\u001b[0m - pipeline_parallel_rank        : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,031] [   DEBUG]\u001b[0m - power                         : 1.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,031] [   DEBUG]\u001b[0m - prediction_loss_only          : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,031] [   DEBUG]\u001b[0m - pref_loss_ratio               : 1.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,031] [   DEBUG]\u001b[0m - process_index                 : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,031] [   DEBUG]\u001b[0m - quant_input_grad              : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,031] [   DEBUG]\u001b[0m - quant_weight_grad             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,031] [   DEBUG]\u001b[0m - recompute                     : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,031] [   DEBUG]\u001b[0m - ref_model_update_steps        : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,031] [   DEBUG]\u001b[0m - reference_free                : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,031] [   DEBUG]\u001b[0m - refined_recompute             : {}\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,031] [   DEBUG]\u001b[0m - release_grads                 : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,031] [   DEBUG]\u001b[0m - remove_unused_columns         : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,031] [   DEBUG]\u001b[0m - report_to                     : ['visualdl']\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,031] [   DEBUG]\u001b[0m - resume_from_checkpoint        : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,031] [   DEBUG]\u001b[0m - run_name                      : ./output\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,031] [   DEBUG]\u001b[0m - save_on_each_node             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,031] [   DEBUG]\u001b[0m - save_rng_states               : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,031] [   DEBUG]\u001b[0m - save_sharded_model            : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,031] [   DEBUG]\u001b[0m - save_sharding_stage1_model_include_freeze_params: False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,031] [   DEBUG]\u001b[0m - save_steps                    : 10000000\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,031] [   DEBUG]\u001b[0m - save_strategy                 : IntervalStrategy.STEPS\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,031] [   DEBUG]\u001b[0m - save_tokenizer                : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,032] [   DEBUG]\u001b[0m - save_total_limit              : 5\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,032] [   DEBUG]\u001b[0m - scale_loss                    : 32768\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,032] [   DEBUG]\u001b[0m - seed                          : 23\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,032] [   DEBUG]\u001b[0m - sep_parallel_degree           : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,032] [   DEBUG]\u001b[0m - sequence_parallel             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,032] [   DEBUG]\u001b[0m - sequence_parallel_config      : \u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,032] [   DEBUG]\u001b[0m - server_tp_degree              : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,032] [   DEBUG]\u001b[0m - sft_benchmark                 : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,032] [   DEBUG]\u001b[0m - sft_loss_ratio                : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,032] [   DEBUG]\u001b[0m - sharding                      : []\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,032] [   DEBUG]\u001b[0m - sharding_comm_buffer_size_MB  : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,032] [   DEBUG]\u001b[0m - sharding_degree               : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,032] [   DEBUG]\u001b[0m - sharding_parallel_config      : \u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,032] [   DEBUG]\u001b[0m - sharding_parallel_degree      : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,032] [   DEBUG]\u001b[0m - sharding_parallel_mesh_dimension: dp\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,032] [   DEBUG]\u001b[0m - sharding_parallel_rank        : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,032] [   DEBUG]\u001b[0m - should_load_dataset           : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,032] [   DEBUG]\u001b[0m - should_load_sharding_stage1_model: False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,032] [   DEBUG]\u001b[0m - should_log                    : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,032] [   DEBUG]\u001b[0m - should_save                   : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,032] [   DEBUG]\u001b[0m - should_save_model_state       : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,032] [   DEBUG]\u001b[0m - should_save_model_with_tensor_fusion: False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,032] [   DEBUG]\u001b[0m - should_save_sharding_stage1_model: False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,033] [   DEBUG]\u001b[0m - simpo_gamma                   : 0.5\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,033] [   DEBUG]\u001b[0m - skip_data_intervals           : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,033] [   DEBUG]\u001b[0m - skip_memory_metrics           : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,033] [   DEBUG]\u001b[0m - skip_profile_timer            : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,033] [   DEBUG]\u001b[0m - split_inputs_sequence_dim     : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,033] [   DEBUG]\u001b[0m - split_norm_comm               : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,033] [   DEBUG]\u001b[0m - tensor_parallel_config        : \u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,033] [   DEBUG]\u001b[0m - tensor_parallel_degree        : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,033] [   DEBUG]\u001b[0m - tensor_parallel_rank          : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,033] [   DEBUG]\u001b[0m - tensorwise_offload_optimizer  : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,033] [   DEBUG]\u001b[0m - to_static                     : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,033] [   DEBUG]\u001b[0m - train_batch_size              : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,033] [   DEBUG]\u001b[0m - unified_checkpoint            : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,033] [   DEBUG]\u001b[0m - unified_checkpoint_config     : ['async_save']\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,033] [   DEBUG]\u001b[0m - use_async_save                : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,033] [   DEBUG]\u001b[0m - use_expert_parallel           : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,033] [   DEBUG]\u001b[0m - use_hybrid_parallel           : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,033] [   DEBUG]\u001b[0m - use_lowprecision_moment       : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,033] [   DEBUG]\u001b[0m - use_recompute_mtp             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,033] [   DEBUG]\u001b[0m - use_sp_callback               : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,033] [   DEBUG]\u001b[0m - wandb_api_key                 : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,033] [   DEBUG]\u001b[0m - wandb_http_proxy              : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,033] [   DEBUG]\u001b[0m - warmup_ratio                  : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,034] [   DEBUG]\u001b[0m - warmup_steps                  : 20\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,034] [   DEBUG]\u001b[0m - weight_decay                  : 0.1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,034] [   DEBUG]\u001b[0m - weight_name_suffix            : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,034] [   DEBUG]\u001b[0m - weight_quantize_algo          : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,034] [   DEBUG]\u001b[0m - world_size                    : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,034] [   DEBUG]\u001b[0m - zcc_ema_interval              : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,034] [   DEBUG]\u001b[0m - zcc_pipeline_hooks_capacity_usage: 0.6\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,034] [   DEBUG]\u001b[0m - zcc_save_ema_coef             : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,034] [   DEBUG]\u001b[0m - zcc_workers_num               : 3\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,034] [   DEBUG]\u001b[0m - \u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:17,034] [    INFO]\u001b[0m - Starting training from resume_from_checkpoint : None\u001b[0m\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/distributed/parallel.py:450: UserWarning: The program will return to single-card operation. Please check 1, whether you use spawn or fleetrun to start the program. 2, Whether it is a multi-card program. 3, Is the current environment multi-card.\r\n",
      "  warnings.warn(\r\n",
      "\u001b[32m[2025-07-18 15:44:17,042] [    INFO]\u001b[0m - [timelog] checkpoint loading time: 0.00s (2025-07-18 15:44:17) \u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:17,042] [    INFO]\u001b[0m - ***** Running training *****\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:17,042] [    INFO]\u001b[0m -   Num examples = 800\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:17,042] [    INFO]\u001b[0m -   Num Epochs = 9223372036854775807\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:17,042] [    INFO]\u001b[0m -   Instantaneous batch size per device = 1\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:17,042] [    INFO]\u001b[0m -   Total train batch size (w. parallel, distributed & accumulation) = 8\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:17,042] [    INFO]\u001b[0m -   Gradient Accumulation steps = 8\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:17,042] [    INFO]\u001b[0m -   Total optimization steps = 100\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:17,042] [    INFO]\u001b[0m -   Total num train samples = 800\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 15:44:17,043] [   DEBUG]\u001b[0m -   Number of trainable parameters = 360,748,032 (per device)\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:17,060] [    INFO]\u001b[0m - prepare SequenceDataset ...\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:20,120] [    INFO]\u001b[0m - prepare SequenceDataset done: total number of examples is 6000000\u001b[0m\r\n",
      "W0718 15:44:21.237807 93184 multiply_fwd_func.cc:76] got different data type, run type promotion automatically, this may cause data type been changed.\r\n",
      "\u001b[32m[2025-07-18 15:44:24,412] [    INFO]\u001b[0m - loss: 10.39164352, learning_rate: 5e-07, global_step: 1, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 11.897777318954468, max_memory_allocated: 10.45703935623169, max_memory_reserved: 11.897777318954468, interval_runtime: 7.3676, interval_samples_per_second: 1.0858, interval_steps_per_second: 0.1357, ppl: 32586.178986822717, progress_or_epoch: 0.01\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:25,911] [    INFO]\u001b[0m - loss: 10.39015293, learning_rate: 1e-06, global_step: 2, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 11.897777318954468, max_memory_allocated: 10.45703935623169, max_memory_reserved: 11.897777318954468, interval_runtime: 1.4993, interval_samples_per_second: 5.3358, interval_steps_per_second: 0.667, ppl: 32537.642537246655, progress_or_epoch: 0.02\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:27,566] [    INFO]\u001b[0m - loss: 10.3223896, learning_rate: 1.5e-06, global_step: 3, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 12.813213109970093, max_memory_allocated: 10.462876796722412, max_memory_reserved: 12.813213109970093, interval_runtime: 1.6552, interval_samples_per_second: 4.8331, interval_steps_per_second: 0.6041, ppl: 30405.828621905155, progress_or_epoch: 0.03\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:29,042] [    INFO]\u001b[0m - loss: 10.25313473, learning_rate: 2e-06, global_step: 4, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 13.730960607528687, max_memory_allocated: 10.465795040130615, max_memory_reserved: 13.730960607528687, interval_runtime: 1.4758, interval_samples_per_second: 5.4207, interval_steps_per_second: 0.6776, ppl: 28371.339157937142, progress_or_epoch: 0.04\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:30,509] [    INFO]\u001b[0m - loss: 9.72236824, learning_rate: 2.5e-06, global_step: 5, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 13.730960607528687, max_memory_allocated: 10.465795040130615, max_memory_reserved: 13.730960607528687, interval_runtime: 1.4673, interval_samples_per_second: 5.4522, interval_steps_per_second: 0.6815, ppl: 16686.716120719335, progress_or_epoch: 0.05\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:31,984] [    INFO]\u001b[0m - loss: 8.23078442, learning_rate: 3e-06, global_step: 6, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 13.730960607528687, max_memory_allocated: 10.465795040130615, max_memory_reserved: 13.730960607528687, interval_runtime: 1.4745, interval_samples_per_second: 5.4256, interval_steps_per_second: 0.6782, ppl: 3754.777920103064, progress_or_epoch: 0.06\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:33,447] [    INFO]\u001b[0m - loss: 7.72773361, learning_rate: 3.5e-06, global_step: 7, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 13.730960607528687, max_memory_allocated: 10.465795040130615, max_memory_reserved: 13.730960607528687, interval_runtime: 1.4627, interval_samples_per_second: 5.4694, interval_steps_per_second: 0.6837, ppl: 2270.4506386450303, progress_or_epoch: 0.07\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:34,910] [    INFO]\u001b[0m - loss: 4.5312953, learning_rate: 4e-06, global_step: 8, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 13.730960607528687, max_memory_allocated: 10.465795040130615, max_memory_reserved: 13.730960607528687, interval_runtime: 1.4636, interval_samples_per_second: 5.466, interval_steps_per_second: 0.6833, ppl: 92.87878909514416, progress_or_epoch: 0.08\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:36,378] [    INFO]\u001b[0m - loss: 3.88533902, learning_rate: 4.5e-06, global_step: 9, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 13.730960607528687, max_memory_allocated: 10.465795040130615, max_memory_reserved: 13.730960607528687, interval_runtime: 1.4675, interval_samples_per_second: 5.4514, interval_steps_per_second: 0.6814, ppl: 48.68344432339593, progress_or_epoch: 0.09\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:38,080] [    INFO]\u001b[0m - loss: 1.43456924, learning_rate: 5e-06, global_step: 10, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 13.730960607528687, max_memory_allocated: 10.465795040130615, max_memory_reserved: 13.730960607528687, interval_runtime: 1.7024, interval_samples_per_second: 4.6992, interval_steps_per_second: 0.5874, ppl: 4.197836359278837, progress_or_epoch: 0.1\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:39,544] [    INFO]\u001b[0m - loss: 1.06942534, learning_rate: 5.5e-06, global_step: 11, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 13.730960607528687, max_memory_allocated: 10.465795040130615, max_memory_reserved: 13.730960607528687, interval_runtime: 1.464, interval_samples_per_second: 5.4646, interval_steps_per_second: 0.6831, ppl: 2.913704629280229, progress_or_epoch: 0.11\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:41,009] [    INFO]\u001b[0m - loss: 0.463714, learning_rate: 6e-06, global_step: 12, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 13.730960607528687, max_memory_allocated: 10.465795040130615, max_memory_reserved: 13.730960607528687, interval_runtime: 1.4649, interval_samples_per_second: 5.4611, interval_steps_per_second: 0.6826, ppl: 1.5899681745094114, progress_or_epoch: 0.12\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:42,480] [    INFO]\u001b[0m - loss: 0.05802114, learning_rate: 6.5e-06, global_step: 13, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 13.730960607528687, max_memory_allocated: 10.465795040130615, max_memory_reserved: 13.730960607528687, interval_runtime: 1.4712, interval_samples_per_second: 5.4377, interval_steps_per_second: 0.6797, ppl: 1.0597373983220915, progress_or_epoch: 0.13\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:43,952] [    INFO]\u001b[0m - loss: 0.02088747, learning_rate: 7e-06, global_step: 14, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 13.730960607528687, max_memory_allocated: 10.465795040130615, max_memory_reserved: 13.730960607528687, interval_runtime: 1.472, interval_samples_per_second: 5.4347, interval_steps_per_second: 0.6793, ppl: 1.0211071399856833, progress_or_epoch: 0.14\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:45,416] [    INFO]\u001b[0m - loss: 0.0037058, learning_rate: 7.5e-06, global_step: 15, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 13.730960607528687, max_memory_allocated: 10.465795040130615, max_memory_reserved: 13.730960607528687, interval_runtime: 1.464, interval_samples_per_second: 5.4646, interval_steps_per_second: 0.6831, ppl: 1.0037126749666139, progress_or_epoch: 0.15\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:46,883] [    INFO]\u001b[0m - loss: 0.00050533, learning_rate: 8e-06, global_step: 16, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 13.730960607528687, max_memory_allocated: 10.465795040130615, max_memory_reserved: 13.730960607528687, interval_runtime: 1.4669, interval_samples_per_second: 5.4537, interval_steps_per_second: 0.6817, ppl: 1.000505457700714, progress_or_epoch: 0.16\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:48,493] [    INFO]\u001b[0m - loss: 0.00019829, learning_rate: 8.5e-06, global_step: 17, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 13.730960607528687, max_memory_allocated: 10.465795040130615, max_memory_reserved: 13.730960607528687, interval_runtime: 1.6096, interval_samples_per_second: 4.9701, interval_steps_per_second: 0.6213, ppl: 1.0001983096607616, progress_or_epoch: 0.17\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:49,965] [    INFO]\u001b[0m - loss: 4.877e-05, learning_rate: 9e-06, global_step: 18, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 14.651019811630249, max_memory_allocated: 10.465795040130615, max_memory_reserved: 14.651019811630249, interval_runtime: 1.4724, interval_samples_per_second: 5.4334, interval_steps_per_second: 0.6792, ppl: 1.0000487711892758, progress_or_epoch: 0.18\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:51,428] [    INFO]\u001b[0m - loss: 9.17e-06, learning_rate: 9.5e-06, global_step: 19, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 14.651019811630249, max_memory_allocated: 10.465795040130615, max_memory_reserved: 14.651019811630249, interval_runtime: 1.4627, interval_samples_per_second: 5.4693, interval_steps_per_second: 0.6837, ppl: 1.0000091700420446, progress_or_epoch: 0.19\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:52,885] [    INFO]\u001b[0m - loss: 3.71e-06, learning_rate: 1e-05, global_step: 20, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 14.651019811630249, max_memory_allocated: 10.465795040130615, max_memory_reserved: 14.651019811630249, interval_runtime: 1.4569, interval_samples_per_second: 5.4911, interval_steps_per_second: 0.6864, ppl: 1.0000037100068822, progress_or_epoch: 0.2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:54,355] [    INFO]\u001b[0m - loss: 2.1e-06, learning_rate: 9.997e-06, global_step: 21, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 14.651019811630249, max_memory_allocated: 10.465795040130615, max_memory_reserved: 14.651019811630249, interval_runtime: 1.4707, interval_samples_per_second: 5.4398, interval_steps_per_second: 0.68, ppl: 1.000002100002205, progress_or_epoch: 0.21\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:55,824] [    INFO]\u001b[0m - loss: 1.4e-06, learning_rate: 9.986e-06, global_step: 22, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 14.651019811630249, max_memory_allocated: 10.465795040130615, max_memory_reserved: 14.651019811630249, interval_runtime: 1.4686, interval_samples_per_second: 5.4475, interval_steps_per_second: 0.6809, ppl: 1.00000140000098, progress_or_epoch: 0.22\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:57,290] [    INFO]\u001b[0m - loss: 1.01e-06, learning_rate: 9.969e-06, global_step: 23, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 14.651019811630249, max_memory_allocated: 10.465795040130615, max_memory_reserved: 14.651019811630249, interval_runtime: 1.4658, interval_samples_per_second: 5.4579, interval_steps_per_second: 0.6822, ppl: 1.0000010100005101, progress_or_epoch: 0.23\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:44:58,758] [    INFO]\u001b[0m - loss: 7.9e-07, learning_rate: 9.945e-06, global_step: 24, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 14.651019811630249, max_memory_allocated: 10.465795040130615, max_memory_reserved: 14.651019811630249, interval_runtime: 1.4686, interval_samples_per_second: 5.4475, interval_steps_per_second: 0.6809, ppl: 1.000000790000312, progress_or_epoch: 0.24\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:00,223] [    INFO]\u001b[0m - loss: 6.8e-07, learning_rate: 9.914e-06, global_step: 25, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 14.651019811630249, max_memory_allocated: 10.465795040130615, max_memory_reserved: 14.651019811630249, interval_runtime: 1.4652, interval_samples_per_second: 5.4601, interval_steps_per_second: 0.6825, ppl: 1.0000006800002312, progress_or_epoch: 0.25\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:01,693] [    INFO]\u001b[0m - loss: 6e-07, learning_rate: 9.876e-06, global_step: 26, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 14.651019811630249, max_memory_allocated: 10.465795040130615, max_memory_reserved: 14.651019811630249, interval_runtime: 1.4694, interval_samples_per_second: 5.4444, interval_steps_per_second: 0.6805, ppl: 1.00000060000018, progress_or_epoch: 0.26\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:03,159] [    INFO]\u001b[0m - loss: 6.2e-07, learning_rate: 9.831e-06, global_step: 27, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 14.651019811630249, max_memory_allocated: 10.465795040130615, max_memory_reserved: 14.651019811630249, interval_runtime: 1.4657, interval_samples_per_second: 5.458, interval_steps_per_second: 0.6822, ppl: 1.0000006200001923, progress_or_epoch: 0.27\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:04,623] [    INFO]\u001b[0m - loss: 6e-07, learning_rate: 9.78e-06, global_step: 28, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 14.651019811630249, max_memory_allocated: 10.465795040130615, max_memory_reserved: 14.651019811630249, interval_runtime: 1.464, interval_samples_per_second: 5.4646, interval_steps_per_second: 0.6831, ppl: 1.00000060000018, progress_or_epoch: 0.28\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:06,102] [    INFO]\u001b[0m - loss: 5.5e-07, learning_rate: 9.722e-06, global_step: 29, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4797, interval_samples_per_second: 5.4066, interval_steps_per_second: 0.6758, ppl: 1.0000005500001512, progress_or_epoch: 0.29\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:07,573] [    INFO]\u001b[0m - loss: 5.2e-07, learning_rate: 9.657e-06, global_step: 30, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.471, interval_samples_per_second: 5.4386, interval_steps_per_second: 0.6798, ppl: 1.0000005200001352, progress_or_epoch: 0.3\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:09,041] [    INFO]\u001b[0m - loss: 5e-07, learning_rate: 9.587e-06, global_step: 31, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.468, interval_samples_per_second: 5.4495, interval_steps_per_second: 0.6812, ppl: 1.000000500000125, progress_or_epoch: 0.31\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:10,671] [    INFO]\u001b[0m - loss: 4.9e-07, learning_rate: 9.51e-06, global_step: 32, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.6298, interval_samples_per_second: 4.9087, interval_steps_per_second: 0.6136, ppl: 1.00000049000012, progress_or_epoch: 0.32\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:12,147] [    INFO]\u001b[0m - loss: 5e-07, learning_rate: 9.426e-06, global_step: 33, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4758, interval_samples_per_second: 5.4207, interval_steps_per_second: 0.6776, ppl: 1.000000500000125, progress_or_epoch: 0.33\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:13,621] [    INFO]\u001b[0m - loss: 4.6e-07, learning_rate: 9.337e-06, global_step: 34, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4738, interval_samples_per_second: 5.428, interval_steps_per_second: 0.6785, ppl: 1.0000004600001058, progress_or_epoch: 0.34\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:15,096] [    INFO]\u001b[0m - loss: 4.6e-07, learning_rate: 9.242e-06, global_step: 35, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4748, interval_samples_per_second: 5.4243, interval_steps_per_second: 0.678, ppl: 1.0000004600001058, progress_or_epoch: 0.35\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:16,560] [    INFO]\u001b[0m - loss: 4.5e-07, learning_rate: 9.141e-06, global_step: 36, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4646, interval_samples_per_second: 5.4623, interval_steps_per_second: 0.6828, ppl: 1.0000004500001012, progress_or_epoch: 0.36\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:18,035] [    INFO]\u001b[0m - loss: 4.4e-07, learning_rate: 9.034e-06, global_step: 37, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4752, interval_samples_per_second: 5.4231, interval_steps_per_second: 0.6779, ppl: 1.0000004400000968, progress_or_epoch: 0.37\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:19,509] [    INFO]\u001b[0m - loss: 4.3e-07, learning_rate: 8.922e-06, global_step: 38, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4741, interval_samples_per_second: 5.4272, interval_steps_per_second: 0.6784, ppl: 1.0000004300000924, progress_or_epoch: 0.38\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:21,118] [    INFO]\u001b[0m - loss: 4e-07, learning_rate: 8.804e-06, global_step: 39, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.6084, interval_samples_per_second: 4.974, interval_steps_per_second: 0.6218, ppl: 1.00000040000008, progress_or_epoch: 0.39\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:22,578] [    INFO]\u001b[0m - loss: 3.8e-07, learning_rate: 8.682e-06, global_step: 40, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4604, interval_samples_per_second: 5.478, interval_steps_per_second: 0.6848, ppl: 1.0000003800000723, progress_or_epoch: 0.4\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:24,046] [    INFO]\u001b[0m - loss: 3.8e-07, learning_rate: 8.555e-06, global_step: 41, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4674, interval_samples_per_second: 5.452, interval_steps_per_second: 0.6815, ppl: 1.0000003800000723, progress_or_epoch: 0.41\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:25,527] [    INFO]\u001b[0m - loss: 3.7e-07, learning_rate: 8.423e-06, global_step: 42, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4812, interval_samples_per_second: 5.4012, interval_steps_per_second: 0.6751, ppl: 1.0000003700000684, progress_or_epoch: 0.42\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:27,006] [    INFO]\u001b[0m - loss: 3.5e-07, learning_rate: 8.286e-06, global_step: 43, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4791, interval_samples_per_second: 5.4086, interval_steps_per_second: 0.6761, ppl: 1.0000003500000612, progress_or_epoch: 0.43\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:28,469] [    INFO]\u001b[0m - loss: 3.7e-07, learning_rate: 8.145e-06, global_step: 44, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4636, interval_samples_per_second: 5.4659, interval_steps_per_second: 0.6832, ppl: 1.0000003700000684, progress_or_epoch: 0.44\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:29,938] [    INFO]\u001b[0m - loss: 3.4e-07, learning_rate: 8e-06, global_step: 45, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4683, interval_samples_per_second: 5.4486, interval_steps_per_second: 0.6811, ppl: 1.0000003400000579, progress_or_epoch: 0.45\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:31,550] [    INFO]\u001b[0m - loss: 3.2e-07, learning_rate: 7.851e-06, global_step: 46, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.6125, interval_samples_per_second: 4.9611, interval_steps_per_second: 0.6201, ppl: 1.0000003200000511, progress_or_epoch: 0.46\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:33,019] [    INFO]\u001b[0m - loss: 3.2e-07, learning_rate: 7.699e-06, global_step: 47, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4691, interval_samples_per_second: 5.4453, interval_steps_per_second: 0.6807, ppl: 1.0000003200000511, progress_or_epoch: 0.47\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:34,491] [    INFO]\u001b[0m - loss: 2.8e-07, learning_rate: 7.543e-06, global_step: 48, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4718, interval_samples_per_second: 5.4355, interval_steps_per_second: 0.6794, ppl: 1.0000002800000392, progress_or_epoch: 0.48\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:35,963] [    INFO]\u001b[0m - loss: 2.7e-07, learning_rate: 7.384e-06, global_step: 49, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4715, interval_samples_per_second: 5.4368, interval_steps_per_second: 0.6796, ppl: 1.0000002700000366, progress_or_epoch: 0.49\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:37,432] [    INFO]\u001b[0m - loss: 2.6e-07, learning_rate: 7.222e-06, global_step: 50, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4693, interval_samples_per_second: 5.4447, interval_steps_per_second: 0.6806, ppl: 1.0000002600000337, progress_or_epoch: 0.5\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:38,900] [    INFO]\u001b[0m - loss: 2.4e-07, learning_rate: 7.058e-06, global_step: 51, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4684, interval_samples_per_second: 5.4483, interval_steps_per_second: 0.681, ppl: 1.0000002400000287, progress_or_epoch: 0.51\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:40,368] [    INFO]\u001b[0m - loss: 2.3e-07, learning_rate: 6.891e-06, global_step: 52, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4676, interval_samples_per_second: 5.4512, interval_steps_per_second: 0.6814, ppl: 1.0000002300000264, progress_or_epoch: 0.52\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:41,836] [    INFO]\u001b[0m - loss: 2.2e-07, learning_rate: 6.721e-06, global_step: 53, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4681, interval_samples_per_second: 5.4492, interval_steps_per_second: 0.6812, ppl: 1.0000002200000242, progress_or_epoch: 0.53\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:43,301] [    INFO]\u001b[0m - loss: 2e-07, learning_rate: 6.551e-06, global_step: 54, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4649, interval_samples_per_second: 5.461, interval_steps_per_second: 0.6826, ppl: 1.00000020000002, progress_or_epoch: 0.54\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:44,770] [    INFO]\u001b[0m - loss: 1.9e-07, learning_rate: 6.378e-06, global_step: 55, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4692, interval_samples_per_second: 5.4451, interval_steps_per_second: 0.6806, ppl: 1.000000190000018, progress_or_epoch: 0.55\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:46,237] [    INFO]\u001b[0m - loss: 1.8e-07, learning_rate: 6.204e-06, global_step: 56, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4669, interval_samples_per_second: 5.4536, interval_steps_per_second: 0.6817, ppl: 1.0000001800000162, progress_or_epoch: 0.56\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:47,705] [    INFO]\u001b[0m - loss: 1.7e-07, learning_rate: 6.029e-06, global_step: 57, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4678, interval_samples_per_second: 5.4502, interval_steps_per_second: 0.6813, ppl: 1.0000001700000145, progress_or_epoch: 0.57\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:49,173] [    INFO]\u001b[0m - loss: 1.6e-07, learning_rate: 5.853e-06, global_step: 58, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4678, interval_samples_per_second: 5.4503, interval_steps_per_second: 0.6813, ppl: 1.0000001600000128, progress_or_epoch: 0.58\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:50,651] [    INFO]\u001b[0m - loss: 1.6e-07, learning_rate: 5.677e-06, global_step: 59, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4786, interval_samples_per_second: 5.4106, interval_steps_per_second: 0.6763, ppl: 1.0000001600000128, progress_or_epoch: 0.59\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:52,118] [    INFO]\u001b[0m - loss: 1.5e-07, learning_rate: 5.5e-06, global_step: 60, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4666, interval_samples_per_second: 5.4548, interval_steps_per_second: 0.6818, ppl: 1.0000001500000113, progress_or_epoch: 0.6\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:53,744] [    INFO]\u001b[0m - loss: 1.4e-07, learning_rate: 5.323e-06, global_step: 61, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.6264, interval_samples_per_second: 4.9188, interval_steps_per_second: 0.6148, ppl: 1.0000001400000098, progress_or_epoch: 0.61\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:55,217] [    INFO]\u001b[0m - loss: 1.3e-07, learning_rate: 5.147e-06, global_step: 62, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4722, interval_samples_per_second: 5.4341, interval_steps_per_second: 0.6793, ppl: 1.0000001300000085, progress_or_epoch: 0.62\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:56,688] [    INFO]\u001b[0m - loss: 1.3e-07, learning_rate: 4.971e-06, global_step: 63, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4718, interval_samples_per_second: 5.4356, interval_steps_per_second: 0.6794, ppl: 1.0000001300000085, progress_or_epoch: 0.63\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:58,160] [    INFO]\u001b[0m - loss: 1.3e-07, learning_rate: 4.796e-06, global_step: 64, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4713, interval_samples_per_second: 5.4374, interval_steps_per_second: 0.6797, ppl: 1.0000001300000085, progress_or_epoch: 0.64\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:45:59,637] [    INFO]\u001b[0m - loss: 1.2e-07, learning_rate: 4.622e-06, global_step: 65, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4777, interval_samples_per_second: 5.4139, interval_steps_per_second: 0.6767, ppl: 1.0000001200000073, progress_or_epoch: 0.65\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:01,101] [    INFO]\u001b[0m - loss: 1.1e-07, learning_rate: 4.449e-06, global_step: 66, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4638, interval_samples_per_second: 5.4653, interval_steps_per_second: 0.6832, ppl: 1.000000110000006, progress_or_epoch: 0.66\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:02,574] [    INFO]\u001b[0m - loss: 1.2e-07, learning_rate: 4.279e-06, global_step: 67, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4729, interval_samples_per_second: 5.4314, interval_steps_per_second: 0.6789, ppl: 1.0000001200000073, progress_or_epoch: 0.67\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:04,191] [    INFO]\u001b[0m - loss: 1.1e-07, learning_rate: 4.109e-06, global_step: 68, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.6164, interval_samples_per_second: 4.9493, interval_steps_per_second: 0.6187, ppl: 1.000000110000006, progress_or_epoch: 0.68\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:05,656] [    INFO]\u001b[0m - loss: 1.1e-07, learning_rate: 3.942e-06, global_step: 69, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4655, interval_samples_per_second: 5.459, interval_steps_per_second: 0.6824, ppl: 1.000000110000006, progress_or_epoch: 0.69\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:07,123] [    INFO]\u001b[0m - loss: 1.1e-07, learning_rate: 3.778e-06, global_step: 70, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4669, interval_samples_per_second: 5.4535, interval_steps_per_second: 0.6817, ppl: 1.000000110000006, progress_or_epoch: 0.7\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:08,594] [    INFO]\u001b[0m - loss: 1e-07, learning_rate: 3.616e-06, global_step: 71, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.471, interval_samples_per_second: 5.4385, interval_steps_per_second: 0.6798, ppl: 1.000000100000005, progress_or_epoch: 0.71\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:10,068] [    INFO]\u001b[0m - loss: 1e-07, learning_rate: 3.457e-06, global_step: 72, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4738, interval_samples_per_second: 5.428, interval_steps_per_second: 0.6785, ppl: 1.000000100000005, progress_or_epoch: 0.72\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:11,640] [    INFO]\u001b[0m - loss: 1e-07, learning_rate: 3.301e-06, global_step: 73, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.5718, interval_samples_per_second: 5.0896, interval_steps_per_second: 0.6362, ppl: 1.000000100000005, progress_or_epoch: 0.73\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:13,103] [    INFO]\u001b[0m - loss: 1e-07, learning_rate: 3.149e-06, global_step: 74, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4632, interval_samples_per_second: 5.4675, interval_steps_per_second: 0.6834, ppl: 1.000000100000005, progress_or_epoch: 0.74\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:14,738] [    INFO]\u001b[0m - loss: 9e-08, learning_rate: 3e-06, global_step: 75, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.6352, interval_samples_per_second: 4.8923, interval_steps_per_second: 0.6115, ppl: 1.0000000900000041, progress_or_epoch: 0.75\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:16,211] [    INFO]\u001b[0m - loss: 9e-08, learning_rate: 2.855e-06, global_step: 76, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4733, interval_samples_per_second: 5.43, interval_steps_per_second: 0.6788, ppl: 1.0000000900000041, progress_or_epoch: 0.76\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:17,682] [    INFO]\u001b[0m - loss: 9e-08, learning_rate: 2.714e-06, global_step: 77, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4703, interval_samples_per_second: 5.4412, interval_steps_per_second: 0.6801, ppl: 1.0000000900000041, progress_or_epoch: 0.77\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:19,144] [    INFO]\u001b[0m - loss: 8e-08, learning_rate: 2.577e-06, global_step: 78, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.462, interval_samples_per_second: 5.472, interval_steps_per_second: 0.684, ppl: 1.0000000800000033, progress_or_epoch: 0.78\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:20,608] [    INFO]\u001b[0m - loss: 9e-08, learning_rate: 2.445e-06, global_step: 79, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4647, interval_samples_per_second: 5.462, interval_steps_per_second: 0.6827, ppl: 1.0000000900000041, progress_or_epoch: 0.79\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:22,088] [    INFO]\u001b[0m - loss: 9e-08, learning_rate: 2.318e-06, global_step: 80, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4794, interval_samples_per_second: 5.4078, interval_steps_per_second: 0.676, ppl: 1.0000000900000041, progress_or_epoch: 0.8\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:23,561] [    INFO]\u001b[0m - loss: 8e-08, learning_rate: 2.196e-06, global_step: 81, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4732, interval_samples_per_second: 5.4305, interval_steps_per_second: 0.6788, ppl: 1.0000000800000033, progress_or_epoch: 0.81\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:25,039] [    INFO]\u001b[0m - loss: 8e-08, learning_rate: 2.078e-06, global_step: 82, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4782, interval_samples_per_second: 5.4119, interval_steps_per_second: 0.6765, ppl: 1.0000000800000033, progress_or_epoch: 0.82\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:26,503] [    INFO]\u001b[0m - loss: 8e-08, learning_rate: 1.966e-06, global_step: 83, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4644, interval_samples_per_second: 5.4631, interval_steps_per_second: 0.6829, ppl: 1.0000000800000033, progress_or_epoch: 0.83\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:27,973] [    INFO]\u001b[0m - loss: 8e-08, learning_rate: 1.859e-06, global_step: 84, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4695, interval_samples_per_second: 5.4441, interval_steps_per_second: 0.6805, ppl: 1.0000000800000033, progress_or_epoch: 0.84\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:29,438] [    INFO]\u001b[0m - loss: 8e-08, learning_rate: 1.758e-06, global_step: 85, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4652, interval_samples_per_second: 5.4599, interval_steps_per_second: 0.6825, ppl: 1.0000000800000033, progress_or_epoch: 0.85\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:30,907] [    INFO]\u001b[0m - loss: 8e-08, learning_rate: 1.663e-06, global_step: 86, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4687, interval_samples_per_second: 5.4471, interval_steps_per_second: 0.6809, ppl: 1.0000000800000033, progress_or_epoch: 0.86\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:32,374] [    INFO]\u001b[0m - loss: 8e-08, learning_rate: 1.574e-06, global_step: 87, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4668, interval_samples_per_second: 5.4542, interval_steps_per_second: 0.6818, ppl: 1.0000000800000033, progress_or_epoch: 0.87\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:33,836] [    INFO]\u001b[0m - loss: 8e-08, learning_rate: 1.49e-06, global_step: 88, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4624, interval_samples_per_second: 5.4704, interval_steps_per_second: 0.6838, ppl: 1.0000000800000033, progress_or_epoch: 0.88\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:35,303] [    INFO]\u001b[0m - loss: 8e-08, learning_rate: 1.413e-06, global_step: 89, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.467, interval_samples_per_second: 5.4532, interval_steps_per_second: 0.6816, ppl: 1.0000000800000033, progress_or_epoch: 0.89\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:36,913] [    INFO]\u001b[0m - loss: 8e-08, learning_rate: 1.343e-06, global_step: 90, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.6096, interval_samples_per_second: 4.9702, interval_steps_per_second: 0.6213, ppl: 1.0000000800000033, progress_or_epoch: 0.9\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:38,379] [    INFO]\u001b[0m - loss: 7e-08, learning_rate: 1.278e-06, global_step: 91, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4659, interval_samples_per_second: 5.4573, interval_steps_per_second: 0.6822, ppl: 1.0000000700000025, progress_or_epoch: 0.91\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:39,853] [    INFO]\u001b[0m - loss: 7e-08, learning_rate: 1.22e-06, global_step: 92, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4744, interval_samples_per_second: 5.4261, interval_steps_per_second: 0.6783, ppl: 1.0000000700000025, progress_or_epoch: 0.92\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:41,323] [    INFO]\u001b[0m - loss: 7e-08, learning_rate: 1.169e-06, global_step: 93, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4703, interval_samples_per_second: 5.4412, interval_steps_per_second: 0.6802, ppl: 1.0000000700000025, progress_or_epoch: 0.93\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:42,789] [    INFO]\u001b[0m - loss: 7e-08, learning_rate: 1.124e-06, global_step: 94, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4653, interval_samples_per_second: 5.4595, interval_steps_per_second: 0.6824, ppl: 1.0000000700000025, progress_or_epoch: 0.94\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:44,256] [    INFO]\u001b[0m - loss: 7e-08, learning_rate: 1.086e-06, global_step: 95, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4675, interval_samples_per_second: 5.4514, interval_steps_per_second: 0.6814, ppl: 1.0000000700000025, progress_or_epoch: 0.95\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:45,716] [    INFO]\u001b[0m - loss: 7e-08, learning_rate: 1.055e-06, global_step: 96, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4599, interval_samples_per_second: 5.4797, interval_steps_per_second: 0.685, ppl: 1.0000000700000025, progress_or_epoch: 0.96\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:47,329] [    INFO]\u001b[0m - loss: 7e-08, learning_rate: 1.031e-06, global_step: 97, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.6133, interval_samples_per_second: 4.9589, interval_steps_per_second: 0.6199, ppl: 1.0000000700000025, progress_or_epoch: 0.97\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:48,791] [    INFO]\u001b[0m - loss: 7e-08, learning_rate: 1.014e-06, global_step: 98, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4619, interval_samples_per_second: 5.4722, interval_steps_per_second: 0.684, ppl: 1.0000000700000025, progress_or_epoch: 0.98\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:50,254] [    INFO]\u001b[0m - loss: 7e-08, learning_rate: 1.003e-06, global_step: 99, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4627, interval_samples_per_second: 5.4692, interval_steps_per_second: 0.6837, ppl: 1.0000000700000025, progress_or_epoch: 0.99\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:51,728] [    INFO]\u001b[0m - loss: 6e-08, learning_rate: 1e-06, global_step: 100, current_memory_allocated: 0.6719479560852051, current_memory_reserved: 15.57339072227478, max_memory_allocated: 10.471631526947021, max_memory_reserved: 15.57339072227478, interval_runtime: 1.4744, interval_samples_per_second: 5.4258, interval_steps_per_second: 0.6782, ppl: 1.0000000600000019, progress_or_epoch: 1.0\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:51,729] [    INFO]\u001b[0m - \r\n",
      "Training completed. \r\n",
      "\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:51,729] [    INFO]\u001b[0m - train_runtime: 154.6855, train_samples_per_second: 5.1718, train_steps_per_second: 0.6465, train_loss: 0.7850595176554402, progress_or_epoch: 1.0\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:51,730] [    INFO]\u001b[0m - Saving model checkpoint to ./output\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:51,733] [    INFO]\u001b[0m - tokenizer config file saved in ./output/tokenizer_config.json\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:51,734] [    INFO]\u001b[0m - Special tokens file saved in ./output/special_tokens_map.json\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:51,734] [    INFO]\u001b[0m - added tokens file saved in ./output/added_tokens.json\u001b[0m\r\n",
      "\u001b[33m[2025-07-18 15:46:51,745] [ WARNING]\u001b[0m - Asynchronous saving is not supported for single card environment currently.\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:53,736] [    INFO]\u001b[0m - Configuration saved in ./output/config.json\u001b[0m\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddleformers/generation/configuration_utils.py:316: UserWarning: The generation config instance is invalid -- `.validate()` throws warnings and/or exceptions. Fix these issues to save the configuration. This warning will be raised to an exception.\r\n",
      "\r\n",
      "Thrown during validation:\r\n",
      "using greedy search strategy. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `decode_strategy=\"greedy_search\" ` or unset `temperature`.\r\n",
      "  warnings.warn(\r\n",
      "\u001b[32m[2025-07-18 15:46:53,783] [    INFO]\u001b[0m - [timelog] model saving time: 2.05s (2025-07-18 15:46:53) \u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:53,783] [    INFO]\u001b[0m - ***** train metrics *****\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:53,783] [    INFO]\u001b[0m -   progress_or_epoch        =        1.0\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:53,783] [    INFO]\u001b[0m -   train_loss               =     0.7851\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:53,783] [    INFO]\u001b[0m -   train_runtime            = 0:02:34.68\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:53,783] [    INFO]\u001b[0m -   train_samples_per_second =     5.1718\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:53,783] [    INFO]\u001b[0m -   train_steps_per_second   =     0.6465\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:53,784] [    INFO]\u001b[0m - ***** Running Evaluation *****\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:53,784] [    INFO]\u001b[0m -   Num examples: Unknown\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:53,784] [    INFO]\u001b[0m -   Total prediction steps = 10000\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:53,784] [    INFO]\u001b[0m -   Pre device batch size = 1\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:53,784] [    INFO]\u001b[0m -   Total Batch size = 1\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:53,786] [    INFO]\u001b[0m - prepare SequenceDataset ...\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:53,786] [    INFO]\u001b[0m - prepare SequenceDataset done: total number of examples is 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:53,841] [    INFO]\u001b[0m - eval_loss: 0.09614189714193344, eval_runtime: 0.0576, eval_samples_per_second: 173468.878, eval_steps_per_second: 173468.878, eval_ppl: 1.1009152696414224, progress_or_epoch: 1.0\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:53,842] [    INFO]\u001b[0m - ***** eval metrics *****\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:53,842] [    INFO]\u001b[0m -   eval_loss               =     0.0961\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:53,842] [    INFO]\u001b[0m -   eval_ppl                =     1.1009\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:53,842] [    INFO]\u001b[0m -   eval_runtime            = 0:00:00.05\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:53,842] [    INFO]\u001b[0m -   eval_samples_per_second = 173468.878\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:53,842] [    INFO]\u001b[0m -   eval_steps_per_second   = 173468.878\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:53,842] [    INFO]\u001b[0m -   progress_or_epoch       =        1.0\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 15:46:53,842] [    INFO]\u001b[0m - Saving stop info into ./vdl_log/stop_step.json\u001b[0m\r\n",
      "LAUNCH INFO 2025-07-18 15:46:56,395 Pod completed\r\n",
      "LAUNCH INFO 2025-07-18 15:46:56,396 Exit code 0\r\n"
     ]
    }
   ],
   "source": [
    "!erniekit train ERNIE-develop/examples/configs/ERNIE-4.5-0.3B/sft/run_sft_8k.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ERNIEkit automatically loads the model and data and trains according to the parameters in the configuration file. During training, a log is automatically printed, showing the current number of training steps, loss, learning rate, and other information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Training Process Interpretation\n",
    "\n",
    "In the training log, we can pay attention to the following key metrics:\n",
    "\n",
    "- **loss**: The loss value reflects the difference between the model's predicted value and the true value. The smaller the value, the better.\n",
    "- **learning_rate**: The learning rate indicates the magnitude of the model parameter update.\n",
    "- **eval_loss**: The loss value on the evaluation set can be used to determine whether the model is overfitting.\n",
    "- **eval_accuracy**: The accuracy on the evaluation set intuitively reflects the model's performance on the sentiment analysis task.\n",
    "\n",
    "After training is complete, the model is automatically saved in the directory specified by `output_dir`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation and Prediction\n",
    "\n",
    "After training, we need to evaluate the model's performance and use it to predict new text. ERNIEkit provides convenient tools for this task.\n",
    "\n",
    "### 6.1 Model Evaluation: Quantitative Analysis\n",
    "\n",
    "In supervised fine-tuning (SFT), after converting the task to a generative one (i.e., the model generates text with \"positive\" or \"negative\" sentiment), the core of the evaluation becomes measuring whether the generated text is consistent with the expected labeled text.\n",
    "\n",
    "We can use the `erniekit eval` command to accomplish this. This command runs the model on the evaluation dataset and generates a prediction file containing the model's output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T08:24:53.730475Z",
     "iopub.status.busy": "2025-07-18T08:24:53.730152Z",
     "iopub.status.idle": "2025-07-18T08:25:06.501120Z",
     "shell.execute_reply": "2025-07-18T08:25:06.500536Z",
     "shell.execute_reply.started": "2025-07-18T08:24:53.730455Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/utils/cpp_extension/extension_utils.py:715: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\r\n",
      "  warnings.warn(warning_message)\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/utils/cpp_extension/extension_utils.py:715: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\r\n",
      "  warnings.warn(warning_message)\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,631 -----------  Configuration  ----------------------\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,631 auto_cluster_config: 0\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,631 auto_parallel_config: None\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,631 auto_tuner_json: None\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,631 devices: 0\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,631 elastic_level: -1\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,631 elastic_timeout: 30\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,631 enable_gpu_log: True\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,631 gloo_port: 6767\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,631 host: None\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,631 ips: None\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,631 job_id: default\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,631 legacy: False\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,631 log_dir: erniekit_dist_log\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,631 log_level: INFO\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,631 log_overwrite: False\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,631 master: 127.0.0.1:8080\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,631 max_restart: 3\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,631 nnodes: 1\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,631 nproc_per_node: None\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,631 rank: -1\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,631 run_mode: collective\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,632 server_num: None\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,632 servers: \r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,632 sort_ip: False\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,632 start_port: 6070\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,632 trainer_num: None\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,632 trainers: \r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,632 training_script: /home/ERNIEKit/erniekit/launcher.py\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,632 training_script_args: ['eval', 'ERNIE-develop/examples/configs/ERNIE-4.5-0.3B/sft/run_sft_8k.yaml']\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,632 with_gloo: 1\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,632 --------------------------------------------------\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,632 Job: default, mode collective, replicas 1[1:1], elastic False\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,634 Run Pod: dyjrny, replicas 1, status ready\r\n",
      "LAUNCH INFO 2025-07-18 16:24:59,645 Watching Pod: dyjrny, replicas 1, status running\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/utils/cpp_extension/extension_utils.py:715: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\r\n",
      "  warnings.warn(warning_message)\r\n",
      "\u001b[32m[2025-07-18 16:25:01,881] [    INFO]\u001b[0m - user has defined resume_from_checkpoint: None\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:01,881] [    INFO]\u001b[0m - The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:01,882] [    INFO]\u001b[0m - Tensor_parallel_degree = 1. Set sequence_parallel to False.\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,882] [   DEBUG]\u001b[0m - ============================================================\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,882] [   DEBUG]\u001b[0m -      Model Configuration Arguments      \u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,882] [   DEBUG]\u001b[0m - paddle commit id              : cdcd76a93d1dfe767dde768198e1d7c7488b93f6\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,882] [   DEBUG]\u001b[0m - paddleformers commit id       : 053a5a5e2a72cd2d3b997cbcff81b14af9fe4d47\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,882] [   DEBUG]\u001b[0m - add_tail_layers               : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,882] [   DEBUG]\u001b[0m - continue_training             : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,882] [   DEBUG]\u001b[0m - fine_tuning                   : Full\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,882] [   DEBUG]\u001b[0m - fuse_gate_detach_matmul       : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,882] [   DEBUG]\u001b[0m - fuse_linear                   : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,882] [   DEBUG]\u001b[0m - fuse_rms_norm                 : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,882] [   DEBUG]\u001b[0m - fuse_rope                     : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,882] [   DEBUG]\u001b[0m - fuse_softmax_mask             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,882] [   DEBUG]\u001b[0m - fuse_swiglu                   : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,882] [   DEBUG]\u001b[0m - lora                          : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,882] [   DEBUG]\u001b[0m - lora_alpha                    : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,882] [   DEBUG]\u001b[0m - lora_path                     : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,882] [   DEBUG]\u001b[0m - lora_plus_scale               : 1.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,882] [   DEBUG]\u001b[0m - lora_rank                     : 8\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,882] [   DEBUG]\u001b[0m - model_name_or_path            : ./data/models/30656/ERNIE-4.5-0.3B-Paddle\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,882] [   DEBUG]\u001b[0m - moe_aux_loss_lambda           : 1e-05\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,883] [   DEBUG]\u001b[0m - moe_group                     : dummy\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,883] [   DEBUG]\u001b[0m - moe_group_experts             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,883] [   DEBUG]\u001b[0m - moe_multimodal_dispatch_use_allgather: v2-alltoall-unpad\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,883] [   DEBUG]\u001b[0m - moe_orthogonal_loss_lambda    : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,883] [   DEBUG]\u001b[0m - moe_use_aux_free              : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,883] [   DEBUG]\u001b[0m - moe_use_hard_gate             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,883] [   DEBUG]\u001b[0m - moe_z_loss_lambda             : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,883] [   DEBUG]\u001b[0m - no_recompute_layers           : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,883] [   DEBUG]\u001b[0m - offload_recompute_inputs      : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,883] [   DEBUG]\u001b[0m - pp_seg_method                 : layer:Ernie4_5_DecoderLayer|EmptyLayer\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,883] [   DEBUG]\u001b[0m - recompute_granularity         : full\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,883] [   DEBUG]\u001b[0m - recompute_use_reentrant       : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,883] [   DEBUG]\u001b[0m - rslora                        : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,883] [   DEBUG]\u001b[0m - rslora_plus                   : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,883] [   DEBUG]\u001b[0m - stage                         : SFT\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,883] [   DEBUG]\u001b[0m - tensor_parallel_output        : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,883] [   DEBUG]\u001b[0m - use_attn_mask_start_row_indices: True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,883] [   DEBUG]\u001b[0m - use_flash_attention           : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,883] [   DEBUG]\u001b[0m - use_fused_head_and_loss_fn    : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,883] [   DEBUG]\u001b[0m - use_recompute_moe             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,883] [   DEBUG]\u001b[0m - use_sparse_flash_attn         : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,883] [   DEBUG]\u001b[0m - use_sparse_head_and_loss_fn   : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,884] [   DEBUG]\u001b[0m - virtual_pp_degree             : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,884] [   DEBUG]\u001b[0m - \u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,884] [   DEBUG]\u001b[0m - ============================================================\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,884] [   DEBUG]\u001b[0m -       Data Configuration Arguments      \u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,884] [   DEBUG]\u001b[0m - paddle commit id              : cdcd76a93d1dfe767dde768198e1d7c7488b93f6\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,884] [   DEBUG]\u001b[0m - paddleformers commit id       : 053a5a5e2a72cd2d3b997cbcff81b14af9fe4d47\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,884] [   DEBUG]\u001b[0m - buffer_size                   : 500\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,884] [   DEBUG]\u001b[0m - dataset_type                  : iterable\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,884] [   DEBUG]\u001b[0m - eval_dataset_path             : ./sft-eval.jsonl\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,884] [   DEBUG]\u001b[0m - eval_dataset_prob             : 1.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,884] [   DEBUG]\u001b[0m - eval_dataset_type             : erniekit\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,884] [   DEBUG]\u001b[0m - greedy_intokens               : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,884] [   DEBUG]\u001b[0m - in_tokens_batching            : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,884] [   DEBUG]\u001b[0m - mask_out_eos_token            : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,884] [   DEBUG]\u001b[0m - max_prompt_len                : 2048\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,884] [   DEBUG]\u001b[0m - max_seq_len                   : 8192\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,884] [   DEBUG]\u001b[0m - num_comparisons               : 6\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,884] [   DEBUG]\u001b[0m - num_samples_each_epoch        : 6000000\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,884] [   DEBUG]\u001b[0m - offline_dataset_path          : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,884] [   DEBUG]\u001b[0m - random_shuffle                : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,884] [   DEBUG]\u001b[0m - train_dataset_path            : ./sft-train.jsonl\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,884] [   DEBUG]\u001b[0m - train_dataset_prob            : 1.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,884] [   DEBUG]\u001b[0m - train_dataset_type            : erniekit\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,885] [   DEBUG]\u001b[0m - use_cls                       : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:01,885] [   DEBUG]\u001b[0m - \u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:01,885] [    INFO]\u001b[0m - The global seed is set to 23, local seed is set to 24 and random seed is set to 23.\u001b[0m\r\n",
      "\u001b[33m[2025-07-18 16:25:01,885] [ WARNING]\u001b[0m - Process rank: -1, device: gpu, world_size: 1, distributed training: False, 16-bits training: True\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:01,885] [    INFO]\u001b[0m - Start to load model ...\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,035] [    INFO]\u001b[0m - Loading configuration file ./data/models/30656/ERNIE-4.5-0.3B-Paddle/config.json\u001b[0m\r\n",
      "\u001b[33m[2025-07-18 16:25:02,038] [ WARNING]\u001b[0m - You are using a model of type ernie4_5 to instantiate a model of type ernie4_5_moe. This is not supported for all configurations of models and can yield errors.\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,038] [    INFO]\u001b[0m - Loading weights file ./data/models/30656/ERNIE-4.5-0.3B-Paddle/model.safetensors\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,342] [    INFO]\u001b[0m - Loaded weights file from disk, setting weights to model.\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,342] [    INFO]\u001b[0m - change initializer-range from 0.02 to 0.018041293779826325\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,342] [    INFO]\u001b[0m - using moe-group: dummy\u001b[0m\r\n",
      "W0718 16:25:02.347047 166592 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.8, Runtime API Version: 12.6\r\n",
      "\u001b[32m[2025-07-18 16:25:02,348] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,352] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,354] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,356] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,359] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,361] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,363] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,365] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,368] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,370] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,372] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,375] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,377] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,380] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,382] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,439] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,442] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,445] [    INFO]\u001b[0m - use GQA - num_heads: 16- num_key_value_heads: 2\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,449] [    INFO]\u001b[0m - output-weight:[103424, 1024] config.tie_word_embeddings=True\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,449] [    INFO]\u001b[0m - Use fusedRMSNorm\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,528] [    INFO]\u001b[0m - All model checkpoint weights were used when initializing Ernie4_5_MoeForCausalLM.\r\n",
      "\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,528] [    INFO]\u001b[0m - All the weights of Ernie4_5_MoeForCausalLM were initialized from the model checkpoint at ./data/models/30656/ERNIE-4.5-0.3B-Paddle.\r\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use Ernie4_5_MoeForCausalLM for predictions without further training.\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,530] [    INFO]\u001b[0m - Loading configuration file ./data/models/30656/ERNIE-4.5-0.3B-Paddle/generation_config.json\u001b[0m\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddleformers/generation/configuration_utils.py:250: UserWarning: using greedy search strategy. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `decode_strategy=\"greedy_search\" ` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\r\n",
      "  warnings.warn(\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddleformers/generation/configuration_utils.py:255: UserWarning: using greedy search strategy. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `decode_strategy=\"greedy_search\" ` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\r\n",
      "  warnings.warn(\r\n",
      "\u001b[32m[2025-07-18 16:25:02,540] [    INFO]\u001b[0m - Loading model successfully !\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:02,541] [   DEBUG]\u001b[0m - Model config: Ernie4_5_MoeConfig {\r\n",
      "  \"add_tail_layers\": false,\r\n",
      "  \"architectures\": [\r\n",
      "    \"Ernie4_5_ForCausalLM\"\r\n",
      "  ],\r\n",
      "  \"attention_probs_dropout_prob\": 0.0,\r\n",
      "  \"bos_token_id\": 1,\r\n",
      "  \"cachekv_quant\": false,\r\n",
      "  \"compression_ratio\": 1.0,\r\n",
      "  \"dpo_config\": null,\r\n",
      "  \"dtype\": \"bfloat16\",\r\n",
      "  \"enable_delay_scale_loss\": true,\r\n",
      "  \"enable_mtp_magic_send\": false,\r\n",
      "  \"eos_token_id\": 2,\r\n",
      "  \"fuse_gate_detach_matmul\": true,\r\n",
      "  \"fuse_linear\": false,\r\n",
      "  \"fuse_ln\": false,\r\n",
      "  \"fuse_rms_norm\": true,\r\n",
      "  \"fuse_rope\": true,\r\n",
      "  \"fuse_softmax_mask\": false,\r\n",
      "  \"fuse_swiglu\": true,\r\n",
      "  \"global_aux_loss\": false,\r\n",
      "  \"head_dim\": 128,\r\n",
      "  \"hidden_act\": \"silu\",\r\n",
      "  \"hidden_dropout_prob\": 0.0,\r\n",
      "  \"hidden_size\": 1024,\r\n",
      "  \"ignored_index\": -100,\r\n",
      "  \"initializer_range\": 0.018041293779826325,\r\n",
      "  \"intermediate_size\": 3072,\r\n",
      "  \"max_position_embeddings\": 131072,\r\n",
      "  \"max_sequence_length\": 8192,\r\n",
      "  \"micro_batch_size\": -1,\r\n",
      "  \"model_type\": \"ernie4_5_moe\",\r\n",
      "  \"moe_all_to_all_dropout\": 0.0,\r\n",
      "  \"moe_aux_loss_lambda\": 1e-05,\r\n",
      "  \"moe_capacity\": [],\r\n",
      "  \"moe_dense_experts_token_type_id\": 3,\r\n",
      "  \"moe_dropout_prob\": 0.0,\r\n",
      "  \"moe_gate\": \"topk\",\r\n",
      "  \"moe_gate_act\": \"softmax\",\r\n",
      "  \"moe_group_experts\": false,\r\n",
      "  \"moe_group_origin\": \"dummy\",\r\n",
      "  \"moe_group_orthogonal_loss\": true,\r\n",
      "  \"moe_intermediate_size\": 0,\r\n",
      "  \"moe_k\": 2,\r\n",
      "  \"moe_layer_end_index\": 17,\r\n",
      "  \"moe_layer_interval\": 2,\r\n",
      "  \"moe_layer_start_index\": 0,\r\n",
      "  \"moe_multimodal_dispatch_use_allgather\": \"v2-alltoall-unpad\",\r\n",
      "  \"moe_norm_gate_logits\": true,\r\n",
      "  \"moe_num_experts\": null,\r\n",
      "  \"moe_num_shared_experts\": 0,\r\n",
      "  \"moe_orthogonal_loss_lambda\": 0.0,\r\n",
      "  \"moe_rank\": 0,\r\n",
      "  \"moe_reverse_token_drop\": false,\r\n",
      "  \"moe_use_aux_free\": false,\r\n",
      "  \"moe_use_hard_gate\": false,\r\n",
      "  \"moe_world_size\": 1,\r\n",
      "  \"moe_z_loss_lambda\": 0.0,\r\n",
      "  \"multi_token_pred_lambda\": 0.3,\r\n",
      "  \"num_acc_steps\": 8,\r\n",
      "  \"num_attention_heads\": 16,\r\n",
      "  \"num_hidden_layers\": 18,\r\n",
      "  \"num_key_value_heads\": 2,\r\n",
      "  \"num_nextn_predict_layers\": 0,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"paddleformers_version\": \"0.1\",\r\n",
      "  \"pp_seg_method\": \"layer:Ernie4_5_DecoderLayer|EmptyLayer\",\r\n",
      "  \"recompute_granularity\": \"full\",\r\n",
      "  \"recompute_use_reentrant\": true,\r\n",
      "  \"refined_recompute\": {},\r\n",
      "  \"rms_norm_eps\": 1e-05,\r\n",
      "  \"rope_theta\": 500000,\r\n",
      "  \"sinkhorn_2gate\": true,\r\n",
      "  \"sinkhorn_temp\": 0.03,\r\n",
      "  \"skip_recompute_ops\": {},\r\n",
      "  \"tensor_parallel_degree\": -1,\r\n",
      "  \"tie_word_embeddings\": true,\r\n",
      "  \"token_balance_loss\": false,\r\n",
      "  \"token_balance_seqlen\": false,\r\n",
      "  \"use_bias\": false,\r\n",
      "  \"use_flash_attention\": true,\r\n",
      "  \"use_fused_head_and_loss_fn\": false,\r\n",
      "  \"use_recompute_lm_head\": false,\r\n",
      "  \"use_recompute_loss_fn\": false,\r\n",
      "  \"use_recompute_moe\": false,\r\n",
      "  \"use_recompute_mtp\": false,\r\n",
      "  \"use_rmsnorm\": true,\r\n",
      "  \"use_sparse_flash_attn\": true,\r\n",
      "  \"use_sparse_head_and_loss_fn\": true,\r\n",
      "  \"use_var_len_flash_attn\": false,\r\n",
      "  \"vocab_size\": 103424,\r\n",
      "  \"weight_share_add_bias\": true\r\n",
      "}\r\n",
      "\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:02,541] [    INFO]\u001b[0m - [timelog] basemodel loading time: 0.51s (2025-07-18 16:25:02) \u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:03,590] [    INFO]\u001b[0m - Start to create dataset ...\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:03,592] [    INFO]\u001b[0m - Creating dataset successfully ...\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:03,592] [    INFO]\u001b[0m - The global seed is set to 23, local seed is set to 24 and random seed is set to 23.\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:03,630] [    INFO]\u001b[0m - max_steps is given, it will override any value given in num_train_epochs\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:03,630] [    INFO]\u001b[0m - Using half precision\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,644] [   DEBUG]\u001b[0m - ============================================================\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,645] [   DEBUG]\u001b[0m -     Training Configuration Arguments    \u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,645] [   DEBUG]\u001b[0m - paddle commit id              : cdcd76a93d1dfe767dde768198e1d7c7488b93f6\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,645] [   DEBUG]\u001b[0m - paddleformers commit id       : 053a5a5e2a72cd2d3b997cbcff81b14af9fe4d47\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,645] [   DEBUG]\u001b[0m - _no_sync_in_gradient_accumulation: True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,645] [   DEBUG]\u001b[0m - actscale_moving_rate          : 0.01\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,645] [   DEBUG]\u001b[0m - adam_beta1                    : 0.9\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,645] [   DEBUG]\u001b[0m - adam_beta2                    : 0.95\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,645] [   DEBUG]\u001b[0m - adam_epsilon                  : 1e-08\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,645] [   DEBUG]\u001b[0m - amp_custom_black_list         : ['reduce_sum', 'softmax_with_cross_entropy', 'c_softmax_with_cross_entropy', 'elementwise_div', 'sin', 'cos']\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,645] [   DEBUG]\u001b[0m - amp_custom_white_list         : ['lookup_table', 'lookup_table_v2', 'flash_attn', 'matmul', 'matmul_v2', 'fused_gemm_epilogue']\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,645] [   DEBUG]\u001b[0m - amp_master_grad               : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,645] [   DEBUG]\u001b[0m - apply_hadamard                : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,645] [   DEBUG]\u001b[0m - apply_online_actscale_step    : 200\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,645] [   DEBUG]\u001b[0m - attention_probs_dropout_prob  : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,645] [   DEBUG]\u001b[0m - auto_parallel_resume_form_hybrid_parallel: False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,645] [   DEBUG]\u001b[0m - batch_size                    : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,646] [   DEBUG]\u001b[0m - beta                          : 0.1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,646] [   DEBUG]\u001b[0m - bf16                          : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,646] [   DEBUG]\u001b[0m - bf16_full_eval                : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,646] [   DEBUG]\u001b[0m - ckpt_quant_stage              : O0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,646] [   DEBUG]\u001b[0m - compute_type                  : bf16\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,646] [   DEBUG]\u001b[0m - context_parallel_degree       : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,646] [   DEBUG]\u001b[0m - count_trained_tokens          : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,646] [   DEBUG]\u001b[0m - current_device                : gpu:0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,646] [   DEBUG]\u001b[0m - data_parallel_config          : \u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,646] [   DEBUG]\u001b[0m - data_parallel_degree          : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,646] [   DEBUG]\u001b[0m - data_parallel_rank            : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,646] [   DEBUG]\u001b[0m - dataloader_drop_last          : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,646] [   DEBUG]\u001b[0m - dataloader_num_workers        : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,646] [   DEBUG]\u001b[0m - dataloader_shuffle            : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,646] [   DEBUG]\u001b[0m - dataset_rank                  : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,646] [   DEBUG]\u001b[0m - dataset_world_size            : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,646] [   DEBUG]\u001b[0m - ddp_find_unused_parameters    : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,646] [   DEBUG]\u001b[0m - decay_steps                   : 100\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,646] [   DEBUG]\u001b[0m - device                        : gpu\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,646] [   DEBUG]\u001b[0m - disable_ckpt_quant            : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,646] [   DEBUG]\u001b[0m - disable_tqdm                  : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,646] [   DEBUG]\u001b[0m - distributed_dataloader        : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,647] [   DEBUG]\u001b[0m - do_eval                       : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,647] [   DEBUG]\u001b[0m - do_export                     : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,647] [   DEBUG]\u001b[0m - do_predict                    : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,647] [   DEBUG]\u001b[0m - do_train                      : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,647] [   DEBUG]\u001b[0m - dpo_benchmark                 : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,647] [   DEBUG]\u001b[0m - dpop_lambda                   : 50\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,647] [   DEBUG]\u001b[0m - dropout_warmup_steps          : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,647] [   DEBUG]\u001b[0m - enable_auto_parallel          : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,647] [   DEBUG]\u001b[0m - enable_zero_cost_checkpoint   : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,647] [   DEBUG]\u001b[0m - eval_accumulation_steps       : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,647] [   DEBUG]\u001b[0m - eval_batch_size               : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,647] [   DEBUG]\u001b[0m - eval_steps                    : 10000\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,647] [   DEBUG]\u001b[0m - evaluation_strategy           : IntervalStrategy.STEPS\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,647] [   DEBUG]\u001b[0m - expert_max_capacity           : 4294967296\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,647] [   DEBUG]\u001b[0m - expert_min_capacity           : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,647] [   DEBUG]\u001b[0m - expert_parallel_degree        : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,647] [   DEBUG]\u001b[0m - expert_tensor_parallel_degree : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,647] [   DEBUG]\u001b[0m - flash_device_save_steps       : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,647] [   DEBUG]\u001b[0m - flatten_param_grads           : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,647] [   DEBUG]\u001b[0m - force_reshard_pp              : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,647] [   DEBUG]\u001b[0m - fp16                          : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,647] [   DEBUG]\u001b[0m - fp16_full_eval                : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,647] [   DEBUG]\u001b[0m - fp16_opt_level                : O2\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,648] [   DEBUG]\u001b[0m - fp8_format_type               : hybrid\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,648] [   DEBUG]\u001b[0m - fuse_sequence_parallel_allreduce: False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,648] [   DEBUG]\u001b[0m - gradient_accumulation_steps   : 8\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,648] [   DEBUG]\u001b[0m - greater_is_better             : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,648] [   DEBUG]\u001b[0m - hadamard_block_size           : 32\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,648] [   DEBUG]\u001b[0m - hidden_dropout_prob           : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,648] [   DEBUG]\u001b[0m - hybrid_parallel_topo_order    : pp_first\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,648] [   DEBUG]\u001b[0m - ignore_data_skip              : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,648] [   DEBUG]\u001b[0m - ignore_load_lr_and_optim      : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,648] [   DEBUG]\u001b[0m - ignore_save_lr_and_optim      : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,648] [   DEBUG]\u001b[0m - label_names                   : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,648] [   DEBUG]\u001b[0m - label_smoothing               : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,648] [   DEBUG]\u001b[0m - layerwise_lr_decay_bound      : 1.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,648] [   DEBUG]\u001b[0m - lazy_data_processing          : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,648] [   DEBUG]\u001b[0m - learning_rate                 : 1e-05\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,648] [   DEBUG]\u001b[0m - load_best_model_at_end        : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,648] [   DEBUG]\u001b[0m - load_sharded_model            : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,648] [   DEBUG]\u001b[0m - local_process_index           : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,648] [   DEBUG]\u001b[0m - local_rank                    : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,648] [   DEBUG]\u001b[0m - log_level                     : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,648] [   DEBUG]\u001b[0m - log_level_replica             : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,648] [   DEBUG]\u001b[0m - log_on_each_node              : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,649] [   DEBUG]\u001b[0m - logging_dir                   : ./vdl_log\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,649] [   DEBUG]\u001b[0m - logging_first_step            : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,649] [   DEBUG]\u001b[0m - logging_steps                 : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,649] [   DEBUG]\u001b[0m - logging_strategy              : IntervalStrategy.STEPS\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,649] [   DEBUG]\u001b[0m - logical_process_index         : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,649] [   DEBUG]\u001b[0m - loss_type                     : sigmoid\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,649] [   DEBUG]\u001b[0m - lr_end                        : 1e-07\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,649] [   DEBUG]\u001b[0m - lr_scheduler_type             : SchedulerType.COSINE\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,649] [   DEBUG]\u001b[0m - max_estimate_samples          : 100000.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,649] [   DEBUG]\u001b[0m - max_evaluate_steps            : 10000\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,649] [   DEBUG]\u001b[0m - max_grad_norm                 : 1.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,649] [   DEBUG]\u001b[0m - max_steps                     : 100\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,649] [   DEBUG]\u001b[0m - metric_for_best_model         : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,649] [   DEBUG]\u001b[0m - metrics_output_path           : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,649] [   DEBUG]\u001b[0m - min_lr                        : 1e-06\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,649] [   DEBUG]\u001b[0m - minimum_eval_times            : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,649] [   DEBUG]\u001b[0m - multi_token_pred_lambda       : 0.3\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,649] [   DEBUG]\u001b[0m - no_cuda                       : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,649] [   DEBUG]\u001b[0m - normalize_logps               : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,649] [   DEBUG]\u001b[0m - num_cycles                    : 0.5\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,649] [   DEBUG]\u001b[0m - num_nextn_predict_layers      : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,649] [   DEBUG]\u001b[0m - num_of_gpus                   : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,650] [   DEBUG]\u001b[0m - num_train_epochs              : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,650] [   DEBUG]\u001b[0m - offload_optim                 : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,650] [   DEBUG]\u001b[0m - offset_alpha                  : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,650] [   DEBUG]\u001b[0m - optim                         : OptimizerNames.ADAMW\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,650] [   DEBUG]\u001b[0m - optim_shard_num               : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,650] [   DEBUG]\u001b[0m - optimizer_name_suffix         : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,650] [   DEBUG]\u001b[0m - ordered_save_group_size       : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,650] [   DEBUG]\u001b[0m - output_dir                    : ./output\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,650] [   DEBUG]\u001b[0m - output_signal_dir             : ./output\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,650] [   DEBUG]\u001b[0m - overwrite_output_dir          : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,650] [   DEBUG]\u001b[0m - pad_token_id                  : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,650] [   DEBUG]\u001b[0m - past_index                    : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,650] [   DEBUG]\u001b[0m - pdc_download_ckpt             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,650] [   DEBUG]\u001b[0m - pdc_download_timeout          : 300\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,650] [   DEBUG]\u001b[0m - per_device_eval_batch_size    : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,650] [   DEBUG]\u001b[0m - per_device_train_batch_size   : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,650] [   DEBUG]\u001b[0m - pipeline_parallel_config      : enable_delay_scale_loss enable_release_grads disable_partial_send_recv\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,650] [   DEBUG]\u001b[0m - pipeline_parallel_degree      : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,650] [   DEBUG]\u001b[0m - pipeline_parallel_rank        : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,650] [   DEBUG]\u001b[0m - power                         : 1.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,650] [   DEBUG]\u001b[0m - prediction_loss_only          : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,650] [   DEBUG]\u001b[0m - pref_loss_ratio               : 1.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,650] [   DEBUG]\u001b[0m - process_index                 : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,651] [   DEBUG]\u001b[0m - quant_input_grad              : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,651] [   DEBUG]\u001b[0m - quant_weight_grad             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,651] [   DEBUG]\u001b[0m - recompute                     : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,651] [   DEBUG]\u001b[0m - ref_model_update_steps        : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,651] [   DEBUG]\u001b[0m - reference_free                : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,651] [   DEBUG]\u001b[0m - refined_recompute             : {}\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,651] [   DEBUG]\u001b[0m - release_grads                 : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,651] [   DEBUG]\u001b[0m - remove_unused_columns         : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,651] [   DEBUG]\u001b[0m - report_to                     : ['visualdl']\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,651] [   DEBUG]\u001b[0m - resume_from_checkpoint        : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,651] [   DEBUG]\u001b[0m - run_name                      : ./output\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,651] [   DEBUG]\u001b[0m - save_on_each_node             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,651] [   DEBUG]\u001b[0m - save_rng_states               : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,651] [   DEBUG]\u001b[0m - save_sharded_model            : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,651] [   DEBUG]\u001b[0m - save_sharding_stage1_model_include_freeze_params: False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,651] [   DEBUG]\u001b[0m - save_steps                    : 10000000\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,651] [   DEBUG]\u001b[0m - save_strategy                 : IntervalStrategy.STEPS\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,651] [   DEBUG]\u001b[0m - save_tokenizer                : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,651] [   DEBUG]\u001b[0m - save_total_limit              : 5\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,651] [   DEBUG]\u001b[0m - scale_loss                    : 32768\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,651] [   DEBUG]\u001b[0m - seed                          : 23\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,651] [   DEBUG]\u001b[0m - sep_parallel_degree           : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,651] [   DEBUG]\u001b[0m - sequence_parallel             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,652] [   DEBUG]\u001b[0m - sequence_parallel_config      : \u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,652] [   DEBUG]\u001b[0m - server_tp_degree              : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,652] [   DEBUG]\u001b[0m - sft_benchmark                 : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,652] [   DEBUG]\u001b[0m - sft_loss_ratio                : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,652] [   DEBUG]\u001b[0m - sharding                      : []\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,652] [   DEBUG]\u001b[0m - sharding_comm_buffer_size_MB  : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,652] [   DEBUG]\u001b[0m - sharding_degree               : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,652] [   DEBUG]\u001b[0m - sharding_parallel_config      : \u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,652] [   DEBUG]\u001b[0m - sharding_parallel_degree      : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,652] [   DEBUG]\u001b[0m - sharding_parallel_mesh_dimension: dp\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,652] [   DEBUG]\u001b[0m - sharding_parallel_rank        : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,652] [   DEBUG]\u001b[0m - should_load_dataset           : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,652] [   DEBUG]\u001b[0m - should_load_sharding_stage1_model: False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,652] [   DEBUG]\u001b[0m - should_log                    : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,652] [   DEBUG]\u001b[0m - should_save                   : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,652] [   DEBUG]\u001b[0m - should_save_model_state       : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,652] [   DEBUG]\u001b[0m - should_save_model_with_tensor_fusion: False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,652] [   DEBUG]\u001b[0m - should_save_sharding_stage1_model: False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,652] [   DEBUG]\u001b[0m - simpo_gamma                   : 0.5\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,652] [   DEBUG]\u001b[0m - skip_data_intervals           : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,652] [   DEBUG]\u001b[0m - skip_memory_metrics           : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,652] [   DEBUG]\u001b[0m - skip_profile_timer            : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,652] [   DEBUG]\u001b[0m - split_inputs_sequence_dim     : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,653] [   DEBUG]\u001b[0m - split_norm_comm               : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,653] [   DEBUG]\u001b[0m - tensor_parallel_config        : \u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,653] [   DEBUG]\u001b[0m - tensor_parallel_degree        : -1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,653] [   DEBUG]\u001b[0m - tensor_parallel_rank          : 0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,653] [   DEBUG]\u001b[0m - tensorwise_offload_optimizer  : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,653] [   DEBUG]\u001b[0m - to_static                     : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,653] [   DEBUG]\u001b[0m - train_batch_size              : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,653] [   DEBUG]\u001b[0m - unified_checkpoint            : True\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,653] [   DEBUG]\u001b[0m - unified_checkpoint_config     : ['async_save']\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,653] [   DEBUG]\u001b[0m - use_async_save                : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,653] [   DEBUG]\u001b[0m - use_expert_parallel           : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,653] [   DEBUG]\u001b[0m - use_hybrid_parallel           : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,653] [   DEBUG]\u001b[0m - use_lowprecision_moment       : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,653] [   DEBUG]\u001b[0m - use_recompute_mtp             : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,653] [   DEBUG]\u001b[0m - use_sp_callback               : False\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,653] [   DEBUG]\u001b[0m - wandb_api_key                 : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,653] [   DEBUG]\u001b[0m - wandb_http_proxy              : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,653] [   DEBUG]\u001b[0m - warmup_ratio                  : 0.0\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,653] [   DEBUG]\u001b[0m - warmup_steps                  : 20\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,653] [   DEBUG]\u001b[0m - weight_decay                  : 0.1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,653] [   DEBUG]\u001b[0m - weight_name_suffix            : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,653] [   DEBUG]\u001b[0m - weight_quantize_algo          : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,654] [   DEBUG]\u001b[0m - world_size                    : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,654] [   DEBUG]\u001b[0m - zcc_ema_interval              : 1\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,654] [   DEBUG]\u001b[0m - zcc_pipeline_hooks_capacity_usage: 0.6\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,654] [   DEBUG]\u001b[0m - zcc_save_ema_coef             : None\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,654] [   DEBUG]\u001b[0m - zcc_workers_num               : 3\u001b[0m\r\n",
      "\u001b[35m[2025-07-18 16:25:03,654] [   DEBUG]\u001b[0m - \u001b[0m\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/distributed/parallel.py:450: UserWarning: The program will return to single-card operation. Please check 1, whether you use spawn or fleetrun to start the program. 2, Whether it is a multi-card program. 3, Is the current environment multi-card.\r\n",
      "  warnings.warn(\r\n",
      "\u001b[32m[2025-07-18 16:25:03,662] [    INFO]\u001b[0m - ***** Running Evaluation *****\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:03,662] [    INFO]\u001b[0m -   Num examples: Unknown\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:03,662] [    INFO]\u001b[0m -   Total prediction steps = 10000\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:03,662] [    INFO]\u001b[0m -   Pre device batch size = 1\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:03,663] [    INFO]\u001b[0m -   Total Batch size = 1\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:03,664] [    INFO]\u001b[0m - prepare SequenceDataset ...\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:03,664] [    INFO]\u001b[0m - prepare SequenceDataset done: total number of examples is 2\u001b[0m\r\n",
      "W0718 16:25:04.358070 166592 multiply_fwd_func.cc:76] got different data type, run type promotion automatically, this may cause data type been changed.\r\n",
      "\u001b[32m[2025-07-18 16:25:04,663] [    INFO]\u001b[0m - eval_loss: 9.515118598937988, eval_runtime: 1.0008, eval_samples_per_second: 9992.3098, eval_steps_per_second: 9992.3098, eval_ppl: 13563.241735167847\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:04,663] [    INFO]\u001b[0m - ***** eval metrics *****\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:04,663] [    INFO]\u001b[0m -   eval_loss               =     9.5151\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:04,664] [    INFO]\u001b[0m -   eval_ppl                = 13563.2417\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:04,664] [    INFO]\u001b[0m -   eval_runtime            = 0:00:01.00\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:04,664] [    INFO]\u001b[0m -   eval_samples_per_second =  9992.3098\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:04,664] [    INFO]\u001b[0m -   eval_steps_per_second   =  9992.3098\u001b[0m\r\n",
      "\u001b[32m[2025-07-18 16:25:04,664] [    INFO]\u001b[0m - Saving stop info into ./vdl_log/stop_step.json\u001b[0m\r\n",
      "LAUNCH INFO 2025-07-18 16:25:05,654 Pod completed\r\n",
      "LAUNCH INFO 2025-07-18 16:25:05,654 Exit code 0\r\n"
     ]
    }
   ],
   "source": [
    "!erniekit eval ERNIE-develop/examples/configs/ERNIE-4.5-0.3B/sft/run_sft_8k.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important Note: Log Output from the `eval` Command**\n",
    "\n",
    "When you run the `erniekit eval` command, you'll see a large amount of log information printed to the terminal, similar to what you see during training. **This is completely normal behavior**. `erniekit eval` essentially initiates a distributed evaluation task, which requires loading the distributed environment, parsing the complete model and data configuration, and loading model weights. These processes are all logged in detail.\n",
    "\n",
    "In the log output, pay special attention to the following:\n",
    "\n",
    "1. **Command Execution Status**: Whether `Exit code 0` is displayed at the end indicates that the evaluation task has successfully completed.\n",
    "\n",
    "2. **Key Evaluation Metrics**:\n",
    "\n",
    "- `eval_loss`: The evaluation loss value, which reflects the accuracy of the model's predictions. Smaller values are better.\n",
    "\n",
    "- `eval_ppl`: Perplexity, which measures the performance of the generation task. Smaller values indicate better model performance.\n",
    "\n",
    "- `eval_runtime`: The evaluation duration.\n",
    "- `eval_samples_per_second`: The number of samples processed per second, which reflects the evaluation speed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Performance Optimization Suggestions\n",
    "\n",
    "If you require better performance in your application, please refer to the following optimization solution table. We provide detailed optimization suggestions and specific operational methods from four perspectives: data, training, model, and deployment:\n",
    "\n",
    "#### 6.2.1 Optimization Solution Overview\n",
    "\n",
    "| Optimization Dimensions | Specific Measures | Operational Recommendations | Expected Results | Applicable Scenarios |\n",
    "|:---:|:---|:---|:---|:---|\n",
    "| üìä **Data Optimization** | ‚Ä¢ Expand Data Scale<br>‚Ä¢ Improve Data Quality<br>‚Ä¢ Domain Data Augmentation | ‚Ä¢ Use Data Augmentation Techniques<br>‚Ä¢ Introduce Manual Review Mechanism<br>‚Ä¢ Collect Target Domain Data | ‚Ä¢ Improve Model Generalization Ability<br>‚Ä¢ Reduce Overfitting Risk<br>‚Ä¢ Improve Domain Adaptability | ‚Ä¢ Insufficient Data Amount<br>‚Ä¢ Inconsistent Annotation Quality<br>‚Ä¢ Domain Migration Scenarios |\n",
    "| ‚öôÔ∏è **Training Optimization** | ‚Ä¢ Learning Rate Tuning<br>‚Ä¢ Batch Size Optimization<br>‚Ä¢ Training Strategy Improvement | ‚Ä¢ Use Learning Rate Warmup<br>‚Ä¢ Try gradient accumulation<br>‚Ä¢ Use early stopping | ‚Ä¢ Accelerate convergence<br>‚Ä¢ Improve training stability<br>‚Ä¢ Save computing resources | ‚Ä¢ Unstable training<br>‚Ä¢ Limited video memory<br>‚Ä¢ Severe overfitting |\n",
    "| üß† **Model optimization** | ‚Ä¢ Model selection<br>‚Ä¢ Quantization acceleration<br>‚Ä¢ Knowledge distillation | ‚Ä¢ Try larger/smaller models<br>‚Ä¢ Use INT8/BF16 quantization<br>‚Ä¢ Apply teacher-student distillation | ‚Ä¢ Balance performance and efficiency<br>‚Ä¢ Accelerate inference speed<br>‚Ä¢ Reduce model size | ‚Ä¢ Performance bottleneck<br>‚Ä¢ High inference latency<br>‚Ä¢ Limited resources |\n",
    "| üöÄ **Deployment optimization** | ‚Ä¢ Accelerate text processing<br>‚Ä¢ Improve inference performance<br>‚Ä¢ Batch optimization | ‚Ä¢ Enable FastTokenizer<br>‚Ä¢ Enable inference optimization options<br>‚Ä¢ Implement request batching | ‚Ä¢ Reduce processing latency<br>‚Ä¢ Improve inference speed<br>‚Ä¢ Increase system throughput | ‚Ä¢ Online services<br>‚Ä¢ High concurrency scenarios<br>‚Ä¢ Latency-sensitive |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary and Outlook\n",
    "\n",
    "Congratulations on completing this practical tutorial on Chinese Sentiment Analysis with ERNIE-4.5-0.3B!\n",
    "\n",
    "In this tutorial, we started from scratch and learned how to use ERNIEkit to fine-tune the ERNIE-4.5-0.3B model through supervised fine-tuning and apply it to sentiment analysis tasks. We walked through the complete process from environment preparation, data processing, model fine-tuning, to evaluation and prediction, and delved into the advantages of the ERNIE-4.5-0.3B model and the principles of fine-tuning.\n",
    "\n",
    "Through this tutorial, you should have mastered the following core skills:\n",
    "\n",
    "- **Model Training with ERNIEkit**: You learned how to manage training parameters using configuration files and launch training, evaluation, and prediction using simple commands.\n",
    "- **Processing Custom Datasets**: You learned how to convert your own data into the format required by ERNIEkit and perform effective training.\n",
    "- **Understanding and Applying SFT**: You gained a deep understanding of the principles of supervised fine-tuning and can apply it to practical NLP tasks. - **Evaluating and Optimizing Models**: You learned how to evaluate model performance and mastered various optimization strategies to improve model performance.\n",
    "\n",
    "### 7.1 Future Outlook\n",
    "\n",
    "Sentiment analysis is an evolving field, and with technological advancements, we can explore more interesting directions:\n",
    "\n",
    "- **Multimodal Sentiment Analysis**: Combining text, images, and audio to more comprehensively understand user emotions.\n",
    "\n",
    "- **Fine-Grained Sentiment Analysis**: Not only identifying the polarity of sentiment, but also analyzing its intensity, cause, and target.\n",
    "- **Cross-Domain Sentiment Analysis**: Applying a model trained in one domain to a new domain.\n",
    "- **Small Sample Sentiment Analysis**: How to effectively train sentiment analysis models with limited data.\n",
    "\n",
    "ERNIE-4.5-0.3B, as a powerful foundational model, provides a solid foundation for these cutting-edge research. We encourage you to build on this tutorial and continue exploring and practicing, applying what you've learned to a wider range of fields.\n",
    "\n",
    "Thank you for your time! If you have any questions or suggestions, please feel free to contact us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedback/Contact me: WeChat: G_Fuji"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
